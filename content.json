{"meta":{"title":"lightsmile's Blog","subtitle":"lightsmile","description":"this is a description","author":"lightsmile","url":"http://www.iamlightsmile.com"},"pages":[{"title":"","date":"2018-10-01T10:39:03.456Z","updated":"2017-12-10T11:20:34.000Z","comments":true,"path":"404.html","permalink":"http://www.iamlightsmile.com/404.html","excerpt":"","text":"闲人免进 嘻嘻！就是不给你看！！！"},{"title":"categories","date":"2017-12-21T08:38:30.000Z","updated":"2017-12-21T08:38:48.000Z","comments":false,"path":"categories/index.html","permalink":"http://www.iamlightsmile.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-12-21T08:37:01.000Z","updated":"2017-12-21T08:38:12.000Z","comments":false,"path":"tags/index.html","permalink":"http://www.iamlightsmile.com/tags/index.html","excerpt":"","text":""},{"title":"friends","date":"2017-12-09T05:16:32.000Z","updated":"2019-01-07T03:33:32.703Z","comments":true,"path":"friends/index.html","permalink":"http://www.iamlightsmile.com/friends/index.html","excerpt":"","text":"。。。暂时还没有。。。"},{"title":"about","date":"2017-12-09T05:16:32.000Z","updated":"2019-11-14T12:57:03.000Z","comments":true,"path":"about/index.html","permalink":"http://www.iamlightsmile.com/about/index.html","excerpt":"","text":"基础信息 姓名：李德方 性别：男 出生年月：1996.3 就读大学：武汉理工大学 所在院校：计算机科学与技术 专业技能与程度 专业技能 所学程度 备注 自然语言处理 中等 工作后主要工作方向 知识图谱 基础 工作后主要工作方向相关 深度学习 基础 工作后主要工作方向相关 机器学习 基础 工作后主要工作方向相关 数据结构与算法 基础 大学课程水平 Android开发 基础 大学自学，几门课程大作业都是开发的Android应用，有后台可联网的非demo 前端 略知一二 曾学过一段时间，写了一个用于获取Github图片地址的浏览器插件，以及结合aardio写了个mini电商系统 桌面开发 基础 大学自学，主要使用aardio语言，个人很喜欢 小程序 略知一二 在前端的基础上，编写了了todoList作为个人毕业设计 Linux 略知一二 工作后主要在Linux环境下开发 Java 基础 大学课程，曾开发demo管理系统 Python 中等 工作后主要工作语言 个人评价 自学能力较强 责任心比较重 沟通能力良好 自我驱动比较强 其他相关 个人博客站点 Github 简书 知乎 联系方式 手机：15172335885 QQ：1459679436 邮箱：iamlightsmile@qq.com 、iamlightsmile@gmail.com"},{"title":"projects","date":"2017-12-09T05:16:32.000Z","updated":"2019-04-04T01:42:21.040Z","comments":true,"path":"projects/index.html","permalink":"http://www.iamlightsmile.com/projects/index.html","excerpt":"","text":"项目主要包括： 项目名称 简介 相关技术 开发语言 lightNLP 自然语言处理深度学习框架 NLP，深度学习 Python lightKG 知识图谱深度学习框架 KG，深度学习 Python todolist 微信小程序：微计划日程管理 微信小程序 JavaScript GithubImagePace 获取Github图片路径用作Markdown地址的浏览器插件 浏览器插件 JavaScript SchoolInfoPublishSystem Android App：校园信息发布系统 Android Java MyShoppingWeb 网上购物数据库demo系统 aardio aardio 1.lightNLP基于Pytorch和torchtext的自然语言处理深度学习框架，包含序列标注、文本分类、句子关系、文本生成、结构分析、五大功能模块，已实现了命名实体识别、中文分词、词性标注、语义角色标注、情感分析、关系抽取、语言模型、文本相似度、文本蕴含、依存句法分析等功能。框架功能丰富，开箱可用，极易上手！基本都是学习他人实现然后自己修改融合到框架中，没有细致调参，且有不少Bug～ 2.lightKG基于Pytorch和torchtext的知识图谱深度学习框架，包含知识表示学习、实体识别与链接、实体关系抽取、事件检测与抽取、知识存储与查询、知识推理六大功能模块，已实现了命名实体识别、关系抽取、事件抽取、表示学习等功能。框架功能丰富，开箱可用，极易上手！基本都是学习他人实现然后自己修改融合到框架中，没有细致调参，且有不少Bug～ 3.todolist微信小程序:微计划日程管理 4.GithubImagePace我的获取GitHub图片绝对路径用于Markdown文档图片的浏览器插件 5.QCloudSDKJS腾讯云SDK for JS 6.SchoolInfoPublishSystemAndroid App:校园信息发布系统 7.MyShoppingWebaardio 数据库作业：网上购物数据库综合系统"}],"posts":[{"title":"《论文解读-Never-Ending Learning》","slug":"《论文解读-Never-Ending-Learning》","date":"2020-01-31T10:21:49.000Z","updated":"2020-01-31T10:26:15.337Z","comments":true,"path":"articles/《论文解读-Never-Ending-Learning》/","link":"","permalink":"http://www.iamlightsmile.com/articles/《论文解读-Never-Ending-Learning》/","excerpt":"当前自己仅是简单翻译一下。 0. 论文出处1. 概要虽然人们多年来从不同的经验中学习了许多不同类型的知识，但是大多数当前的机器学习系统仅仅从一个数据集中获得一个函数或数据模型。 我们为机器学习提出了一个永不停歇的学习范式，以更好地反映由人类执行的更有雄心和更广泛的学习类型。 作为一个案例研究，我们描述了永不停息的语言学习者(NELL)，它实现了永不停息的学习者所期望的一些特性，我们讨论了所学到的教训。 NELL从2010年1月开始每天24小时学习网络阅读，到目前为止，它已经掌握了8000多万个信心加权信念(例如，随茶、饼干)的知识库。 NELL还学会了数百万的特性和参数，使它能够从网上阅读这些信念。 此外，它还学会了对这些信念进行推理以推断出新的信念，并能够通过综合新的关系谓词来扩展其本体。 可以通过 http://rtw.ml.cmu.edu 在线跟踪NELL，也可以通过@CMUNELL在Twitter上跟踪它。","text":"当前自己仅是简单翻译一下。 0. 论文出处1. 概要虽然人们多年来从不同的经验中学习了许多不同类型的知识，但是大多数当前的机器学习系统仅仅从一个数据集中获得一个函数或数据模型。 我们为机器学习提出了一个永不停歇的学习范式，以更好地反映由人类执行的更有雄心和更广泛的学习类型。 作为一个案例研究，我们描述了永不停息的语言学习者(NELL)，它实现了永不停息的学习者所期望的一些特性，我们讨论了所学到的教训。 NELL从2010年1月开始每天24小时学习网络阅读，到目前为止，它已经掌握了8000多万个信心加权信念(例如，随茶、饼干)的知识库。 NELL还学会了数百万的特性和参数，使它能够从网上阅读这些信念。 此外，它还学会了对这些信念进行推理以推断出新的信念，并能够通过综合新的关系谓词来扩展其本体。 可以通过 http://rtw.ml.cmu.edu 在线跟踪NELL，也可以通过@CMUNELL在Twitter上跟踪它。 2. 引言机器学习是人工智能的一个非常成功的分支，机器学习软件现在被广泛应用于从垃圾邮件过滤、语音识别、信用卡欺诈检测到人脸识别的任务中。 尽管取得了这样的成功，但与人类学习相比，今天计算机学习的方式仍然出奇地狭隘。 本文探索了一种新的机器学习范式，它更紧密地模拟了人类学习的多样性、能力和累积性。我们称这种替代范式为无止境的学习（never-ending learning）。 为了说明这一点，请注意，在上面的每个示例中，计算机只学习单个函数来独立执行单个任务，通常是从该函数的输入和输出的人工标记的训练示例中学习。例如，在垃圾邮件过滤中，训练示例包括特定的电子邮件和每个邮件的垃圾邮件或非垃圾邮件标签。 这种学习方式通常被称为监督函数逼近，因为抽象的学习问题是逼近某个未知函数f : X → Y(例如，垃圾邮件过滤器)，给定该函数的输入/输出对{}。 其他的机器学习范例也存在(例如，无监督聚类、主题建模)，但是这些范例通常也只从单个数据集获取单个函数或数据模型。 与这些在短时间内从组织良好的数据集中学习单个函数的范例不同，人类学习许多不同的函数(例如，多年来积累了丰富的经验，使用广泛的背景知识从早期的经验中学习来指导后续的学习。 这篇论文的主题是，我们永远不会真正理解机器或人类的学习，除非我们可以建立一个计算机程序，向人类那样： 学习许多不同类型的知识或功能 从多年的多样化，大多是自我监督的经验 在一种分阶段的课程模式中，以前学到的知识使我们能够学习更多类型的知识， 自我反省和形成新的表现形式和新的学习任务的能力使学习者避免遇到学习瓶颈并停滞不前。 我们把这种学习模式称为“永无止境的学习”。这篇论文的贡献在于: 更精确地定义了永无止境的学习范式 以一个名为“永不停息的语言学习者”(NELL)的计算机程序为例，该程序实现了其中的一些功能，并且在四年多的时间里每天24小时地学习阅读web 识别来自NELL的长处和短处许多关键的设计特点对任何永无止境的学习系统都很重要 3. 相关工作略 4. Never-Ending Learning非正式地说，我们将一个永不停息的学习主体定义为一个系统，它像人类一样，从多年多样的、主要是自我监督的经验中学习多种类型的知识，使用先前学习的知识来改进随后的学习，并进行充分的自我反思，以避免学习时的表现停滞不前。代理所面临的永无止境的学习问题包括一组学习任务，以及将它们的解决方案耦合在一起的约束。 never-ending learning problem形式化定义 其中： 表示一个never-ending learning problem 表示学习任务的集合，即，其中表示给定的表现性评价任务，表示性能度量，表示特定类型的经验 表示上述学习任务的解决方案之间的耦合约束所组成的集合，即，其中是两个或多个学习任务上的实值函数，表示约束的满足程度，是学习任务上的一个指数向量，指定的参数。 的具体含义是定义要学习的函数即的域和范围上的值所组成的对，即 的具体含义是，即定义了对于第i个学习任务的最优学习函数：，其中表示从到所有可能函数的集合。 具体示例：略 Never-Ending Learning的定义 学习许多不同类型的知识；也就是说，包含了许多的学习任务 从多年的多样化，大多是自我监督的经验；也就是说，学习所基于的经验实际上是多种多样的，而且大部分是由系统本身提供的 在一种分阶段的课程模式中，以前学到的知识使我们能够学习更多类型的知识；也就是说，不同的学习任务不需要同时解决-解决一个有助于解决下一个 自我反省和形成新的表现形式和新的学习任务的能力使学习者避免遇到学习瓶颈并停滞不前；也就是说，学习者自身可能会添加新的学习任务和新的耦合约束来帮助解决给定的学习问题。 NELL的输入-输出规范 初始输入： 一个定义了类别(例如，体育，运动员)和二元关系(例如，AthletePlaysSport(x,y))的初始本体 每个类别和关系大约有12个标记的训练示例(例如，运动的示例可能包括名词短语棒球和足球) 网络(最初的5亿个网页来自ClueWeb 2009集合(Callan和Hoy 2009)，每天访问100,000个谷歌API搜索查询) 偶尔与人交互(例如，通过NELL的公共网站http://rtw.ml.cmu.edu) NELL每天24小时不间断地做： 阅读(从网上提取)更多的信念，并删除旧的错误信念，以填充一个不断增长的知识库，其中包含每个信念的置信度和出处 学会比前一天读得更好 NELL从2010年1月开始，每天从网络中提取更多的信念，然后重新训练自己以提高自己的能力。到目前为止，结果是一个拥有超过8000万个相互关联的信念的知识库(参见下图)，连同数以百万计的已学过的短语、形态特征和网页结构，NELL现在用来从网络中提取信念。NELL现在也正在学习对它所提取的知识进行推理，以推断出它还没有读过的新信念，并且它现在能够对它最初手工提供的本体提出扩展。 NELL的学习任务 NELL将学习超过2500个不同的学习任务，其中每个任务都有其对应的，具体来说NELL将对学习到对应的映射函数：。这些学习任务大致可以分为以下几个大类： 类别分类：根据语义类别对名词短语进行分类的函数(例如，一个用于对给定的名词短语是否与食物相关进行分类的布尔值函数)。NELL在其本体中为280个类别中的每个类别学习不同的布尔函数，允许名词短语指代多个语义类别中的实体(例如，apple既可以指代食品，也可以指代公司)。根据名词短语的五种不同视角(五种不同的Xi)，NELL对每个类别学习了多达五种不同的预测Yi的功能，分别是： 名词短语的特征(例如，名词短语是否以字符串“…自治市”结尾)。这是由CML系统(Carlson et al. 2010b)执行的，它通过具有数千个字符串特征的向量表示名词短语。 在2009年ClueWeb2009文本语料库(Callan and Hoy 2009)的5亿个英语网页中，这个名词短语周围的文本上下文分布情况(例如，名词短语N在“N的市长”的上下文中出现的频率)。这是由CPL系统执行的(Carlson et al. 2010b)。 通过主动的网络搜索，在这个名词短语周围发现的文本上下文分布。这是由OpenEval系统(Samadi、Veloso和Blum 2013)执行的，它使用与上述CPL系统稍微不同的上下文特性，并使用实时web搜索来收集这些信息。 包含名词短语的网页的HTML结构(例如，名词短语是否出现在HTML列表中，与其他已知的城市一起)。这是由SEAL系统完成的(Wang和Cohen 2007)。 当名词短语被提供给图像搜索引擎时，与该名词短语相关的视觉图像。这是由NEIL系统(Chen, Shrivastava, and Gupta 2013)执行的，并且只适用于NELL的本体类别的子集(例如，不适用于音乐类型)。 关系分类：根据名词短语对对它们是否满足给定的关系进行分类的函数(例如，将这对名词短语&lt;“Pittsburgh”,”U.S.”&gt;是否满足“CityLocatedInCountry(x,y)”关系进行分类)。NELL在其本体论中为327个关系中的每个关系学习不同的布尔值分类函数。对于每个关系，NELL根据输入名词短语对的不同特征视图学习三个不同的分类函数。具体来说，它使用了两种分类方法:CPL和OpenEval，这两种方法是根据网页上两个名词短语之间的文本上下文分布情况来进行分类;它使用了基于网页HTML结构的SEAL分类方法。 实体解析：根据名词短语对是否为同义词(例如，NYC和Big Apple是否可以指同一个实体)对其进行分类的函数。这种分类方法在(Krishnamurthy和Mitchell 2011)中有描述。对于NELL的280个类别中的每一个，它联合训练两个同义词分类器:一个基于两个名词短语之间的字符串相似性，另一个基于它们提取的信念的相似性。 信念三元组之间的推理规则：将NELL的当前知识库映射到应该添加到其知识库中的新信念的函数。对于NELL’s本体中的每个关系，其对应的功能由PRA系统学习到的限制性Horn子句规则集合表示(Lao, Mitchell, and Cohen 2011;Gardner等，2014)。 上面的每个函数表示一个NELL中的性能任务，每个函数映射到获取该函数的学习任务，给定某种类型的经验和在学习期间要优化的性能度量。 在所有情况下,只有一个除外,经验的组成： 人工标注训练的例子(NELL本体中每个实体和关系都有十几个标记示例,以及通过NELL网站贡献了一段时间的标注实例) 一组对应NELL当前的知识库的NELL自标记训练例子 大量未标记的web文本。 唯一的例外是通过视觉图像学习，这是由NEIL系统通过它自己的训练程序来处理的。 NELL的耦合约束 NELL的永无止境的学习任务的第二个组成部分是连接其学习任务的耦合约束集。NELL的耦合约束分为五组： 多视角的协同训练的耦合。NELL的对名词短语进行类别分类(以及对名词短语进行关系分类)的多个方法提供了一个自然的协同训练的机制 (Blum and Mitchell 1998), 其中属于同一类别的可替换的众多分类器应该在给定同一输入的预测结果一致，尽管它们的预测基于不同的名词短语特征。 子集/超集耦合。当一个新的类别被添加到NELL的本体论时，它的直接父类(超集)是明确的(例如，饮料被声明为食物的子集)。当类别C1作为类别C2的一个子集添加时，NELL使用耦合约束。这将学习预测C1的任务和学习预测C2的任务结合起来。 多标签互斥耦合。当类别C被添加到NELL的本体论中时，已知与类别C不相交(相互排斥)的类别也是明确的(例如，饮料被声明为与情感、城市等相互排斥)。这些互斥约束通常继承自更一般的类，但是可以由显式断言覆盖。当类别C1被声明为与C2互斥时，NELL采用约束。 将关系耦合到它们的参数类型。当一个关系被添加到NELL的本体时，编辑者必须指定它的参数的类型(例如，zooInCity(x,y)分别需要Zoo和City类型的参数)。NELL使用这些参数类型声明作为其类别和关系分类器之间的耦合约束。 Horn子句耦合。每当NELL学习一个Horn子句规则，从现有的信念中推断出新的知识库信念时，该规则作为一个耦合约束来增强NELL的永不结束学习问题。例如，当NELL学习具有概率p的形式的规则时，该规则作为一个新的概率耦合约束作用于学习关系R1、R2和R3的函数。每个习得的Horn子句都要求从名词短语对映射到R1、R2和R3关系标签的习得函数与此Horn子句一致;因此，它们类似于NELL的子集/超集耦合约束，它要求从名词短语到类别标签的映射函数应该与子集/超集约束一致。NELL’s never ending learning problem包含超过2500个学习任务，相互关联的耦合约束超过100万个。事实上，NELL的永无止境的学习问题是开放的，因为NELL有能力以习得的Horn子句(如上所述)的形式添加新的一致性约束和新的学习任务，为其本体发明新的谓词(如下所述)。 9 NELL的软件体系结构 NELL的增长知识库(KB)作为一个共享的黑板，通过它的各种阅读和推理模块相互作用。NELL的学习周期使用当前的知识库迭代地重新训练这些软件模块，然后使用这些改进的模块更新知识库。 10 NELL的学习方法和架构NELL的软件架构，如上图所示，包括一个知识库(KB)，它充当一个黑板，通过它NELL的各种学习和推理模块进行通信。如图所示，这些软件模块与前一节中提到的不同类型函数的学习方法(CPL、CML、SEAL、OpenEval、PRA、NEIL)紧密映射，使得NELL的各种学习任务在这些模块之间进行了划分。 NELL的学习是对EM的一种近似NELL处于一个无限循环中，类似于EM算法的半监督学习，在每次迭代中执行类似于m的步骤。在类似的步骤中，每个读取和推断模块都建议对知识库进行更新(添加和删除特定的信念，以及特定的信任和来源信息)。知识整合器(KI)既记录这些单独的建议，又对知识库中分配给每个潜在信念的置信度做出最终决定。然后，在类似m的步骤中，使用特定于模块的学习算法，使用这个精练的知识库对每个软件模块进行再培训。其结果是一个大规模的耦合培训系统，其中数千个学习任务通过共享知识库和耦合约束由彼此的结果引导。 注意！对于NELL系统而言，一个完整的EM算法是不切实际的。NELL经常考虑数千万个名词短语，在名词短语对中产生了$10^{17}$个潜在的关系断言。在每一个类似E的步骤上估计每一个潜在断言的概率是不切实际的。相反，NELL只构造和考虑它最确信的信念，限制每个软件模块仅为任何给定迭代上的任何给定谓词建议有限数量的新候选信念。这使得NELL能够灵活地操作，同时保留在多次迭代中添加数百万个新信念的能力。 NELL中的知识集成器知识集成器(KI)集成知识库更新的传入建议。为了提高效率，KI只考虑适度的信心候选信念，并使用一致性约束和信念的完整图的有限子图重新评估信心。例如，KI考虑当前知识库中的所有信念，以确保新的关系断言满足参数类型，但不考虑在相同的迭代中对这些参数类型的信念进行可能的更新。 在多次迭代中，约束的影响通过信念和约束的图更广泛地传播。最近(Pujara et al. 2013)证明了一种更有效的算法来解决KI所面临的联合推理问题;我们现在正在升级NELL的KI来使用这个实现。 在NELL中添加学习任务和本体扩展NELL有能力通过使用OntExt系统发明新的关系谓词来扩展其本体(Mohamed, Hruschka Jr.和Mitchell 2011)。OntExt考虑了NELL当前本体论中的每一对范畴，以寻找经常讨论的范畴范畴之间关系的证据。 提取提及两个类别的已知实例的句子（例如：对于类别对&lt;药物，疾病&gt;而言，如果百忧解和偏头痛已经在在NELL当前的知识库中，那么句子百忧解可能导致偏头痛可能被抽取出来 从提取的句子中，通过上下文共现矩阵建立上下文，然后将相关的上下文聚在一起。每个集群对应于两个输入类别实例之间可能的新关系。 在允许新的关系(例如，DrugHasSideEffect(x,y))被添加到NELL的本体之前，使用一个经过训练的分类器，并进行最后阶段的人工筛选。 OntExt为NELL的本体增加了62个新的关系。注意，每个新关系都会衍生出相关的新学习任务，包括三个新任务:学习如何分类哪些名词短语对满足该关系(基于名词短语对的不同观点)，以及一个学习Horn子句规则的任务，以从其他关系中推断出该新关系。 11 实证性评估我们对NELL进行实验评估的主要目标是了解NELL在阅读能力、知识库大小和质量方面随着时间的推移在多大程度上得到了提高。 首先，考虑NELL的KB随时间的增长，从2010年1月开始到2014年11月，NELL已经完成了886次迭代。 NELL的KB很明显在增长，尽管它的高自信信念比它的全部信念增长得更慢。还要注意，在最近的迭代中，高度自信信念的增长有所减少。 这部分是由于NELL已经在他的本体论中渗透了一些范畴和关系。例如，对于类别Country，它在前几百次迭代中提取了大多数实际的国家名称。 第二，考虑NELL阅读能力的准确性。为了评估这一点，我们应用了NELL在其历史上不同迭代中获得的不同版本，从一组固定的文本数据中提取信念，这些文本数据包括2009年ClueWeb2009语料库中的5亿个英语网页，以及截至2014年11月14日的万维网。 然后我们手动评估这些不同历史版本的NELL所提取的信念的准确性，以NELL内尔的阅读能力的发展。为了获得随时间变化的不同版本的NELL，我们依赖于这样一个事实，即NELL在任何给定时间的状态完全由其KB决定。 特别地，在第i次迭代中，对于给定的NELL的KB，我们首先让NELL在KB加上未标记的文本上训练自己，然后让它将其训练过的方法应用到一组固定的未标记的web文本上，从而提出一组排序排序的信心加权信念。我们评估了这些信念的准确性，以衡量NELL在不同的时间点演变的能力。 12 NELL的可优化之处 向NELL添加一个自我反省功能，使它能够检测在什么地方做得好，在什么地方做得不好，什么时候它已经充分地填充了任何给定的类别或关系，使它能够以一种更有针对性的方式分配其工作 扩展NELL用于提取信念的数据范围，例如通过包括英语、图像数据和Twitter之外的语言 通过更多地依赖于发明新的关系和类别的自动化算法，以及将其他开源本体(如DBpedia)合并到NELL的本体来极大地扩展NELL的本体 将新一代的微型阅读方法（可以对单个句子和文本段落进行深度语义分析的方法）添加到NELL中，因此不需要依赖网络冗余来实现准确阅读。 我们目前正在积极探索这些方向。 13 可以从NELL学到的NELL是一个学习代理，它演示了一些我们认为对任何永无止境的学习系统都很重要的特性，尽管它也有局限性。根据我们与NELL的经验，我们为任何永无止境的学习系统推荐了四个有用的设计特性： 为了实现成功的半监督学习，需要结合许多不同学习任务的训练:NELL成功地从少量的监督中学习了数千种功能的主要原因是，它被设计成同时学习数千种不同的功能，这些功能被大量的耦合约束紧密地连接在一起。当其中一个学习任务开始取得进展时，耦合约束允许所学习的信息约束其他任务的后续学习。 允许代理学习额外的耦合约束:由于耦合对许多函数的训练至关重要，通过自动学习额外的耦合约束可以获得很大的收益。在NELL中，这是通过数据挖掘NELL的KB来学习限制形式的概率性Horn子句来实现的。NELL已经学会了成千上万个概率性的Horn子句，它用这些子句来推断它还没有读过的新的KB信念。作为创造新的信念的一个副作用，这些新的信念后来被用来重新训练NELL的阅读功能，这些Horn子句也作为耦合约束来进一步约束和指导NELL的阅读功能的后续学习。 学习新的表示方法，它涵盖了初始表示之外的相关现象:为了不断改进，并避免在性能上达到稳定状态，一个永不停止的学习系统可能需要将其表示扩展到最初提供的之外。NELL有一种原始但已经有用的能力来扩展它的表示，方法是在现有类别(例如，river,city)之间提出新的关系谓词(例如，RiverFlowsThroughCity(x,y))。NELL所引入的每一种新关系都会导致新的学习任务，如学习从文本中提取这种关系，以及学习从其他信念中推断这种关系的实例。 将一系列的学习任务组织成一门容易却越来越难的课程:给定一组复杂的学习任务，通常会出现这样的情况:有些学习任务比较容易，有些则为其他任务提供了必要的知识。在NELL中，随着时间的推移，我们通过手动引入新的学习任务类型来改进系统。在NELL的头六个月里，它唯一的任务就是把名词短语分成不同的类别，把名词短语对分成不同的关系。后来，一旦它在这些方面达到了某种程度的能力，并相应地增加了它的知识库，它就可以面对更具挑战性的任务。至此，我们介绍了对知识库进行数据挖掘以发现有用的Horn子句规则的任务，以及基于NELL的类别实例知识发现新的关系谓词的任务。一个关键的开放研究问题是学习主体本身如何形成一个有用的学习任务课程。 NELL的一些限制 自我反省和明确的学习目标。目前，NELL在监督自身表现和进步方面的能力非常薄弱。例如，它没有注意到它在过去一年中没有学到任何有用的国家类别的新成员，它继续研究这个问题，尽管它在这方面的知识已经饱和。此外，它没有尝试将其学习努力分配给那些特别有生产力的任务(例如，收集新的web文本来描述那些它只有低信心信念的实体)。很明显，开发一种自我反省的能力来监控和估计自己的准确性，并根据感知到的需求计划具体的学习行动，将允许系统更有效地使用其计算工作。 普遍的可塑性。虽然NELL能够通过学习改变许多方面的行为，但它的其他部分的行为是固定不变的。例如NELL检测名词短语的方法是一个固定的程序，不开放的学习。在设计不断学习的代理时，重要的是理解如何构建代理，使其尽可能多的行为是可塑的，是可以学习的。否则，代理将面临性能停滞不前的风险，在这种情况下，进一步的改进需要对系统中本身无法修改的部分进行修改。 表示和推理。目前，NELL使用一种简单的基于框架的知识表示，并通过PRA推理系统进行扩展，该推理系统基于受限的Horn子句执行可处理但有限类型的推理。NELL的能力已经受到限制，部分原因是它缺乏更强大的推理组件:目前缺乏表示和推理时间和空间的方法。因此，表征和可处理推理的核心AI问题也是不断学习的代理的核心研究问题。 关于never-ending learning的一些重要的的概念和理论问题 一致性和正确性之间的关系。一个自主学习代理永远无法真正感知它是否正确，它最多只能检测到它的内部一致性。例如，即使它观察到它的预测(例如，内尔斯习得Horn子句预测的新信念)与它所感知的一致(例如，内尔从文本中读到的内容)，它也不能区分所观察到的一致性是由于正确的预测，还是不正确的感知。这对于理解永无止境的学习很重要，因为它建议组织学习代理随着时间的推移变得越来越一致，而这正是NELL如何使用其一致性约束来指导学习。因此，一个关键的开放理论问题是，在什么条件下可以保证一个越来越一致的学习代理同时也是一个越来越正确的代理?(Platanios, Blum, and Mitchell 2014)为这个方向提供了一个步骤，通过提供一种方法，不久将允许NELL根据所观察到的其学习函数之间的一致性率来估计其准确性，但是对于这个基本的理论问题还有很多需要了解的地方。 趋同在理论上和实践中都是必然的。对于永不停息的学习代理而言，第二个基本问题是，什么样的代理体系结构能够充分保证代理原则上能够生成一系列自修改，从而将其从初始状态转换为日益高性能的代理，而不会达到性能瓶颈?注意，这可能需要体系结构支持普遍的可塑性、改变其表示的能力等。这里的一个问题是，架构是否有足够的自修改操作来允许它在原则上对自身产生不断改进的修改。其次，相关的问题是它的学习机制是否会做出这些潜在的改变，在可处理的计算量和训练经验下，在实践中趋同。 致谢略 参考略","categories":[{"name":"知识图谱","slug":"知识图谱","permalink":"http://www.iamlightsmile.com/categories/知识图谱/"}],"tags":[{"name":"知识图谱","slug":"知识图谱","permalink":"http://www.iamlightsmile.com/tags/知识图谱/"}]},{"title":"《论文解读-Toward an Architecture for Never-Ending Language Learning》","slug":"《论文解读-Toward an Architecture for Never-Ending Language Learning》","date":"2020-01-31T10:18:02.000Z","updated":"2020-01-31T10:30:08.479Z","comments":true,"path":"articles/《论文解读-Toward an Architecture for Never-Ending Language Learning》/","link":"","permalink":"http://www.iamlightsmile.com/articles/《论文解读-Toward an Architecture for Never-Ending Language Learning》/","excerpt":"当前自己仅是简单翻译一下。 0. 论文出处1. NELL系统概述NELL（never-ending language learner）系统每天不间断地执行两个任务： 阅读任务:从web文本中提取信息，进一步填充结构化事实和知识的不断增长的知识库。 学习任务:学习阅读，每天都比前一天更好，这是由它的能力证明，回到昨天的文本来源，提取更多的信息更准确","text":"当前自己仅是简单翻译一下。 0. 论文出处1. NELL系统概述NELL（never-ending language learner）系统每天不间断地执行两个任务： 阅读任务:从web文本中提取信息，进一步填充结构化事实和知识的不断增长的知识库。 学习任务:学习阅读，每天都比前一天更好，这是由它的能力证明，回到昨天的文本来源，提取更多的信息更准确 2. 理论基础网络上庞大的信息冗余(例如，许多事实以不同的方式被多次陈述)将使具有正确学习机制的系统获得成功。 3. 研究定位这项研究的一个观点是，它是一个终生学习的案例研究。第二种观点认为，这是一种提高自然语言处理艺术水平的尝试。第三种观点认为，这是开发世界上最大的结构化知识库的一种尝试——反映万维网的事实内容，这将对许多人工智能工作有用。 4. NELL系统掌握的知识类型目前，NELL掌握了两种类型的知识: 关于哪些名词短语指哪些特定语义类别的知识，如城市、公司和运动队; 关于哪些名词短语对满足哪些特定语义关系的知识，如hasOfficesIn(组织、位置)。 5. NELL系统的贡献 构建一个永不停息的学习代理的体系结构的进展，以及一组帮助成功实现该体系结构的设计原则 对该体系结构实现的web级实验评估 这是迄今为止规模最大、最成功的bootstrap学习实现之一 6. 系统组成 一个持续增长的共享的知识库 一系列实现了互补的知识抽取方法的阅读/学习子系统组件 7. 知识库初始定义 1个本体（定义了类别和关系的谓词集合） 这个本体中每个谓词的一些种子示例(例如，一些个示例城市)。 8. 系统目标通过阅读不断地增长知识库，并学习更好地阅读。 9. 系统体系结构 添加到知识库中的类别和关系实例被划分为候选事实和信念。 子系统组件可以从知识库中读取数据并参考其他外部资源(例如文本库或Internet)，然后提出新的候选事实。 组件为每个提议的候选提供一个概率，并提供支持它的源证据的摘要。 知识整合器(KI)检查这些提出的候选事实，并将其中最有力的支持提升到信念状态。 10. 系统工作原理 在我们的初始实现中，这个循环是迭代操作的。在每个迭代中，给定当前的知识库，每个子系统组件都运行到完成，然后KI根据新提出的候选事实做出决定。 知识库在迭代中不断增长，提供了越来越多的信念，然后每个子系统组件使用这些信念来重新训练自己，以便在下一次迭代中更好地阅读。通过这种方式，我们的方法可以被看作是实现了一种耦合的、半监督的学习方法，在这种方法中，多个组件在KI的监督下学习和共享互补类型的知识。 可以将此方法视为期望最大化(EM)算法的近似值，其中E步骤涉及迭代地估计共享知识库中非常大的一组虚拟候选信念的真值，M步骤涉及重新培训各种子系统组件提取方法。 如果标记错误累积，这种迭代学习方法可能会出现问题。为了帮助缓解这个问题，我们将允许系统每天与人进行10-15分钟的交互，以帮助它保持“在正轨上”。“然而，在这里报道的工作中，我们对人力投入的使用有限。 11. 系统设计原则 使用产生不相关错误的子系统组件。 当多个组件出现不相关的错误时，它们都出现相同错误的概率是它们各自错误概率的乘积，从而导致错误率大大降低。 学习多种类型的相关知识。 例如，我们使用一个组件学习从文本资源中提取谓词实例，另一个组件学习从知识库中的其他信念中推断关系实例。这为相同类型的信念提供了多种独立的来源。 使用耦合半监督学习方法来利用正在学习的谓词之间的约束(Carlson et al. 2010)。 为了提供耦合的机会，将类别和关系安排到一个分类法中，该分类法定义哪些类别是其他类别的子集，以及哪些类别对是相互排斥的。另外，指定每个关系参数的期望类别以启用类型检查。子系统组件和KI可以从利用耦合的方法中获益。 将知识库中的高自信信念与低自信候选者区分开来，并保留每种信念的来源证明。 使用统一的知识库表示来捕获候选事实和促进所有类型的信念，并使用可以在此共享表示上操作的关联推理和学习机制。 12. 系统设计到的知识 半监督学习 终身学习 bootstrap学习 耦合半监督学习 13. 系统子系统组件 耦合模式学习器(Coupled Pattern Learner，CPL)：一个用于自由文本的提取器，它学习和使用上下文模式，如“市长的X”和“X发挥Y”提取范畴和关系的实例。CPL使用名词短语和上下文模式之间的共现统计(均使用词性标记序列定义)来学习感兴趣的每个谓词的提取模式，然后使用这些模式来查找每个谓词的其他实例。谓词之间的关系用于过滤过于一般化的模式。Carlson等人(2010)对CPL进行了详细描述。CPL提取的候选实例的概率是使用公式1 0.5 c启发式分配的，其中c是提取候选实例的提升模式的数量。在我们的实验中，CPL作为20亿个句子的语料库的输入，这些句子是使用OpenNLP 包从ClueWeb09数据集中的5亿个网页英语部分提取、标记和后置标签句子生成的(Callan和Hoy 2009)。 耦合密封(Coupled SEAL，CSEAL):一个半结构化的提取器，它使用来自每个类别或关系的信念集查询Internet，然后挖掘列表和表来提取相应谓词的新实例。CSEAL使用互斥关系来提供负面示例，这些示例用于过滤掉过于一般的列表和表。CSEAL也由Carlson等人(2010)描述，它基于Wang和科恩(2009)。给定一组种子实例，CSEAL通过对知识库中的信念进行子抽样并在查询中使用这些抽样的种子来执行查询。CSEAL被配置为为每个类别发出5个查询，为每个关系发出10个查询，并为每个查询获取50个web页面。CSEAL提取的候选事实使用与CPL相同的方法分配概率，只不过c是提取实例的未过滤包装器的数量。 耦合形态分类器(Coupled Morphological Classifier，CMC):一组二元l2正则化逻辑回归模型，每个类别一个，根据不同的形态特征(单词、大写字母、词缀、词性等)对名词短语进行分类。来自知识库的信念被用作训练实例，但是在每个迭代中CMC被限制为至少有100个提升实例的谓词。与CSEAL一样，互斥关系用于识别负面实例。CMC检查其他组件提出的候选事实，并在每次迭代中每个谓词分类多达30个新信念，最小后验概率为0.75。这些启发式度量有助于确保较高的精度。 规则学习器(Rule Learner，RL):类似于FOIL (Quinlan和Cameron-Jones 1993)的一阶关系学习算法，它学习概率性的Horn子句。这些学习到的规则用于从知识库中已经存在的其他关系实例中推断新的关系实例。 14. 知识整合器（KI）我们对知识整合器(KI)的实现使用硬编码的、直观的策略将候选事实提升到信念的状态。从单一来源(后&gt; 0.9)获得高可信度的候选事实将得到提升，而从多个来源获得低可信度的候选事实将得到提升。 KI通过遵守互斥和类型检查信息来利用谓词之间的关系。特别是,候选类别实例不会被提升如果他们已经属于一个互斥的类别；关系实例同样不会提升,除非他们的论元至少属于候选的合适的类别类型(而不是已经被认为是一个类别的实例与适当的类型相互排斥）。 在我们当前的实现中，一旦将候选事实提升为信念，它就永远不会降级。KI被配置为每次迭代每个谓词最多提升250个实例，但是在我们的实验中很少达到这个阈值。 NELL中的KB是基于Tokyo Cabinet2(一种快速、轻量级的键/值存储)的THEO框架表示(Mitchell et al. 1991)的重新实现。知识库可以在一台机器上处理数百万个值。 15. 实验我们实验中使用的输入本体包括123个类别，每个类别有10-15个种子实例和5个CPL种子模式(源自Hearst模式(Hearst 1992))。 类别包括地点(例如，山脉、湖泊、城市、博物馆)、人(例如，科学家、作家、政治家、音乐家)、动物(例如，爬行动物、鸟类、哺乳动物)、组织(例如，公司、大学、网站、运动队)和其他。其中包括55个关系，还有10-15个种子实例和5个负面实例(通常通过屏蔽种子实例的参数生成)。关系捕获不同类别之间的关系(例如，teamPlaysSport、bookWriter、companyProducesProduct)。 在我们的实验中，CPL、CSEAL和CMC每次迭代运行一次。RL在每批10次迭代之后运行，并由人工筛选提议的输出规则。手动批准这些规则只需要几分钟。为了估计NELL生成的知识库中的信念的精度，最后知识库中的信念被随机抽样，并由几个人类裁判进行评估。在作出决定之前，对意见不一致的情况进行了详细的讨论。曾经正确但现在不正确的事实(例如，一个运动队的前教练)被认为是正确的评价，因为NELL目前没有处理其信仰的时间范围。虚假的形容词(如《今日芝加哥论坛报》(today ‘s Chicago Tribune)是被允许的，但很少见。 16. 抽取结果示例 17. 结果略 18. 讨论尽管NELL的持续学习允许它每天提取更多的事实，但提取事实的准确性随着时间的推移而缓慢下降。部分原因是最简单的提取发生在早期的迭代中，而后期的迭代需要更精确的提取器来达到同样的精度。 然而，NELL犯的错误也会导致他学会犯更多的错误。虽然我们认为目前的系统很有前途，但还有许多研究工作要做。 19. 总结我们提出了一个永不停止的语言学习代理的体系结构，并描述了该体系结构的部分实现，它使用四个子系统组件来学习以互补的方式提取知识。在运行了67天之后，这个实现填充了一个包含242,000多个事实的知识库，估计精度为74%。 这些结果说明了使用一组不同的知识提取方法的好处，这些方法适合于学习，并且一个知识库允许存储候选事实和自信的信念。 20. 可以改进之处有许多改进的机会,包括: 反省决定下一步该做什么, 更有效地利用10的15分钟的日常人际互动, 学习新发现的谓词, 学习额外的知识类型语言, 实体级(而不是string-level)建模 更复杂的概率建模的实现。 21. 致谢略 22. 参考略","categories":[{"name":"知识图谱","slug":"知识图谱","permalink":"http://www.iamlightsmile.com/categories/知识图谱/"}],"tags":[{"name":"知识图谱","slug":"知识图谱","permalink":"http://www.iamlightsmile.com/tags/知识图谱/"}]},{"title":"《NLP基础任务之新词发现探索之路》","slug":"《NLP基础任务之新词发现探索之路》","date":"2020-01-26T09:53:09.000Z","updated":"2020-01-26T13:37:09.094Z","comments":true,"path":"articles/《NLP基础任务之新词发现探索之路》/","link":"","permalink":"http://www.iamlightsmile.com/articles/《NLP基础任务之新词发现探索之路》/","excerpt":"step1：寻找综述没找到太好的综述。","text":"step1：寻找综述没找到太好的综述。 step2：寻找技术博客文章如寻找技术博客（如CSDN与个人博客站点）与文章（如知乎、简书），具体到新词发现任务，如： 基于互信息和左右信息熵的短语提取识别-码农场 互联网时代的社会语言学：基于SNS的文本数据挖掘 | Matrix67: The Aha Moments python3实现互信息和左右熵的新词发现 - 简书 step3：寻找已有实现如从Github上搜索与筛选相关开源项目，如： xylander23/New-Word-Detection: 新词发现算法(NewWordDetection) zhanzecheng/Chinese_segment_augment: python3实现互信息和左右熵的新词发现 step4：结合知识点研读开源项目算法初始思路经过研究以上代码与相关文章，发现主要有2种思路： 不依赖分词，直接进行新词发现，如上面开源项目1 在原有分词基础上进行，如上面开源项目2 相比而言（更多的是感性认识，并没有对比观察多少数据从而建立起有依据的推论），不依赖分词能够避免原有分词错误而引起的后面的错误，而在原有分词基础上进行则更加准确，因为可以依赖于分词结果作为输入特征，个人认为可能方案2（即在原有分词基础上进行）可能会更好些，当然这又受限于分词的准确率。 相关特征识别新词即确定两个词（或多个）是否能够组合成为一个词，主要看词内部的凝固度以及词外部的自由度，其中内部的凝固度可以用点间互信息来衡量，而自由度则可以用左右邻的信息熵来衡量。 大致流程对于所有的候选新词分别计算以上两个特征，通过某种方式组合在一起，或线性加和或幂次乘积来给候选新词打分，同时设定一些阈值过滤掉不符合条件的候选词，并将所有过滤后的候选词按分数高低降序排序，从而得到最终的结果。 step5：改进与整合原有项目自己主要参考项目2，但发现存在一些不足，如： 没有实现开箱即用的接口 数据结构设计不合理，比如遍历自定义的类所组成的列表进行匹配查找，耗时较多 虽然将引入外部词典数据进行初始化构建的模型进行了pickle持久化操作，但是其实没必要 不能很好地多次调用，每次调用都需要初始化或读取持久化的对象，耗时较长。 经过不断实践与探索，基本上比较好地解决了以上问题，同时在过程中也考虑了很多问题，如： 基于分词还是不基于分词 是否引入外部词典作为结果排序矫正 是否提供用户自定义词典以及自定义停用词接口 采用何种数据结构，是否照搬项目中数据结构，还是进行优化改进 在每次调用时都需要进行对外部词典数据初始化的过程，使用pickle文件写入读取持久化还是使用deepcopy进行对象拷贝，怎样更快 如何对如互信息与信息熵等统计特征进行加权组合，参数如何选取调整 如何引入其他信息增强发现能力以及矫正能力，比如词性信息（然而结巴的那个词典里面许多词性信息都不准确，比如说将知识的词性标注为动词） 设计一个什么样的接口才能使用户很方便的使用 如何将该新词发现模块与分词系统等较好地整合在一起 如何更好地融入人工校验机制 是否加入机器学习、深度学习等算法，包括有监督、无监督、强化学习、在线学习等 实现smilelight/lightText: 文本处理相关库，目前包括新词发现等功能。 后记当今nlp各任务的各种实现从传统规则到机器学习再到深度学习比比皆是，层出不穷，然而根本就没有完美的算法，没有完美的系统，有的只是不断地改进和优化。 个人心得在进行系统设计时，前期一定要对项目有一个比较清晰的规划，比如它的定位是什么、有哪些可以参考借鉴的已有实现，重要的搭一个能够跑起来的架子，不论啥效果；在中期优化过程中，则需要综合考虑时间空间硬件精度等多种因素，在一方面有所得有时必须建立在在其它某些方面有所失，比如各种时间空间互换、精度与时间空间互换等，在不同的时期不同的场景下主要矛盾不同，因此所对应的最佳策略也不唯一；在整个项目的生命周期中都需要不断考虑项目的拓展性，许多时候多写几个函数，多整几个文件来将不确定的、复杂的实现解耦，便于后续的排查调整。 参考略","categories":[{"name":"NLP","slug":"NLP","permalink":"http://www.iamlightsmile.com/categories/NLP/"}],"tags":[{"name":"NLP, 新词发现","slug":"NLP-新词发现","permalink":"http://www.iamlightsmile.com/tags/NLP-新词发现/"}]},{"title":"《国士无双-林俊德》","slug":"《国士无双-林俊德》","date":"2020-01-22T08:33:56.000Z","updated":"2020-01-26T13:38:15.976Z","comments":true,"path":"articles/《国士无双-林俊德》/","link":"","permalink":"http://www.iamlightsmile.com/articles/《国士无双-林俊德》/","excerpt":"人物简介林俊德（1938年3月13日—2012年5月31日），男，福建永春人，中国爆炸力学与核试验工程领域著名专家、总装备部某试验训练基地研究员，1960年毕业于浙江大学机械系，1993年晋升为少将军衔，2001年当选为中国工程院院士。2018年，经中央军委批准，增加“献身国防科技事业杰出科学家”林俊德为全军挂像英模。 2019年9月25日，入选“最美奋斗者”个人名单。","text":"人物简介林俊德（1938年3月13日—2012年5月31日），男，福建永春人，中国爆炸力学与核试验工程领域著名专家、总装备部某试验训练基地研究员，1960年毕业于浙江大学机械系，1993年晋升为少将军衔，2001年当选为中国工程院院士。2018年，经中央军委批准，增加“献身国防科技事业杰出科学家”林俊德为全军挂像英模。 2019年9月25日，入选“最美奋斗者”个人名单。 参考 林俊德（中国工程院院士）_百度百科","categories":[{"name":"其他","slug":"其他","permalink":"http://www.iamlightsmile.com/categories/其他/"}],"tags":[{"name":"国士无双","slug":"国士无双","permalink":"http://www.iamlightsmile.com/tags/国士无双/"}]},{"title":"《国士无双-黄旭华》","slug":"《国士无双-黄旭华》","date":"2020-01-22T08:27:28.000Z","updated":"2020-01-26T13:37:17.467Z","comments":true,"path":"articles/《国士无双-黄旭华》/","link":"","permalink":"http://www.iamlightsmile.com/articles/《国士无双-黄旭华》/","excerpt":"人物简介黄旭华，1924年2月24日出生于广东省汕尾市海丰县田墘镇，中国核潜艇之父，原籍广东省揭阳市揭东区玉湖镇新寮村，交通大学1949届校友，中船重工集团公司719研究所研究员、名誉所长，中国第一代攻击型核潜艇和战略导弹核潜艇总设计师。开拓了中国核潜艇的研制领域， 1994年当选为中国工程院院士。湖北省科协荣誉委员，曾任前中国船舶工业总公司719研究所副总工程师、副所长、所长兼代理党委书记、以及核潜艇工程副总设计师、总设计师、研究员、高级工程师等职。","text":"人物简介黄旭华，1924年2月24日出生于广东省汕尾市海丰县田墘镇，中国核潜艇之父，原籍广东省揭阳市揭东区玉湖镇新寮村，交通大学1949届校友，中船重工集团公司719研究所研究员、名誉所长，中国第一代攻击型核潜艇和战略导弹核潜艇总设计师。开拓了中国核潜艇的研制领域， 1994年当选为中国工程院院士。湖北省科协荣誉委员，曾任前中国船舶工业总公司719研究所副总工程师、副所长、所长兼代理党委书记、以及核潜艇工程副总设计师、总设计师、研究员、高级工程师等职。 2014年1月，黄旭华当选中国中央电视台2013年度感动中国十大人物。2017年10月25日，获2017年度何梁何利基金科学与技术成就奖。11月9日，获得第六届全国道德模范敬业奉献类奖项。 黄旭华为中国核潜艇事业的发展做出了重要贡献，在核潜艇水下发射运载火箭的多次海上试验任务中，作为核潜艇工程总设计师、副指挥，开拓了中国核潜艇的研制领域，被誉为中国核潜艇之父。 2020年1月10日，获国家最高科学技术奖。 参考 黄旭华（中国核潜艇之父）_百度百科","categories":[{"name":"其他","slug":"其他","permalink":"http://www.iamlightsmile.com/categories/其他/"}],"tags":[{"name":"国士无双","slug":"国士无双","permalink":"http://www.iamlightsmile.com/tags/国士无双/"}]},{"title":"《国士无双-于敏》","slug":"《国士无双-于敏》","date":"2020-01-22T08:17:11.000Z","updated":"2020-01-26T13:37:40.172Z","comments":true,"path":"articles/《国士无双-于敏》/","link":"","permalink":"http://www.iamlightsmile.com/articles/《国士无双-于敏》/","excerpt":"人物简介于敏（1926年8月16日—2019年1月16日），出生于河北省宁河县（今天津市宁河区）芦台镇，核物理学家，国家最高科技奖获得者。","text":"人物简介于敏（1926年8月16日—2019年1月16日），出生于河北省宁河县（今天津市宁河区）芦台镇，核物理学家，国家最高科技奖获得者。 1949年毕业于北京大学物理系。1980年当选为中国科学院学部委员（院士）。 原中国工程物理研究院副院长、研究员、高级科学顾问。 在中国氢弹原理突破中解决了一系列基础问题，提出了从原理到构形基本完整的设想，起了关键作用。此后长期领导核武器理论研究、设计，解决了大量理论问题。对中国核武器进一步发展到国际先进水平作出了重要贡献。从20世纪70年代起，在倡导、推动若干高科技项目研究中，发挥了重要作用。 1982年获国家自然科学奖一等奖。1985年、1987年和1989年三次获国家科技进步奖特等奖。1994年获求是基金杰出科学家奖。1999年被国家授予“两弹一星”功勋奖章。1985年荣获“五一劳动奖章”。1987年获“全国劳动模范”称号。2015年获2014年度国家最高科技奖。2018年12月18日，党中央、国务院授予于敏同志改革先锋称号，颁授改革先锋奖章，并获评“国防科技事业改革发展的重要推动者”。2019年1月16日，于敏在北京逝世，享年93岁。2019年9月17日，国家主席习近平签署主席令，授予于敏“共和国勋章”。 参考 于敏（中国“氢弹之父”）_百度百科","categories":[{"name":"其他","slug":"其他","permalink":"http://www.iamlightsmile.com/categories/其他/"}],"tags":[{"name":"国士无双","slug":"国士无双","permalink":"http://www.iamlightsmile.com/tags/国士无双/"}]},{"title":"《国士无双-张伯驹》","slug":"《国士无双-张伯驹》","date":"2020-01-22T08:04:22.000Z","updated":"2020-01-26T13:37:44.561Z","comments":true,"path":"articles/《国士无双-张伯驹》/","link":"","permalink":"http://www.iamlightsmile.com/articles/《国士无双-张伯驹》/","excerpt":"个人简介张伯驹（1898年3月14日—1982年2月26日），原名张家骐，字家骐，号丛碧，别号游春主人、好好先生，河南项城人。爱国民主人士，收藏鉴赏家、书画家、诗词学家、京剧艺术研究家。","text":"个人简介张伯驹（1898年3月14日—1982年2月26日），原名张家骐，字家骐，号丛碧，别号游春主人、好好先生，河南项城人。爱国民主人士，收藏鉴赏家、书画家、诗词学家、京剧艺术研究家。 曾任故宫博物院专门委员、国家文物局鉴定委员会委员，吉林省博物馆副研究员、副馆长，中央文史馆馆员，任燕京大学国文系中国艺术史名誉导师，北京中国画研究会名誉会长，中国书法家协会名誉理事等职。建国初期，张伯驹将多件珍贵文物捐献给国家。 主要著作有《丛碧词》《春游词》《秦游词》《雾中词》《无名词》《续断词》和《氍毹纪梦诗》《氍毹纪梦诗注》《洪宪纪事诗注》及《乱弹音韵辑要》《丛碧书画录》《素月楼联语》等。 参考 张伯驹_百度百科","categories":[{"name":"其他","slug":"其他","permalink":"http://www.iamlightsmile.com/categories/其他/"}],"tags":[{"name":"国士无双","slug":"国士无双","permalink":"http://www.iamlightsmile.com/tags/国士无双/"}]},{"title":"本博客分类详情","slug":"本博客分类详情","date":"2020-01-18T11:59:45.000Z","updated":"2020-01-18T12:01:33.167Z","comments":true,"path":"articles/本博客分类详情/","link":"","permalink":"http://www.iamlightsmile.com/articles/本博客分类详情/","excerpt":"","text":"本博客暂定分类如下： Linux NLP 知识图谱 Python 深度学习 计算机 随念 其他","categories":[{"name":"计算机","slug":"计算机","permalink":"http://www.iamlightsmile.com/categories/计算机/"}],"tags":[{"name":"blog","slug":"blog","permalink":"http://www.iamlightsmile.com/tags/blog/"}]},{"title":"light系列库设想架构","slug":"light系列库设想架构","date":"2020-01-08T12:22:20.000Z","updated":"2020-01-18T12:16:18.291Z","comments":true,"path":"articles/light系列库设想架构/","link":"","permalink":"http://www.iamlightsmile.com/articles/light系列库设想架构/","excerpt":"自己开发或整合的一系列light库之间的架构组织关系如图所示：","text":"自己开发或整合的一系列light库之间的架构组织关系如图所示： 整体架构如上图所示，整个light系列库之间的组织架构共分为： 工具层 lightSpider lightUtils lightDict 其他light库 其他工具库 算法层 lightNLP lightKG 通用神经网络模型算法 其他NLP框架 其他KG框架 业务层 lightText lightKB 其他相关业务 界面层 浏览器前端 整个架构的中心都是围绕着自然语言处理和知识图谱两个大的方向。目的是搭一个比较通用的架子，然后可以在上面展开一些尝试性、探索性的实验和业务，根本上是作为自己想法的舞台。 工具层工具层包括lightSpider、lightUtils、lightDict、其他light库以及其他工具库（如NLTK）。 其中lightSpider是用来获取网上的知识（以网上各网站的公开语料）。lightUtils则是一些较通用的工具类库，包含了比如说日志打印、获取系统可用tcp端口等功能。lightDict则包含了一些在网上搜集到的中文的字典词典资料，并且构建了一个lib以方便使用。其他light库则视以后需求增加。 算法层算法层包括lightNLP、lightKG、其他NLP框架（比如说fastNLP）、其他KG框架（比如说OpenNRE）以及其他通用神经网络模型算法，包括但不限于强化学习、对抗学习、终生学习等。 业务层业务层构建于算法层之上包括各种知识图谱任务和自然语言处理技术，比如关键词抽取、文本摘要、文本分类、命名实体识别、信息抽取、文本生成、实体链接、本体分类与构建、知识存储等功能，会用到各种算法知识和技术，包括基于深度学习的、基于机器学习的、基于规则的，基于监督学习的、基于弱监督学习的、基于无监督学习的等等。 界面层（用户层）用户层则主要考虑采用Vue+Flask等技术，在可视化方面主要采用2D层面，但在一些本体与事件展示时更倾向于使用3D效果。","categories":[{"name":"NLP","slug":"NLP","permalink":"http://www.iamlightsmile.com/categories/NLP/"}],"tags":[{"name":"light系列库","slug":"light系列库","permalink":"http://www.iamlightsmile.com/tags/light系列库/"}]},{"title":"centos安装miniconda","slug":"centos安装miniconda","date":"2020-01-07T08:06:09.000Z","updated":"2020-01-18T11:10:36.754Z","comments":true,"path":"articles/centos安装miniconda/","link":"","permalink":"http://www.iamlightsmile.com/articles/centos安装miniconda/","excerpt":"","text":"步骤1. 下载miniconda12cd ~ &amp;&amp; mkdir tmp &amp;&amp; cd tmpwget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh 2. 运行miniconda安装脚本1sh Miniconda3-latest-Linux-x86_64.sh 3. 验证是否安装成功1conda -V 若输出类似conda 4.7.12，说明安装conda环境成功。如提示：zsh：command not find:conda，则需要将conda配置到路径变量中，详情参考zsh：command not find:conda 的详细解决办法 - 简书","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"http://www.iamlightsmile.com/tags/CentOS/"}]},{"title":"购买国内云服务器与备案注册","slug":"购买国内云服务器与备案注册","date":"2020-01-07T06:50:32.000Z","updated":"2020-01-18T11:14:19.374Z","comments":true,"path":"articles/购买国内云服务器与备案注册/","link":"","permalink":"http://www.iamlightsmile.com/articles/购买国内云服务器与备案注册/","excerpt":"更新我真傻，真的。没想到腾讯云有120元/年，同样配置的学生优惠活动：腾讯云学生服务器_学生机_云服务器优惠套餐-云+校园 - 腾讯云，只是主机只能选上海或者深圳。并且25岁以下免学生认证，立马我就把之前用了500优惠券+600多买的云服务器给退了。。。 前言突然大发兴致，想要购买国内云服务器，并且配置域名以及备案注册，想要搞事情，具体搞什么还没想好，比如说爬虫或者部署demo之类的。虽然自己也有搬瓦工的服务器，虽然也算物美价廉，但是毕竟不能备案绑定域名，况且内存和国内访问速度都比较慢，还是搞个真正的云服务器比较好。","text":"更新我真傻，真的。没想到腾讯云有120元/年，同样配置的学生优惠活动：腾讯云学生服务器_学生机_云服务器优惠套餐-云+校园 - 腾讯云，只是主机只能选上海或者深圳。并且25岁以下免学生认证，立马我就把之前用了500优惠券+600多买的云服务器给退了。。。 前言突然大发兴致，想要购买国内云服务器，并且配置域名以及备案注册，想要搞事情，具体搞什么还没想好，比如说爬虫或者部署demo之类的。虽然自己也有搬瓦工的服务器，虽然也算物美价廉，但是毕竟不能备案绑定域名，况且内存和国内访问速度都比较慢，还是搞个真正的云服务器比较好。 调研这里主要是比较各厂商（主要是阿里云、腾讯云两家）的云服务器产品的性能和价格。发现网上阿里口碑不错，如果不差钱就选阿里好了，而腾讯云价格相对较低一些，毕竟起步较晚，一些布局和服务等没有阿里云那么完善，只能在价格上搞搞事情了。 虽然各厂商都对新用户有比较大的力度优惠，然而奈何自己都不是。在阿里云上买过域名和OSS，也在腾讯云上买过域名。 下面是阿里云的： 链接地址为：全民云计算_云服务器促销_便宜云服务器活动_阿里云 优惠链接地址：阿里云2020年1月最新优惠信息 - 独特优惠码 下面是腾讯云的： 链接地址为：云服务器选购 - 腾讯云 优惠链接地址：腾讯云优惠券_代金券_云服务器折扣券-腾讯云 其中里面一些优惠确实算是挺大的： 最终左右权衡之后，觉得确实腾讯云的性价比更高一些，况且适合自己以后部署爬虫等需要长时间消耗CPU等资源的应用。 购买域名及备案购买域名自己其实已经有3个域名了，但是都不太合适作为新服务器的域名，于是自己又买了一个域名：lightsmile.cn。哎，感叹一下lightsmile.com这个域名早就被别人买了，并且价格还挺高，所以自己看来短期内无法把它搞到手。 域名买了之后需要实名注册，然后设置解析，具体不表。 备案备案的话，现在其实都算挺方便的。无论是阿里云还是腾讯云，直接在电脑上操作或者使用微信小程序操作，然后上传一些资料，比如个人身份证件图片以及一些必要的备案信息等，然后就可以默默等待审核结果了。 后记不得不说，买个云服务器确实还挺贵的，自己也没有什么资金收入，还得找家里一直要钱。客观对比一下，我发现自己其实和一些大学生年轻人是一样的，只不过他们喜欢把钱投资到喜欢的衣服和鞋子，而我则喜欢购买互联网产品，充一些有助于自己成长的平台的会员。但归根结底都是图自己爽。 虽然有了自己的云服务器之后又可以有一番作为，但是确实还是很肉疼啊。 参考 1核 2G云服务器选择腾讯云还是阿里云？-魏艾斯博客 阿里云和腾讯云哪个好？云服务器如何选择？ - 简书","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"http://www.iamlightsmile.com/tags/CentOS/"}]},{"title":"高速下载国外数据软件","slug":"高速下载国外数据软件","date":"2020-01-04T05:34:01.000Z","updated":"2020-01-18T11:51:31.935Z","comments":true,"path":"articles/高速下载国外数据软件/","link":"","permalink":"http://www.iamlightsmile.com/articles/高速下载国外数据软件/","excerpt":"背景很多时候要下载国外网站的数据和软件包的时候默认浏览器下载速度极慢，甚至可能到几k/s，要下载个几M的东西都要花好长时间。","text":"背景很多时候要下载国外网站的数据和软件包的时候默认浏览器下载速度极慢，甚至可能到几k/s，要下载个几M的东西都要花好长时间。 解决方案突然想到自己有办理搬瓦工的服务器呀~。使用代理服务器下载想要的数据，然后再传到自己的电脑不就好了嘛。 使用流程1.获取下载链接地址如图，使用Chrome浏览器下载，然后右键点击URL选择“复制链接地址”。 2.使用代理服务器下载数据如图，使用Xshell等终端软件登录代理服务器，执行wget xxx命令： 3.将数据从代理服务器传至本机如图，使用Xftp等文件传输软件连接至代理服务器，将下载文件传输到本地： 后话虽然在将文件从代理服务器传输到本机的过程中可能速度也不快，但是起码可用了，200k也算可以接受了。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"小窍门","slug":"小窍门","permalink":"http://www.iamlightsmile.com/tags/小窍门/"}]},{"title":"程序猿注意颈椎保护","slug":"程序猿注意颈椎保护","date":"2020-01-03T12:51:42.000Z","updated":"2020-01-18T11:50:44.702Z","comments":true,"path":"articles/程序猿注意颈椎保护/","link":"","permalink":"http://www.iamlightsmile.com/articles/程序猿注意颈椎保护/","excerpt":"","text":"下面是一些视频网址和文字教程，在这里分享一下： 亲身实践，颈椎病自愈法 - 知乎 老中医治疗你的颈椎病_哔哩哔哩 (゜-゜)つロ 干杯~-bilibili 10分钟颈椎操颈椎病的自我治疗，每天10分钟，轻松20年！_哔哩哔哩 (゜-゜)つロ 干杯~-bilibili","categories":[{"name":"其他","slug":"其他","permalink":"http://www.iamlightsmile.com/categories/其他/"}],"tags":[{"name":"颈椎病","slug":"颈椎病","permalink":"http://www.iamlightsmile.com/tags/颈椎病/"}]},{"title":"简单调研操作Neo4j的Python库","slug":"简单调研操作Neo4j的Python库","date":"2020-01-03T12:49:41.000Z","updated":"2020-01-18T11:52:32.247Z","comments":true,"path":"articles/简单调研操作Neo4j的Python库/","link":"","permalink":"http://www.iamlightsmile.com/articles/简单调研操作Neo4j的Python库/","excerpt":"前言如官网所述，目前用于操作Neo4j的Python库主要包括如下几种： Neo4j Python Driver（官方提供，长期更新支持） Py2neo（非官方看网上教程多数都是这个） Neomodel（也是社区版）","text":"前言如官网所述，目前用于操作Neo4j的Python库主要包括如下几种： Neo4j Python Driver（官方提供，长期更新支持） Py2neo（非官方看网上教程多数都是这个） Neomodel（也是社区版） 对比 对比\\模型 Neo4j Driver Py2neo Neomodel 代码活跃程度 最近更新于一个月内 最近更新于8个月前 不明 国内适用范围 较少 很多 不明 代码特性 一般 简洁 一般 说明文档内容 较少 一般 不明 配套文档版本 最新 最新源码和文档有冲突 不明 结论经过对比，还是先结合源码来学习Py2neo吧。大家都用，并且代码用起来确实比较舒服~并且，本质上也只是一个使用Neo4j的接口，无非语句不通而已，但最终执行的增删改查都是一样的。 参考 The Py2neo v4 Handbook — The Py2neo v4 Handbook Neo4j系列-新手入门（二） - 简书 Neo4j简介及Py2Neo的用法 | 静觅","categories":[{"name":"知识图谱","slug":"知识图谱","permalink":"http://www.iamlightsmile.com/categories/知识图谱/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.iamlightsmile.com/tags/Python/"},{"name":"Neo4j","slug":"Neo4j","permalink":"http://www.iamlightsmile.com/tags/Neo4j/"}]},{"title":"使用ReadtheDocs给项目添加教程文档","slug":"使用ReadtheDocs给项目添加教程文档","date":"2020-01-03T12:43:18.000Z","updated":"2020-01-18T11:54:02.728Z","comments":true,"path":"articles/使用ReadtheDocs给项目添加教程文档/","link":"","permalink":"http://www.iamlightsmile.com/articles/使用ReadtheDocs给项目添加教程文档/","excerpt":"当开源项目的内容比较多、比较杂的时候，就需要将一些说明性的东西、如教程、文档等东西从README.md文件中剥离出来搞一个文档，许多项目都是如此，于是自己也简单学了一下使用ReadtheDocs。","text":"当开源项目的内容比较多、比较杂的时候，就需要将一些说明性的东西、如教程、文档等东西从README.md文件中剥离出来搞一个文档，许多项目都是如此，于是自己也简单学了一下使用ReadtheDocs。 步骤1.从ReadtheDocs官网注册账号并连接到GithubReadtheDocs官网地址：首页 | Read the Docs 在注册成功后在设置-&gt;已连接的服务中点击Connect to Github： 2.在Github上创建一个项目，如test-cookbook，并将其克隆到本地。3.安装Sphinx1pip install sphinx 4.创建工程将路径切换到项目根目录下，执行以下命令：1sphinx-quickstart 5.对工程进程配置项目的配置，主要是更改source/conf.py文件。 5.1 更改主题在项目中更改或添加以下代码123import sphinx_rtd_themehtml_theme = \"sphinx_rtd_theme\"html_theme_path = [sphinx_rtd_theme.get_html_theme_path()] 5.2 添加markdown支持首先安装recommonmark1pip install recommonmark 并在项目中增加以下代码12345from recommonmark.parser import CommonMarkParsersource_parsers = &#123; '.md': CommonMarkParser,&#125;source_suffix = ['.rst', '.md'] 6.导入到ReadtheDocs在ReadtheDocs个人面板点击Import a Project：然后选择对应的项目，如果项目列表为空或者未显示当前项目，点击右上角等待刷新项目即可： 之后可以对项目进行一些设置，如图： 7.向工程中添加实际教程和文档如新建.rst或.md文件，并修改项目的index.rst等，具体请参考最后的参考链接。 8.生成文档在项目根目录执行1make html 以生成html格式的文档。 可能在生成文档会失败，如遇到Sphinx error: master file [..]/checkouts/latest/contents.rst not found这样的错误，可以参考Sphinx error: master file [..]/checkouts/latest/contents.rst not found · Issue #2569 · readthedocs/readthedocs.org来解决。 9.预览效果进入build/html目录下用浏览器打开其中的index.html来预览项目文档。如： 10.push到Github仓库三连git：123git add .git commit -m \"update cookbook\"git push 11.查看在线效果在ReadtheDocs的项目主页点击阅读文档以查看实际效果： 效果如： 参考 如何用 ReadtheDocs、Sphinx 快速搭建写书环境 - 简书 使用ReadtheDocs托管文档 | 飞污熊博客 Sphinx error: master file [..]/checkouts/latest/contents.rst not found · Issue #2569 · readthedocs/readthedocs.org","categories":[{"name":"计算机","slug":"计算机","permalink":"http://www.iamlightsmile.com/categories/计算机/"}],"tags":[{"name":"ReadtheDocs","slug":"ReadtheDocs","permalink":"http://www.iamlightsmile.com/tags/ReadtheDocs/"}]},{"title":"实用命令行工具-Gow","slug":"实用命令行工具-Gow","date":"2020-01-03T12:37:36.000Z","updated":"2020-01-18T11:53:53.602Z","comments":true,"path":"articles/实用命令行工具-Gow/","link":"","permalink":"http://www.iamlightsmile.com/articles/实用命令行工具-Gow/","excerpt":"Windows和Linux对于程序员来说，就像张爱玲笔下的红玫瑰和白玫瑰。对于有钱的成年人来说，选择自然是“我全都要”，然而对于目前经济窘迫、只有一台爱机的我，鱼和熊掌也许并不是那么容易兼得。","text":"Windows和Linux对于程序员来说，就像张爱玲笔下的红玫瑰和白玫瑰。对于有钱的成年人来说，选择自然是“我全都要”，然而对于目前经济窘迫、只有一台爱机的我，鱼和熊掌也许并不是那么容易兼得。 0.前言Windows除了开发感觉干啥都很方便，而Linux除了开发感觉啥都不方便。Linux的很大的一个很大的优点就在于有大量丰富的命令行工具，能够在命令行里敲几个字就能解决的事情为什么要费力用鼠标点来点去呢？使用键盘的比例越高，往往说明生产效率越高。所以选择Windows作为平时的生活开发系统而言，如果Windows上也能很方便的使用那些命令行工具就很完美了，比如说head、tail等命令。而Gow(Gnu On Windows)恰恰是满足了这一需求点的近乎完美工具。 1.介绍 Gow (Gnu On Windows)是Cygwin的轻量级替代品。它使用了一个方便的Windows安装程序，安装了大约130个非常有用的开源UNIX应用程序，这些程序编译为本机win32二进制文件。它被设计为尽可能小，大约10 MB，而Cygwin根据不同的选项可以运行超过100 MB。 2.下载下载页：Releases · bmatzelle/gow如图：点击红框中的链接下载然后双击安装即可，非常简单易用~ 3.使用示例如图：","categories":[{"name":"计算机","slug":"计算机","permalink":"http://www.iamlightsmile.com/categories/计算机/"}],"tags":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.iamlightsmile.com/tags/开发工具/"},{"name":"Windows","slug":"Windows","permalink":"http://www.iamlightsmile.com/tags/Windows/"}]},{"title":"常用自然语言处理框架之StanfordNLP使用","slug":"常用自然语言处理框架之StanfordNLP使用","date":"2020-01-03T02:37:57.000Z","updated":"2020-01-03T02:52:11.399Z","comments":true,"path":"articles/常用自然语言处理框架之StanfordNLP使用/","link":"","permalink":"http://www.iamlightsmile.com/articles/常用自然语言处理框架之StanfordNLP使用/","excerpt":"","text":"使用123456789101112131415import stanfordnlp# stanfordnlp.download('zh') 从网络上下载模型文件，超级慢zh_nlp = stanfordnlp.Pipeline(lang='zh', models_dir=r\"D:\\Data\\NLP\\model\\stanfordnlp\")text = \"清华大学是一所中国的一流大学。\"zh_doc = zh_nlp(text)for i, sent in enumerate(zh_doc.sentences): print(\"[Sentence &#123;&#125;]\".format(i+1)) for word in sent.words: print(\"&#123;:12s&#125;\\t&#123;:12s&#125;\\t&#123;:6s&#125;\\t&#123;:d&#125;\\t&#123;:12s&#125;\".format(\\ word.text, word.lemma, word.pos, word.governor, word.dependency_relation)) print(\"\") 首先应该先下载模型，然而如果是直接运行stanfordnlp.download(&#39;zh&#39;)命令，那么下载速度实在是太慢了，后来把它的源码下载下来，找到了对应了文件下载地址，然后使用Chrome下载，发现速度有所提升但是也很慢，最后尝试了一下先使用Xshell登录代理浏览器下载模型，然后使用Xftp将模型传输到本地，结果速度变快了好多，尤其是代理浏览器下载模型的速度超级快，达80M/s，太惊人了。","categories":[{"name":"NLP","slug":"NLP","permalink":"http://www.iamlightsmile.com/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"http://www.iamlightsmile.com/tags/NLP/"}]},{"title":"常用自然语言处理框架之StanfordCoreNLP使用","slug":"常用自然语言处理框架之StanfordCoreNLP使用","date":"2020-01-03T02:26:54.000Z","updated":"2020-01-18T14:37:23.128Z","comments":true,"path":"articles/常用自然语言处理框架之StanfordCoreNLP使用/","link":"","permalink":"http://www.iamlightsmile.com/articles/常用自然语言处理框架之StanfordCoreNLP使用/","excerpt":"","text":"使用12345678910111213from stanfordcorenlp import StanfordCoreNLP# 加载模型nlp = StanfordCoreNLP(r\"D:\\Data\\NLP\\model\\stanford_corenlp\\stanford-corenlp-full-2018-10-05\", lang='zh')# 使用text = \"清华大学是一所中国的一流大学。\"print('Tokenize:', nlp.word_tokenize(text))print('Part of Speech:', nlp.pos_tag(text))print('Named Entities:', nlp.ner(text))print('Constituency Parsing:', nlp.parse(text))print('Dependency Parsing:', nlp.dependency_parse(text)) 参考 Python中使用Stanford CoreNLP_Mr番茄蛋的博客-CSDN博客 在Mac OS中安装和使用Stanford NLP - 简书 报错按照网上教程下载模型并且运行代码后没反应，然后搜索网上相关解决方案，找到了关于使用stanfordcorenlp一直运行不报错的解决方法 - monty12 - 博客园，并且设置了logger.DEBUG后发现了类似以下报错信息，然后继续重装Java，经过反复两次发现还是不行。 12345nitializing native server...INFO:root:java -Xmx4g -cp \"F:\\space\\wingide\\stanfordnlp\\*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000INFO:root:Server shell PID: 8504INFO:root:Waiting until the server is available.INFO:root:Waiting until the server is available. 后来从这个网址：Java SE Runtime Environment 8 - Downloads，下载了如下红框中标出的链接重新安装Java之后，才提示安装了64位，并且程序可以正常运行。","categories":[{"name":"NLP","slug":"NLP","permalink":"http://www.iamlightsmile.com/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"http://www.iamlightsmile.com/tags/NLP/"}]},{"title":"Github上开源Python仓库维护流程","slug":"Github上开源Python仓库维护流程","date":"2019-12-31T03:51:25.000Z","updated":"2020-01-18T11:56:28.758Z","comments":true,"path":"articles/Github上开源Python仓库维护流程/","link":"","permalink":"http://www.iamlightsmile.com/articles/Github上开源Python仓库维护流程/","excerpt":"stepsstep1： 明确更新缘由比如说有用户提出bug的issue，则可以考虑在空闲时分析问题甚至重现问题以寻找到bug，然后修改代码修复bug。 又如对项目进行重构或增加新的feature等，也相应的修改代码。","text":"stepsstep1： 明确更新缘由比如说有用户提出bug的issue，则可以考虑在空闲时分析问题甚至重现问题以寻找到bug，然后修改代码修复bug。 又如对项目进行重构或增加新的feature等，也相应的修改代码。 step2：对修改后代码进行测试对修改后的项目代码进行测试，以确保问题修复，或代码的修改完善并未影响其他的代码的正常运行。 step3: 根据需要修改项目配置和说明文件 在README.md中做说明。 修改setup.py文件中版本号 step4: 提交代码到Github仓库git的add、commit、push三连。 step5: 编译项目并更新到pypi源中参考我的另一篇文章：python库打包分发 | lightsmile’s Blog step6: 友好回复提出问题的用户遵守“富强、民主、文明、和谐、自由、平等、公正、法治、爱国、敬业、诚信、友善”社会主义核心价值观，和用户进行友好沟通，告知用户已解决问题或其他说明。","categories":[{"name":"计算机","slug":"计算机","permalink":"http://www.iamlightsmile.com/categories/计算机/"}],"tags":[{"name":"Github","slug":"Github","permalink":"http://www.iamlightsmile.com/tags/Github/"}]},{"title":"2019回忆总结录","slug":"2019回忆总结录","date":"2019-12-30T12:00:48.000Z","updated":"2020-01-18T11:06:08.993Z","comments":true,"path":"articles/2019回忆总结录/","link":"","permalink":"http://www.iamlightsmile.com/articles/2019回忆总结录/","excerpt":"时光匆匆如流水，眨眼间，2019年就这么过去了。距离你好，2019也马上就一年整了。","text":"时光匆匆如流水，眨眼间，2019年就这么过去了。距离你好，2019也马上就一年整了。 总体回顾这一年，也算奋斗和荒废都有。由于要考研以及积累学习，所以在2018年12月底辞职，然后回家。 在1月份，主要是学习Pytorch和torchtext，开始探索看项目源码。同时计划当一个网上的家教老师，平台是掌门，准备了一段时间，结果面试没有通过，妈了个巴子的。 在2月份开始鼓捣Manjaro，期间重装系统多次，真是痛并快乐着，现在回想起来：一方面在探索的过程中遇到困难，解决困难的历程很爽；另一方面说实在的，并没有积累到太多实用的计算机技术，有点浪费时间了（ps：Linux系统还是单独装吧，装个双系统放在普通硬盘里实在是挺慢的，可能和KDE环境占用内存较大也有关系；最近出于学习效率还是回到了Windows的怀抱，啊好香啊）。其间报了个上海的创意编程（就是教Scratch）老师，也经历了准备面试、远程面试通过等过程，然而在培训过程中感觉不太好于是主动退出了） 到了3月份，之前在网易云课堂报的自然语言处理工程师微专业开班了，于是主要是学习课程资源，积累相关知识；同时开始在Github上寻觅使用Pytorch实现的nlp任务的实现（最开始是文本分类，之后是命名实体识别），开始了不断学习源码之路；其间萌生了用torchtext照着实现一遍以增进自己对任务的理解、以及提升自己的实践动手能力的想法，便有了最初的lightNLP。同时也想着开发其他框架供自己使用，如lightKG、lightText、lightUtils。当时的定位主要是： lightNLP：lightNLP基于Pytorch和torchtext是一个深度学习自然语言处理框架，实现了如文本分类、命名实体识别、语句相似度、文本蕴涵、依存句法分析等功能。 lightKG：lightsmile个人的知识图谱框架 lightUtils：lightsmile个人的工具类库 lightText：lightText是中文文本处理框架，在设计上会包含各种词典资源，一些算法的传统或机器学习实现，包含广泛且更高级的功能，如对文本进行分析，抽取出关键词、分类、进行信息抽取等功能，会依赖于lightNLP的深度学习自然语言处理框架、lightKG的知识图谱框架、lightUitls的其他工具类库，以及包含一些词典资源等等各种资源。 到了4月份，还是继续学习网易云课堂的自然语言处理课程，当然重心已经发生了转移，因为感觉自己在Github上寻找各nlp基础任务的简单实现并阅读源码的过程中学到挺多的，更甚于网易云课堂每周一更的录制课程，所以主要还是看代码，重新实现，以及学习微专业课程。 到了5月份，家里有人生病住院，我相对空闲所以去陪护，用去了一段时间。其他主要是继续上课，和看代码和敲代码，以及一些其他娱乐活动？忘了。 剩下的6~12月份，主要是复习备考，期间有认真复习的日子，也有荒废游戏的日子，甚至于连续几天熬夜打游戏，也有熬夜看小说，并没有多刻苦，也并没有很好地执行计划并坚决执行，甚至到了后期每天的真正学习时间反而更短了。 等考完后，发现心情一般，可能是发挥的一般，尤其是数学，考的极差，做了几套往年的真题，感觉还蛮简单的，于是就放松懈怠了，导致有的大题没写，有的只写了第一问，填空和选择也有不会的；也可能是因为自己平时就没有多努力，多刻苦，所以并没有放松解脱自由的感觉。 感谢学妹临考前每天的鼓励，真的挺感动的。 等考完后，本来想说玩游戏放松，可是不知道玩什么；本来想说看小说，可是备考期间也看了；那些本应该在考完后放松的事情让我在备考期间做了个遍，真想狠狠地扇自己！ 同时自己也有太多想做的事，比如学习Vue、学习爬虫、继续完善lightNLP、继续丰富lightKG、学习fastNLP源码、学习Neo4j、阅读知识图谱技术相关论文、阅读自然语言处理相关论文等等，奈何精力有限，只能一步步慢慢来。 不得不说，这一路走来，有奋斗、也有颓废。关于内心的变化，感觉自己变得比以前更现实了，甚至是相当现实了，比去年还是满脑子空想的我相比现实的太多了。心态也更加平和、冷静，抗干扰能力有所提升，内心不会因为外界的言语有多少波动。不会再把精力浪费在认为不值得的人、不值得的事上面。把名看得更淡，把利看得更多。世界观也更加健全完善，看到世界上发生的许多事情新闻都已经很平静了。尽管几乎去年一整年没有和社会打交道，同样积累了些许人生道理。 不管满意与否，今年的历程对今后的道路会有什么影响，路都已经走过了，也不能再回头了。 无论等一个多月之后公布的考研初试成绩如何，无论在今后找工作的道路上遇到多少艰难险阻，我都会继续追求我的自然语言处理和知识图谱的理想永不放弃。 脑子里又回想起当时那个面临继续工作还是辞职考研两个选择的自己，我可以回答他：这条路走的不后悔。毕竟在月亮和六便士面前，我曾经选择了月亮。 2020，继续冲鸭！","categories":[{"name":"随念","slug":"随念","permalink":"http://www.iamlightsmile.com/categories/随念/"}],"tags":[{"name":"个人","slug":"个人","permalink":"http://www.iamlightsmile.com/tags/个人/"}]},{"title":"如何理解WordEmbedding？","slug":"如何理解WordEmbedding？","date":"2019-04-22T08:15:12.000Z","updated":"2019-04-22T08:33:36.562Z","comments":true,"path":"articles/如何理解WordEmbedding？/","link":"","permalink":"http://www.iamlightsmile.com/articles/如何理解WordEmbedding？/","excerpt":"之前自己也是懵懵懂懂的不太理解，经过一段时间的学习和思考，感觉自己有了新的认识，所以在这里分享一下，也算自己的总结了。 不谈数学原理，我认为理解Word Embedding可以从以下3个角度来理解。","text":"之前自己也是懵懵懂懂的不太理解，经过一段时间的学习和思考，感觉自己有了新的认识，所以在这里分享一下，也算自己的总结了。 不谈数学原理，我认为理解Word Embedding可以从以下3个角度来理解。 1.背景《深度学习》一书中有以下几句话，略有小改： 简单的机器学习算法的性能在很大程度上依赖于给定数据的表示。 使用机器学习来发掘表示本身的方法即表示学习。 从原始数据中提取高层次、抽象的特征是非常困难的。 深度学习通过其他较简单的表示来表达复杂表示。 我们可以认为不同数学函数的每一次应用都为输入提供了新的表示。 分布式表示的思想是系统的每一个输入都应该由多个特征表示，并且每一个特征都应该参与到多个可能输入的表示。 联结主义的中心思想是当网络把大量简单的计算单元连接在一起时可以实现智能行为。 万能近似定理表明，神经网络可以近似从任何有限离散空间映射到另一个的任意函数。 其实我认为深度学习的应用核心就是上面几句话。 接下来我拿传统的确定性算法、机器学习和深度学习做一个简单的对比。 原来对于一些流程比较清晰简单的任务，我们的做法是编写确定性的算法来实现，而对于那些很复杂的，难以用简单的规则去说明的任务通常束手无策。 机器学习的作用则是直接从数据中去学习，总结规律，但通常我们要花费大量的精力在特征工程上面，同时对于许多任务来说，我们很难知道应该提取哪些特征。而深度学习则表示：特征不用你们整，只要你们给的数据足够好，我保证给你们一个更好的模型。 上面这句话的意思是，原来特征工程的累活我们不用做了，深度学习可以自己学到好的特征，同时万能近似定理也确保了深度神经网络可以保证模型学习效果的上限很高，当前前提是我们给的数据比较好。 以上交代了下背景，接下来言归正传。 自然语言要作为神经网络模型的输入之前，我们首先需要将其映射为计算机可以表示的形式。 独热编码最简单，将每一个字或者词都唯一编码成了01向量，除了维度灾难，我认为最大的缺点就是在这一映射过程中丢掉了许多词或者字的词义和语义特征，除了表示唯一以外，不包含任意其它信息。 这时我们应该思考：那什么样的表示才算好的表示？表示中应该保留哪些特征又如何保留这些特征呢？ 怀着对上面问题的疑问，我们来看一下他山之石。 2.卷积神经网络的工作原理我们都知道卷积神经网络中最主要的部分：卷积层、池化层、激活层的作用就是提取和匹配局部特征，将特征提取结果作为全连接层的输入从而得到最终的输出。 其中的每一个卷积核都可以被视为一个特征过滤器，卷积神经网络通过依次的扫描输入并进行卷积运算提取得到哪些位置可能包含哪些特征的信息，随后这些特征位置信息被进一步的提取从而得到更高级、更抽象的特征。 举个例子，如在识别图片中是否包含人时，卷积神经网络大致的作用原理如首先提取出某些位置是否是横线、竖线还是斜线以及颜色等特征，然后对这些特征进一步组合以得到哪些位置是否包含人脸、上肢、下肢等特征，通过提取到的这些特征，神经网络就可以做出决策得到图片中是否包含人的结果。 通过了解卷积神经网络的工作原理，我们可以知道卷积神经网络的最大作用就是可以自动学习并提取局部特征。对于计算机视觉中的图片而言，最微小的组成单元是一个个的像素点，然后局部组合就得到了线条和颜色块等信息特征；而对于自然语言处理而言，最小的组成单元则是一个个的字符，如英文中的‘a’、汉字中的‘我’等。 许多计算机视觉的预训练模型都是通用的，对于具体任务，我们只需要finetune（精调）或者只学习后面的层就可以了。这其中的原理是学到的模型提取特征的能力是可复用的，不依赖于某一具体任务。同样的，如果我们可以从语料中学到词或者字的词义和语义特征就好了，之后可以直接作为词或者字的表示用于模型训练和预测，这就是词的预训练。两者有异曲同工之妙。 3.Harris提出的分布式假说及Firth对此的阐述和论证Harris曾于1954年提出分布式假说：“上下文相似的词，其语义也相似”，后来又经过Firth对该假说进行阐述和论证，“词的语义由其上下文确定”。基于该思想，我们可以从该词在语料中的上下文学习得到该词的语义，同时也可以得到相同上下文下不同的词之间的联系。 结合上文提到的分布式表示的思想，我们可以想到：我们可以用某个词以及该词所指代的实体所具备的属性和特征来表示该词。 再举个不恰当例子： 如何表示“程序猿”和“单身狗”这两个词呢？假设我们有以下特征向量序列： 123456[\"有头发\",\"人傻\",\"钱多\",\"死得快\"] 我们可以设定: 1234567程序猿 = [0.3, 0.6, 0.6, 0.6]``` 同样的，我们可以设定：```python单身狗 = [0.6, 0.7, 0.3, 0.5] 基于此，我们便得到了“程序猿”和“单身狗”的语义相似度为： \\sqrt{( 1 - \\left| 0.3 - 0.6 \\right|)^2 +( 1 - \\left| 0.6 - 0.7 \\right|)^2 + ( 1 - \\left| 0.6 - 0.3 \\right|)^2 + ( 1 - \\left| 0.6 - 0.5 \\right|)^2} = 0.72从中我们可以得到“程序猿”和“单身狗”这两个词还是挺接近的。 注意：以上具体数值和计算公式是自己瞎掰的。 具体到属性特征有哪些以及具体每个词的分量数值应该是多少，这个神经网络是可以自己去学的，只不过学到的可以被视为潜在语义信息，并不是直观的”有头发”, “人傻”, “钱多”, “死得快”等特征，通常都是不可解释的。 总之，通过类似以上的方式，单词的语义信息就被比较有效的编码和表示起来了。这时我们再回顾一下之前的Word2Vec和最近非常火的BERT，则可以被视为以上思想的工程实践。只不过训练方式和优化目标愈加完善，使得词表示可以包含更多更好的语义表示罢了。 总结机器学习也好，深度学习也罢，其任务目标都是想要学习现实世界中某些量与某些量之间的映射变化关系。只不过有的关系是线性的，比较简单，而有的则极其复杂。对于这些复杂的问题，才是深度学习的用武之地。 许多任务都可以被看作是回归或分类问题，正如老子云：“天下皆知美之为美，斯恶已。”，美丑两端即定义一个维度。 对于神经网络的理解，也可以从还原论的哲学思想来入手。 参考 Word Embeddings: Encoding Lexical Semantics [透析]卷积神经网络CNN究竟是怎样一步一步工作的？ 通俗理解word2vec 自然语言处理—-文本表示","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://www.iamlightsmile.com/categories/深度学习/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"http://www.iamlightsmile.com/tags/NLP/"},{"name":"深度学习","slug":"深度学习","permalink":"http://www.iamlightsmile.com/tags/深度学习/"}]},{"title":"大学数学与深度学习","slug":"大学数学与深度学习","date":"2019-04-22T07:45:42.000Z","updated":"2020-01-18T11:50:57.832Z","comments":true,"path":"articles/大学数学与深度学习/","link":"","permalink":"http://www.iamlightsmile.com/articles/大学数学与深度学习/","excerpt":"我们都知道，世间的万事万物都是彼此联系和不断发展的。而我们要生存发展进步，则要不断地去尝试探索理解彼此之间到底是如何联系和发展的，要得到那些定性和定量的规律，哲学和数学以及其他学问在此基础上产生不断进化繁衍。 而事物与事物之间的关联法则与映射关系即对应于数学中函数这一概念，函数即是定义和研究自变量和因变量之间的映射关系的。","text":"我们都知道，世间的万事万物都是彼此联系和不断发展的。而我们要生存发展进步，则要不断地去尝试探索理解彼此之间到底是如何联系和发展的，要得到那些定性和定量的规律，哲学和数学以及其他学问在此基础上产生不断进化繁衍。 而事物与事物之间的关联法则与映射关系即对应于数学中函数这一概念，函数即是定义和研究自变量和因变量之间的映射关系的。 事物之间的联系有简单线性的，也有复杂非线性的，对于简单线性的，古人们通过初等数学等知识即可求解，而复杂非线性的则常常无能为力。 而微积分，作为复杂函数计算的有力工具，使得我们可以解决原本无法使用初等数学知识无法解决的问题，进而极大地推动了科学的发展和技术的进步。 然而尽管如此，许多现实中的复杂问题即使是微积分也无能为力，因为我们甚至无法得到其可以用数学公式表达的形式，同时数学作为研究数与形的学问也并非能解决所有问题。 虽然不能直捣黄龙，理解许多世界中的本质规律，但是我们可以通过抽象近似和归纳统计等方式另觅它径，以达曲径通幽之妙。 如通过“以直代曲”的核心思想，我们可以把许多非线性问题近似看作线性问题，从而使用线性代数来研究其规律。 同时我们也可以使用统计学和概率学知识不去细微探索直接探究其本质关联规律，而是在基于统计的基础上跳出局部站在比较宏观的角度建立起现象与现象之间的数学关系，从而得到表层的统计规律。 再如最近很火的神经网络、深度学习等，其本质则是用含有大量参数的神经网络模型不断地优化更新参数，来去尽可能地拟合变量之间的对应关系。","categories":[{"name":"其他","slug":"其他","permalink":"http://www.iamlightsmile.com/categories/其他/"}],"tags":[{"name":"数学","slug":"数学","permalink":"http://www.iamlightsmile.com/tags/数学/"}]},{"title":"数理统计学","slug":"数理统计学","date":"2019-04-22T07:28:33.000Z","updated":"2020-01-18T12:15:54.678Z","comments":true,"path":"articles/数理统计学/","link":"","permalink":"http://www.iamlightsmile.com/articles/数理统计学/","excerpt":"","text":"数理统计学只是从数量表现的层面上来分析问题，完全不触及问题的专业内涵。 数理统计方法是一个中立性的工具，这“中立”的含义是，它既不在任何问题上有何主张，也不维护任何利益或在任何学科中坚持任何学理。 由于数理统计方法只是从表面上的数量关系来分析问题，其结论不可混同于因果关系。","categories":[{"name":"其他","slug":"其他","permalink":"http://www.iamlightsmile.com/categories/其他/"}],"tags":[{"name":"数学","slug":"数学","permalink":"http://www.iamlightsmile.com/tags/数学/"}]},{"title":"向量与矩阵","slug":"向量与矩阵","date":"2019-04-22T07:10:37.000Z","updated":"2020-01-18T11:55:38.446Z","comments":true,"path":"articles/向量与矩阵/","link":"","permalink":"http://www.iamlightsmile.com/articles/向量与矩阵/","excerpt":"线性代数的基本研究单位是向量。 向量可以视为存储信息和结构的基本量。 矩阵既可以视为一组向量的集合，也可以视为一组向量的映射关系。","text":"线性代数的基本研究单位是向量。 向量可以视为存储信息和结构的基本量。 矩阵既可以视为一组向量的集合，也可以视为一组向量的映射关系。","categories":[{"name":"其他","slug":"其他","permalink":"http://www.iamlightsmile.com/categories/其他/"}],"tags":[{"name":"数学","slug":"数学","permalink":"http://www.iamlightsmile.com/tags/数学/"}]},{"title":"大学数学基础体系脉络","slug":"大学数学基础体系脉络","date":"2019-04-22T06:50:35.000Z","updated":"2020-01-18T11:50:50.604Z","comments":true,"path":"articles/大学数学基础体系脉络/","link":"","permalink":"http://www.iamlightsmile.com/articles/大学数学基础体系脉络/","excerpt":"一般来说，问题总是可以分成两类：连续问题和离散问题。相应的，大学数学中高等数学（也就是说微积分）是用来解决连续问题的，关心的函数的变量可以都非常小；而线性代数则是用来解决离散问题的，关心的是维度。","text":"一般来说，问题总是可以分成两类：连续问题和离散问题。相应的，大学数学中高等数学（也就是说微积分）是用来解决连续问题的，关心的函数的变量可以都非常小；而线性代数则是用来解决离散问题的，关心的是维度。 以下是来自万门大学童哲校长在线性代数两日特训班中所画的简单说明图：","categories":[{"name":"其他","slug":"其他","permalink":"http://www.iamlightsmile.com/categories/其他/"}],"tags":[{"name":"数学","slug":"数学","permalink":"http://www.iamlightsmile.com/tags/数学/"}]},{"title":"整体论与还原论","slug":"整体论与还原论","date":"2019-04-22T06:26:43.000Z","updated":"2020-01-18T11:56:13.415Z","comments":true,"path":"articles/整体论与还原论/","link":"","permalink":"http://www.iamlightsmile.com/articles/整体论与还原论/","excerpt":"还原论所谓还原，是一种把复杂的系统（或者现象、过程）层层分解为其组成部分的过程。还原论认为，复杂系统可以通过它各个组成部分的行为及其相互作用来加以解释。还原论方法是迄今为止自然科学研究的最基本的方法，人们习惯于以“静止的、孤立的”观点考察组成系统诸要素的行为和性质，然后将这些性质“组装”起来形成对整个系统的描述。例如，为了考察生命，我们首先考察神经系统、消化系统、免疫系统等各个部分的功能和作用，在考察这些系统的时候我们又要了解组成它们的各个器官，要了解器官又必须考察组织，直到最后是对细胞、蛋白质、遗传物质、分子、原子等的考察。现代科学的高度发达表明，还原论是比较合理的研究方法，寻找并研究物质的最基本构件的做法当然是有价值的。","text":"还原论所谓还原，是一种把复杂的系统（或者现象、过程）层层分解为其组成部分的过程。还原论认为，复杂系统可以通过它各个组成部分的行为及其相互作用来加以解释。还原论方法是迄今为止自然科学研究的最基本的方法，人们习惯于以“静止的、孤立的”观点考察组成系统诸要素的行为和性质，然后将这些性质“组装”起来形成对整个系统的描述。例如，为了考察生命，我们首先考察神经系统、消化系统、免疫系统等各个部分的功能和作用，在考察这些系统的时候我们又要了解组成它们的各个器官，要了解器官又必须考察组织，直到最后是对细胞、蛋白质、遗传物质、分子、原子等的考察。现代科学的高度发达表明，还原论是比较合理的研究方法，寻找并研究物质的最基本构件的做法当然是有价值的。 整体论与还原论相反的是整体论，这种哲学认为，将系统打碎成为它的组成部分的做法是受限制的，对于高度复杂的系统，这种做法就行不通，因此我们应该以整体的系统论观点来考察事物。比如考察一台复杂的机器，还原论者可能会立即拿起螺丝刀和扳手将机器拆散成几千、几万个零部件，并分别进行考察，这显然耗时费力，效果还不一定很理想。整体论者不这么干，他们采取比较简单一些的办法，不拆散机器，而是试图启动运行这台机器，输入一些指令性的操作，观察机器的反应，从而建立起输入──输出之间的联系，这样就能了解整台机器的功能。整体论基本上是功能主义者，他们试图了解的主要是系统的整体功能，但对系统如何实现这些功能并不过分操心。这样做可以将问题简化，但当然也有可能会丢失一些比较重要的信息。 还原论与整体论的关系还原论与整体论之争由来已久，并且激发了脑研究和人工智能领域内的大争论。还原论方法将大脑还原为神经元，然后设法将神经元组装成大脑。人工智能的一个学派认为，通过创造元数字电路，我们能够建造越来越复杂的电路，直到我们创造人工智能。这个学派沿着现代电子计算机这条思路，对“智能”的模仿取得了初步的成功，但深入下去就比较令人失望，因为它甚至连模仿大脑的最简单功能，比如模糊记忆，都无法做到。面对人工智能研究的窘境，一些科学家从研究方法上进行反思，认为还原论方法在人工智能的研究方面没有前途，应设法采取一种更加整体的方法对待大脑，不必纠缠于人脑运作中的一些细小环节，应该建立起把大脑视为整体的模型，将大脑的一些基本功能从一开始就建造在这个模型系统里。神经网络理论基本上就是基于这样一种方法而建立起来的理论模型，这是一种功能主义的整体研究方式。这种方式现在看来也是困难重重，不过它才刚刚起步，其未来的前途如何尚未可知。 我的观点是，还原论与整体论作为两种不同的研究方法，它们本身无所谓优劣之分，我们具体选择哪种方法，这完全视乎具体情形，并取决于我们个人的喜好。在某种情形下我们采取还原的方法，在另外的情形下我们可能会采取整体论的方法，这都是可以的。但是，在大多数情况下，人们倾向于采用还原论方法，这比较可靠，也比较能够满足我们寻根究底的好奇心，所以只要有可能，人们总是乐于使用它。 事实上整体论总是只能进行一些初步的研究，一旦深入下去就必须使用还原论的方法。因此，对待自然界，我们总是首先了解其大致的、整体的规律，这是整体论的方法，接着一定要再对它层层进行还原分解，以此考察和研究它的深层次本质规律。例如为了研究人体的生物性状，我们首先了解各个系统，如消化系统、神经系统、免疫系统等的功能，这时候我们是将各个系统当作一个整体来予以研究的；而接着，我们要继续研究组成系统的各器官的功能，再接着是组织、细胞、分子、原子等层面，这便是一个逐层还原的过程。随着层层还原过程的深入，我们对人体的机制就能够得到越来越多的了解。 是的，对那些过于复杂的系统，比如人的大脑，还原论方法到达一定地步之后就会显得异常繁难，人类的心智看来根本就无法做到将其彻底还原，这时候我们不得不退而求其次，对系统的某些细节忽略不计，从而引进一种比较整体的功能主义研究方式。类似地，对于像“视窗”这样复杂的软件系统，整个系统的逻辑是非常复杂的，如果有人想要模拟而不是剽窃这个系统，最好的办法是：在了解它的功能后再另行编制一个具有几乎相同功能的系统。如果妄想将一台装有“视窗”系统的电脑拆散，从物理的角度了解整个系统的逻辑结构，然后再一一复制出来，这肯定极其艰难甚至劳而无功。所以，对人的大脑采取功能主义的整体论方式进行模拟将比还原论方法也许更为行之有效。 但是，即使对复杂系统的研究，人类的心智有时候会变得一筹莫展，这也并不意味着还原论就没有价值。因为我们需要知道：系统的表现为什么会是这样？如果我们将一部哪怕最简单的计算器拿到古代，古代的科学家也可能被迫采取整体论的方式对它进行研究，他们或许能了解其主要功能，知道它可以用于数字计算，但他们必然不清楚：它为什么会是这样的呢？这时候，他们将会多么的遗憾。对人体的研究，虽然我们很难用原子和分子的行为来计算和推导出人的行为，但我们至少希望通过原子和分子的行为来解释和理解人的行为。很显然，我们需要能够直接描述复杂系统的整体定律，所以我们有化学定律、有混沌定律、有经济学定律和社会学定律，但这些定律不会是最基本的定律，我们会问为什么？为什么这些定律是这个样子？这时候，这些定律需要用个体行为来进行解释，需要用 “部分”的行为来进行解释。 还原论的方法肯定是最基本的科学方法。但由于混沌学说的巨大成功，一些人对整体论产生了过分的自信，在今天的很大部分科学哲学家眼里，还原论变成了坏东西，他们为整体论欢呼雀跃，却想法设法要与还原论划清界限。他们走得太远了，他们将整体论的作用过于夸大了，我们有些哲学家甚至还将整体论当作哲学本体论概念来进行介绍，煞有介事地探讨起“世界是简单还是复杂的”这样一些哲学命题来。他们的道理是，整体不等于部分之和，因此自然界是不可彻底还原的，因此整体论才是最优等的哲学。 有这样一个关于还原论的笑话：老师带学生走进实验室，指着一排玻璃仪器，说那是一个人，因为玻璃瓶里装着人的所有组成物质，包括水、碳、脂肪、蛋白质……。这个笑话的实质是说，还原论者只会将“部分”简单地累加起来形成整体，却愚蠢地并不考虑“部分”之间的相互作用。 我以为，认为还原论忽视了部分之间的相互作用，这样的指责毫无根据。还原论并不忽视“部分”之间的相互作用，相反，还原的目的正是为了更好地考察这种相互作用。通过还原，“部分”之间的相互作用变成了每个“部分”的边界条件，变成了每个“部分”的输入和输出，这使得我们能更精确地考察这种作用，并建立起将这些相互作用联系起来的方程。整体确实不等于部分之和，但整体必定等于部分及其相互作用之和。 有些人认为整体论的定律才是最基本的定律，而个体的行为要通过整体的行为来解释，甚至对人类社会也必须采取整体论的方法，认为如果只考察个体，则可能忽略掉人类社会这个群体的一些性质。这种说法是相当奇怪的，人类社会的所有性质归根结底都可以从个体性质及其相互作用而得到解释，虽然我们为了方便起见，可能采取整体论的研究方式，但肯定只有这种整体论的方式才有可能丢失一些重要的信息，而还原论的方式不会。 我们经常听到这样的训诫：使用还原论要谨慎从事。使用整体论更需谨慎从事。如果只是弄出一个整体论的定律，而个体层次发生的事情都以这个整体的行为来进行解释，这样的理论体系是难以令人信服的。 不过，还原论方法虽为我们所偏爱，但还原的过程必然只能进行到一定的层次，这不仅仅因为我们的心智不够，还有更重要的原因：自然界是不可以彻底还原的。 我们知道，世界是普遍联系的，世界上每个事物都和其他每个事物联系着。但事物之间的联系是怎样实现的呢？传统观点认为：不同的东西通过大量的中介过程统一起来，这就是说，事物之间的联系是层层递进的，是定域性的，任何物体只和其邻近产生即时联系，事物的超距作用是不可能的。世界的可还原性就建立在这样的宇宙绘景中，在这样的宇宙中，我们原则上可以将任何系统从宇宙中孤立出来进行考察，这个系统的边界条件是稳定的、可知的，我们可以通过边界条件的变化掌握和了解这个系统的性质和运行规律。将系统孤立的过程就是一个还原的过程，我们可以将大系统分割成一个个的小系统，小系统再细分为更小的系统，这样层层细分下去，从而我们所处的世界至少在理论上是可以彻底还原的。 然而，量子理论表明，世界的联系并不是定域性的。宇宙中的一切物质都存在着即时的普遍联系。在量子理论中，一切事物的运动都应该用波函数来描述，而波函数是遍布整个宇宙的。我现在坐在椅子上，我的身体伴随着有一个波函数，可以肯定这个波函数的值主要集中在我身体占有的空间内，接近100%，但不可能等于100%，在宇宙的其他地方，比如在火星上也会分布有我的波函数，虽然它们的值很小，非常接近于零，但不可能等于零。如果我的身体有任何的运动或变化，比如我动一下手指头，那么伴随我身体的波函数必然也要发生变化，而这个变化产生的影响将会遍布整个宇宙！火星上的一块石头如果“足够”地灵敏，它将会“感受”到这种影响，这种影响虽然非常非常之小，非常非常接近于零，但毕竟不等于零。在这样的宇宙绘景中，宇宙是一个不可分割的整体，如果我们一定要将某个时空孤立起来进行考察，那么由于宇宙中任何的变化都对它有影响，从而它的边界条件将会是整个宇宙！这个边界条件显然是不可知的。而且，外界对系统的作用也并不局限在边界，而是“深入”到系统内的每一个“部分”，这样系统内部的作用“场”也是不可知的。因此，这样的分割还原就变得没有任何实质性的意义。 所以，当我们用还原论的方法对事物进行考察的时候，我们实际上忽略了事物之间联系的量子效应。这样的“忽略”在通常情况下不会有什么问题，毕竟我的波函数在离开我身体哪怕只有一微米的地方就将衰减到几乎为零，它太小了，完全可以忽略不计。但是在那些必须考虑量子效应的地方，比如亚原子领域、比如宇宙“创生”的过程，这样的忽略就不能允许，这时候我们不能再采用还原论的研究方法，我们必须将整个宇宙都作为一个整体来考察。 很显然，只有在局域性不能忽略的地方，还原论才原则上不可行；在不必考虑局域性的地方，还原论原则上可行！ 那么，在还原论原则上不可行的亚原子领域，还原论就没有价值了吗？我认为，还原论仍然有重大的价值。因为，即便是存在非局域性，导致还原论原则上不可行的领域，我们还是需要了解个体的性质，要通过个体的行为来理解（而不是推导）整体的行为。 参考资源 整体论 还原论 刘劲杨：论整体论与还原论之争","categories":[{"name":"其他","slug":"其他","permalink":"http://www.iamlightsmile.com/categories/其他/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"http://www.iamlightsmile.com/tags/哲学/"},{"name":"抽象","slug":"抽象","permalink":"http://www.iamlightsmile.com/tags/抽象/"}]},{"title":"线性代数","slug":"线性代数","date":"2019-04-22T06:26:05.000Z","updated":"2020-01-18T11:55:30.373Z","comments":true,"path":"articles/线性代数/","link":"","permalink":"http://www.iamlightsmile.com/articles/线性代数/","excerpt":"基本介绍线性代数是研究线性空间及其线性映射的，或者说各种线性结构和态射。 价值由于线性结构非常常见，所以线性代数的价值也相当大。","text":"基本介绍线性代数是研究线性空间及其线性映射的，或者说各种线性结构和态射。 价值由于线性结构非常常见，所以线性代数的价值也相当大。 意义和地位线性代数在数学、物理学和技术学科中有各种重要应用，因而它在各种代数分支中占居首要地位。在计算机广泛应用的今天，计算机图形学、计算机辅助设计、密码学、虚拟现实等技术无不以线性代数为其理论和算法基础的一部分。线性代数所体现的几何观念与代数方法之间的联系，从具体概念抽象出来的公理化方法以及严谨的逻辑推证、巧妙的归纳综合等，对于强化人们的数学训练，增益科学智能是非常有用的。随着科学的发展，我们不仅要研究单个变量之间的关系，还要进一步研究多个变量之间的关系，各种实际问题在大多数情况下可以线性化，而由于计算机的发展，线性化了的问题又可以被计算出来，线性代数正是解决这些问题的有力工具。线性代数的计算方法也是计算数学里一个很重要的内容。线性代数的含义随数学的发展而不断扩大。线性代数的理论和方法已经渗透到数学的许多分支，同时也是理论物理和理论化学所不可缺少的代数基础知识。 “以直代曲”是人们处理很多数学问题时一个很自然的思想。很多实际问题的处理，最后往往归结为线性问题，它比较容易处理。因此，线性代数在工程技术和国民经济的许多领域都有着广泛的应用，是一门基本的和重要的学科。 如果进入科研领域，你就会发现，只要不是线性的东西，我们基本都不会！线性是人类少数可以研究得非常透彻的数学基础性框架。学好线性代数，你就掌握了绝大多数可解问题的钥匙。有了这把钥匙，再加上相应的知识补充，你就可以求解相应的问题。可以说，不学线性代数，你就漏过了95%的人类智慧！非线性的问题极为困难，我们并没有足够多的通用的性质和定理用于求解具体问题。如果能够把非线性的问题化为线性的，这是我们一定要走的方向！ 事实上，微积分“以直代曲”的思想就是将整体非线性化为局部线性的一个经典的例子，尽管高等数学在定义微分时并没有用到一点线性代数的内容。许多非线性问题的处理――譬如流形、微分几何等，最后往往转化为线性问题。包括科学研究中，非线性模型通常也可以被近似为线性模型。随着研究对象的复杂化与抽象化，对非线性问题线性化，以及对线性问题的求解，就难免涉及到线性代数的术语和方法了。从这个意义上，线性代数可以被认为是许多近、现代数学分支的共同基础。 参考 线性代数 把非线性转化成线性","categories":[{"name":"其他","slug":"其他","permalink":"http://www.iamlightsmile.com/categories/其他/"}],"tags":[{"name":"数学","slug":"数学","permalink":"http://www.iamlightsmile.com/tags/数学/"}]},{"title":"概率论与数理统计","slug":"概率论与数理统计","date":"2019-04-22T06:25:41.000Z","updated":"2020-01-18T11:51:07.211Z","comments":true,"path":"articles/概率论与数理统计/","link":"","permalink":"http://www.iamlightsmile.com/articles/概率论与数理统计/","excerpt":"概率论与数理统计的核心是利用微积分工具研究随机现象背后的客观规律性。","text":"概率论与数理统计的核心是利用微积分工具研究随机现象背后的客观规律性。","categories":[{"name":"其他","slug":"其他","permalink":"http://www.iamlightsmile.com/categories/其他/"}],"tags":[{"name":"数学","slug":"数学","permalink":"http://www.iamlightsmile.com/tags/数学/"}]},{"title":"微积分","slug":"微积分","date":"2019-04-22T04:04:24.000Z","updated":"2020-01-18T11:55:09.259Z","comments":true,"path":"articles/微积分/","link":"","permalink":"http://www.iamlightsmile.com/articles/微积分/","excerpt":"1.极限设函数$f(x)$在点$x_0$的某一去心邻域内有定义。若存在常数$A$，对于任意给定的$\\epsilon&gt;0$（不论它多么小），总存在正数$\\delta$，使得当$0&lt;|x-x_0|&lt;\\delta$时，对应的函数值$f(x)$都满足不等式$|f(x)-A|&lt;\\epsilon$，则$A$就叫函数$f(x)$当$x\\to x_0$时的极限，记为 \\lim_{x\\to x_0}f(x)=A或 f(x)\\to A,(x\\to x_0)写成$\\epsilon-\\delta$语言是：$\\lim_{x\\to x_0}f(x)=A\\Leftrightarrow \\forall \\epsilon&gt;0,\\exists \\delta&gt;0$，当$0&lt;|x-x_0|&lt;\\delta$时，$|f(x)-A|&lt;\\epsilon$。","text":"1.极限设函数$f(x)$在点$x_0$的某一去心邻域内有定义。若存在常数$A$，对于任意给定的$\\epsilon&gt;0$（不论它多么小），总存在正数$\\delta$，使得当$0&lt;|x-x_0|&lt;\\delta$时，对应的函数值$f(x)$都满足不等式$|f(x)-A|&lt;\\epsilon$，则$A$就叫函数$f(x)$当$x\\to x_0$时的极限，记为 \\lim_{x\\to x_0}f(x)=A或 f(x)\\to A,(x\\to x_0)写成$\\epsilon-\\delta$语言是：$\\lim_{x\\to x_0}f(x)=A\\Leftrightarrow \\forall \\epsilon&gt;0,\\exists \\delta&gt;0$，当$0&lt;|x-x_0|&lt;\\delta$时，$|f(x)-A|&lt;\\epsilon$。 2.导数参见《高数18讲》p51页 1.导数的概念。 3.增量增量亦称改变量，指的是在一段时间内，自变量取不同的值所对应的函数值之差。 4.微分参见《高数18讲》p53页 5.微分的概念。 自己的浅解微分是相对于某点而言，变量的线形近似增量。 微分的意义参见《高数18讲》p53页中 6.可微的判别【注】(1)。 参考 微分符号 dx、dy 表示什么含义？ - 马同学的回答 - 知乎 积分中dx的意义是什么？ 5.积分参见《高数18讲》p110页 1.原函数与不定积分。 自己浅解微分之和即积分 6.微积分基本定理自己浅解","categories":[{"name":"其他","slug":"其他","permalink":"http://www.iamlightsmile.com/categories/其他/"}],"tags":[{"name":"数学","slug":"数学","permalink":"http://www.iamlightsmile.com/tags/数学/"}]},{"title":"Hexo主题继续优化","slug":"Hexo主题继续优化","date":"2019-04-03T16:13:11.000Z","updated":"2020-01-18T11:56:46.446Z","comments":true,"path":"articles/Hexo主题继续优化/","link":"","permalink":"http://www.iamlightsmile.com/articles/Hexo主题继续优化/","excerpt":"本次优化的方向主要围绕以下几点来展开： 自定义背景文字颜色 添加雪花特效 添加爆炸特效 添加输入特效 我当前使用的主题还是比较流行、作者一直在维护的主题Material-X.","text":"本次优化的方向主要围绕以下几点来展开： 自定义背景文字颜色 添加雪花特效 添加爆炸特效 添加输入特效 我当前使用的主题还是比较流行、作者一直在维护的主题Material-X. 自定义背景文字颜色参见Material-X doc中配色描述，将背景和文字颜色设置为暗色主题，同时将主题设置为深绿色，效果如图所示： 注意：如果是单纯修改以上内容，其实并不能生效，还要关闭主题的_config.yml文件中的cdn服务，如下图所示： 添加雪花特效从站长之家找到的JS制作雪花飘落背景动画特效, 下载后将两个js放入source目录下的js目录中，并在layout目录下的layout.ejs中添加相关script路径，如下图所示： 添加爆炸特效发现生如夏花的博客的点击效果比较炫酷，查看其发布的文章并没有介绍具体实现，于是查看其网页源码，得到了对应的fireworks.js文件，同雪花特效一样添加到指定路径并配置路径，如下图所示： 添加输入特效发现搅拌糖对主题进行了炫酷的DIY，如背景切换，滑动栏自定义等，同上查看了其网页源码，得到cooltext.js文件，同雪花特效一样添加到指定路径并配置路径，如下图所示： 经过以上步骤，hexo主题又得到了进一步的自定义优化。 ps：花了许多时间排查看板娘插件是如何出现的，自己只是安装的依赖库，并没有配置，然而却被渲染到最终的生成页面中，真是百思不得其解，由于个人不太喜欢二次元，同时手机端看起来体验不好（占了很大的空间），最终选择将依赖库移除从而去除掉了看板娘效果。","categories":[{"name":"计算机","slug":"计算机","permalink":"http://www.iamlightsmile.com/categories/计算机/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://www.iamlightsmile.com/tags/Hexo/"},{"name":"blog","slug":"blog","permalink":"http://www.iamlightsmile.com/tags/blog/"}]},{"title":"Manjaro下数据备份","slug":"Manjaro下数据备份","date":"2019-04-03T06:25:51.000Z","updated":"2020-01-18T11:57:51.931Z","comments":true,"path":"articles/Manjaro下数据备份/","link":"","permalink":"http://www.iamlightsmile.com/articles/Manjaro下数据备份/","excerpt":"Linux一时爽，崩后火葬场；Manjaro一时爽，一直用一直爽。 以下简单介绍几种manjaro下进行数据备份的方案选择以及一些使用流程。其中自己编写的使用流程如下 使用百度云盘+ baidupcs-go 使用Google Drive MEGA 使用sftp直连数据备份方案 物理介质 自己搭建私有云 选择网盘服务商 其他方案","text":"Linux一时爽，崩后火葬场；Manjaro一时爽，一直用一直爽。 以下简单介绍几种manjaro下进行数据备份的方案选择以及一些使用流程。其中自己编写的使用流程如下 使用百度云盘+ baidupcs-go 使用Google Drive MEGA 使用sftp直连数据备份方案 物理介质 自己搭建私有云 选择网盘服务商 其他方案 物理介质1. 移动硬盘优势：离线存储，简洁快速，数据安全劣势：丢失无法找回，不能自动同步 2. 移动U盘优势：离线存储，简洁快速，数据安全劣势：丢失无法找回，不能自动同步 自己搭建私有云1. Owncloud优势：数据安全劣势：搭建成本高搭建教程： 如何搭建私密云存储之ownCloud 2. NextCloud优势：数据安全劣势：搭建成本高搭建教程: Ubuntu16.04 搭建NextCloud私有云3. Seafile优势：数据安全劣势：搭建成本高搭建教程： 部署Seafile搭建自己的网盘 选择网盘服务商1. 百度网盘优势：容量大劣势：限速，建议使用 BaiduPCS-Go工具进行管理 2. Google Drive优势：跨平台劣势：需要翻墙，容量小 3. MEGA优势：Linux下使用体验好劣势： 坚果云优势：劣势：容量小 其他方案1. 有道云笔记（VIP版）和印象笔记相比，虽然网页剪裁的功能弱了一些，但是在界面上和markdown支持上都是要优于印象笔记的优势：劣势： 2. 使用sftp连接远程服务器优势：劣势： 使用流程百度网盘+BaiduPCS-Go安装baidupcs-go1yay -S baidupcs-go-bin 启动1baidupcs 如图所示： 登录1BaiduPCS-Go &gt; login 然后输入自己的账号密码，进行验证之后便登录成功了，如图： 使用输入-h可查看相关指令，下载起来速度很快。1BaiduPCS-Go &gt; -h 可参考 BaiduPCS-Go | 百度网盘命令行工具（基于 Go） Google Drive安装kio-gdrive1yay -S kio-gdrive 使用在安装成功后，此时再打开Dolphin（即文件管理器），会发现远程网络中多了一个文件夹，如图：之后我们双击它，得到如图：上图左侧的账号是我之前添加的，此时也可点击 下方+添加Google账号然后选中要同步的账号，选中，如下图所示，然后点击确定。之后右下角提示正在同步文件夹，稍等片刻便可同步成功了，如图： 可参考 KIO GDriveMEGA注册账号登录官网注册账号，填写个人信息，然后打开邮箱进行验证，随后下载客户端应用（对于manjaro来说，直接通过pacman下载就可以，就是这么方便，当然也可以先下载安装包，然后通过pacman -U来安装） 安装1yay -S megasync 设置个人信息首先[Alt] + [Space]打开plasma搜索，输入megasync打开MEGA客户端，然后输入邮箱密码，接着设置同步目录，其他设置自己看情况。如下图： 可参考 网盘可以良心到什么程度? 试试MEGA吧! 使用sftp直连使用方式很简单，如下图：双击连接网络文件夹，选择安全Shell，点击Next填写网络文件夹信息，然后点击保存并连接如果填写无误的话，就连接成功了，如图：","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"Manjaro","slug":"Manjaro","permalink":"http://www.iamlightsmile.com/tags/Manjaro/"}]},{"title":"Manjaro下vscode中zsh乱码","slug":"Manjaro下vscode中zsh乱码","date":"2019-04-03T06:24:25.000Z","updated":"2020-01-18T11:58:01.102Z","comments":true,"path":"articles/Manjaro下vscode中zsh乱码/","link":"","permalink":"http://www.iamlightsmile.com/articles/Manjaro下vscode中zsh乱码/","excerpt":"解决方案","text":"解决方案 下载Menlo for Powerline字体 1git clone https://github.com/abertsch/Menlo-for-Powerline.git 将字体放到ttf文件夹中 123cd Menlo-for-Powerlinesudo cp *.ttf* /usr/share/fonts/TTF/sudo fc-cache -f -v # 刷新字体 设置vscode中终端的字体为Menlo for Powerline 参考 在Ubuntu 18.04系统下vscode中zsh乱码的解决方法","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"Manjaro","slug":"Manjaro","permalink":"http://www.iamlightsmile.com/tags/Manjaro/"}]},{"title":"torchtext安装","slug":"torchtext安装","date":"2019-04-03T06:20:52.000Z","updated":"2020-01-18T11:58:39.823Z","comments":true,"path":"articles/torchtext安装/","link":"","permalink":"http://www.iamlightsmile.com/articles/torchtext安装/","excerpt":"","text":"使用如下命令安装torchtext1pip install https://github.com/pytorch/text/archive/master.zip","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://www.iamlightsmile.com/categories/深度学习/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"http://www.iamlightsmile.com/tags/NLP/"},{"name":"深度学习","slug":"深度学习","permalink":"http://www.iamlightsmile.com/tags/深度学习/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://www.iamlightsmile.com/tags/Pytorch/"}]},{"title":"Manjaro下截屏及设置快捷键","slug":"Manjaro下截屏及设置快捷键","date":"2019-04-03T06:19:40.000Z","updated":"2020-01-18T11:57:38.064Z","comments":true,"path":"articles/Manjaro下截屏及设置快捷键/","link":"","permalink":"http://www.iamlightsmile.com/articles/Manjaro下截屏及设置快捷键/","excerpt":"我认为当前Manjaro下最好的截屏工具要属deepin-screenshot了。","text":"我认为当前Manjaro下最好的截屏工具要属deepin-screenshot了。 下载安装 1yay -S deepin-screenshot 配置系统快捷键在【系统设置】-【工作区】-【自定义快捷键】中，点击【编辑】-【新建】-【全局快捷键】-【命令/URL：】然后填写动作名称，如我这里是Deepin截图,然后分别填写注释（非必须）、触发器和动作，如下图： 然后就可以尽情使用啦，不得不感慨deepin真的挺强挺好的！","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"Manjaro","slug":"Manjaro","permalink":"http://www.iamlightsmile.com/tags/Manjaro/"}]},{"title":"Manjaro下安装使用kenlm","slug":"Manjaro下安装使用kenlm","date":"2019-04-03T06:18:33.000Z","updated":"2020-01-18T11:57:28.664Z","comments":true,"path":"articles/Manjaro下安装使用kenlm/","link":"","permalink":"http://www.iamlightsmile.com/articles/Manjaro下安装使用kenlm/","excerpt":"kenlm是一个linux下快速轻量的语言模型训练工具。","text":"kenlm是一个linux下快速轻量的语言模型训练工具。 下载1git clone https://github.com/kpu/kenlm.git 或者1wget https://kheafield.com/code/kenlm.tar.gz | tar xz 安装依赖1yay -S boost eigen 编译安装以上两种来源区别我也不是很清楚，没有细究。12345mkdir kenlm/buildcd kenlm/buildcmake ..make -j8make install 安装Python库以上下载的文件中有python安装脚本setup.py文件，执行1python setup.py install 或者，1pip install https://github.com/kpu/kenlm/archive/master.zip 或者从pypi源安装，1pip install kenlm 训练模型准备训练数据首先我们需要有一个分好词的语料文件，如： 训练然后使用以下命令训练：1lmplz -o 3 &lt;pku_training.utf8&gt; lm_ng3.arpa 其中-o参数指明n-gram语法为3，&lt;&gt;中的为训练语料路径，后面跟模型保存路径 模型压缩对模型压缩可以提高加载速度，不压缩也可以1build_binary -s lm_ng3.arpa lm_ng3.bin 使用Python接口123456789import kenlmimport jiebamodel = kenlm.LanguageModel(&apos;./lm_ng3.bin&apos;)sent_1 = &apos;哈哈，我是李磊，你好呀&apos;sent_2 = &apos;安赛飞啊，诶爱尔兰&apos;def process(sent): return &apos; &apos;.join(jieba.cut(sent))print(model.score(process(sent_1))print(model.score(process(sent_2)) 结果输出：12-40.40456008911133-47.40667724609375 其中，分数越小，句子分数越低，越”不像“一个句子。 参考 kenlm kenlm语言模型相关，c++、python相关接口 网易云课堂-微专业-AI工程师（自然语言处理方向）","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"Manjaro","slug":"Manjaro","permalink":"http://www.iamlightsmile.com/tags/Manjaro/"}]},{"title":"Manjaro系统报错集锦","slug":"Manjaro系统报错集锦","date":"2019-04-03T06:17:26.000Z","updated":"2020-01-18T11:57:16.687Z","comments":true,"path":"articles/Manjaro系统报错集锦/","link":"","permalink":"http://www.iamlightsmile.com/articles/Manjaro系统报错集锦/","excerpt":"以下是自己在使用manjaro系统中遇到的错误和相应的解决方案 unable to initialize decompress status for section .debug_info以及file not recognized: file format not recognized 进入grub rescue模式","text":"以下是自己在使用manjaro系统中遇到的错误和相应的解决方案 unable to initialize decompress status for section .debug_info以及file not recognized: file format not recognized 进入grub rescue模式 1. unable to initialize decompress status for section .debug_info以及file not recognized: file format not recognized错误出处在安装kenlm库以及allennlp时报的安装错误; 更新：在安装scrapy框架及其依赖库twisted时也报了同样的错误，解决方法一样。 报错截图 解决方案从arch包源下载旧版的bintools,然后降级安装,如图: 参考 [SOLVED]unable to initialize decompress status for section .debug_info 2. 进入grub rescue模式错误出处在系统启动过程中由于目录分区映射及挂载失败导致 解决方案注意:我这里boot目录和根目录分别挂载在不同分区,所以后续路径可能和其他参考有所不同，在使用时视实际情况而定 确定boot目录和根目录位置12345# ls查看一下设备状态，可使用tab键自动补全，并有各分区提示信息grub rescue&gt; ls hd0, (hd0, gpt1), (hd0, gpt2), (hd0, gpt3)grub rescue&gt; ls (hd0,gpt3)/./ ../ lost+found/ 通过查看找到boot目录和root目录所在分区，比如分别为gpt1和gpt2 设置grub的启动分区和路径 1234567grub rescue&gt; set root=(hd0,gpt1) #设置grub启动分区grub rescue&gt; set prefix=(hd0,gpt1)/grub #设置grub启动路径# 查看一下设置情况,直接输入set可以查看root和prefix的配置grub rescue&gt; setprefix=(hd0,gpt1)/grubroot=hd0,gpt1 加载基本模块 1grub rescue&gt; insmod normal #加载基本模块 进入正常模式 1grub rescue&gt; normal #进入普通模式，出现菜单，如果加载grub.cfg（错误的）可能出现问题，按shift可以出现菜单，之后按c键进入控制台 进入正常模式后就会出现grub&gt;这样的提示符，在这里支持的命令就非常多了。 引导系统 1234grub&gt; set root=(hd0,gpt1) #设置正常启动分区grub&gt; linux /vmlinuz-4.19-x86_64 ro text root=/dev/sda2 #加载内核，进入控制台模式grub&gt; initrd /intel-ucode.img /initramfs-4.19-x86_64.img #加载initrd.imggrub&gt; boot #引导 更新grub 1234# 进入系统后，先更新grubupdate-grub #更新# 修改grub.cfg后，再执行installgrub-install /dev/sda #安装 注意:注意上面的是sda，硬盘号，而不是具体某个分区号，如sda1 参考 grub rescue救援模式的处理 Ubuntu开机出现grub rescue模式修复方法 Ubuntu启动问题以及Grub Rescue修复方法","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"Manjaro","slug":"Manjaro","permalink":"http://www.iamlightsmile.com/tags/Manjaro/"}]},{"title":"Tensorflow编译血泪史","slug":"Tensorflow编译血泪史","date":"2019-04-03T06:14:59.000Z","updated":"2020-01-18T11:58:32.128Z","comments":true,"path":"articles/Tensorflow编译血泪史/","link":"","permalink":"http://www.iamlightsmile.com/articles/Tensorflow编译血泪史/","excerpt":"为了安装tensorflow，导致我Linux系统重装，Windows系统差点也没了，哎。。。","text":"为了安装tensorflow，导致我Linux系统重装，Windows系统差点也没了，哎。。。 本人笔记本电脑有一个256 SSD和1TB机械硬盘，固态装C盘，机械硬盘装D、E和F，各330G，系统为Win10，显卡为NVIDIA1060。后来打算装manjaro双系统，进行编程和机器学习、深度学习的开发工作，于是F盘分了一半约160G给manjaro系统，其中根目录和家目录等单独划分分区挂载，根目录分区大小为30G，此是前话。 在安装tensorflow之前自己先装了pytorch，因为觉得这个框架代码更优雅，代码风格自己更喜欢。后来在安装tensorflow时发现还挺麻烦，需要独立cuda和cudnn库，不同版本的tensorflow依赖于不同版本的cuda和cudnn，而cuda和cudnn依赖于gcc，如下图所示。 而manjaro系统属于arch系，各软件包滚动更新速度很快，基本总是保持最新，比如系统默认python环境竟然时3.7.2，我的个乖乖，自己的系统里安装的gcc是此时最新的8.2.1，与cuda所需的gcc6冲突，如果要装gcc6还要卸载gcc8，而其他软件包会依赖于gcc8，况且安装旧版本包这种行为一点都不arch，于是使用tensorflow官方预编译好的whl文件安装就不太现实了，只能自己在本机上编译构建了，幸好网上搜到了一篇最近的、讲得很好很详细、和自己情况正相符的一篇帖子：编译 Tensorflow 1.10 + CUDA9.2 + MKL，在这里向作者由衷的表示感谢！ 于是便红红火火按照教程开始来装了，于是问题旧开始出现了。首先问题是当下载了tensorflow源码之后发现自己不能切换安装版本，如果选择默认master以外的分支，则报无法引用到/tensorflow/tools/bazel.rc文件的错误，于是只能在master分支装吧，不管了。如图： 同时发现自己访问github下载文件的速度太慢了，导致bazel程序运行失败，后来找到了相关博客如git clone速度太慢的解决办法进行配置，发现还是未解决，自己在命令前加proxychains代理也不行，因为是程序内部调用系统网络去下载文件，代理命令无效，经过多次尝试后，自己打算通过浏览器下载一个文件试试，如https://github.com/bazelbuild/rules_closure/archive/9889e2348259a5aad7e805547c1a0cf311cfcd91.tar.gz,发现下载的挺快的，是因为代理，而自己直接调用wget命令发现好慢，同时还发现了该文件的最终下载域名为：codeload.github.com，后来自己参考那个教程在https://www.ipaddress.com/里搜索得到了对应的ip并将其和ip加到hosts文件中，如图所示：速度一下就快了不少，虽说只有几十k，但是也比之前的几十几百b强，同时安装也不报下载文件失败访问不了文件的错误了。 后来又遇到：invalid conversion from &#39;const char*&#39; to &#39;char*&#39;这样的代码error，于是网上找到了invalid conversion from ‘const char‘ to ‘char‘ 的解决方法这篇文章，于是便修改了报错处的源码，重新继续编译，看着编译进行的挺顺利，自己还蛮开心的，可谁知命运给自己开的玩笑才刚刚开始。 经过了漫长的编译时间，突然又报错了，说是什么文件访问失败，没有剩余空间了，当时我就蒙了，这是咋回事，后来发现：根目录所在分区满了，安装过程中所有文件都保存在根目录所在分区，即已经到了30G了，使用df -h命令查看所在分区使用率已经到了100%，我擦！！！ 这可如何是好，没想到编译个tensorflow这么占存储空间，后来网上查找相关案例和解决方案，暂时只是把用不到的大软件卸载了，如Clion，发现效果不明显，还是占用了29G多，于是心想：老子不装了，不装了还不行吗，回归pytorch，pytorch才是老纸的真爱，卸载之后发现：使用率还是90%，这这这，后来想到满了那就扩充啊，于是就在网上找扩充根目录分区的方法教程，然而历史说明正是这一步开始使我踏进了深渊。 网上搜了不少方法，发现许多都不好使，同时分区满了我装个软件都装不了了，感觉要炸！发现有个说法说在拓展分区之前要先挂载，于是我就尝试着把根目录所在分区给挂载掉了，在卸载时还提示错误，说device is busy，于是网上找到类似如linux umount命令介绍与device is busy解决方法的答案，于是敲下了罪恶的umount -l /，后来系统崩了，重启，发现又好了，哈哈。 后来就想着硬盘F盘还有剩余空间，想划分出来给根目录所在分区，经过尝试之后发现直接划分不行，因为自己没有搞lvm，不能通过卷组或逻辑卷相关的指令操作来进行，后来发现了一个可行的法子是把硬盘中根目录所在分区位置后面的空间腾出来，然后便可以扩充了，把原来的数据放到其他位置就可以了，于是通过这样的操作进行了var挂载分区的移动，感觉还不错，其中主要参考的是linux(manjaro)磁盘迁移/opt /home,而在进行boot分区的移动时发现自己未成功进行boot分区的重新挂载，于是系统又崩了，重启也报错了，进入grub rescue模式中，此时有点慌了，后来找到类似该篇博客grub rescue救援模式的处理所说内容,重新挂载了boot目录，并且重新生成grub配置文件，于是问题解决了。 之后在进行home分区的操作时自己忘记了备份，直接挂载和格式化掉了（通过 mkfs.ext4 /dev/sda*)，发现出了问题之后重新登录都登录不了，因为相关用户信息都没了，只能进入命令行界面，同时home目录为空，后来在各分区找了半天发现没有找到备份，这时自己真的慌掉了，还有不少数据呢，比如项目代码、还有博客环境配置和博客原文件等，找了半天都没能找到可行的办法，因为系统都登录不进去，连修复软件啥的都安装不了，况且天色已晚，于是就先睡了。 等到第二天自己想到可以在window系统上安装然后修复那个分区的数据吧？于是先尝试了DiskGenius软件，发现好像它识别的分区不全，并且也只能恢复文件，会丢失文件名等信息，这样也仅是得到一些文件，不是整体的恢复分区，而后又下载了testdisk软件，经过一阵蒙蔽的操作之后，发现自己的D盘和E盘也不见了，赶忙重启发现还是没有，由于许多软件都是安装在D盘上，所以导致window系统下的环境也出问题了，要炸啊，幸亏自己的chrome浏览器在C盘装的，又下载了DiskGenius，发现还要注册，还挺麻烦，于是又尝试下了绿色破解版，经过扫描，找到了丢失的D盘和E盘，只是其他数据全部都没有了（指manjaro系统下全部信息）。哎，一声长叹之后只能重新再装系统了。 只是可惜了当时探索了不少软件，同时还有不少有用的数据资料，还有自己最新的代码，以及最新的博客环境配置文件和最新的博客原文件。 而后再划分分区安装的时候，有了之前的教训和探索，自己对分区的理解更加深刻，于是在划分时感觉熟悉了好多，把整个300G空间全部给新系统了，同时多分配了一些空间给根目录和var目录所在分区。后来重装系统，还好自己当时写了安装记录的博客在网上可以看，于是又重新安装配置环境，配置NVIDIA独显，配置科学上网，后来心想以后再做记录先只在简书和有道上吧，自己的博客先不管了吧，毕竟环境也丢了，能找到的是好久之前的了，要配置还挺麻烦，博客内容自己自己也增删改的比较多，再捡起来比较耗时，于是暂时就不考虑维护自己的博客了，之前也尝试在知乎专栏和简书上写文章，发现简书支持Markdown效果很好，而知乎则导入效果很差，于是便最终选择了简书作为最终的自己发布内容的平台啦。 后来重新参考之前提到的编译tensorflow的那篇文章，还是只能master分支，还是要配置hosts文件中github对应域名和ip，不过编译的还挺顺利的，不过还是要好久，最终吃了个晚饭，回来发现又报错了，我真的快要崩溃了，报ImportError: No module named keras.preprocessing的错误，后来我就想是不是版本问题，于是切换r1.12和r1.10，发现还是报bazel.rc文件的错，于是又切换回master分支，继续网上找相关问题和答案，并在github上成功找到了答案：1.10 build fails with “No module named ‘keras_applications’” ,即通过pip安装keras_applications和keras_preprocessing这两个库。 后来重新执行编译命令，又等待了好一会儿（比之前快多了，因为有缓存之前的编译结果），终于成功了哈哈哈！后来经过测试，发现编译成功，tensorflow已经被正常安装在自己的pip列表中了。以下是耗时截图： 安装tensorflow的whl包后，发现安装的就是现行版r1.12。。。 这里是分区使用率截图： 相比而言，pytorch安装就要简单许多了，并且提供了许多预编译好的可选。 在这里自己简单记录一下心酸的历程，也提醒各位看客同样需要编译tensorflow时留意自己的分区使用率～","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"Manjaro","slug":"Manjaro","permalink":"http://www.iamlightsmile.com/tags/Manjaro/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://www.iamlightsmile.com/tags/Tensorflow/"}]},{"title":"Manjaro下使用图床工具PicGo","slug":"Manjaro下使用图床工具PicGo","date":"2019-04-03T06:12:47.000Z","updated":"2020-01-18T11:57:44.478Z","comments":true,"path":"articles/Manjaro下使用图床工具PicGo/","link":"","permalink":"http://www.iamlightsmile.com/articles/Manjaro下使用图床工具PicGo/","excerpt":"0. 前言在这里简单吐槽以下简书的锁定文章的功能，真是日了狗了！ 因为觉得简书的锁定的文章的功能太恶心，不想受制于人，于是想回到自己的个人博客-Github Pages + Hexo，于是此时图床的问题就来了，原来自己的主要实现逻辑是将图片首先先上传到Github的一个仓库中，写了一个auto_run.sh，然后在浏览器中右击图片得到Markdown格式下的图片连接（自己写了一个浏览器插件），但是还是有些麻烦。","text":"0. 前言在这里简单吐槽以下简书的锁定文章的功能，真是日了狗了！ 因为觉得简书的锁定的文章的功能太恶心，不想受制于人，于是想回到自己的个人博客-Github Pages + Hexo，于是此时图床的问题就来了，原来自己的主要实现逻辑是将图片首先先上传到Github的一个仓库中，写了一个auto_run.sh，然后在浏览器中右击图片得到Markdown格式下的图片连接（自己写了一个浏览器插件），但是还是有些麻烦。 后来网上搜索相关图床工具，得到的方案如下： 搭建私有图床如：使用Chevereto搭建免费私有图床 使用付费图床或免费图床，同时可以配合开源跨平台的的工具PicGo付费的如：又拍云、腾讯云、阿里云、七牛云、微博免费的如：Github 其他相对非主流方案 权衡之后选择使用第二种方案，对于图床而言，自己选择Github，因为有的图床存储还要求备案，如七牛云，很是麻烦。 1. 下载安装PicGo使用如下命令：1yay -S picgo-appimage 这里对于arch系来说不算友好，因为如Windows平台、Mac平台以及其他主流Linux系统如Ubuntu等等都有预编译安装包，而对于arch而言要自己下载编译得到appimage形式的可执行软件包。 2. 设置Github仓库略，可参考最后链接给出文章。 3. 设置仓库信息略，可参考最后链接给出文章。不过我这里不知为何设置网络代理并没有成功,同时实际使用时复制速度挺慢的，不知为何。 4. 上传测试 5. 下载其他依赖如果要使用快捷上传的粘贴板功能时，如图： 还需要下载xclip包1yay -S xclip 6. 总结发现PicGo这个软件还真是挺不错的，同时还了解了appimage这种软件形式 7. 参考 Install Appimage under Arch Linux 图床工具的使用—-PicGo PicGo+GitHub图床，让Markdown飞","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"Manjaro","slug":"Manjaro","permalink":"http://www.iamlightsmile.com/tags/Manjaro/"}]},{"title":"python库打包分发","slug":"python库打包分发","date":"2019-02-02T05:11:46.000Z","updated":"2020-01-06T01:32:28.998Z","comments":true,"path":"articles/python库打包分发/","link":"","permalink":"http://www.iamlightsmile.com/articles/python库打包分发/","excerpt":"Python库打包分发主要有以下步骤： 注册PyPI账号（执行一次） 安装打包分发工具（执行一次） 编写setup.py文件 通过命令打包分发","text":"Python库打包分发主要有以下步骤： 注册PyPI账号（执行一次） 安装打包分发工具（执行一次） 编写setup.py文件 通过命令打包分发 1.注册PyPI账号进入PyPI的官网，进去注册账号密码，绑定邮箱等。 在成功注册账号之后，创建～/.pypirc文件，在文件中配置自己的PyPI访问地址和账号密码等信息，如下： 123456[distutils]index-servers = pypi[pypi]username:xxxpassword:xxx 2.安装打包分发工具这里通过twine来打包安装。 通过以下命令下载： 1pip install twine 3.编写setup.py文件格式不再详述，具体查看参考1. 举例如： 123456789101112131415161718192021222324252627282930313233from distutils.core import setupimport setuptoolswith open('./README.md', 'r', encoding='utf8') as f: long_description = f.read()with open('./requirements.txt', 'r', encoding='utf8') as f: install_requires = list(map(lambda x: x.strip(), f.readlines()))setup( name='lightNLP', version='0.3.2.0', description=\"lightsmile's nlp library\", author='lightsmile', author_email='iamlightsmile@gmail.com', url='https://github.com/smilelight/lightNLP', packages=setuptools.find_packages(), install_requires=install_requires, long_description=long_description, long_description_content_type='text/markdown', license='Apache-2.0', classifiers=[ 'Development Status :: 4 - Beta', 'Operating System :: OS Independent', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.6', 'Programming Language :: Python :: 3.7', 'Topic :: Software Development :: Libraries' ],) 4.通过命令打包分发打包在setup.py文件目录下执行： 1python setup.py sdist bdist_wheel 如果报error: invalid command &#39;bdist_wheel&#39;的错的话，可以执行以下命令： 1pip install wheel 分发在setup.py文件目录下执行： 1twine upload dist/* 后记之后便可以登录PyPI网站查看自己的projects了。需要注意的是新建包的名字不能在忽视大小写情况下和其他包重复。 参考 Python 库打包分发(setup.py 编写)简易指南 pypi twine Why is python setup.py saying invalid command ‘bdist_wheel’ on Travis CI? - Stack Overflow","categories":[{"name":"Python","slug":"Python","permalink":"http://www.iamlightsmile.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.iamlightsmile.com/tags/Python/"}]},{"title":"Manjaro设置交换分区","slug":"Manjaro设置交换分区","date":"2019-01-24T05:11:13.000Z","updated":"2020-01-18T11:57:04.397Z","comments":true,"path":"articles/Manjaro设置交换分区/","link":"","permalink":"http://www.iamlightsmile.com/articles/Manjaro设置交换分区/","excerpt":"0.前言在安装Manjaro系统的时候发现自己没有设置交换分区，用htop命令发现是空的，所以这里通过后续的命令配置交换分区。","text":"0.前言在安装Manjaro系统的时候发现自己没有设置交换分区，用htop命令发现是空的，所以这里通过后续的命令配置交换分区。 1.查看磁盘信息使用 1sudo fdisk -l 得到如下信息： 2.查看挂载状态使用 1sudo blkid -o list 得到如下信息： 3.设置交换分区使用 1mkswap /dev/sd** 其中**用具体某个分区名替换，如： 4.启用交换分区使用 1swapon /dev/sd** 其中**用具体某个分区名替换，如： 5.查看交换分区状态使用 1swapon -s 或者 1free -m 如： 6.总结至此便设置交换分区成功了。 7.参考 Swap (简体中文)) Linux系统下如何查看所有存储设备（磁盘分区）","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"Manjaro","slug":"Manjaro","permalink":"http://www.iamlightsmile.com/tags/Manjaro/"}]},{"title":"人生苦短，我用Manjaro！","slug":"人生苦短，我用Manjaro！","date":"2019-01-23T05:10:46.000Z","updated":"2020-01-18T11:53:10.664Z","comments":true,"path":"articles/人生苦短，我用Manjaro！/","link":"","permalink":"http://www.iamlightsmile.com/articles/人生苦短，我用Manjaro！/","excerpt":"想必每一个程序员心里都有一个Linux。 更新:为了便于自己下次重装系统时更方便一些，这里再把过程详细记录一下。","text":"想必每一个程序员心里都有一个Linux。 更新:为了便于自己下次重装系统时更方便一些，这里再把过程详细记录一下。 0.前言一直想学Linux，之前尝试了Ubuntu和centos，虽然两者非常大众化只是觉得有点丑，后来通过搜索了解到了Arch Linux和Manjaro，简单查看之后，觉得非常喜欢Manjaro的众多特性，于是就想着自己装一下，作为自己以后常用的Linux系统来工作。 关于Manjaro的桌面主题，主要有XFce、Gnome、KDE，同时还有社区版Deepin等，简单的对比之后，决定使用KDE，因为感觉功能更丰富。 之前在公司自己尝试着使用虚拟机装了一版，简单尝试了一下，体验还不错，只是不能使用Nvidia显卡来跑GPU程序，这就比较不爽了，毕竟是虚拟机里的东西，到底不如真机下爽快。 趁着这段时间在家相对空闲，同时Windows10下面的Pytorch突然报错（后来通过pip重新安装已修复），有点不能忍，于是打算在自己的电脑上折腾一下双系统：Windows 10 + Manjaro（KDE）。 根据我的个人体验而言，如果机子配置还可以的话，还是选择KDE版本吧，使用起来比Gnome版还是要方便高级，deepin的没试，不过风格也还不错的。 整体下来流程如下： 下载Manjaro系统镜像文件 制作启动盘及划分efi分区 安装系统 基本配置 安装常用应用 科学上网 使用Nvidia独显 系统安装过程中常见问题 更换主题 添加桌面小部件 1.下载Manjaro系统镜像文件从此处选择下载：https://www.manjaro.cn/153 建议选择中科大的镜像源，好像清华的有些时间没更新了呢。 2.制作启动盘及划分efi分区此处仅介绍Windows环境下 从rufus官网下载启动盘刻录工具 选择ISO镜像刻录到U盘，注意选择DD模式 使用diskpart划分efi分区 详情可参考此教程：manjaro双系统双硬盘的安装 3.安装系统 在电脑启动时，按F2进入BIOS系统设置，设置boot启动顺序 随后F10启动系统，按F12后选择USB启动 在进入Manjaro的boot页面时，可以选择lang为中文，driver这里我选择不开源的nonfree版本好像不行，所以我选择了默认的free版本 在分区划分时可以选择并存安装或取代一个分区，这里自己选择手动分区，划分以下分区： 挂载路径 中文目录 建议大小(至少) 其他说明 / 根目录 40G 略 /boot 启动目录 500M 略 /boot/efi 啥意思不重要 10M 略 /home 家目录 40G 平时自己的数据资料等都放下这个目录下面 /var 变量分区 30G 存放在正常运行的系统中其内容不断变化的文件 /srv 服务进程相关 10G 存放服务进程所需的数据文件和一些服务的执行脚本 /opt 其他软件安装目录 30G 发行版附加的一些软件包，如anaconda、pycharm的安装目录 注意： 不要单独挂载/usr目录到单独的分区，我就是因为这个导致了错误重装系统 如果要安装一些比较大型的软件和包时，那么建议多划分一些磁盘大小给根目录，我有两次是因为拓展根目录重装的系统 注意保留一个分区作为swap交换分区，空间大小为内存大小的一半比较合适（其实我也不是很清楚，好像其他资料有这么说） 系统安装流程可以主要参考：manjaro双系统双硬盘的安装。 关于磁盘分配可参考：manjaro 安装分区以及配置方案 4.基本配置在安装完系统后重启可能进不去桌面，此时可以在Grub菜单启动界面按[E]编辑，并在后面加上（注意空格）nouveau.modeset=1 acpi_osi=! acpi_osi=&#39;Windows 2009&#39;，然后按F10进入系统，在进入系统之后，修改grub的配置文件sudo nano /etc/default/grub，比如我的系统中部分参数如下：，随后使用sudo update-grub命令更新grub文件，在之后使用如果还是不能进入系统甚至进入grub rescue模式，原因可能是分区挂载映射问题等，可以参考我的另一篇文章。 在进入系统后要做一些常规配置。 配置更新源并更新系统 配置中国mirrors1sudo pacman-mirrors -i -c China -m rank 随后在出现的窗口中选择更新源，我选择了所有。。。哈哈 添加archlinuxcn和antergos库在/etc/pacman.conf后面添加以下内容： 1234567[archlinuxcn]SigLevel = TrustAllServer = https://mirrors.tuna.tsinghua.edu.cn/archlinuxcn/$arch[antergos]SigLevel = TrustAllServer = https://mirrors.tuna.tsinghua.edu.cn/antergos/$repo/$arch 同步并更新系统 1sudo pacman -Syyu 安装archlinuxcn签名钥匙&amp;antergos签名钥匙 1sudo pacman -S archlinuxcn-keyring antergos-keyring 安装配置中文输入法 安装搜狗拼音输入法和fcitx管理工具: 123sudo pacman -S fcitx-sougoupinyinsudo pacman -S fcitx-imsudo pacman -S fcitx-configtool 添加配置~/.xprofile文件： 123export GTK_MODULE=fcitxexport QT_IM_MODULE=fcitxexport XMODIFIERS=\"@im=fcitx\" 可参考：Manjaro linux 安装与配置 5.安装常见应用可参考：Manjaro安装后你需要这样做 以下是一些我的常用应用列表： 软件名称 软件说明 typora Markdown编辑软件 deepin-screenshot Deepin截图工具，相对很好用 latte-dock Dock栏 tmux 终端复用工具 bat 终端文件查看工具 gitkraken 跨平台git可视化操作软件 shadowsocks-qt5 科学上网 visual-studio-code-bin VSCode htop 进程查看工具 neofetch 终端查看配置 zsh 好用的shell yay 比pacman更全更好用 google-chrome chrome浏览器 pycharm 强大的Python集成开发环境 anaconda 数据科学集成环境 electronic-wechat Linux下的微信 netease-cloud-music 网易云音乐 ncdu 磁盘占用分析器 xflux flux护眼程序 redshift 同flux,护眼程序 其他的还可以安装deepin系列的微信、QQ和迅雷，只不过我这里不知为何没有安装成功。 如果有道云笔记有Linux版就爽歪歪了。 6.科学上网 使用yay -S shadowsocks-qt5安装shadowsocks软件，选择qt时直接enter选择所有 打开shadowsocks软件，填写配置信息，或者从图片导入等，然后测试延迟，点击连接，对于某一个连接，可以选择程序启动时自动连接，并且可以设置程序在系统登录时启动。如图： Shadowsocks pac代理 安装genpac 1pip install genpac 命令行生成pac文件 1genpac --proxy=\"SOCKS5 127.0.0.1:1080\" --gfwlist-proxy=\"SOCKS5 127.0.0.1:1080\" -o autoproxy.pac --gfwlist-url=\"https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt\" 设置系统自动代理在设置—&gt;网络设置—&gt;代理设置中选择自动代理，URL填写生成的PAC文件地址，file://文件路径/文件名(可以直接把文件拖到URL栏),如图：不过说实在的，不知为何我这里并没有代理成功，玉于是选择了全局代理：可参考：Manjaro17.0.1(xfce)+SS+PAC模式配置笔记linux PAC 自动代理 规则设置 终端代理 安装Proxychains 1yay -S proxychains-ng 编辑proxychains配置将最后面的socks4 127.0.0.1 9095 改为 socks5 127.0.0.1 1080如图： 可参考： Manjaro安装记录 7.使用Nvidia独显使用bumblebee版1. 安装驱动及第三方程序在[系统设置]-[硬件设定]里面选择紫色框住的video-hybrid-intel-nvidia-bumblebee，右键点击安装（不得不提真的超方便啊，和其他系统或发行版相比；注意我这里的显卡是1060，如果是9*0的版本，可能安装的是下面390xx的那个版本） 2. 修改配置文件 修改/etc/bumblebee/bumblebee.conf文件将Driver的值设置为nvidia，来让其使用nvidia驱动，其次将nvidia配置下的PMMethod的值设置为bbswitch，让它使用刚刚安装的bbswitch来进行显卡的切换。 修改（没有则新建）/etc/modprobe.d/bbswitch.conf文件添加options bbswitch load_state=0 unload_state=0来设置bbswitch的状态。 重启电脑，不然系统还不知道bbswitch模块 加载bbswitch模块 1modprobe bbswitch 将用户添加到bumblebee组中 1gpasswd -a username bumblebee 上面的username替换为自己的用户名，如我的是lightsmile 设置bumblebeed服务为开机自启 1systemctl enable bumblebeed 启用bumblebeed服务 1systemctl start bumblebeed 切换使用独显和集显。 打开独立显卡命令： 1sudo tee /proc/acpi/bbswitch &lt;&lt;&lt; ON 关闭独立显卡命令： 1sudo tee /proc/acpi/bbswitch &lt;&lt;&lt; OFF 查看nvidia显卡相关信息 1nvidia-smi 如图所示： 可参考：arch如何使用独显和Manjaro linux 安装与配置 8.系统安装过程中常见问题常见问题可参考：Manjaro linux 安装与配置 9.更换主题自己探索如图所示： 10.添加桌面小部件自己探索桌面右键，选择添加部件，然后在左侧的部件栏中自行选择想要添加的部件，然后可以在桌面中拖放，选择位置，如图： 11.小彩蛋1. 吃豆人 打开/etc/pacman.conf文件 在“# Misc options”部分，去掉“Color”前的“#”。 添加“ILoveCandy”。12.后记 最初后记安装系统容易，不过配置nvidia驱动则比较麻烦，笔者前前后后重装了不下十余次系统，苦心人天不负，最终得以成功安装，真是坑了个爹啦！ 不过最终桌面效果如下，也算小有所获啦～ 新版后记Linux一时爽，崩后火葬场。望大家小心谨慎使用系统，注意及时数据备份，要不是用于编程开发，还是Windows爸爸管着好啊！ 13.参考 Manjaro安装与基本配置 linux PAC 自动代理 规则设置 pyCharm最新2019激活码 manjaro安装及设置 人生苦短，我用Manjaro Bumblebee (简体中文) - ArchWiki) Manjaro安装以及美化教程 Manjaro安装后你需要这样做 Manjaro Deepin安装使用分享 安装Arch Linux之后要做的几件事情 我的 Manjaro🐧 - 网上冲浪指南 Manjaro linux 安装与配置 arch如何使用独显","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"Manjaro","slug":"Manjaro","permalink":"http://www.iamlightsmile.com/tags/Manjaro/"}]},{"title":"个性化hexo主题","slug":"个性化hexo主题","date":"2019-01-07T02:48:35.000Z","updated":"2020-01-18T11:51:48.008Z","comments":true,"path":"articles/个性化hexo主题/","link":"","permalink":"http://www.iamlightsmile.com/articles/个性化hexo主题/","excerpt":"个性化hexo主题1. 换Material X主题原来自己用的是indigo主题，还是蛮material的，只是后来发现material x的主题更好看，插件更加丰富一些，于是就探索切换了一番，哈哈哈。","text":"个性化hexo主题1. 换Material X主题原来自己用的是indigo主题，还是蛮material的，只是后来发现material x的主题更好看，插件更加丰富一些，于是就探索切换了一番，哈哈哈。 1. 下载主题，设置切换首先把主题下下来，然后在config文件里设置 2. 参考使用文档，添加小部件2. 增加Google统计之前看别人的博客下面有网站运行时间，很是羡慕，猜测是统计插件的原因，后来按照教程探索增加Google Analytics 统计功能，发现并不是这个原因，不过可以更详致的统计网站信息了，虽然现在只有自己看。。。 3. 增加运行时间网上搜索到教程，然后照搬小改完成，原来只是增加一个script脚本，逐渐理解其原理。 4. 增加转载说明参考别人写的个性化hexo博客里有一部分提到了此节，于是将其迁到了ejs中，发现只不过是一段模板代码，初步理解一小点hexo框架原理 5. 增加点击红心功能也是照搬教程，原来也是一段script脚本而已。 6. 增加canvas以及3D效果这个也可以实现，不过考虑实用，并没有加入 7. 增加live2d看板娘效果此技术看起来还是不错的，由于自己本身并不是二次元爱好者，所以就不考虑加入此功能了。 参考网址： 二次元live2d看板娘效果中的web前端技术 给hexo博客增加live2d看板卡通人物动画","categories":[{"name":"计算机","slug":"计算机","permalink":"http://www.iamlightsmile.com/categories/计算机/"}],"tags":[{"name":"blog","slug":"blog","permalink":"http://www.iamlightsmile.com/tags/blog/"},{"name":"hexo","slug":"hexo","permalink":"http://www.iamlightsmile.com/tags/hexo/"}]},{"title":"统计学重要知识点","slug":"统计学重要知识点","date":"2019-01-06T04:36:57.000Z","updated":"2020-01-18T11:55:03.596Z","comments":true,"path":"articles/统计学重要知识点/","link":"","permalink":"http://www.iamlightsmile.com/articles/统计学重要知识点/","excerpt":"统计学重要知识点1. 概念 概率：概率是一个事件发生、一种情况出现的可能性大小的数量指标，介于0与1之间。 分布：分布包括离散分布和连续分布，用来表述随机变量取值的概率规律。 概率密度函数（probability density function，PDF）： 在数学中，连续型随机变量的概率密度函数（在不至于混淆时可以简称为密度函数）是一个描述这个随机变量的输出值，在某个确定的取值点附近的可能性的函数。当概率密度函数存在时，累计分布函数式概率密度函数的积分。 累积分布函数（cumulative distribution function，CDF）：又叫分布函数，是概率密度函数的积分，能完整描述一个实随机变量X的概率分布，一般以大写“CDF”标记。","text":"统计学重要知识点1. 概念 概率：概率是一个事件发生、一种情况出现的可能性大小的数量指标，介于0与1之间。 分布：分布包括离散分布和连续分布，用来表述随机变量取值的概率规律。 概率密度函数（probability density function，PDF）： 在数学中，连续型随机变量的概率密度函数（在不至于混淆时可以简称为密度函数）是一个描述这个随机变量的输出值，在某个确定的取值点附近的可能性的函数。当概率密度函数存在时，累计分布函数式概率密度函数的积分。 累积分布函数（cumulative distribution function，CDF）：又叫分布函数，是概率密度函数的积分，能完整描述一个实随机变量X的概率分布，一般以大写“CDF”标记。 伯努利分布（零一分布、两点分布、0-1分布）伯努利试验成功的次数服从伯努利分布 二项分布： 重复n次独立的伯努利试验 泊松分布: 在二项分布的伯努利试验中，如果试验次数n很大，二项分布的概率p很小，且乘积$\\lambda=np$比较适中，则事件出现的次数的概率可以用泊松分布来逼近。事实上，二项分布可以看做泊松分布在离散时间上的对应物。同样的，泊松分布也可看为二项分布在特殊情况下的极限。 大数定律: 在数学与统计学中，大数定律又称大数法则、大数律，是描述相当多次数重复实验的结果的定律。根据这个定律知道，样本数量越多，则其算术平均值就有越高的概率接近期望值。大数定律很重要，因为它“说明”了一些随机事件的均值的长期稳定性。 正态分布: 正态分布又名高斯分布，是一个非常常见的连续概率分布。正态分布是自然科学与行为科学的定量现象的一个方便模型。各种各样的心理学测试分数和物理现象比如光子计数都被发现近似地服从正态分布，尽管这些现象的根本原因经常是未知的，理论上可以证明如果把许多小作用加起来看做一个变量，那么这个变量服从正态分布。 中心极限定理： 中心极限定理是指概率论中讨论随机变量序列部分和分布渐进于正态分布的一类定理。这组定理是数理统计学和误差分析的理论基础，指出了大量随机变量近似服从正态分布的条件。它是概率论中最重要的一类定理，有广泛的实际应用背景。在自然界与生产中，一些现象受到许多相互独立的随机因素的影响，如果每个因素所产生的影响都很微小时，总的影响可以看作是服从正态分布的。中心极限定理就是从数学上证明了这一现象。 离散分布：离散分布描述离散随机变量的每个值的发生概率，如伯努利分布、二项分布、泊松分布。离散随机变量是指具有可计数的值的随机变量，例如非负整数的列表。在离散概率分布中，离散随机变量的每个可能值可与一个非零概率想关联。因此，离散概率分布通常具有表格形式。 连续分布：连续分布描述连续随机变量的可能值的概率，例如正太分布。连续随机变量是一组无限且不可计数的可能值（称为范围）的随机变量。连续随机变量（X）的概率被定义为其PDF曲线下的面积。因此，只有值范围才能具有非零的概率。连续随机变量等于某个值的概率始终为零。 2. 相关1. 概率分布的种类 概率分布要么是连续概率分布，要么是离散概率分布，这取决于它们是定理连续变量还是离散变量的概率。 2. 大数定理和中心极限定理的联系和区别 大数定律（LLN）和中心极限定理（CLT）的联系与区别在于： 共同点：都是用来描述独立同分布（i.i.d）的随机变量的和的渐近表现（asymptotic behavior） 区别：它们描述的是在不同的收敛速度（convergence rate）之下的表现，其次LLN前提条件弱一点：$E(|X|) &lt; \\infty$，CLT条件强一点:$E(X^2) &lt; \\infty$。 假设有n个i.i.d的随机变量，令它们的和为$S_p = \\sum^{n}_{i=1}X_i$.大数定律（以其中弱大数定律为例）说的是$\\frac{1}{n}S_n - E(X) \\underrightarrow{P} 0$.中心极限定理说的是$\\sqrt{n}(\\frac{1}{n}S_n - E(X)) \\underrightarrow{D} N(0,E)$.作者：Detian Deng；来源：知乎；原文链接 大数定律讨论的是依概率收敛，中心极限定理涉及按分布收敛（按分布收敛比点点收敛弱很多啊）。私以为搞清楚随机变量序列的收敛性就是为了方便在样本量很大情况下计算概率。。。 大数定律是说随机变量序列的算术平均以概率收敛到其均值的算术平均。比较经典的运用就是用频率确定概率，比如估计不合格品率，抽样的不合格品比例就是可以作为总体的不合格品率估计值。 中心极限定理说的是给出随机变量和的分布函数在什么条件下收敛到正太分布。比较熟悉的比如用来估计误差，误差基本上都是由这样那样大大小小微小因素叠加的，这些个因素相加就是总的误差，这个时候就要用到参数估计和假设检验了，在认为误差近似正太分布情况下，给出误差上限下限，置信度，判断质量是否达到要求等等工作就可以做了。作者：yyylll；来源：知乎；原文链接 大数定律揭示了大量随机变量的平均结果，但没有涉及到随即变量的分布的问题。而中心极限定理说明的是在一定条件下，大量随机独立变量的平均数是以正态分布为极限的。 3. 泊松分布的现实意义 马同学的讲解：泊松分布的现实意义是什么，为什么现实生活多数服从于泊松分布？ 先说结论：泊松分布是二项分布n很大而p很小时的一种极限形式二项分布是说，已知某件事情发生的概率是p，那么做n次试验，事情发生的次数就服从于二项分布。泊松分布是指某段连续的时间内某件事情发生的次数，而且“某件事情”发生所用的时间是可以忽略的。例如，在五分钟内，电子元件遭受脉冲的次数，就服从于泊松分布。假如你把“连续的时间”分割成无数小份，那么每个小份之间都是相互独立的。在每个很小的时间区间内，电子元件都有可能“遭受到脉冲”或者“没有遭受到脉冲”，这就可以被认为是一个p很小的二项分布。而因为“连续的时间”被分割成无穷多份，因此n(试验次数)很大。所以，泊松分布可以认为是二项分布的一种极限形式。因为二项分布其实就是一个最最简单的“发生”与“不发生”的分布，它可以描述非常多的随机的自然界现象，因此其极限形式泊松分布自然也是非常有用的。作者：ctian；来源：知乎；原文链接 4. 理解概率分布函数和概率密度函数 产品经理马忠信的讲解： 应该如何理解概率分布函数和概率密度函数？ 3. 参考 连续和离散分布 泊松分布 为什么我觉得大数定理和中心极限定理是矛盾的？ 中心极限定理 中心极限定理 正态分布 二项分布、泊松分布、正态分布的关系","categories":[{"name":"其他","slug":"其他","permalink":"http://www.iamlightsmile.com/categories/其他/"}],"tags":[{"name":"数学","slug":"数学","permalink":"http://www.iamlightsmile.com/tags/数学/"},{"name":"统计学","slug":"统计学","permalink":"http://www.iamlightsmile.com/tags/统计学/"}]},{"title":"概念集锦","slug":"概念集锦","date":"2019-01-05T09:54:10.000Z","updated":"2020-01-18T11:51:22.411Z","comments":true,"path":"articles/概念集锦/","link":"","permalink":"http://www.iamlightsmile.com/articles/概念集锦/","excerpt":"数学 数学是利用符号研究数量、结构、变化以及空间等概念的一门学科，从某种角度看属于形式科学的一种。数学透过抽象化和逻辑推理的使用，由计数、计算、量度和对物体形状及运动的观察而产生。数学家们拓展这些概念，为了公式化新的猜想以及从选定的公理及定理中建立起严谨推导出的定理。","text":"数学 数学是利用符号研究数量、结构、变化以及空间等概念的一门学科，从某种角度看属于形式科学的一种。数学透过抽象化和逻辑推理的使用，由计数、计算、量度和对物体形状及运动的观察而产生。数学家们拓展这些概念，为了公式化新的猜想以及从选定的公理及定理中建立起严谨推导出的定理。 函数 函数，在数学中，为两集合间的一种对应关系：输入值集合中的每项元素皆能对应唯一一项输入值集合中的元素。 决定论 决定论，是一种哲学立场，认为每个事件的发生，包括人类的认知、举止、决定和行动，都有条件决定它发生，而非另外的事件发生。决定论认为，自然界和人类世界中普遍存在一种客观规律和因果关系。一切结果都是由先前的某种原因导致的，或者是可以根据前提条件来预测未来可能出现的结果。其重要观点即是：“有其因必有其果。”或黑格尔的“凡是合乎理性的东西都是现实的，凡是现实的东西都是合乎理性的。”","categories":[{"name":"其他","slug":"其他","permalink":"http://www.iamlightsmile.com/categories/其他/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"http://www.iamlightsmile.com/tags/哲学/"}]},{"title":"你好，2019","slug":"你好，2019","date":"2019-01-01T14:41:46.000Z","updated":"2020-01-18T11:40:41.180Z","comments":true,"path":"articles/你好，2019/","link":"","permalink":"http://www.iamlightsmile.com/articles/你好，2019/","excerpt":"再见，2018.","text":"再见，2018. 终于领悟到，自己早就已经成年，已经步入社会，该是个成熟的成年人了，不再是小孩子了。 要学会一个人照顾好自己，经营好自己，不要发脾气，不要因畏惧而胆怯。 要学会先做应该做的事，再做自己想做的事。 独自在外，要有一个人远航的心理准备，没有家和学校这样的避风港，许多事就算不想做也要去做，不要再想当然的随意而为了，要学会对自己负责，称为真正心理成熟的成年人。 凡事要做好规划，目标要明确，要有强大的执行力作为支撑，要有强大的意志力做燃料。 不要再去讲黑白对错了，社会永远都是森林法则，弱肉强食，规律如此，何来对错？学会适应这个法则吧，努力变强，什么都会有的。 不要再执念于过去了，回忆再美好也只是曾经，现在再悔恨也于事无补，把视角向前看吧。 不要再惦记喜欢的人了，现在的你配不上她。 不喜欢的饭就算难以下胃也要吃下去，不要饿肚子。 不要只有想法而不付出行动，想法谁都有，最终还是行动说明一切。 该向游戏和网络小说说再见了，不要再把精力放到没有意义的事情上去了。 过去曾经幼稚的孩子，也该死掉了。 你好，2019.","categories":[{"name":"随念","slug":"随念","permalink":"http://www.iamlightsmile.com/categories/随念/"}],"tags":[{"name":"个人","slug":"个人","permalink":"http://www.iamlightsmile.com/tags/个人/"}]},{"title":"自然语言处理（1）基本概念","slug":"自然语言处理（1）基本概念","date":"2018-05-26T14:23:47.000Z","updated":"2020-01-18T11:10:59.678Z","comments":true,"path":"articles/自然语言处理（1）基本概念/","link":"","permalink":"http://www.iamlightsmile.com/articles/自然语言处理（1）基本概念/","excerpt":"自然语言处理（Natural Language Processing，NLP）：自然语言处理是人工智能和语言学领域的分支学科，主要研究如何让计算机处理和运用自然语言。 自然语言处理广义上分为两大部分，第一部分是自然语言理解，是指让电脑“懂”人类的语言；第二部分为自然语言生成，是指把计算机数据转化为自然语言。","text":"自然语言处理（Natural Language Processing，NLP）：自然语言处理是人工智能和语言学领域的分支学科，主要研究如何让计算机处理和运用自然语言。 自然语言处理广义上分为两大部分，第一部分是自然语言理解，是指让电脑“懂”人类的语言；第二部分为自然语言生成，是指把计算机数据转化为自然语言。 自然语言处理研究的内容： 机器翻译（machine translation，MT）：实现一种语言到另一种语言的自动翻译。 自动文摘（automatic summarizing或automatic abstracting）：将原文档的主要内容和含义自动归纳、提炼出来，形成摘要或缩写。 信息检索（information retrieval）：信息检索也称情报检索，就是利用计算机系统从海量文档中找到符合用户需要的相关文档。面向两种或两种以上语言的信息检索叫做跨语言信息检索（cross-language/trans-lingual information retrieval）。 文档分类（document categorization/classification）：文档分类也称文本分类（text categorization/classification）或信息分类（information categorization/classification），其目的就是利用计算机系统对大量的文档按照一定的分类标准（例如，根据主题或内容划分等）实现自动归类。 问答系统（question-answering system）：通过计算机系统对用户提出的问题的理解，利用自动推理等手段，在有关知识资源中自动求解答案并做出相应的回答。 信息过滤（information filtering）：通过计算机系统自动识别和过滤那些满足特定条件的文档信息。通常指网络有害信息的自动识别和过滤，主要用于信息安全和防护、网络内容管理等。 信息收取（information extraction）：指从文本中收取出特定的事件（event）或事实信息，有时候又称事件抽取（event extraction）。 文本挖掘（text mining）：有时又称数据挖掘（data mining），是指从文本（多指网络文本）中获取高质量信息的过程。 舆情分析（public opinion analysis）：舆情是指在一定的社会空间内，围绕中介性社会事件的发生、发展和变化，民众对社会管理者产生和持有的社会政治态度。 隐喻计算（metaphorical computation）：“隐喻”就是用乙事物或其某种特征来描述甲事物的语言现象。简要的讲，隐喻计算就是研究自然语言语句或篇章中隐喻修辞的理解方法。 文字编辑和自动校对（automatic proofreading）：对文字拼写、用词，甚至语法、文档格式等进行自动检查、校对和编排。 作文自动评分：对作文质量和写作水平进行自动评价和打分。 光读字符识别（optical character recognition，OCR）：通过计算机系统对印刷体或手写体等文字进行自动识别，将其转换成计算机可以处理的电子文本，简称字符识别或文字识别。 语音识别（speech recognition）：将输入计算机的语音信号识别转换成书面语表示。 文语转换（text-to-speech conversion）：将书面文本自动转换成对应的语音表征，又称语音合成（speech synthesis）。 说话人识别/认证/验证（speaker recognition/identification/verification）：对一说话人的言语样本做声学分析，依据推断（确定或验证）说话人的身份。（摘自《统计自然语言处理》（第2版）） 自然语言处理涉及的几个层次：形态学（morphology）、语法学（syntax）、语义学（semantics）、语用学（pragmatics）。","categories":[{"name":"NLP","slug":"NLP","permalink":"http://www.iamlightsmile.com/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"http://www.iamlightsmile.com/tags/NLP/"}]},{"title":"腾讯云SDKforJS开发实战","slug":"腾讯云SDKforJS开发实战","date":"2018-04-21T07:31:34.000Z","updated":"2020-01-18T11:27:41.121Z","comments":true,"path":"articles/腾讯云SDKforJS开发实战/","link":"","permalink":"http://www.iamlightsmile.com/articles/腾讯云SDKforJS开发实战/","excerpt":"前面曾经提到过的，我想要把自然语言处理相关的技术接入到我的毕设微信小程序里面。 由于腾讯云未提供JS的SDK，要自己编写HTTP请求来实现，之前觉得比较麻烦，相关说明文档没有整明白，不想尝试，后来觉得既然是自己选择的路，那么无论再苦再累，都要坚持走下去，无论结果是什么，也算对得起当初自己的豪情壮志了。","text":"前面曾经提到过的，我想要把自然语言处理相关的技术接入到我的毕设微信小程序里面。 由于腾讯云未提供JS的SDK，要自己编写HTTP请求来实现，之前觉得比较麻烦，相关说明文档没有整明白，不想尝试，后来觉得既然是自己选择的路，那么无论再苦再累，都要坚持走下去，无论结果是什么，也算对得起当初自己的豪情壮志了。 再贴一下我的参考文档：腾讯云文智自然语言处理API链接 大致了解了签名方法和技术之后，我就在网上搜关于JS的HmacSHA256加密和Base64编码的函数库，发现了Crypto.js，在官网上吧zip文件下下来之后，参照一篇文章细说CryptoJs使用（微信小程序加密解密)把core.js和sha256.js和enc-base64.js的内容放到一个叫crypto.js文件中，最后再加上module.exports = CryptoJS。（话说我之前看截图里是module.export = CryptoJS，我也就照搬下来，试了半天结果总是不行，后来发现export后面还有个s，真是尬） 随后测试了一下这个函数库，经过测试发现加密的结果与API文档中的样例一致，然后就开始下一步了。 关于具体的格式我也不是很清楚，经过大胆尝试之后总是说有问题，后来只能去学习Python SDK的源码了。 通过源码的探索，我了解到了从最初的传参到生成URL的整体过程，同时也注意到了一些文档中并没有提到的细节和注意事项。然而经过测试之后还是提示说鉴权失败，我真是日了狗了。不过最终我还是成功了，下面是几个记录： 我下载的SDK是Python SDK，而我要编写的是JS代码。其中的time获取函数不同，其中Python中为int(time.time()),获取到的是整数时间戳，而JS中的则为Date.now()获取到的是以毫秒为单位的所以要做进一步的转化为Math.floor(Date.now()/1000) 同时要使用SDK必须要带要有版本号如SDK_PYTHON_2.0.13，如果没有则提示错误信息：Exception ‘Version’，而腾讯云中并没有提到这一点，所以我们必须要模拟一个，即加一个这样的参数：RequestClient=SDK_PYTHON_2.0.13 同时最最他妈的坑爹的一点就是腾讯云中明确提到了签名方式用HmacSHA1或者HmacSHA256都可以，只要参数中说明即可，即加上：SignatureMethod: ‘HmacSHA1’即可，而我之前网上搜的大多使用256，所以我也使用256，但是一直报鉴权失败的问题，可是我的签名方式（拿腾讯云提供的demo测试了一下，得到的签名一致）和参数都没有问题，困扰了好久，最终我把Python的SDK源码改了改，如修改当前时间戳Timestamp、修改随机正整数Nonce等，发现了Timestamp不能乱改，和腾讯云的服务器的时间戳间隔不能超过2小时，同时时间戳一定的情况下Nonce不能重复，后来在Python SDK上尝试使用HmacSHA256发现也报错了！我的哥！又改回HmacSHA1发现又没问题了，不会是现在腾讯云后台不支持256吧，然后我把JS的代码相关部分也改成了使用HmacSHA1，皇天不负有心人，终于他妈的成功了！不行你倒是说一声啊，同时具体的一些细节也不交代清楚。 同时还有的是JS实现网络调用的库，因为不同的引擎不同的平台所以实现肯定会有所不同，我最终搜索到了Fly.js这个很好用的库。 简体中文版说明文档链接福利在这里！Flyio帮助文档 不同的环境Fly的入口文件不同。 前面提到了腾讯云没有JS的SDK，而作为读过了Python SDK的程序员，难以控制自己想要编写自己的SDK的冲动，一方面是也算是一个挑战和尝试，一方面是这样也方便了自己的使用，最后好像是莫名的强迫症，如果不做的话实在是受不了。 于是大致样式就开始照搬Python SDK的实现，同时由于自己仅仅是小尝试，简单成功就可以了，至于module的健壮性和架构也就忽略掉了。 我的是在Webstorm上编写调试JS的，引擎是NodeJs。由于报import、from的错，所以只能含泪把es6的语法写成了CommonJS的形式。 最终的成果长成这么个吊样子，文件名为qcloud.js： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596/*不同的应用平台fly.js的引入方式不同，同时fly的内部实现也略有不同毕竟不同的平台js的引擎也不同，所以相关网络请求访问的底层实现也会有所不同比如说浏览器环境中是构造XmlHttpRequest执行ajax调用而微信小程序则是使用底层api：wx.request函数node环境依赖http模块及net模块的底层实现详情参见 https://wendux.github.io/dist/#/doc/flyio/readme不同环境下文件引入实例：具体文件自己去找，去下浏览器环境const Fly = require('./fly.umd.min')微信小程序环境const Fly = require('./fly')node环境const Fly=require(\"flyio/src/node\")*///以下是node环境下引入fly的方式const Fly = require(\"flyio/src/node\");const CryptoJS = require('./crypto');function sortKeys(obj) &#123; let newobj = &#123;&#125;; Object.keys(obj).sort().forEach(value =&gt; newobj[value] = obj[value]); return newobj&#125;function codeObj(obj) &#123; let arr = []; for (let k in obj) &#123; arr.push(k + '=' + obj[k]) &#125; return arr.join('&amp;')&#125;class QCloud &#123; constructor()&#123; this.config = &#123; protocol:'https://', path:'/v2/index.php', method:'GET', region:'gz', domain:'.api.qcloud.com', requestClient:'SDK_PYTHON_2.0.13', signatureMethod:'HmacSHA1', secretId:'', secretKey:'' &#125; this.params = &#123;&#125; &#125; init(config)&#123; Object.assign(this.config,config); this.fly = new Fly; this.fly.config.baseURL = this.config.protocol+this.config.module+this.config.domain &#125; getParams() &#123; return this.config.method+this.config.module+this.config.domain+ this.config.path+'?'+codeObj(sortKeys(this.params)) &#125; getUrl(action,params)&#123; this.initParams(); this.params.Action = action; Object.assign(this.params,params); this.sign(); return this.config.protocol+this.config.module+this.config.domain+this.config.path+'?'+this.getParams() &#125; use(action,params,fthen,fcatch)&#123; this.initParams(); this.params.Action = action; Object.assign(this.params,params) this.sign() this.request(fthen,fcatch) &#125; sign()&#123; let pa = this.getParams(); let signnature = CryptoJS.enc.Base64.stringify(CryptoJS.HmacSHA1(pa,this.config.secretKey)); this.params.Signature = signnature &#125; initParams()&#123; this.params = &#123; Region: this.config.region, Nonce: Math.floor(Math.random()*Number.MAX_SAFE_INTEGER), Timestamp: Math.floor(Date.now()/1000), RequestClient: this.config.requestClient, SignatureMethod: this.config.signatureMethod, SecretId: this.config.secretId, &#125; &#125; request(fthen,fcatch)&#123; this.fly.get(this.config.path,this.params).then(fthen).catch(fcatch) &#125;&#125;module.exports = new QCloud(); 这个不写注释的问题好像确实要改。。。 下面是测试代码文件（testMyModule.js）：12345678910111213141516const QCloud = require('./qclooud')QCloud.init(&#123; module:'wenzhi', secretId:'自己的secretId', secretKey:'自己的secretKey'&#125;)let params = &#123; 'content':'人生苦短，please Python。太祖、刘邦、朱元璋哪个更厉害？！'&#125;QCloud.use('TextClassify',params,function (responce) &#123; console.log(responce.data)&#125;,function (error) &#123; console.log(error)&#125;) 下面是输出结果：1&#123;\"code\":0,\"message\":\"\",\"codeDesc\":\"Success\",\"classes\":[&#123;\"class\":\"\\u6587\\u5316\",\"class_num\":61,\"conf\":0.713&#125;,&#123;\"class\":\"\\u5386\\u53f2\",\"class_num\":95,\"conf\":0.221&#125;,&#123;\"class\":\"\\u672a\\u5206\\u7c7b\",\"class_num\":0,\"conf\":0.066&#125;]&#125; 关于上面\\u问题的出现，我们使用eval函数把json string转成json object就可以了，如：1console.log(eval('('+responce.data+')')) 即可得下面的结果：1234567&#123; code: 0, message: '', codeDesc: 'Success', classes: [ &#123; class: '文化', class_num: 61, conf: 0.713 &#125;, &#123; class: '历史', class_num: 95, conf: 0.221 &#125;, &#123; class: '未分类', class_num: 0, conf: 0.066 &#125; ] &#125; 因为JS本身异步调用的特点，使得我们对于事件的业务逻辑处理许多时候都是通过回调函数来解决而并非Python常见的同步处理。下面是相关的Python调用示例：1234567891011121314151617181920212223242526272829303132from QcloudApi.qcloudapi import QcloudApifrom settings import secretId,secretKeyimport jsonfrom pprint import pprintmodule = 'wenzhi'config = &#123; 'secretId': secretId, 'secretKey': secretKey, 'Region': 'gz', 'method': 'POST'&#125;action = 'TextClassify' #文本分类params = &#123; 'content':'人生苦短，please Python。太祖、刘邦、朱元璋哪个更厉害？！'&#125;try: service = QcloudApi(module,config) print(service.generateUrl(action,params)) pprint(json.loads(service.call(action,params)))except Exception as e: print('Exception',e) 看起来我实现的module还是有点样子的嘛哈哈！ 我已经把相关的源码放到了我的GitHub上，欢迎各位有需要的看客们下载使用！","categories":[{"name":"Python","slug":"Python","permalink":"http://www.iamlightsmile.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.iamlightsmile.com/tags/Python/"}]},{"title":"科技发展之小感慨","slug":"科技发展之小感慨","date":"2018-04-21T07:23:00.000Z","updated":"2020-01-18T11:29:29.957Z","comments":true,"path":"articles/科技发展之小感慨/","link":"","permalink":"http://www.iamlightsmile.com/articles/科技发展之小感慨/","excerpt":"现在真的是越来越理解“人生而有涯而知也无涯”了。 现在科技发展的速度这么快，技术更迭周期越来越短，我们这些将来要搞编程的到时候真的是活到老学到老啊！ 比如近几年来大火的人工智能、云计算、大数据、机器学习、深度学习等等，还有物联网和机器人技术等，就在不久的将来，一定会极大的改变人们的生产生活方式。","text":"现在真的是越来越理解“人生而有涯而知也无涯”了。 现在科技发展的速度这么快，技术更迭周期越来越短，我们这些将来要搞编程的到时候真的是活到老学到老啊！ 比如近几年来大火的人工智能、云计算、大数据、机器学习、深度学习等等，还有物联网和机器人技术等，就在不久的将来，一定会极大的改变人们的生产生活方式。 现在发现自己真的是一个井底之蛙，所知甚少。最近接触和了解的一些工具、术语和概念简直让我头大，比如说什么Racket语言、Julia语言、Dart语言、Scala框架、Flink框架、Flutter框架、Scrapy框架等等，虽然从理论上讲这些都是术与器的层面，但是这些东西的技术覆盖面和更迭速度还是有些让我措手不及，感觉要学的东西好多啊。 哎，果然人生最重要的是要学会选择。要想得到什么，就必须要做好失去其他的心理准备。 只有与时俱进，终身学习的人才能不被这个时代落后太远。 相对来讲，如果所从事的职业是医学、法律等知识更迭速度比较慢、半衰期很长的领域，那么可能是经验越丰富越值钱，而我们搞编程的不仅是技术，甚至是思想也会变化。如果不注重培养自己的核心竞争力，稍有不慎，可能就被年轻人迎头赶上，丢掉低级码农的饭碗。 相对而言，搞纯工程以后的道路可能是技术总监、项目经理啥的，如果搞学术，可能自己真的没有这个条件了，另外的出路应该是除了计算机领域之外，去学习和掌握一些其他领域的知识智慧，做一个跨学科的交叉复合型人才，这样不仅可以更好的发展和应用该领域的知识学问，还可以使计算机更好的发挥价值吧？","categories":[{"name":"随念","slug":"随念","permalink":"http://www.iamlightsmile.com/categories/随念/"}],"tags":[{"name":"个人","slug":"个人","permalink":"http://www.iamlightsmile.com/tags/个人/"}]},{"title":"自然语言处理与知识图谱相关市场研究","slug":"自然语言处理与知识图谱相关市场研究","date":"2018-04-19T14:15:10.000Z","updated":"2020-01-18T11:10:48.304Z","comments":true,"path":"articles/自然语言处理与知识图谱相关市场研究/","link":"","permalink":"http://www.iamlightsmile.com/articles/自然语言处理与知识图谱相关市场研究/","excerpt":"经过我的探索，发现现在商用也好，学习也罢，目前提供NLP技术服务的大致分三种： 一种是大学院校的教授、助教和研究生等依托团队的学术背景和技术沉淀，通过创办规模较小的公司提供技术支持，以实现技术变现。服务对象主要为科研院所、政府部门、一些没有精力或没有必要自己去做这方面服务的大公司和一些没有条件或没有必要自己去做的中小型公司。 一种是大公司如Google、Facebook、Microsoft、阿里、腾讯、百度、华为、科大讯飞等，目前也都在这方面发力。其中关于自然语言处理方面在BAT三者之间应该是百度做的最早，目前腾讯的比较成熟，而阿里在这方面才刚刚开始，前两天才公测结束，服务正式上线日期官网说是4月23号。科大讯飞的特点应该主要是语音相关的。华为的不了解。这些公司相关领域技术自己是要自己开拓发展的。 第三种则应该是比较专业，主打自然语言处理及其衍生相关服务的了。基本上创始人和主要的技术人员都是来自国内外知名的大学和公司，有学习相关的专业技术，并有丰富的从业经验，后来自主创业，开辟相关市场，想要在自然语言处理服务领域彻底火起来之前做大做强，多吃点蛋糕。国外的有不少，国内的现在也在发展中，估计目前至少有10家公司在做相关的了。服务对象和第一种基本相同。","text":"经过我的探索，发现现在商用也好，学习也罢，目前提供NLP技术服务的大致分三种： 一种是大学院校的教授、助教和研究生等依托团队的学术背景和技术沉淀，通过创办规模较小的公司提供技术支持，以实现技术变现。服务对象主要为科研院所、政府部门、一些没有精力或没有必要自己去做这方面服务的大公司和一些没有条件或没有必要自己去做的中小型公司。 一种是大公司如Google、Facebook、Microsoft、阿里、腾讯、百度、华为、科大讯飞等，目前也都在这方面发力。其中关于自然语言处理方面在BAT三者之间应该是百度做的最早，目前腾讯的比较成熟，而阿里在这方面才刚刚开始，前两天才公测结束，服务正式上线日期官网说是4月23号。科大讯飞的特点应该主要是语音相关的。华为的不了解。这些公司相关领域技术自己是要自己开拓发展的。 第三种则应该是比较专业，主打自然语言处理及其衍生相关服务的了。基本上创始人和主要的技术人员都是来自国内外知名的大学和公司，有学习相关的专业技术，并有丰富的从业经验，后来自主创业，开辟相关市场，想要在自然语言处理服务领域彻底火起来之前做大做强，多吃点蛋糕。国外的有不少，国内的现在也在发展中，估计目前至少有10家公司在做相关的了。服务对象和第一种基本相同。 除此之外，其他的一些技术公司或大公司中则主要使用公司内部相关研发团队或技术部门主要针对与公司业务的技术和成果做一些辅助工作，不提供外部服务，没有想发展壮大的目标计划，同时种种原因也不想借助他人的服务。 在知识图谱相关应用中，有用于企业决策的，也有用于金融分析的，基本情况应该是基本类似于自然语言处理服务领域。","categories":[{"name":"NLP","slug":"NLP","permalink":"http://www.iamlightsmile.com/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"http://www.iamlightsmile.com/tags/NLP/"}]},{"title":"腾讯云-云智自然语言处理API小试","slug":"腾讯云-云智自然语言处理API小试","date":"2018-04-19T13:02:27.000Z","updated":"2020-01-18T11:27:54.512Z","comments":true,"path":"articles/腾讯云-云智自然语言处理API小试/","link":"","permalink":"http://www.iamlightsmile.com/articles/腾讯云-云智自然语言处理API小试/","excerpt":"前述（妈耶！这是昨天的文章了，昨天晚上写着写着突然断电，而我的电脑是台式机。。。） 今天在忙毕设的事情，毕设项目是做一个微计划日程管理的小程序，目前已经完成了大部分的功能。 其中包括图表统计、时间轴、四象限、小卡片、数据备份和数据还原等功能。不过今天刚通知了说审核失败，理由是身份为个人的开发者不能做备忘录相关的微信小程序。 昨天想着能不能把自己的兴趣（自然语言处理+知识图谱）和毕设结合起来，打算通过调用一些开放的自然语言处理的Restful API接口来处理一些todo、plan、target相关分析统计工作。","text":"前述（妈耶！这是昨天的文章了，昨天晚上写着写着突然断电，而我的电脑是台式机。。。） 今天在忙毕设的事情，毕设项目是做一个微计划日程管理的小程序，目前已经完成了大部分的功能。 其中包括图表统计、时间轴、四象限、小卡片、数据备份和数据还原等功能。不过今天刚通知了说审核失败，理由是身份为个人的开发者不能做备忘录相关的微信小程序。 昨天想着能不能把自己的兴趣（自然语言处理+知识图谱）和毕设结合起来，打算通过调用一些开放的自然语言处理的Restful API接口来处理一些todo、plan、target相关分析统计工作。 哈工大的ltp之前尝试过，不过现在调用的结果还是说未授权的用户，虽然网页上显示我的可使用流量还有18G之多。 复旦的话有知识工场有提供知识图谱的相关Restful API，尝试了一下感觉还可以，蛮不错的，有时间也做个记录。 以上的都是使用的是http，而小程序的request请求只能是https，所以许多方法也就都不实用了。除非自己搭设一个https的服务器，然后转接请求http请求，就和代理差不多。 一些其他公司的服务经过探索后也都是有的，比如说百度、阿里、腾讯、华为等。估计差不多都大同小异，用起来也都差不多。基本上都是提供相关平台语言SDK来服务的，如果是要自己动手去写出http请求的话，还要自己对签名进行处理等等，比较麻烦，目前并不想尝试实践。 由于先搜到的腾讯云，同时由于小程序的缘故刚注册的腾讯云的微信公共平台的账号，所以就在腾讯云上学习探索了。 发现调用的方式其实挺简单的，相关的文章网上也早已经有了。 比如说：腾讯文智自然语言处理-分词API Python小实验和开发者实验室体验之文智自然语言处理SDK by python等。 腾讯云文智自然语言处理API链接：https://cloud.tencent.com/document/api/271 下面简单的贴一下相关的代码。 虽然从逻辑上讲这些重复性的代码可以通过运用相关设计模式经验封装成模块和函数更为合理，但是这里仅是简单的测试，所以也就没继续搞了。 情感分析123456789101112131415161718192021222324252627282930313233from QcloudApi.qcloudapi import QcloudApifrom settings import secretId,secretKeyimport jsonfrom pprint import pprintmodule = 'wenzhi'config = &#123; 'secretId': secretId, 'secretKey': secretKey, 'Region': 'gz', 'method': 'POST'&#125;action = 'TextSentiment' #情感分析params = &#123; 'content': \"李亚鹏挺王菲：加油！孩他娘。\"&#125;try: service = QcloudApi(module,config) print(service.generateUrl(action,params)) pprint(json.loads(service.call(action,params)))except Exception as e: print('Exception',e) 运行结果：123456https://wenzhi.api.qcloud.com/v2/index.php&#123;'code': 0, 'codeDesc': 'Success', 'message': '', 'negative': 0.0051898001693189, 'positive': 0.99481022357941&#125; 其中的settings模块里面装有自己的secretId和secretKey，就两行代码而已：12secretId = '自己的secretId'secretKey = '自己的secretKey' 很明显无法打印出有效的URL~因为使用的方法为POST，相关的数据在请求体中而非GET方法中的请求头中。 后面的所有代码只需要修改action和params的值即可 文本抓取12345action = 'ContentGrab'# 文本抓取params = &#123; 'url': 'http://www.iamlightsmile.com'&#125; 运行结果：靠，之前还好好的，现在报错了！1234https://wenzhi.api.qcloud.com/v2/index.php&#123;'code': 4000, 'codeDesc': 'InvalidParameter', 'message': '(-100) service timeout.'&#125; 不知为啥，有时会出现如上的错误，尽管代码没有问题，多尝试几次可能就出现正常的结果了，尽管这种不确定性还是挺烦人的。。。正确结果如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879https://wenzhi.api.qcloud.com/v2/index.php&#123;'code': 0, 'codeDesc': 'Success', 'content': 'lightsmile\\n' '1459679436@qq.com\\n' \"lightsmile's Blog\\n\" \"lightsmile's Blog\\n\" ' lightsmile \\n' '2018-04-18\\n' 'GithubPages新尝试\\n' ' 由于某些不便明说的原因，我要再申请一个域名，再申请一个GitHub账号，再搞一个GitHub ' 'Pages。打算用来记录一些不便明说的东西。 ' '这次域名的申请不同于之前的在万网的iamlightsmile.com，这次是在腾讯云上申请的，不过都大同小异了。接着等待大概3天左右的实名认证，通过后域名就可以解析可用了。由于只是使用GitHub ' 'Pages 作为静态网页，不需要另外购置服务器，所以也不... 阅读全文… \\n' 'GitHub\\n' '2018-04-17\\n' '学习Python设计模式\\n' ' 本书主要参阅的书籍是《精通Python设计模式》 ' '本书分为创建型模式、结构型模式、行为型模式三大类，同时又细分为16种模式。具体到每个模式，则通过简单介绍、现实生活中例子、软件应用实例、应用场景、具体代码实现、小结几部分，多个角度加深对某个设计模式的理解。案例贴近生活，代码简单易懂，描述清晰明白，翻译水平上佳，确实算是我认为的好书，同时翻译还将代码上传到GitHub上方便读者下载学习，这里真... ' '阅读全文… \\n' '2018-04-14\\n' '推荐阅读书籍\\n' ' 此博文作为书籍阅读及相关的记录哲学篇 《和谐辩证法》 《智慧之根》 计算机篇 《统计学习理论基础》 《大数据智能》 ' '《统计自然语言处理》（第二版） 《Python自然语言处理》（第2版，没有纸质） 基础篇 《线性代数及其应用》 历史篇小说篇 ' '《天行健》 《英雄志》 《国士无双》 思维篇 《如何系统思考》 阅读全文… \\n' '2018-04-07\\n' '哈工大ltp小试\\n' ' 今天开始探索学习使用哈工大的LTP（Language Technology Platform）。 这里是官网地址 ' '这里是GitHub地址 这里是pyltp的使用文档 ' '平台采用的语言是C++，但是也提供了Python和Java的封装。由于本人目前使用Python作为自然语言处理的工具语言，所以以下的探索流程都是使用本人电脑中的Window8.1操作系统的PyCharm集成开发环境，使用的Pyt... ' '阅读全文… \\n' 'Python\\n' 'ltp\\n' '自然语言处理\\n' '2018-04-06\\n' 'Scrapy爬取知乎数据小试\\n' ' 啊啊啊，没时间写啦，以后有时间再写吧！ 。。。发现今天是周五，不熄灯。。。 ' '前两周一直在忙毕设的事情，由于某些原因毕设选择了相对简单的微信小程序，经过奋战之后一些主要的基本功能已经实现多半。 ' '自然语言处理的一些最基本的概念已经有所了解，下面想要找点实战项目练练手。由于处理的第一步便是要获取语料，想着以后爬虫这东西肯定是要学的，于是从昨天开始学习相关视频、配置相关环境，今天看了部分，照着Dem... ' '阅读全文… \\n' 'Scrapy\\n' '爬虫\\n' '2018-04-03\\n' '随想\\n' ' 其实这世上哪有什么善恶，有的只是不同环境下不同的选择。 我发现人和人相识的过程基本上都是从他的经历中提取特质然后贴上标签的过程。 ' '普天之下又有多少人敢把自己的灵魂放在阳光下炙烤呢？草他妈的！ 阅读全文… \\n' '2018-03-28\\n' '计算机\\n' '微信小程序的component\\n' ' ' '我发现无法直接在样式即wxss里通过color属性设置icon组件的颜色，是无效的，只能通过在wxml里设置它的color属性为js传入的变量值或者是通过变量值来控制具体的颜色值。 ' '我们可以将微信小程序中的components组件视为一个对象，没错，它本来就是一个对象，只是相对而言，它的初始化方法和设置方式不同于在一般的js语言中，它的data属性里是这个对象建立时初始化时的数据，作用域... ' '阅读全文… \\n' '微信小程序\\n' '2018-03-19\\n' '计算机\\n' 'learnNLTKbyWatchVideo\\n' ' The following is learning from the video:NLTK with Python 3 for ' 'Natural Language Processing.You can watch the videos in ' 'YouTube,iliibili and the author’s website: pythonprogramming.net ' 'I use jupyte... 阅读全文… \\n' 'NLTK\\n' 'Python\\n' '自然语言处理\\n' '2018-03-13\\n' '线性代数与微积分浅解\\n' ' ' '以前在大一大二时曾学过高等数学（微积分）与线性代数，不过在当时都是被动的学一学，考个分数而已，同时教授一般也都是照本宣科的围绕理论展开，平淡无味的 ' '阅读全文… \\n' '2018-03-13\\n' '《自然语言处理综论》学习笔记\\n' ' Bill Manaris 关于自然语言处理的定义 阅读全文… \\n' '博客内容遵循 知识共享 署名 - 非商业性 - 相同方式共享 4.0 国际协议\\n' '扫一扫，分享到微信\\n' '&#123;title&#125;\\n' ' &#123;tags&#125; \\n' '&#123;date&#125;\\n', 'message': '', 'title': \"lightsmile's Blog | lightsmile\"&#125; 内容转码123456action = 'ContentTranscode'# 内容转码params = &#123; 'url': 'www.iamlightsmile.com', 'to_html': 1&#125; 运行结果：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146https://wenzhi.api.qcloud.com/v2/index.php&#123;'code': 0, 'codeDesc': 'Success', 'content': '&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE html PUBLIC ' '\"-//WAPFORUM//DTD XHTML Mobile 1.0//EN\" ' '\"http://www.wapforum.org/DTD/xhtml-mobile10.dtd\"&gt;&lt;html ' 'xmlns=\"http://www.w3.org/1999/xhtml\"&gt;&lt;head&gt;&lt;meta ' 'http-equiv=\"Content-Type\" content=\"application/xhtml+xml; ' 'charset=UTF-8\"/&gt;&lt;title&gt;lightsmile\\'s Blog | ' 'lightsmile&lt;/title&gt;&lt;style type=\"text/css\"&gt;* ' '&#123;margin:0;padding:0;&#125;body &#123;font-family: ' 'Arial,Helvetica,sans-serif;&#125;a &#123;cursor: pointer;text-decoration: ' 'underline;&#125;body, div, p, a, table, textarea, form, img, ol, ul, ' 'li, h1, h2, h3, h4, h5, h6 &#123;border:0 none;&#125;#tc_content ' '&#123;font-size: 16px;line-height: 25px;word-wrap: break-word;padding: ' '5px 6px;overflow: hidden;&#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;div ' 'id=\"tc_content\"&gt;&lt;div class=\"fold_div\"&gt;&lt;a class=\"fold_a\" ' 'href=\"http://www.iamlightsmile.com##bk=1&amp;pg=1\"&gt;[展开]&amp;#160;1459679436@qq.com&amp;#160;&lt;/a&gt;&lt;/div&gt;lightsmile\\'s&amp;#160;Blog&amp;#160;&lt;br ' \"/&gt;lightsmile's&amp;#160;Blog&amp;#160;&amp;#160;lightsmile&amp;#160;&lt;br \" '/&gt;2018-04-18&amp;#160;&lt;a ' 'href=\"http://www.iamlightsmile.com/2018/04/18/GithubPages%E6%96%B0%E5%B0%9D%E8%AF%95/\" ' 'position=\"6\"&gt;GithubPages新尝试&lt;/a&gt;&amp;#160;由于某些不便明说的原因，我要再申请一个域名，再申请一个GitHub账号，再搞一个GitHub&amp;#160;Pages。打算用来记录一些不便明说的东西。\\n' '这次域名的申请不同于之前的在万网的iamlightsmile.com，这次是在腾讯云上申请的，不过都大同小异了。接着等待大概3天左右的实名认证，通过后域名就可以解析可用了。由于只是使用GitHub&amp;#160;Pages&amp;#160;作为静态网页，不需要另外购置服务器，所以也不...\\n' '&lt;a ' 'href=\"http://www.iamlightsmile.com/2018/04/18/GithubPages%E6%96%B0%E5%B0%9D%E8%AF%95/\" ' 'position=\"6\"&gt;阅读全文…&lt;/a&gt; &lt;a ' 'href=\"http://www.iamlightsmile.com/tags/GitHub/\" ' 'position=\"6\"&gt;GitHub&lt;/a&gt; &lt;br /&gt;2018-04-17&amp;#160;&lt;a ' 'href=\"http://www.iamlightsmile.com/2018/04/17/%E5%AD%A6%E4%B9%A0Python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/\" ' 'position=\"6\"&gt;学习Python设计模式&lt;/a&gt; &lt;br ' '/&gt;&amp;#160;本书主要参阅的书籍是《精通Python设计模式》\\n' '本书分为创建型模式、结构型模式、行为型模式三大类，同时又细分为16种模式。具体到每个模式，则通过简单介绍、现实生活中例子、软件应用实例、应用场景、具体代码实现、小结几部分，多个角度加深对某个设计模式的理解。案例贴近生活，代码简单易懂，描述清晰明白，翻译水平上佳，确实算是我认为的好书，同时翻译还将代码上传到GitHub上方便读者下载学习，这里真...\\n' '&lt;a ' 'href=\"http://www.iamlightsmile.com/2018/04/17/%E5%AD%A6%E4%B9%A0Python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/\" ' 'position=\"6\"&gt;阅读全文…&lt;/a&gt; &lt;br /&gt;2018-04-14&amp;#160;&lt;a ' 'href=\"http://www.iamlightsmile.com/2018/04/14/%E6%8E%A8%E8%8D%90%E9%98%85%E8%AF%BB%E4%B9%A6%E7%B1%8D/\" ' 'position=\"6\"&gt;推荐阅读书籍&lt;/a&gt; &lt;br /&gt;&amp;#160;此博文作为书籍阅读及相关的记录哲学篇\\n' '《和谐辩证法》\\n' '《智慧之根》\\n' '计算机篇\\n' '《统计学习理论基础》\\n' '《大数据智能》\\n' '《统计自然语言处理》（第二版）\\n' '《Python自然语言处理》（第2版，没有纸质）\\n' '基础篇\\n' '《线性代数及其应用》\\n' '历史篇小说篇\\n' '《天行健》\\n' '《英雄志》\\n' '《国士无双》\\n' '思维篇\\n' '《如何系统思考》\\n' '&lt;a ' 'href=\"http://www.iamlightsmile.com/2018/04/14/%E6%8E%A8%E8%8D%90%E9%98%85%E8%AF%BB%E4%B9%A6%E7%B1%8D/\" ' 'position=\"6\"&gt;阅读全文…&lt;/a&gt; &lt;br /&gt;2018-04-07&amp;#160;&lt;a ' 'href=\"http://www.iamlightsmile.com/2018/04/07/%E5%93%88%E5%B7%A5%E5%A4%A7ltp%E5%B0%8F%E8%AF%95/\" ' 'position=\"6\"&gt;哈工大ltp小试&lt;/a&gt; &lt;br ' '/&gt;&amp;#160;今天开始探索学习使用哈工大的LTP（Language&amp;#160;Technology&amp;#160;Platform）。\\n' '这里是官网地址\\n' '这里是GitHub地址\\n' '这里是pyltp的使用文档\\n' '平台采用的语言是C++，但是也提供了Python和Java的封装。由于本人目前使用Python作为自然语言处理的工具语言，所以以下的探索流程都是使用本人电脑中的Window8.1操作系统的PyCharm集成开发环境，使用的Pyt...\\n' '&lt;a ' 'href=\"http://www.iamlightsmile.com/2018/04/07/%E5%93%88%E5%B7%A5%E5%A4%A7ltp%E5%B0%8F%E8%AF%95/\" ' 'position=\"6\"&gt;阅读全文…&lt;/a&gt; &lt;br /&gt;&lt;a ' 'href=\"http://www.iamlightsmile.com/tags/Python/\" ' 'position=\"6\"&gt;Python&lt;/a&gt; &lt;a ' 'href=\"http://www.iamlightsmile.com/tags/ltp/\" ' 'position=\"6\"&gt;ltp&lt;/a&gt; &lt;a ' 'href=\"http://www.iamlightsmile.com/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/\" ' 'position=\"6\"&gt;自然语言处理&lt;/a&gt; &lt;br /&gt;2018-04-06&amp;#160;&lt;a ' 'href=\"http://www.iamlightsmile.com/2018/04/06/Scrapy%E7%88%AC%E5%8F%96%E7%9F%A5%E4%B9%8E%E6%95%B0%E6%8D%AE%E5%B0%8F%E8%AF%95/\" ' 'position=\"6\"&gt;Scrapy爬取知乎数据小试&lt;/a&gt; &lt;br /&gt;&amp;#160;啊啊啊，没时间写啦，以后有时间再写吧！\\n' '。。。发现今天是周五，不熄灯。。。\\n' '前两周一直在忙毕设的事情，由于某些原因毕设选择了相对简单的微信小程序，经过奋战之后一些主要的基本功能已经实现多半。\\n' '自然语言处理的一些最基本的概念已经有所了解，下面想要找点实战项目练练手。由于处理的第一步便是要获取语料，想着以后爬虫这东西肯定是要学的，于是从昨天开始学习相关视频、配置相关环境，今天看了部分，照着Dem...\\n' '&lt;a ' 'href=\"http://www.iamlightsmile.com/2018/04/06/Scrapy%E7%88%AC%E5%8F%96%E7%9F%A5%E4%B9%8E%E6%95%B0%E6%8D%AE%E5%B0%8F%E8%AF%95/\" ' 'position=\"6\"&gt;阅读全文…&lt;/a&gt; &lt;br /&gt;&lt;a ' 'href=\"http://www.iamlightsmile.com/tags/Scrapy/\" ' 'position=\"6\"&gt;Scrapy&lt;/a&gt; &lt;a ' 'href=\"http://www.iamlightsmile.com/tags/%E7%88%AC%E8%99%AB/\" ' 'position=\"6\"&gt;爬虫&lt;/a&gt; &lt;br /&gt;2018-04-03&amp;#160;&lt;a ' 'href=\"http://www.iamlightsmile.com/2018/04/03/%E9%9A%8F%E6%83%B3/\" ' 'position=\"6\"&gt;随想&lt;/a&gt; &lt;br /&gt;&amp;#160;其实这世上哪有什么善恶，有的只是不同环境下不同的选择。\\n' '我发现人和人相识的过程基本上都是从他的经历中提取特质然后贴上标签的过程。\\n' '普天之下又有多少人敢把自己的灵魂放在阳光下炙烤呢？草他妈的！\\n' '&lt;a ' 'href=\"http://www.iamlightsmile.com/2018/04/03/%E9%9A%8F%E6%83%B3/\" ' 'position=\"6\"&gt;阅读全文…&lt;/a&gt; &lt;br /&gt;2018-03-28&amp;#160;&lt;a ' 'href=\"http://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/\" ' 'position=\"6\"&gt;计算机&lt;/a&gt; &lt;br /&gt;&lt;a ' 'href=\"http://www.iamlightsmile.com/2018/03/28/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%8E%A2%E7%B4%A2%E9%9A%8F%E7%AC%94/\" ' 'position=\"6\"&gt;微信小程序的component&lt;/a&gt; &lt;br ' '/&gt;&amp;#160;我发现无法直接在样式即wxss里通过color属性设置icon组件的颜色，是无效的，只能通过在wxml里设置它的color属性为js传入的变量值或者是通过变量值来控制具体的颜色值。\\n' '我们可以将微信小程序中的components组件视为一个对象，没错，它本来就是一个对象，只是相对而言，它的初始化方法和设置方式不同于在一般的js语言中，它的data属性里是这个对象建立时初始化时的数据，作用域...\\n' '&lt;a ' 'href=\"http://www.iamlightsmile.com/2018/03/28/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%8E%A2%E7%B4%A2%E9%9A%8F%E7%AC%94/\" ' 'position=\"6\"&gt;阅读全文…&lt;/a&gt; &lt;br /&gt;&lt;a ' 'href=\"http://www.iamlightsmile.com/tags/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F/\" ' 'position=\"6\"&gt;微信小程序&lt;/a&gt; &lt;br /&gt;2018-03-19&amp;#160;&lt;a ' 'href=\"http://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/\" ' 'position=\"6\"&gt;计算机&lt;/a&gt; &lt;br /&gt;&lt;a ' 'href=\"http://www.iamlightsmile.com/2018/03/19/learnNLTKbyWatchVideo/\" ' 'position=\"6\"&gt;learnNLTKbyWatchVideo&lt;/a&gt; &lt;br ' '/&gt;&amp;#160;The&amp;#160;following&amp;#160;is&amp;#160;learning&amp;#160;from&amp;#160;the&amp;#160;video:NLTK&amp;#160;with&amp;#160;Python&amp;#160;3&amp;#160;for&amp;#160;Natural&amp;#160;Language&amp;#160;Processing.You&amp;#160;can&amp;#160;watch&amp;#160;the&amp;#160;videos&amp;#160;in&amp;#160;YouTube,iliibili&amp;#160;and&amp;#160;the&amp;#160;author’s&amp;#160;website:&amp;#160;pythonprogramming.net\\n' 'I&amp;#160;use&amp;#160;jupyte...\\n' '&lt;a ' 'href=\"http://www.iamlightsmile.com/2018/03/19/learnNLTKbyWatchVideo/\" ' 'position=\"6\"&gt;阅读全文…&lt;/a&gt; &lt;br /&gt;&lt;a ' 'href=\"http://www.iamlightsmile.com/tags/NLTK/\" ' 'position=\"6\"&gt;NLTK&lt;/a&gt; &lt;a ' 'href=\"http://www.iamlightsmile.com/tags/Python/\" ' 'position=\"6\"&gt;Python&lt;/a&gt; &lt;a ' 'href=\"http://www.iamlightsmile.com/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/\" ' 'position=\"6\"&gt;自然语言处理&lt;/a&gt; &lt;br /&gt;2018-03-13&amp;#160;&lt;a ' 'href=\"http://www.iamlightsmile.com/2018/03/13/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E5%BE%AE%E7%A7%AF%E5%88%86%E6%B5%85%E8%A7%A3/\" ' 'position=\"6\"&gt;线性代数与微积分浅解&lt;/a&gt; &lt;br ' '/&gt;&amp;#160;以前在大一大二时曾学过高等数学（微积分）与线性代数，不过在当时都是被动的学一学，考个分数而已，同时教授一般也都是照本宣科的围绕理论展开，平淡无味的\\n' '&lt;a ' 'href=\"http://www.iamlightsmile.com/2018/03/13/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E5%BE%AE%E7%A7%AF%E5%88%86%E6%B5%85%E8%A7%A3/\" ' 'position=\"6\"&gt;阅读全文…&lt;/a&gt; &lt;br /&gt;2018-03-13&amp;#160;&lt;a ' 'href=\"http://www.iamlightsmile.com/2018/03/13/%E3%80%8A%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%BB%BC%E8%AE%BA%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/\" ' 'position=\"6\"&gt;《自然语言处理综论》学习笔记&lt;/a&gt; &lt;br ' '/&gt;&amp;#160;Bill&amp;#160;Manaris&amp;#160;关于自然语言处理的定义\\n' '&lt;a ' 'href=\"http://www.iamlightsmile.com/2018/03/13/%E3%80%8A%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%BB%BC%E8%AE%BA%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/\" ' 'position=\"6\"&gt;阅读全文…&lt;/a&gt; &lt;br /&gt;1&amp;#160;&lt;a ' 'href=\"http://www.iamlightsmile.com/page/2/\" ' 'position=\"786432\"&gt;2&lt;/a&gt; &lt;a ' 'href=\"http://www.iamlightsmile.com/page/3/\" ' 'position=\"786432\"&gt;3&lt;/a&gt; &lt;a ' 'href=\"http://www.iamlightsmile.com/page/4/\" ' 'position=\"786432\"&gt;4&lt;/a&gt; &lt;a ' 'href=\"http://www.iamlightsmile.com/page/2/\" ' 'position=\"786432\"&gt;下一页&lt;/a&gt; &lt;br /&gt;博客内容遵循&amp;#160;&lt;a ' 'href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh\" ' 'position=\"6\"&gt;知识共享&amp;#160;署名&amp;#160;-&amp;#160;非商业性&amp;#160;-&amp;#160;相同方式共享&amp;#160;4.0&amp;#160;国际协议&lt;/a&gt; ' '&lt;br /&gt;lightsmile&amp;#160;&amp;amp;copy;&amp;#160;2015&amp;#160;-&amp;#160;2018\\n' 'Power&amp;#160;by&amp;#160;&lt;a href=\"http://hexo.io/\" ' 'position=\"6\"&gt;Hexo&lt;/a&gt;&amp;#160;Theme&amp;#160;&lt;a ' 'href=\"https://github.com/yscoder/hexo-theme-indigo\" ' 'position=\"6\"&gt;indigo&lt;/a&gt; &lt;br /&gt;扫一扫，分享到微信&amp;#160;&lt;br /&gt;&lt;a ' 'href=\"http://www.iamlightsmile.com/%7Bpath%7D\" ' 'position=\"6\"&gt;&#123;title&#125;&#123;tags&#125;&#123;date&#125;&lt;/a&gt; &lt;br /&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;', 'message': ''&#125; 分词、词性标注、命名实体识别1234567action = 'LexicalAnalysis'# 分词、词性标注、命名实体识别params = &#123; 'text': \"我爱洗澡\", 'code': 0x00200000, #0x00200000表示utf-8 'type': 0 #取值 0 或 1，默认为 0。 0 为基础粒度版分词，倾向于将句子切分的更细，在搜索场景使用为佳。 1 为混合粒度版分词，倾向于保留更多基本短语不被切分开。&#125; 1234567891011121314151617181920https://wenzhi.api.qcloud.com/v2/index.php&#123;'code': 0, 'codeDesc': 'Success', 'combtokens': [&#123;'cls': '短语', 'pos': 0, 'wlen': '8', 'word': '我爱洗澡'&#125;], 'message': '', 'tokens': [&#123;'pos': 0, 'wlen': '2', 'word': '我', 'wtype': '代词', 'wtype_pos': 27&#125;, &#123;'pos': 2, 'wlen': '2', 'word': '爱', 'wtype': '动词', 'wtype_pos': 31&#125;, &#123;'pos': 4, 'wlen': '4', 'word': '洗澡', 'wtype': '动词', 'wtype_pos': 31&#125;]&#125; 文本纠错12345action = 'LexicalCheck' #文本纠错params = &#123; 'text': '人生苦短，我用Python！哼哼哈嘿！巴啦巴啦小魔仙！'&#125; 1234567https://wenzhi.api.qcloud.com/v2/index.php&#123;'code': 0, 'codeDesc': 'Success', 'conf': 1, 'message': '', 'text': '人生苦短，我用Python！哼哼哈嘿！巴啦巴啦小魔仙！', 'text_annotate': '人生苦短，我用Python！哼哼哈嘿！巴啦巴啦小魔仙！'&#125; 同义词12345action = 'LexicalSynonym'# 同义词params = &#123; 'text': '人生苦短，我用Python。我爱自然语言处理和知识图谱！'&#125; 12345678910111213https://wenzhi.api.qcloud.com/v2/index.php&#123;'code': 0, 'codeDesc': 'Success', 'message': '', 'query': None, 'syns': [&#123;'word_ori': &#123;'idx_beg': 7, 'idx_end': 8, 'text': '爱'&#125;, 'word_syns': [&#123;'conf': 0.32546776533127, 'text': '最爱'&#125;]&#125;, &#123;'word_ori': &#123;'idx_beg': 8, 'idx_end': 9, 'text': '自然'&#125;, 'word_syns': [&#123;'conf': 0.36934259533882, 'text': '大自然'&#125;]&#125;, &#123;'word_ori': &#123;'idx_beg': 11, 'idx_end': 12, 'text': '和'&#125;, 'word_syns': [&#123;'conf': 0.60000002384186, 'text': '与'&#125;]&#125;, &#123;'word_ori': &#123;'idx_beg': 13, 'idx_end': 14, 'text': '图谱'&#125;, 'word_syns': [&#123;'conf': 0.37899446487427, 'text': '图片'&#125;]&#125;]&#125; 文本分类12345action = 'TextClassify' #文本分类params = &#123; 'content':'人生苦短，please Python。太祖、刘邦、朱元璋哪个更厉害？！'&#125; 1234567https://wenzhi.api.qcloud.com/v2/index.php&#123;'classes': [&#123;'class': '文化', 'class_num': 61, 'conf': 0.713&#125;, &#123;'class': '历史', 'class_num': 95, 'conf': 0.221&#125;, &#123;'class': '未分类', 'class_num': 0, 'conf': 0.066&#125;], 'code': 0, 'codeDesc': 'Success', 'message': ''&#125; 句法分析12345action = 'TextDependency'# 句法分析params = &#123; 'content': '我爱自然语言处理'&#125; 123456789101112131415161718192021222324https://wenzhi.api.qcloud.com/v2/index.php&#123;'code': 0, 'codeDesc': 'Success', 'keywords': [[&#123;'dep_rel': 'SBV', 'father_id': 2, 'id': 1, 'postag': 'r', 'word': '我'&#125;, &#123;'dep_rel': 'HED', 'father_id': 0, 'id': 2, 'postag': 'v', 'word': '爱'&#125;, &#123;'dep_rel': 'VOB', 'father_id': 2, 'id': 3, 'postag': 'n', 'word': '自然语言'&#125;, &#123;'dep_rel': 'COO', 'father_id': 2, 'id': 4, 'postag': 'v', 'word': '处理'&#125;]], 'message': ''&#125; 关键词提取12345678action = 'TextKeywords' #关键词提取params = &#123; 'title': '自然语言处理', 'content': '''自然语言处理（英语：natural language processing，缩写作 NLP）是人工智能和语言学领域的分支学科。此领域探讨如何处理及运用自然语言；自然语言认知则是指让电脑“懂”人类的语言。自然语言生成系统把计算机数据转化为自然语言。自然语言理解系统把自然语言转化为计算机程序更易于处理的形式。'''&#125; 1234567https://wenzhi.api.qcloud.com/v2/index.php&#123;'code': 0, 'codeDesc': 'Success', 'keywords': [&#123;'keyword': '自然语言', 'score': 0.57486760616302, 'type': 'keyword'&#125;], 'message': ''&#125; 敏感信息识别123456action = 'TextSensitivity' #敏感信息识别params = &#123; 'content': \"中共统治！压迫，人民！续一秒！\", 'type': 2&#125; 123456https://wenzhi.api.qcloud.com/v2/index.php&#123;'code': 0, 'codeDesc': 'Success', 'message': '', 'nonsensitive': 0.37754066879815, 'sensitive': 0.62245933120185&#125;","categories":[{"name":"NLP","slug":"NLP","permalink":"http://www.iamlightsmile.com/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"http://www.iamlightsmile.com/tags/NLP/"}]},{"title":"GithubPages新尝试","slug":"GithubPages新尝试","date":"2018-04-18T08:01:53.000Z","updated":"2020-01-18T11:56:36.476Z","comments":true,"path":"articles/GithubPages新尝试/","link":"","permalink":"http://www.iamlightsmile.com/articles/GithubPages新尝试/","excerpt":"由于某些不便明说的原因，我要再申请一个域名，再申请一个GitHub账号，再搞一个GitHub Pages。打算用来记录一些不便明说的东西。 这次域名的申请不同于之前的在万网的iamlightsmile.com，这次是在腾讯云上申请的，不过都大同小异了。接着等待大概3天左右的实名认证，通过后域名就可以解析可用了。由于只是使用GitHub Pages 作为静态网页，不需要另外购置服务器，所以也不需要备案的了，备案真是好屌麻烦！","text":"由于某些不便明说的原因，我要再申请一个域名，再申请一个GitHub账号，再搞一个GitHub Pages。打算用来记录一些不便明说的东西。 这次域名的申请不同于之前的在万网的iamlightsmile.com，这次是在腾讯云上申请的，不过都大同小异了。接着等待大概3天左右的实名认证，通过后域名就可以解析可用了。由于只是使用GitHub Pages 作为静态网页，不需要另外购置服务器，所以也不需要备案的了，备案真是好屌麻烦！ 刚开始还挺顺利的，输入网址后顺利输出了相关内容，由于这次同样想使用Hexo搭建博客平台，所以也将先搭起环境然后设置相关github.io的项目，不过到了设置ssh这里出现了问题，经过测试发现可以访问，但是用hexo deploy时则提示权限受限，后来在网上连找了好久关于ssh的相关内容，不过尝试后发现并不能解决问题，后来在GitHub的settings页面中，在SSH keys下面发现一段比较小的段落，有一个common SSH Problems的超链接，点进去之后研磨了好久终于发现问题所在。 原来是由于我用的自己原来的GitHub账号来更新新创建的GitHub账号仓库的内容，默认的权限不够，只能通过将smilelight添加到该项目的协作者或同一个组织下才行。邀请了smilelight之后发现没有反应，账号下没有通知，也没有邮件提醒，还以为是GitHub的问题，后来把那个邀请链接复制下来之后，发现是一个新的页面，需要点进去点击接受才可以，经过几番磨练之后终于提交成功。 至于为什么Hexo还是用我原来的GitHub账号我就不清楚了，虽然我在这个文件的.git的config中修改了自己的用户名和邮箱，但是身份用的还是smilelight，估计可能Hexo默认或者只能使用全局的Git账号信息吧。","categories":[{"name":"计算机","slug":"计算机","permalink":"http://www.iamlightsmile.com/categories/计算机/"}],"tags":[{"name":"Github","slug":"Github","permalink":"http://www.iamlightsmile.com/tags/Github/"}]},{"title":"学习Python设计模式","slug":"学习Python设计模式","date":"2018-04-17T02:16:59.000Z","updated":"2020-01-18T11:26:43.052Z","comments":true,"path":"articles/学习Python设计模式/","link":"","permalink":"http://www.iamlightsmile.com/articles/学习Python设计模式/","excerpt":"本书主要参阅的书籍是《精通Python设计模式》 本书分为创建型模式、结构型模式、行为型模式三大类，同时又细分为16种模式。具体到每个模式，则通过简单介绍、现实生活中例子、软件应用实例、应用场景、具体代码实现、小结几部分，多个角度加深对某个设计模式的理解。案例贴近生活，代码简单易懂，描述清晰明白，翻译水平上佳，确实算是我认为的好书，同时翻译还将代码上传到GitHub上方便读者下载学习，这里真应该点个赞了！","text":"本书主要参阅的书籍是《精通Python设计模式》 本书分为创建型模式、结构型模式、行为型模式三大类，同时又细分为16种模式。具体到每个模式，则通过简单介绍、现实生活中例子、软件应用实例、应用场景、具体代码实现、小结几部分，多个角度加深对某个设计模式的理解。案例贴近生活，代码简单易懂，描述清晰明白，翻译水平上佳，确实算是我认为的好书，同时翻译还将代码上传到GitHub上方便读者下载学习，这里真应该点个赞了！ 我们在学习设计模式的时候不应当仅仅立足于软件开发这一角度，同时应该立足于实际，或者以更加抽象的角度来看待这些设计模式背后的思想。比如针对某个设计模式，我们要明白想通过它实现怎么样的功能，这样设计的好处在哪里，我要提供什么输入，我将得到什么输出，即通过函数或黑盒子的视角从外面看待这个设计模式。同时也要将视角放到该设计模式的内部，可以把具体的某个方法视为车间、某个对象视为工人，将之与现实世界某个应用场景映射起来，分析通过怎么样的一个调度实现了业务的功能，其中的结构优势何在，节省了空间还是时间上的资源等。 笔记摘抄 设计模式的本质是在已有的方案之上发现更好的方案（而不是全新发明）。 设计模式并非是某种高大上或者神秘的东西，而是一些常见的软件工程设计问题的最佳实践方案。 个人认为软件开发技术的学习都应该以实践为前提，只有理解实践过程中遇到的种种问题，才能明白那些技术的本质和目的是什么，因为每种新技术都是因某个/某些问题而出现的。 设计模式一般是描述如何组织代码和使用最佳实践来解决常见的设计问题。 书籍结构创建型模式创建型设计模式处理对象创建相关的问题，目标是当直接创建对象不太方便时，提供更好的方式。 工厂模式工厂背后的思想是简化对象的创建 通过将创建对象的代码和使用对象的代码解耦，工场能够降低应用维护的复杂度。 工厂通常有两种形式：一种是工厂方法，它是一个方法（或以地道的Python数据来说，是一个函数），对不同的输入参数返回不同的对象；第二种是抽象工厂，它是一组用于创建一系列相关事物对象的工厂方法。 工厂方法可以在必要时创建新的对象，从而提高性能和内存使用率。 一个抽象工厂是（逻辑上的）一组工厂方法，其中的每个工厂方法负责产生不同种类的对象。 抽象工厂模式是工厂方法模式的一种泛化。 通常一开始时使用工厂方法，因为它更简单。 工厂方法和抽象工厂设计模式可适用于以下场景： 想要追踪对象莱恩创建时 想要将对象的创建与使用解耦时 想要优化应用的性能和资源占用时 建造者模式建造者模式将一个复杂对象的构造过程与其表现分离，这样，同一个构造过程可用于创建多个不同的表现。 如果我们知道一个对象必须经过多个步骤来创建，并且要求同一个构造过程可以产生不同的表现，就可以使用建造者模式。 建造者模式可适用于以下场景： 想要创建一个复杂对象（对象由多个部分构成，且对象的创建要经过多个不同的步骤，这些步骤也许还需遵从特定的顺序） 要求一个对象能有不同的表现，并希望将对象的构造与表现解耦 想要在某个时间点创建对象，但在稍后的时间点再访问 原型模式原型设计模式用于创建对象的完全副本。 一般创建副本的两种方式： 当创建一个浅副本时，副本依赖引用 当创建一个深副本时，副本复制所有东西 第一种情况下，我们希望提升应用性能和优化内存使用，在对象之间引入数据共享，但需要小心地修改数据，因为所有变更对所有副本都是可见的。 第二种情况下，我们希望能够对一个副本进行更改而不会影响其他对象。 结构型模式结构型设计模式处理一个系统中不同实体（比如，类和对象）之间的关系，关注的是提供一种简单的对象组合方式来创建新功能。 适配器模式适配器模式帮助我们实现两个不兼容接口之间的兼容 开放/封闭原则（open/close principle）是面向对象设计的基本原则之一，声明一个软件实体应该对拓展是开放的，对修改则是封闭的。本质上这意味着我们应该无需修改一个软件实体的源码就能拓展其行为。适配器模式遵从开放/封闭原则。 适配器让一件产品在制造出来之后需要应对新需求之时还能工作。 修饰器模式修饰器模式通常用于拓展一个对象的功能。 一般来说，应用中有些部件是通用的，可应用于其他部件，这样的部件被看作横切关注点。 修饰器模式是实现横切关注点的绝佳方案，因为横切关注点通用但不太适合使用面向对象编程范式来实现。 Python进一步拓展了修饰器的概念，允许我们无需使用继承或组合就能拓展任意可调用对象（函数、方法或类）的行为。 外观模式外观模式有助于隐藏系统所的内部复杂性，并通过一个简化的接口向客户端暴露必要的部分。本质上，外观（Facade）是在已有复杂系统之上实现的一个抽象层。 使用外观模式的最常见理由是为一个复杂系统提供单个简单的入口点。 不把系统的内部功能暴露给客户端代码有一个额外的好处：我们可以改变系统内部代码，但客户端代码不用关心这个改变，也不会受到这个改变的影响。客户端代码不需要进行任何改变。 如果你的系统包含多层，外观模式也能派上用场。你可以为每一层引入一个外观入口点，并让所有层级通过它们的外观相关通信。这提高了层级之间的松耦合性，尽可能保持层级独立。 外观模式是一种隐藏系统复杂性的优雅方式，因为多数情况下客户端代码并不应该关心系统的这些细节。 享元模式作为软件工程师，我们应该编写更好的软件来解决软件问题，而不是要求客户购买更多更好的硬件。 享元模式通过为相似对象引入数据共享来最小化内存使用，提升性能。 一个享元（Flyweight）就是一个包含状态独立的不可变（又称固有的）数据的共享对象。 若想要享元模式有效，需要满足GoF的《设计模式》一书罗列的以下几个条件。 应用需要使用大量的对象。 对象太多，存储/渲染它们的代价太大。 对象ID对于应用不重要。 一般来说，在应用需要创建大量的计算代价大但共享许多属性的对象时，可以使用享元。 模型-视图-控制器模式关注点分离（Separation of Concerns，SoC）原则是软件工程相关的设计原则之一。 SoC原则背后的思想是将一个应用切分成不同的部分，每个部分解决一个单独的关注点。 模型-视图-控制器（Model-View-Controller，MVC）模式是应用到面向对象编程的SOC原则。 其中，模型是核心的部分，代表着应用的信息本源，包含和管理（业务）逻辑、数据、状态以及应用的规则。视图是模型的可视化表现。视图只是展示数据，并不处理数据。控制器是模型与视图之间的链接/粘附。模型与视图之间的所有通信都通过控制器进行。 为了实现模型与其表现之间的解耦，每个视图通常都需要属于它的控制器。（我认为作者想表达的是没有控制器也可以，但是由于视图并不具备处理数据的功能，并且通常每个页面所要处理的业务都会不同，因此这样的模型是高度定制的模型，适用性很差） 在从头开始实现MVC时，请确保创建的模型很智能，控制器很瘦，视图很傻瓜。 可以将具有以下功能的模型视为智能模型： 包含所有的校验/业务规则/逻辑 处理应用的状态 访问应用数据（数据库、云或其他） 不依赖UI可以将符合以下条件的控制器视为瘦控制器： 在用户与视图交互时，更新模型 在模型改变时，更新视图 如果需要，在数据传递给模型/视图之前进行处理 不展示数据 不直接访问应用数据 不包含校验/业务规则/逻辑可以将符合以下条件的视图视为傻瓜视图： 展示数据 允许用户与其交互 仅做最小的数据处理，通常由一种模板语言提供处理能力（例如，使用简单的变量和循环控制） 不存储任何数据 不直接访问应用数据 不包含校验/业务规则/逻辑 使用MVC时，请确保创建智能的模型（核心功能）、瘦控制器（实现视图与模型之间通信的能力）以及傻瓜式的视图（外在表现，最小化逻辑处理） 代理模式四种不同的知名代理类型： 远程代理：实际存在于不同地址空间（例如，某个网络服务器）的对象在本地的代理者。 虚拟代理：用于懒初始化，将一个大计算量对象的创建延迟到真正需要的时候进行。 保护/防护代理：控制对敏感对象的访问。 智能（引用）代理：在对象被访问时执行额外的动作。此类代理的例子包括引用计数和线程安全检查。 现实中，，永远不要执行以下操作： 在源代码中存储密码 以明文形式存储密码 使用一种弱（例如，MD5）或自定义加密形式 行为型模式行为型模式处理对象互联和算法的问题 责任链模式责任链（Chain of Responsibility）模式用于让多个对象来处理单个请求时，或者用于预先不知道应该由哪个对象（来自某个对象链）来处理某个特定请求时。其原则如下所示： 存在一个对象链（链表、树或任何其他便捷的数据结构）。 我们一开始将请求发送给链中的第一个对象。 对象决定其是否要处理该请求。 对象将请求转发给下一个对象。 重复该过程，直到到达链尾。 通过使用责任链模式，我们能让许多对象来处理一个特定请求。在我们预先不知道应该由哪个对象来处理某个请求时，这是有用的。另一个责任链可以派上用场的场景是，在我们知道可能会有多个对象都需要对同一个请求进行处理之时。 这一模式的价值在于解耦。 客户端与所有处理程序（一个处理程序与所有其他处理程序之间也是如此）之间不再是多对多关系，客户端仅需要知道如何与链的起始节点（标头）进行通信。 在无法预先知道处理程序的数量和类型时，该模式有助于对请求/处理事件进行建模。适合使用责任链模式的系统例子包括基于事件的系统、采购系统和运输系统。 命令模式命令设计模式帮助我们将一个操作（撤销、重做、复制、粘贴）封装成一个对象。简而言之，这意味着创建一个类，包含实现该操作所需要的所有逻辑和方法。 这样做的优势如下所述参考： 我们并不需要直接执行一个命令。命令可以按照希望执行。 调用命令的对象与知道如何执行命令的对象解耦。调用者无需知道命令的任何实现细节。 如果有意义，可以把多个命令组织起来，这样调用者能够按顺序执行它们。例如，在实现一个多层撤销命令时，这是很有用的。 解释器模式解释器（Interpreter）模式仅能引起应用的高级用户的兴趣。这是因为解释器模式背后的贮存思想是让非初级用户和领域专家使用一门简单的语言来表达想法。 领域特定语言（Domain Specific Language，DSL）是一种针对一个特定领域的有限表达能力的计算机语言。DSL分为内部DSL和外部DSL。 内部DSL构建在一个宿主编程语言之上。 优势：我们不必担心创建、编译及解析语法，因为这些已经被宿主语言解决掉了。 劣势：会受限于宿主语言的特性。如果宿主语言不具备这些特性，构建一种表达能力强、简洁而且优美的内部DSL是富有挑战性的。 外部DSL不依赖某种宿主语言。DSL的创建者可以决定语言的方方面面（语法、句法等），但也要负责为其创建一个解析器和编译器。为一种新语言创建解析器和编译器是一个非常复杂、长期而又痛苦的过程。 解释器模式仅与内部DSL相关。 观察者模式观察者模式描述单个对象（发布者，又称为主持者或可观察者）与一个或多个对象（订阅者，又称为观察者）之间的发布-订阅关系。 观察者模式背后的思想等同于MVC和关注点分离原则背后的思想，即降低发布者与订阅者之间的耦合度，从而易于在运行时添加/删除订阅者。此外，发布者不关心它的订阅者是谁。它只是将通知发送给所有订阅者。 当我们希望在一个对象（主持者/发布者/可观察者）发生变化时通知/更新另一个或多个对象的时候，通常会使用观察者模式。观察者的数量以及谁是观察者可能会有所不同，也可以（在运行时）动态地改变。 状态模式在很多问题中，有限状态机（通常名为有限状态机）是一个非常方便的状态转换建模（并在必要时以数学方式形式化）工具。 状态机是一个抽象机器，有两个关键部分，状态和转换。状态是指系统的当前（激活）状况。一个状态机在任意时间点只会有一个激活状态。转换是指从一个状态切换到另一个状态，因某个事件或条件的触发而开始。在一个转换发生之前或之后通常会执行一个或多个动作。 状态机带一个不错的特性是可以用图来表现（称为状态图），其中每个状态都是一个节点，每个转换都是两个节点之间的边。 状态模式就是应用到一个特定软件工程问题的状态机。 使用状态模式本质上相当于实现一个状态机来解决特定领域的一个软件问题。 状态设计模式解决的是一定上下文中无限数量状态的完全封装，从而实现更好的可维护性和灵活性。 策略模式策略模式通常用在我们希望对同一个问题透明地使用多种方案时。如果并不存在针对所有输入数据和所有情况的完美算法，那么我们可以使用策略模式，动态地决定在每种情况下应使用哪种算法。 模板模式编写优秀代码的一个要素是避免冗余。 模板模式关注的是消除代码冗余，其思想是我们应该无需改变算法结构就能重新定义一个算法的某个部分。 设计模式是被发现，而不是被发明出来的。","categories":[{"name":"Python","slug":"Python","permalink":"http://www.iamlightsmile.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.iamlightsmile.com/tags/Python/"}]},{"title":"哈工大ltp小试","slug":"哈工大ltp小试","date":"2018-04-07T15:28:35.000Z","updated":"2020-01-18T11:52:16.895Z","comments":true,"path":"articles/哈工大ltp小试/","link":"","permalink":"http://www.iamlightsmile.com/articles/哈工大ltp小试/","excerpt":"今天开始探索学习使用哈工大的LTP（Language Technology Platform）。 这里是官网地址 这里是GitHub地址 这里是pyltp的使用文档 平台采用的语言是C++，但是也提供了Python和Java的封装。由于本人目前使用Python作为自然语言处理的工具语言，所以以下的探索流程都是使用本人电脑中的Window8.1操作系统的PyCharm集成开发环境，使用的Python版本是3.6。","text":"今天开始探索学习使用哈工大的LTP（Language Technology Platform）。 这里是官网地址 这里是GitHub地址 这里是pyltp的使用文档 平台采用的语言是C++，但是也提供了Python和Java的封装。由于本人目前使用Python作为自然语言处理的工具语言，所以以下的探索流程都是使用本人电脑中的Window8.1操作系统的PyCharm集成开发环境，使用的Python版本是3.6。 使用流程很简单： 下载最新版本的模型（目前是3.4） 安装pyltp，在命令行输入指令：pip install pyltp。不过我的一直安装失败，总是不成功，后来从网上找了pyltp 3.6的whl文件，然后通过pip install pyltp-0.2.1-cp36-cp36m-win_amd64.whl成功了。 这里有一篇博客专门讲安装的，发现他的界面有点黑客风，挺炫酷的哈~ 通过PyCharm新建Python项目后，整个工程长成这个样子： 不过其中的data文件夹、source文件夹和test文件夹是自己新创建的，其中data文件夹内放置下载的模型，source文件夹放置那个其实也没啥东西的txt文件，test中放置编写的Python代码。 照着使用文档敲的testltp.py内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import pyltp# 分句from pyltp import SentenceSplittersents = SentenceSplitter.split('元芳你怎么看？我就趴窗口上看呗！')print('\\n'.join(sents))# 分词from pyltp import Segmentorsegmentor = Segmentor()segmentor.load('../data/cws.model')words = segmentor.segment(\"元芳你怎么看\")segmentor.release()print(list(words))# 词性标注from pyltp import Postaggerpostagger = Postagger()postagger.load('../data/pos.model')posts = postagger.postag(list(words))postagger.release()print(list(zip(list(words),list(posts))))#命名实体识别from pyltp import NamedEntityRecognizerrecognizer = NamedEntityRecognizer()recognizer.load('../data/ner.model')nettags = recognizer.recognize(list(words),list(posts))recognizer.release()print(list(zip(list(words),list(nettags))))#依存语法分析from pyltp import Parserparer = Parser()parer.load('../data/parser.model')arcs = parer.parse(list(words),list(posts))parer.release()print(list(zip(list(words),[(arc.head,arc.relation) for arc in arcs])))#语义角色标注from pyltp import SementicRoleLabellerlabeller = SementicRoleLabeller()labeller.load('../data/pisrl_win.model')roles = labeller.label(list(words),list(posts),arcs)labeller.release()for role in roles: print(role.index, \"\".join( [\"%s:(%d,%d)\" % (arg.name, arg.range.start, arg.range.end) for arg in role.arguments])) 其中我的pyltp不知道怎么安装的，竟然成了build-in里的东西了，而不是在site-packages里面。 执行以上代码的结果为： 其中要注意的是这里在语义角色标注中使用的并非pisrl.model而是pisrl_win.model，前者会报错的。 同时由于文档中提到： 于是我又去申请了哈工大的语言云个人账号,经过邮箱激活之后，按照人家的使用文档就要探索一下，不过没想到出现了问题。。。 由于官网提供的Python示例代码使用的是2.7版本，所以这里我使用的是另外的一个网络请求模块：requests，最终的代码testltpCloud.py长成这样： 1234567891011121314import requestsfrom settings import APIKEYurl_get_base = \"http://api.ltp-cloud.com/analysis/\"args = &#123; 'api_key': APIKEY, 'text': '我是中国人。', 'pattern': 'dp', 'format': 'plain'&#125;# result = urllib.request.urlopen(url_get_base, urllib.parse.urlencode(args)) # POST methodresult = requests.post(url_get_base,args)print(result.text) 在同路径下的settings.py的内容为： 其中APIKEY的内容是邮件发给你的api_key字符串。 不过运行的结果为： 显示未授权用户，但是我的账户类型是免费的，刚注册的啊，为啥这样，搜了搜没搜出个啥，就先这样吧。 又向目标迈进了一步，嘿嘿，加油！","categories":[{"name":"NLP","slug":"NLP","permalink":"http://www.iamlightsmile.com/categories/NLP/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.iamlightsmile.com/tags/Python/"},{"name":"NLP","slug":"NLP","permalink":"http://www.iamlightsmile.com/tags/NLP/"},{"name":"ltp","slug":"ltp","permalink":"http://www.iamlightsmile.com/tags/ltp/"}]},{"title":"Scrapy爬取知乎数据小试","slug":"Scrapy爬取知乎数据小试","date":"2018-04-06T15:06:27.000Z","updated":"2020-01-18T11:58:23.466Z","comments":true,"path":"articles/Scrapy爬取知乎数据小试/","link":"","permalink":"http://www.iamlightsmile.com/articles/Scrapy爬取知乎数据小试/","excerpt":"啊啊啊，没时间写啦，以后有时间再写吧！ 。。。发现今天是周五，不熄灯。。。 前两周一直在忙毕设的事情，由于某些原因毕设选择了相对简单的微信小程序，经过奋战之后一些主要的基本功能已经实现多半。 自然语言处理的一些最基本的概念已经有所了解，下面想要找点实战项目练练手。由于处理的第一步便是要获取语料，想着以后爬虫这东西肯定是要学的，于是从昨天开始学习相关视频、配置相关环境，今天看了部分，照着Demo练了练小手。","text":"啊啊啊，没时间写啦，以后有时间再写吧！ 。。。发现今天是周五，不熄灯。。。 前两周一直在忙毕设的事情，由于某些原因毕设选择了相对简单的微信小程序，经过奋战之后一些主要的基本功能已经实现多半。 自然语言处理的一些最基本的概念已经有所了解，下面想要找点实战项目练练手。由于处理的第一步便是要获取语料，想着以后爬虫这东西肯定是要学的，于是从昨天开始学习相关视频、配置相关环境，今天看了部分，照着Demo练了练小手。 B站真是个好地方，上面有不少免费的好的视频可以看，虽然版权这方面%&amp;@#￥！@￥……@#￥%……#@￥%##￥@ 这是学习爬虫的视频链接 作者是拿轮子哥vczh作为start_user的，当时还愣了一下，可以的，会玩，想当年自己也关注过轮子哥一段时间，不过看他经常给美女们点赞、抖机灵，后来便取关了。 废话少说，言归正传： 爬虫：请求网站并提取数据的自动化程序。 爬虫的基本流程： 发起请求：通过HTTP库向目标站点发起请求,即发送一个Request,情况请可以包含额外的headers等信息,等待服务器响应。 获取响应内容：如果服务器能正常响应，会得到一个Response，Response的内容便是所要获取的页面内容，内容可能有HTML，Json字符串，二进制数据（如图片视频）等类型。 解析内容：得到的内容可能是HTML，可以用正则表达式、网页解析库进行解析，可呢是Json，可以直接转为Json对象解析，可能是二进制数据，可以做保存或者进一步的处理。 保存数据：保存形式多样，可以存为文本，也可以保存至数据库，或者保存特定格式的文件。 项目所实现的是从首个著名知乎用户（本项目中为vczh）个人信息及其所有关注人、所有粉丝相关信息爬取开始、一直延伸整个关注网，并将结果数据集保存在MongoDB中。 具体来说就是先爬轮子哥的个人信息数据，然后依次爬取他的所有关注人的个人信息以及他的所有粉丝们的个人信息，这样的策略应用到每一个爬虫经过的用户上，从而实现数据的遍历抽取。单纯从Python代码的角度上讲，类似于会重复的深度优先遍历，然而具体的Scrapy引擎内部会如何调度这些Request队列就是人家内部的算法了。 视频的上传时间是18年1月11日，当时从网页中获取到的用户信息相对比较简单、集中、丰富，今天我试了又试，发现可获取到的直接信息变少了。由于只是初步尝试，所以也就按部就班的照样执行，没有做得不偿失的优化了。 Scrapy引擎的框架大致如下： 我们可以看到整个引擎主要是由四部分组成： Scheduler（调度器） Downloader（下载器） Spiders（爬虫） Item Pipeline（项目 管道） 其中Spider中定义了具体的爬虫逻辑，比如我们要怎么爬，爬什么，后面跟着的s表明这通常不是一个Spider，而是通常有多个Spider，我们可以根据不同的具体需求编写对应的Spider。 Spiders之上的是一些Spider Middlewares（即爬虫中间件），有点类似于Python中函数的修饰器，可以对函数进行一些增强和拓展，同样的，我们可以通过这些Spider中间件来丰富和拓展我们编写的小Spider，让它们表现的更给力一些，同时这也可以简化我们的编写逻辑，因为我们只需要在之上套些中间件就可以了，套什么中间件视具体需求而定，比如说冬天穿大衣、夏天穿衬衫等。 当Spider生成好之后，引擎会开始执行这个Spider的内部逻辑，如start_requests方法，和parse方法等等，具体的它会将HTTP的Request请求交给Downloader完成，由Downloader完成从Internet上下载资源数据的具体任务，而Downloader也可以有自己的中间件也就是Downloader Middlewares，可以对Downloader进行改装，增强。 Downloader完成下载后，Scrapy引擎会将Downloader的成果Responses交给之前的Spider，执行它的解析方法。之后视具体情况，Spider可能会爬取更多的数据，相应的会产生更多的Request请求，或者将Response中的数据进行处理，处理为Item，然后转交给Item Pipeline做最后的数据处理工作。 因为爬虫一般不是一个一个的爬，而是通常成百上千乃至上万的爬，Scheduler的主要作用类似于CPU的处理器对这些请求做一个规划调度，先做哪个，后做哪个等等。 Item Pipline 中，Item可以视为一个数据对象的容器，而Pipline则类似Unix系统中的管道，或者更通俗点，就像流水线的的工人，从网上获取原材料之后，Spider这个工人进行加工处理，之后这些Pipline们做做类似贴标签的工作，最终提交正式的产品。 因为我们爬虫的编写都是具有针对性的，知己知彼百战不殆嘛。所以首先要分析知乎相关的数据流通状况： 以上是轮子哥的知乎页面。 首先必须要按F12打开开发者工具，查看Network页面。 对于某个用户的具体信息，如关注人或粉丝列表中的，我们只需要将鼠标请放在某个人的图像上，知乎就会通过Ajax去请求这个人的数据，以Json对象的格式返回给浏览器，同样的，当我们查看关注人列表和粉丝列表时，知乎也是通过Ajax请求返回这些数据对象的，具体的如以下几张图片： 这是轮子哥关注的某个人的信息，观看图右侧我们发现这个人相关信息就在这个Json对象中。而如果要获取到这个Response体中的Json对象，我们只要执行最上面的网络请求就可以了： 还有类似的关注人列表和粉丝列表也都是大概类似的情况，不过情况的url中的参数和内容稍有不同罢了。 关注人列表： 相关请求： 粉丝列表： 相关请求： 其实爬虫这个东西的基本原理很简单，就是执行HTTP请求，处理响应的数据，将这个过程重复化自动化而已。 而基于前面我们所提到的爬取信息的相关策略，我们要做的就是爬轮子哥的数据，然后请求两个列表中其他人的数据，并拓展开来。 整个项目的结构如下： 这里我们需要编写的是zhihu.py、items.py、piplines.py、settings.py 在settings.py中我们进行了请求头、Item Pipline中间件和MongoDB相关的配置。 如下： 1234567891011121314DEFAULT_REQUEST_HEADERS = &#123; 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en', 'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; W…) Gecko/20100101 Firefox/57.0', 'authorization':' oauth c3cef7c66a1843f8b3a9e6a1e3160e20'&#125;ITEM_PIPELINES = &#123; 'zhihuUser.pipelines.MongoPipeline': 300,&#125;MONGO_URI = 'localhost'MONGO_DATABASE = 'zhihu' 我们针对Json对象的内容编写的ZhihuUserItem对象： 123456789101112131415161718192021222324252627from scrapy import Item,Fieldclass ZhihuUserItem(Item): # define the fields for your item here like: # name = scrapy.Field() id = Field() is_followed = Field() avatar_url_template = Field() user_type = Field() answer_count = Field() is_following = Field() url = Field() url_token = Field() allow_message = Field() articles_count = Field() is_blocking = Field() name = Field() headline = Field() badge = Field() is_advertiser = Field() avatar_url = Field() is_org = Field() gender = Field() follower_count = Field() employments = Field() type = Field() 因为要将数据存储到MongoDB中，所以要进行MongoDB的Item Pipline中间件的编写： 12345678910111213141516171819202122232425262728import pymongoclass MongoPipeline(object): collection_name = 'user_info' def __init__(self, mongo_uri, mongo_db): self.mongo_uri = mongo_uri self.mongo_db = mongo_db @classmethod def from_crawler(cls, crawler): return cls( mongo_uri=crawler.settings.get('MONGO_URI'), mongo_db=crawler.settings.get('MONGO_DATABASE') ) def open_spider(self, spider): self.client = pymongo.MongoClient(self.mongo_uri) self.db = self.client[self.mongo_db] def close_spider(self, spider): self.client.close() def process_item(self, item, spider): self.db[self.collection_name].insert_one(dict(item)) # self.db[self.collection_name].update(&#123;'url_token': item['url_token']&#125;,&#123;'$set': item&#125;,True) 最后是zhihu.py 中 ZhihuSpider的编写： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import jsonimport scrapyfrom scrapy import Requestfrom zhihuUser.items import ZhihuUserItemclass ZhihuSpider(scrapy.Spider): name = 'zhihu' allowed_domains = ['www.zhihu.com'] start_urls = ['http://www.zhihu.com/'] start_user = 'excited-vczh' user_url = 'https://www.zhihu.com/api/v4/members/&#123;user&#125;?include=&#123;include&#125;' user_query = 'allow_message,is_followed,is_following,is_org,is_blocking,employments,answer_count,follower_count,articles_count,gender,badge[?(type=best_answerer)].topics' followees_url = 'https://www.zhihu.com/api/v4/members/&#123;user&#125;/followees?include=&#123;include&#125;&amp;offset=&#123;offset&#125;&amp;limit=&#123;limit&#125;' followees_query = 'data[*].answer_count,articles_count,gender,follower_count,is_followed,is_following,badge[?(type=best_answerer)].topics' followers_url = 'https://www.zhihu.com/api/v4/members/&#123;user&#125;/followers?include=&#123;include&#125;&amp;offset=&#123;offset&#125;&amp;limit=&#123;limit&#125;' followers_query = 'data[*].answer_count,articles_count,gender,follower_count,is_followed,is_following,badge[?(type=best_answerer)].topics' def start_requests(self): yield Request(self.user_url.format(user=self.start_user,include=self.user_query),callback=self.parse_user) # yield Request(self.followees_url.format(user=self.start_user,include=self.followees_query,offset=0,limit=20),callback=self.parse_followees) def parse_user(self, response): result = json.loads(response.text) item = ZhihuUserItem() for field in item.fields: if field in result.keys(): item[field] = result.get(field) yield item yield Request(self.followees_url.format(user=result.get('url_token'), include=self.followees_query, offset=0, limit=20), callback=self.parse_followees) yield Request( self.followers_url.format(user=result.get('url_token'), include=self.followers_query, offset=0, limit=20), callback=self.parse_followees) # print(json.loads(response.text)) def parse_followees(self, response): result = json.loads(response.text) if 'data' in result.keys(): for result in result.get('data'): yield Request(self.user_url.format(user=result.get('url_token'),include=self.user_query),callback=self.parse_user) if 'paging' in result.keys() and result.get('paging').get('is_end') == False: next_page = result.get('paging').get('next') yield Request(next_page,callback=self.parse_followees) def parse_followers(self, response): result = json.loads(response.text) if 'data' in result.keys(): for result in result.get('data'): yield Request(self.user_url.format(user=result.get('url_token'),include=self.user_query),callback=self.parse_user) if 'paging' in result.keys() and result.get('paging').get('is_end') == False: next_page = result.get('paging').get('next') yield Request(next_page,callback=self.parse_followers) def parse(self, response): pass 在终端下执行scrapy crawl zhihu后，爬虫便会开始启动，由于这个工程一直爬一直爬，所以让它爬一会做个样子就行了，通过Ctrl+C停止当前任务，随后我们可以通过可视化工具查看到存入MongoDB中的数据： 大功告成！虽然超级简单。。。","categories":[{"name":"计算机","slug":"计算机","permalink":"http://www.iamlightsmile.com/categories/计算机/"}],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://www.iamlightsmile.com/tags/爬虫/"},{"name":"Scrapy","slug":"Scrapy","permalink":"http://www.iamlightsmile.com/tags/Scrapy/"}]},{"title":"微信小程序的component","slug":"微信小程序探索随笔","date":"2018-03-28T09:14:22.000Z","updated":"2020-01-18T11:55:22.874Z","comments":true,"path":"articles/微信小程序探索随笔/","link":"","permalink":"http://www.iamlightsmile.com/articles/微信小程序探索随笔/","excerpt":"我发现无法直接在样式即wxss里通过color属性设置icon组件的颜色，是无效的，只能通过在wxml里设置它的color属性为js传入的变量值或者是通过变量值来控制具体的颜色值。","text":"我发现无法直接在样式即wxss里通过color属性设置icon组件的颜色，是无效的，只能通过在wxml里设置它的color属性为js传入的变量值或者是通过变量值来控制具体的颜色值。 我们可以将微信小程序中的components组件视为一个对象，没错，它本来就是一个对象，只是相对而言，它的初始化方法和设置方式不同于在一般的js语言中，它的data属性里是这个对象建立时初始化时的数据，作用域和生命周期伴随着component对象实例，而properties属性效果类似，均可以在component对象内部的函数和方法中使用this.data获取到，只是相对而言，data的数据是组件内部的数据，它是属于组件本身的属性，从设计上讲不取决于外部的应用场景；而properties属性则是暴露在组件外部的属性，它的作用相当于一般的编程语言中我们在new一个对象时做的初始化工作如new People(name=”lightsmile”,sex = false)，也就是说组件的一些业务属性是要通过这些属性接口来实现的，它是根据场景所制订的，具体实例体现在如： 1&lt;order-by bindtap=\"handOrderTap\" id=\"fuck\" test=\"&#123;&#123;5&#125;&#125;\" data-tes=\"&#123;&#123;test&#125;&#125;\" data-fuck=\"fuck\" data-order=\"&#123;&#123;orders&#125;&#125;\" data-&gt;&lt;/order-by&gt; 中id是每个标签都具有的值，而以“data-”开头的数据都是这个页面中，暴露给触发事件的值，在事件处理函数中，可以通过如 1234567handOrderTap(e) &#123; console.log(e) console.log(e.currentTarget.id) this.fuck = this.selectComponent(\"#fuck\") console.log(this.fuck.data) console.log(this.fuck.dataset)&#125; 获取到e（event）事件的具体信息，这里的handOrderTag只是自定义的函数，e.target和e.currentTarget分别代表不同的对象。 其中target是指事件的原触发对象，而currentTarget是指当前事件的触发对象，这是与事件的冒泡捕获机制相关的。 而不以“data-”开头，也不是如class、id、style等其他的属性如在上例中属性名为test的是页面传递给组件对象的信息，这里的test对应着组件对象之前设定的test属性，即在2中提到的暴露的属性名 而“=”号后面的“”和“”则均是属于当前页面的逻辑层Page对象内部的数据，即this.data.test和this.tata.orders（其中的this指代的是当前对象），也就是说，在与Component组件或页面Page对象对应的wxml中，其中的永远都是指的当前组件或页面对象，无法外指和内值，即在Component对应wxml中无法引用外部Page的对象（这个很合理，因为组件本来就是要被复用的，不应该出现还可以引用外部的数据的情况），Page对应的wxml中也无法引用内部Component对象的内部属性，而如果要使用内部的值，一种方法是内部定义触发的方法然后再使用如this.triggerEvent(‘change’, this)触发外部的change事件，这样组件外部就可以使用bindchange=”方法名”进行handle处理了。如下几个阶段： 1. 在Page的wxml中使用组件order-by,绑定了自定义事件MyEvent，这样在MyEvent事件被触发时，Page对象的handleMyEvent方法就会被执行。 2. handleMyEvent方法的内容如下： 3.Component的wxml中的text组件绑定tap事件到Component对象的myEvent方法 4.myEvent方法的内容如下： 因此整个的流程应当为：当我点击text文本的时候，会触发tap事件，这样它绑定的myEvent方法会被执行，然后方法内部又会主动引发MyEvent事件，这样在Page页面对其绑定的handleMyEvent方法会被执行，而该方法定义在Page对象内部。（注意不要搞混事件和方法，虽然我这里的名字比较混乱）控制台输出的结果为： 即先触发tap事件，再触发MyEvent自定义事件，下面我们来看一看内部传递的东西： 从中我们可以发现第一个事件e的currentTarget属性的dataset属性是一个空对象，对应着我们并没有在wxml的text组件内部填写“data-xx”属性，而第二个事件e的currentTarget属性的dataset属性是一个包含了fuck、order、tes三个属性的对象，尽管其中order和tes的内容为空（因为对应的数据在Page对象中没有，我错误的写成了Component对象内部的了，发现获取不到，这才有了这篇文章）。 因此一般情况下，我们可以通过这种事件的方式来实现数据的传递工作，并且 this.triggerEvent() 方法接收自定义事件名称外，还接收两个对象，eventDetail 和 eventOptions。这也就是说，我们完全可以不传递this，而传递任意自己定义的对象数据，比如在myEvent中我可以不传this，接着传e，我也可以定义只与业务相关的数据对象来处理，由于方法定义在页面或组件对象内部，可以访问内部数据，而通过事件传递后可以通过参数访问数据，以此就实现了组件向页面的数据传递工作。 当然，这样的一个特点是事件绑定是放在视图view层，而事件处理传递是放在逻辑js层，可能在做一些其他业务时还是需要相应的业务转化工作才可以，不够直接和方便，因为页面还是无法做到直接访问组件数据。 后来发现果然页面提供了这么一个方法：this.selectComponent(“#fuck”)可以在页面js中使用selectComponent选择某个component组件对象的实例，在此之上可以继续访问到它的data属性、dataset属性和properties属性，分别对应的是组件的properties属性、data属性和properties属性，如下图所示： 这里我们将组件的id设为fuck，handleOrderTap方法的内容如下： 打印的内容为： 我们可以发现它的id是自己定义的fuck,而is是项目的绝对路径，还有上面提到的data、properties、dataset属性（显而易见，properties和data属性指向同一个属性对象）（然而，经过测试发现虽然内容相同，不过并非指向同一个对象，如下图所示：真是奇了怪了。。。）。 如果打开proto属性，会发现更多的东西，比如说方法： 通过this.fuck.loghaha()即可完成对方法的调用，当然了，这里获取完全可以写成let fuck = this.selectComponent(“#fuck”)，然后通过fuck.loghaha()来调用，这里简单沿袭了网上搜的文章的实例。以上，也算自己学习的小经历总结吧。","categories":[{"name":"计算机","slug":"计算机","permalink":"http://www.iamlightsmile.com/categories/计算机/"}],"tags":[{"name":"微信小程序","slug":"微信小程序","permalink":"http://www.iamlightsmile.com/tags/微信小程序/"}]},{"title":"常见10种自然语言处理技术（转载）","slug":"常见10种自然语言处理技术（转载）","date":"2018-03-05T07:28:41.000Z","updated":"2020-01-18T11:47:34.575Z","comments":true,"path":"articles/常见10种自然语言处理技术（转载）/","link":"","permalink":"http://www.iamlightsmile.com/articles/常见10种自然语言处理技术（转载）/","excerpt":"原文 该作者也是翻译的外文，英文原文链接 引言自然语言处理（NLP）是一种艺术与科学的结合，旨在从文本数据中提取信息。在它的帮助下，我们从文本中提炼出适用于计算机算法的信息。从自动翻译、文本分类到情绪分析，自然语言处理成为所有数据科学家的必备技能之一。 常见的10个NLP任务如下： 词干提取 词形还原 词向量化 词性标注 命名实体消岐 命名实体识别 情感分析 文本语义相似分析 语种辨识 文本总结","text":"原文 该作者也是翻译的外文，英文原文链接 引言自然语言处理（NLP）是一种艺术与科学的结合，旨在从文本数据中提取信息。在它的帮助下，我们从文本中提炼出适用于计算机算法的信息。从自动翻译、文本分类到情绪分析，自然语言处理成为所有数据科学家的必备技能之一。 常见的10个NLP任务如下： 词干提取 词形还原 词向量化 词性标注 命名实体消岐 命名实体识别 情感分析 文本语义相似分析 语种辨识 文本总结 以下将详细展开：1.词干提取什么是词干提取？词干提取是将词语去除变化或衍生形式，转换为词干或原型形式的过程。词干提取的目标是将相关词语还原为同样的词干，哪怕词干并非词典的词目。例如，英文中: beautiful和beautifully的词干同为beauti Good,better和best 的词干分别为good,better和best。 相关论文：Martin Porter的波特词干算法原文 相关算法：Porter2词干算法的Python实现 程序实现：Porter2算法做词干提取的代码： 123#!pip install stemmingfrom stemming.porter2 import stemstem(\"casually\") 2. 词形还原什么是词形还原？ 词形还原是将一组词语还原为词源或词典的词目形式的过程。还原过程考虑到了POS问题，即词语在句中的语义，词语对相邻语句的语义等。例如，英语中： beautiful和beautifully被分别还原为beautiful和beautifully。 good, better和best被分别还原为good, good和good 相关论文1: 这篇文章详细讨论了词形还原的不同方法。想要了解传统词形还原的工作原理必读。 相关论文2: 这篇论文非常出色，讨论了运用深度学习对变化丰富的语种做词形还原时会遇到的问题。 数据集: 这里是Treebank-3数据集的链接，你可以使用它创建一个自己的词形还原工具。 程序实现：下面给出了在spacy上的英语词形还原代码 1234567#!pip install spacy#python -m spacy download enimport spacynlp=spacy.load(\"en\")doc=\"good better best\"for token in nlp(doc): print(token,token.lemma_) 3. 词向量化什么是词向量化？词向量化是用一组实数构成的向量代表自然语言的叫法。这种技术非常实用，因为电脑无法处理自然语言。词向量化可以捕捉到自然语言和实数间的本质关系。通过词向量化，一个词语或者一段短语可以用一个定维的向量表示，例如向量的长度可以为100。 例如：Man这个词语可以用一个五维向量表示。 这里的每个数字代表了词语在某个特定方向上的量级。 相关博文：这篇文章详细解释了词向量化 相关论文：这篇论文解释了词向量化的细节。深入理解词向量化必读。 相关工具：这是个基于浏览器的词向量可视化工具。 预训练词向量：这里有一份facebook的预训练词向量列表，包含294种语言。 这里可以下载google news的预训练词向量。 1234#!pip install gensimfrom gensim.models.keyedvectors import KeyedVectorsword_vectors=KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',binary=True)word_vectors['human'] 程序实现：这段代码可以用gensim训练你自己的词向量 12sentence=[['first','sentence'],['second','sentence']]model = gensim.models.Word2Vec(sentence, min_count=1,size=300,workers=4) 4.词性标注什么事词性标注？简单来说，词性标注是对句子中的词语标注为名字、动词、形容词、副词等的过程。例如，对句子“Ashok killed the snake with a stick”，词性标注会识别： Ashok 代词 killed 动词 the 限定词 snake 名词 with 连词 a 限定词 stick 名词 . 标点 论文1：choi aptly的这篇《The Last Gist to theState-of-the-Art 》介绍了一种叫动态特征归纳的新方法。这是目前词性标注最先进的方法。 论文2：这篇文章介绍了通过隐马尔科夫模型做无监督词性标注学习的方法。 程序实现：这段代码可以在spacy上做词性标注 123456#!pip install spacy#!python -m spacy download en nlp=spacy.load('en')sentence=\"Ashok killed the snake with a stick\"for token in nlp(sentence): print(token,token.pos_) 5. 命名实体消歧什么是命名实体消岐？命名实体消岐是对句子中的提到的实体识别的过程。例如，对句子“Apple earned a revenue of 200 Billion USD in 2016”，命名实体消岐会推断出句子中的Apple是苹果公司而不是指一种水果。一般来说，命名实体要求有一个实体知识库，能够将句子中提到的实体和知识库联系起来。 论文1：Huang的这篇论文运用了基于深度神经网络和知识库的深层语义关联模型，在命名实体消岐上达到了领先水平。 论文2：Ganea and Hofmann的这篇文章运用了局部神经关注模型和词向量化，没有人为设置特征。 6. 命名实体识别体识别是识别一个句子中有特定意义的实体并将其区分为人名，机构名，日期，地名，时间等类别的任务。例如，一个NER会将一个这样的句子： “Ram of Apple Inc. travelled to Sydney on 5th October 2017” 返回如下的结果： RamofApple ORGInc. ORGtravelledtoSydney GPEon5th DATEOctober DATE2017 DATE 这里，ORG代表机构组织名，GPE代表地名。 然而，当NER被用在不同于该NER被训练的数据领域时，即使是最先进的NER也往往表现不佳。 论文：这篇优秀的论文使用双向LSTM（长短期记忆网络）神经网络结合监督学习和非监督学习方法，在4种语言领域实现了命名实体识别的最新成果。 程序实现：以下使用spacy执行命名实体识别。 1234import spacynlp=spacy.load('en')sentence=\"Ram of Apple Inc. travelled to Sydney on 5th October 2017\"for token in nlp(sentence): print(token, token.ent_type_) 7. 情感分析什么是情感分析？情感分析是一种广泛的主观分析，它使用自然语言处理技术来识别客户评论的语义情感，语句表达的情绪正负面以及通过语音分析或书面文字判断其表达的情感等等。例如： “我不喜欢巧克力冰淇淋”—是对该冰淇淋的负面评价。 “我并不讨厌巧克力冰激凌”—可以被认为是一种中性的评价。 从使用LSTMs和Word嵌入来计算一个句子中的正负词数开始，有很多方法都可以用来进行情感分析。 博文1：本文重点对电影推文进行情感分析。 博文2：本文重点对印度金奈洪水期间的推文进行情感分析。 论文1：本文采用朴素贝叶斯的监督学习方法对IMDB评论进行分类。 论文2：本文利用LDA的无监督学习方法来识别用户生成评论的观点和情感。本文在解决注释评论短缺的问题上表现突出。 资料库：这是一个很好的包含相关研究论文和各种语言情感分析程序实现的资料库。 数据集1：多域情感数据集版本2.0 数据集2：Twitter情感分析数据集 竞赛：一个非常好的比赛，你可以检查你的模型在烂番茄电影评论的情感分析任务中的表现。 8. 语义文本相似度什么是语义文本相似度分析？语义文本相似度分析是对两段文本的意义和本质之间的相似度进行分析的过程。注意，相似性与相关性是不同的。 例如： 汽车和公共汽车是相似的，但是汽车和燃料是相关的。 论文1：本文详细介绍了文本相似度测量的不同方法。是一篇可以一站式了解目前所有方法的必读文章。 论文2：本文介绍了用CNN神经网络去比对两个短文本。 论文3：本文利用Tree-LSTMs方法得到了文本的语义相关和语义分类的最新成果。 9. 语言识别什么是语言识别？语言识别指的是将不同语言的文本区分出来。其利用语言的统计和语法属性来执行此任务。语言识别也可以被认为是文本分类的特殊情况。 博文：在这篇由fastText撰写的博文中介绍了一种新的工具，其可以在1MB的内存使用情况下识别170种语言。 论文1：本文讨论了285种语言的7种语言识别方法。 论文2：本文描述了如何使用深度神经网络来实现自动语言识别的最新成果。 10. 文本摘要什么是文本摘要？文本摘要是通过识别文本的重点并使用这些要点创建摘要来缩短文本的过程。文本摘要的目的是在不改变文本含义的前提下最大限度地缩短文本。 论文1：本文描述了基于神经注意模型的抽象语句梗概方法。 论文2：本文描述了使用序列到序列的RNN在文本摘要中达到的最新结果。 资料库：Google Brain团队的这个资料库拥有使用为文本摘要定制的序列到序列模型的代码。该模型在Gigaword数据集上进行训练。 应用程序：Reddit的autotldr机器人使用文本摘要来梗概从文章到帖子的各种评论。这个功能在Reddit用户中非常有名。 程序实现：以下是如何用gensim包快速实现文本摘要。 123fromgensim.summarization import summarizesentence=\"Automatic summarization is the process of shortening a text document with software, in order to create a summary with the major points of the original document. Technologies that can make a coherent summary take into account variables such as length, writing style and syntax.Automatic data summarization is part of machine learning and data mining. The main idea of summarization is to find a subset of data which contains the information of the entire set. Such techniques are widely used in industry today. Search engines are an example; others include summarization of documents, image collections and videos. Document summarization tries to create a representative summary or abstract of the entire document, by finding the most informative sentences, while in image summarization the system finds the most representative and important (i.e. salient) images. For surveillance videos, one might want to extract the important events from the uneventful context.There are two general approaches to automatic summarization: extraction and abstraction. Extractive methods work by selecting a subset of existing words, phrases, or sentences in the original text to form the summary. In contrast, abstractive methods build an internal semantic representation and then use natural language generation techniques to create a summary that is closer to what a human might express. Such a summary might include verbal innovations. Research to date has focused primarily on extractive methods, which are appropriate for image collection summarization and video summarization.\"summarize(sentence) 结束语以上所有是最流行的NLP任务以及相关的博客、研究论文、资料库、应用等资源。 祝你学习愉快！","categories":[{"name":"NLP","slug":"NLP","permalink":"http://www.iamlightsmile.com/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"http://www.iamlightsmile.com/tags/NLP/"}]},{"title":"朕的感情史-编程语言篇！","slug":"朕的感情史-编程语言篇！","date":"2018-03-05T01:16:32.000Z","updated":"2020-01-18T11:56:03.364Z","comments":true,"path":"articles/朕的感情史-编程语言篇！/","link":"","permalink":"http://www.iamlightsmile.com/articles/朕的感情史-编程语言篇！/","excerpt":"对于每一个有理想有追求的程序猿而言，他们可以没有对象，但是不能没有自己的喜欢的语言。 古言道：兄弟诚可贵，老婆价更高。若为编程故（指死亡之die~），躲也躲不掉。 好吧，接下来我要正式介绍一下朕的后宫！","text":"对于每一个有理想有追求的程序猿而言，他们可以没有对象，但是不能没有自己的喜欢的语言。 古言道：兄弟诚可贵，老婆价更高。若为编程故（指死亡之die~），躲也躲不掉。 好吧，接下来我要正式介绍一下朕的后宫！ 第一任：C++ 大一学习编程语言最开始上手的就是C++，不过学了半天也没学出个所以然来，经常挣扎于混杂的概念之中，却又缺少电脑无法有效开展实战编程。后来随着考试结束，我和她的感情也就慢慢的越来越淡了。 好吧，不过呢，作为系统编程和游戏开发的无可替代的语言，她的高性能与开发效率综合而言目前怕是所有所有的都比不上。 大部分企业面试笔试好像都会问到C++，感觉不会点C++真的不配说自己是程序员，但是我觉得人生苦短，何必找死呢。感觉C++是我等屁民不可轻易染指的高冷女神。 第二任：C 为了更好的学习C++，曾经又跑去学了C，因为我觉得她是C++的姐姐吧。不过还是由于驱动力不足之类的原因吧，最终也没能学出个卵子，不过也在某种程度上理解了C++相对于C而言做的改进，例如多态、名称空间、类等对于结构化的编程还是挺有用的吧。 C语言也可以做的很吊，但是由于语言的设计里本身并没有许多高级概念，所以用起来不是很直接方便，搞系统编程或者其他对效率要求极高的才会用吧。看上去没有C++的高冷，但是也不好追，并且语言特性相对低级，自己本身不太喜欢。 第三任：Java Java这门语言其实真的是相当不错的。如所有的类都有一个共同的基类，只能继承自一个父类，其他的通过接口来实现，相对于C++的名称空间来说要好不少。 Java的语言世界里，程序总是在一个个实例化的类或类本身中的属性和方法中穿梭，某种程度上来说其实挺好的。相比C++而言，普通的人很容易上手并能培养起初步良好的编程习惯。 我在Java实验课程中手撸一个什么系统，在此过程中，初步培养起了软件编程的极初始的经验体会。后来学习Android过程中，由于也要用到Java，所以功底还算可以。 但是在定义和使用的过程中，还是会感觉到比较冗杂，当然规矩多了某种程度上也算好事。那些之后在JVM之上出现的其他语言，也是同样在JVM上运行程序，但是相对而言可能更简洁、更少束缚、更强表现力，如Scala、Kotlin等等。 曾经问我家邻居学软件怎么入手，他说你就学Java吧。Java语言在企业级应用系统开发中的主导地位怕是很难被动摇的。 无论什么时候，Java都是一个值得选择拥抱的小姐姐。 第四任：C# C#开发最初的目的可能是微软用于应对Java吧。 C#这门语言在面向对象的语言家族中还是很不错的，某些设计理念比Java还要先进。然而正如以前的VBScript等更多的是被捆绑在Windows操作系统中，不开源，在某种程度上也算束缚了它的发展进步。虽说现在开源了，但是由于Java已经占领了大部分市场，C#的份额还是挺小的了。 因课结缘，课完缘尽。定位和Java类似，但是对Java更有好感。 第五任：Lua 不得不说，Lua真的是个好语言，只是之前没怎么好好学，并且它上手极为简单容易。现在的话，很少接触，因为基本上用不到。对于它的C源码还是有必要看一下的。感觉很有好感的小妹妹。 第六任：Python Python的设计哲学现在看来真的是极好，这些年的发展壮大足以说明一切，在大部分编程应用领域里几乎都有了它的身影。极强的代码阅读性，上手很容易。于我而言，她现在是一个贤妻良母型的。 第七任：Ruby Python和Ruby各领风骚，许多爱好者各爱各的好。Ruby我以前也学过一下下，Ruby好像是基于对象的，里面啥都是对象。相对而言，用法超级灵活，而且比较简洁炫酷，但是可能因为用的少，我看着Ruby代码好像阅读起来不是很爽，比Python而言差远了。开发效率极高，Ruby on Rails嘛，但是好像项目做大之后就会受限于它的运行效率。现在也早就分了。感觉Ruby和我三观不符，私人感觉Ruby是一个比较追求时尚新颖的女生，比较开放外向。 第八任：Scala 我曾经学习过很短时间的Scala，网上的说法是学习起来很复杂，我当时感觉还不错，后来因为用不到也没在学了，可能还是不太感兴趣吧。也是一个不错的小姐姐，但是如果太专情于此，怕是不好吃饭。。。 第九任：aardio 最爱，没有之一。虽然它生于Windows，长于Windows，最终也将死于Windows，但是这还是无法阻挠我对它的喜爱，况且正是由于仅限于Windows平台，她的美才更加表现出来。她的不开源我也理解，是我我也不开源，正是一鹤校长非常爱她，才不允许其他误解开源精神的染指搞事情。 动态语言，快速开发，名称空间、类，句法灵活，调用简单，几行代码就可以实现复杂的功能，并且很方便的就可以开发出控制台、桌面、网络、后台程序，可以方便与其他语言实现互相调用。 自从无意间了解到这门语言之后，感觉一下子就被吸引到了，因为她当时完全符合我对编程语言的所有需求，他妈的当时把老纸激动坏了，差点一宿没睡着。当时学了编程两年多，都写不出个什么桌面程序来，用Java写的太丑，用C#开发的还得运行在.Net框架上。一点成就感都没有，我对可视化的界面还是很执着的。 后来花钱报了班，看视频学习，有时会在群里探讨问题，有时会直接向校长询问，感觉真的很值。后来我数据库实验、编译原理实验、操作系统实验等等全都是用的aardio语言，因为用起来实在是太爽了。 于我而言，aardio是我的初恋，是我第一门喜欢上的语言，虽然现在由于没有需求已经暂停和她失去了联系，但是我会永远喜欢她！ 第十任：Processing Processing这门语言用来做艺术设计以及自然模拟都是很不错的，并且跨平台，可以生成可执行程序，本身使用Java语言写的，同时也有JavaScript版和Python版，也是用不到所以没在用了。在我看来，像是一个很可爱的萝莉。 第十一任：JavaScript 个人感觉，JavaScript最屌了。它的语言哲学相对来说和我的三观最为符合，原型继承，闭包等等概念都很不错。随着es6的出现，它的语法规范感觉十分高级，个人十分喜欢，在某种程度上，部分设计已经超越了aardio（感觉aardio是集许多好的语言的特性于一身）。事件驱动、非阻塞I/O、回调的NodeJs感觉也很棒。是一个我非常想深入学习的语言，对我来说是一个极具诱惑力的女神。 第十二任：Racket Racket是Scheme的一种方言，而Scheme则是Lisp的一种方言，语言中处处都是函数式编程，感觉非常新颖且高大上，但是程序复杂起来了之后阅读体验极差，远远比不上Python。接下来打算有时间接触一下下，多吸取里面的先进思想。 第十三任：Julia 2018/3/5刚接触Julia语言，感觉真的挺厉害的，元编程，并行计算，超高性能，语法像Python、用法像Lisp、速度像C，渍渍，真是厉害了~ 第十四任：？ 第十五任：？ 第十六任：？ 第十七任：？ …… 接下来的语言还没出现或者还没接触到，可能今后才会冒出来，或者是我自己设计定义实现的吧……","categories":[{"name":"计算机","slug":"计算机","permalink":"http://www.iamlightsmile.com/categories/计算机/"}],"tags":[{"name":"编程语言","slug":"编程语言","permalink":"http://www.iamlightsmile.com/tags/编程语言/"}]},{"title":"Python学习笔记（1）骚操作之Unicode编码","slug":"Python学习笔记（1）骚操作之Unicode编码","date":"2018-03-04T11:53:42.000Z","updated":"2020-01-18T11:58:14.130Z","comments":true,"path":"articles/Python学习笔记（1）骚操作之Unicode编码/","link":"","permalink":"http://www.iamlightsmile.com/articles/Python学习笔记（1）骚操作之Unicode编码/","excerpt":"Python3内部使用的是Unicode编码，所以在变量定义的时候或许可以搞点事情。","text":"Python3内部使用的是Unicode编码，所以在变量定义的时候或许可以搞点事情。 例如创建一个文件,名为：人.py，里面的代码是：12class 人(object): 性别 = \"男\" 然后同目录下创建一个test.py文件，里面内容为：123from 人 import 人李明 = 人()print(李明.性别) 结果输出：男，是不是有点骚~","categories":[{"name":"Python","slug":"Python","permalink":"http://www.iamlightsmile.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.iamlightsmile.com/tags/Python/"}]},{"title":"《和谐辩证法》笔记与心得（3）吾之平衡辩证法","slug":"《和谐辩证法》笔记与心得（3）吾之平衡辩证法","date":"2018-03-04T01:14:31.000Z","updated":"2020-01-18T11:50:01.038Z","comments":true,"path":"articles/《和谐辩证法》笔记与心得（3）吾之平衡辩证法/","link":"","permalink":"http://www.iamlightsmile.com/articles/《和谐辩证法》笔记与心得（3）吾之平衡辩证法/","excerpt":"吾之所见为，宇宙的发展其实就是能量间从不平衡状态到平衡状态的迁移罢了。 事物的稳定与不稳定两种状态可理解为运动之趋势变化抑或不变耳。 事物总是从不平衡的状态朝向平衡的状态运动和发展的，而之所以运动不止，发展不断，则是由于外界的作用又使得事物可能从平衡又趋于不平衡。","text":"吾之所见为，宇宙的发展其实就是能量间从不平衡状态到平衡状态的迁移罢了。 事物的稳定与不稳定两种状态可理解为运动之趋势变化抑或不变耳。 事物总是从不平衡的状态朝向平衡的状态运动和发展的，而之所以运动不止，发展不断，则是由于外界的作用又使得事物可能从平衡又趋于不平衡。 事物内部或事物之间的平衡或不平衡的状态实际上就是指在没有外物的作用下，事物之间或事物内部各要素之间能否保持稳定而不变化的状态，对应的是时刻，状态或趋势。而运动或静止对应的是时间，过程或阶段。平衡或不平衡是决定事物或事物之间运动以相互作用的决定因素，而运动与静止则是从不平衡态向平衡态迁移或平衡态迁移到不平衡态的实现过程。 然而吾仍不解的是宇宙之始态为何，宇宙之终态又为何，同时为什么能量非要从不平衡态迁移到平衡态。 举例如：生产关系之调整是生产关系与生产力从不平衡到平衡的过程；生产力之进步是生产力与人类生存发展不平衡到平衡的过程；人类之生存发展是理想与现实之不平衡到平衡的过程；但理想之追求非平衡，而是贪念和占有，故此之平衡终为不可持续之平衡，故马克思理想之共产主义社会终究不会实现与持久，缘何？人类与大自然和环境之极大不平衡也。当然，最好的结果自然是人类延续，欲望无休止，继续开采资源直至到其他星球为止。最坏的结果当为人类自掘坟墓、自取灭亡。","categories":[{"name":"其他","slug":"其他","permalink":"http://www.iamlightsmile.com/categories/其他/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"http://www.iamlightsmile.com/tags/哲学/"}]},{"title":"《和谐辩证法》笔记与心得（2）能量供求之己见","slug":"《和谐辩证法》笔记与心得（2）能量供求之己见","date":"2018-03-04T01:08:20.000Z","updated":"2020-01-18T11:49:53.162Z","comments":true,"path":"articles/《和谐辩证法》笔记与心得（2）能量供求之己见/","link":"","permalink":"http://www.iamlightsmile.com/articles/《和谐辩证法》笔记与心得（2）能量供求之己见/","excerpt":"本书作者以为存在两种性质不同的能量作用方式，即：1.单向能量供求关系2.双向能量供求关系。同时存在三种不同的能量供求结果，即：1.能量相容2.能量冲突3.能量中立。 单向能量供求关系可形成能量链，链条上的每一节都存在能量的转换与运动形式的转换。 而双向能量供求关系则表现为单两者之间的相互吸引或者相互对抗、相互满足或者相互伤害。 然吾不以为然，因为事物之间的彼此联系实际上就是说存在着相互作用的关系，彼此可以影响对方的运动和发展。","text":"本书作者以为存在两种性质不同的能量作用方式，即：1.单向能量供求关系2.双向能量供求关系。同时存在三种不同的能量供求结果，即：1.能量相容2.能量冲突3.能量中立。 单向能量供求关系可形成能量链，链条上的每一节都存在能量的转换与运动形式的转换。 而双向能量供求关系则表现为单两者之间的相互吸引或者相互对抗、相互满足或者相互伤害。 然吾不以为然，因为事物之间的彼此联系实际上就是说存在着相互作用的关系，彼此可以影响对方的运动和发展。 所以可以说“凡事皆为众因之果，万物齐作众果之因”。 吾以为凡世间种种因缘之变化，皆能量相互作用之结果。能量自然成链，无限接力也。然天下间万事万物皆作能量之一小环，有供有求，无时无刻不相互作用耳。作者之见，实为取何其浩大之细微，沧海之一粟，往来之一瞬。然后取关联以相接，得知为链，然作者岂不明乎：双向能量供求关系岂非特殊两者之链而成环哉！ 如下图：,此即细微也。圆圈指能量体或物质外显或抽象之概念，而这指向圆环的箭头其实也是外界相加于圆圈之能量，而自圆环外指的箭头当为圆环向外界其他能量体施加之能量。 本书作者之单向能量链为：。 而双向能量供求关系为：。 岂不过度抽象与特殊化乎。所谓单向或双向在我看来无非作用程度不同罢了。 所谓“大道至简”，因而绝非有两种存在。 同时参考吾之运动与静止理解，可得，万事万物，都会直接或者间接地影响和改变某一事物内在的结构和内容或其作为要素与整体及整体的其他要素之关系，从而推动事物的运动和发展。 若拿函数方程来粗浅理解，如三个变量X，Y，Z，有函数方程组：。 三个方程三个未知量，若是再知道初态X0 、Y0、Z0，那么从逻辑上或许总是可以得到依次的相互对应的X，Y，Z的值的。 然而现实是现实中的未知量实在是太多了，同时函数关系式也太复杂了，所以理论来说实际上是不可能得到准确的解的。然而我们通过观察现实中某些量或许是线性的，也就是说两者之间是线性联系或者呈现出其他的联系函数，正是在这个基础上，我们的认识才更加深化和进步。 故而可理解为世间或宇宙或许为能量之一个奇大无比之网，而我们万物无非其中一个小小结罢了。 同时关于三种能量供求结果，我的想法是可以从物理学上机械能做功的角度。 （机械宏观运动中）物体运动有其方向，即速度是一个矢量，而外力平行于该方向上的分力，若方向一致则做正功，推动事物原有方向上的发展。若相反，则做负功。阻碍事物原有方向的发展，甚至使方向发生180度变化。而垂直于运动方向上的力不做功，但仍有改变方向之效用，因而能量相容即外界之能量作用于事物产生的运动状态与物质本身、当前运动状态相一致则为相容。相反则为冲突。垂直则为中立，并非无用，可起到改变方向之作用，但中立应该是特殊状态，且仅一瞬的状态，因为运动方向一旦改变而作用方向不变，即产生非中立关系，因而是不可持续的，若是站在物理力学之坐公交度，则不存在此状态。","categories":[{"name":"其他","slug":"其他","permalink":"http://www.iamlightsmile.com/categories/其他/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"http://www.iamlightsmile.com/tags/哲学/"}]},{"title":"《和谐辩证法》笔记与心得（1）物质运动与静止之己见","slug":"《和谐辩证法》笔记与心得（1）物质运动与静止之己见","date":"2018-03-04T01:07:10.000Z","updated":"2020-01-18T11:49:43.322Z","comments":true,"path":"articles/《和谐辩证法》笔记与心得（1）物质运动与静止之己见/","link":"","permalink":"http://www.iamlightsmile.com/articles/《和谐辩证法》笔记与心得（1）物质运动与静止之己见/","excerpt":"对应p35吾以为马克思之运动与静止之观点与本书作者之运动与静止之观点均有偏颇之处，或者各有所见。然吾之角度或许不同于二者乎。 马克思云运动之绝对而静止之相对，而本书作者云运动与静止均绝对。恩格斯之运动绝对体现在：1.任何事物都是运动的2.任何事物在任何时候都是运动的。 而本书作者之运动与静止之界限取决于事物是否在特定能量下作为一个整体的运动变化，同时还伴随着其特定能量的释放。","text":"对应p35吾以为马克思之运动与静止之观点与本书作者之运动与静止之观点均有偏颇之处，或者各有所见。然吾之角度或许不同于二者乎。 马克思云运动之绝对而静止之相对，而本书作者云运动与静止均绝对。恩格斯之运动绝对体现在：1.任何事物都是运动的2.任何事物在任何时候都是运动的。 而本书作者之运动与静止之界限取决于事物是否在特定能量下作为一个整体的运动变化，同时还伴随着其特定能量的释放。 而吾之运动静止观在于两方面：1.事物内部各要素之间联系是否发生改变，事物的结构与内容是否发生变化2.事物作为一个整体的要素是否与其他要素之间的联系是否发生改变，以及因此导致的整体的结构及内容的变化。 然而事物作为一个整体而言，其要素的划分方式并非绝对的，而是相对的，同时该事物作为一个要素而言，可以和别的事物组成一整体，而这种组合也是多变的，多样的。具体含义为：一个事物根据不同的角度可以被划分为多种不同的要素的有机组合，如abcd可以分为a、b、c、d或者ab、cd或者abc、d等等，同时这一事物可以和其他事物组成不同的多样的整体，如a和b可以组合成ab而a和c可以组合成ac，此外同为ab与ba尽管内容相同，但内部要素之间结构不同，因而算是不同事物。 故吾看来，事物之运动或静止取决于以上两方面，同时他们的根本属性并非绝对性而在于其相对性，运动是相对的，静止也是相对的。这里的相对并非事物与事物之间的相对，而是事物与角度之间的相对。","categories":[{"name":"其他","slug":"其他","permalink":"http://www.iamlightsmile.com/categories/其他/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"http://www.iamlightsmile.com/tags/哲学/"}]},{"title":"《智慧之根》笔记与心得（2）事物之结构浅解","slug":"《智慧之根》笔记与心得（2）事物之结构浅解","date":"2018-03-04T00:47:56.000Z","updated":"2020-01-18T11:50:22.946Z","comments":true,"path":"articles/《智慧之根》笔记与心得（2）事物之结构浅解/","link":"","permalink":"http://www.iamlightsmile.com/articles/《智慧之根》笔记与心得（2）事物之结构浅解/","excerpt":"&emsp;&emsp;吾以为，事物之结构该当如下：（注意：这里的事物应当是能量的物质外显，抑或人们的抽象之概念，然吾之推测当人们所不明之结构也当如此） &emsp;&emsp;联系需要联系者，因为联系是联系者之间的联系。联系者具体地说就是具体事物，抽象地说就是联系环节，因而联系环节就是指抽象的联系者。联系的基本环节包括：系统和要素、结构和功能、形势和内容、本质和现象、原因和结果、内因和外因、质与量、肯定与否定。","text":"&emsp;&emsp;吾以为，事物之结构该当如下：（注意：这里的事物应当是能量的物质外显，抑或人们的抽象之概念，然吾之推测当人们所不明之结构也当如此） &emsp;&emsp;联系需要联系者，因为联系是联系者之间的联系。联系者具体地说就是具体事物，抽象地说就是联系环节，因而联系环节就是指抽象的联系者。联系的基本环节包括：系统和要素、结构和功能、形势和内容、本质和现象、原因和结果、内因和外因、质与量、肯定与否定。 一 系统和要素 任何系统本身既是个系统，又处于更大的系统之中。系统是由要素构成的，因而相对于更大系统而言的某一具体事物又成为构成更大系统的要素。 系统是由一定数量相互联系的要素资格，有特定结构、性质和功能的有机整体。 如上图中，可将这个大的系统结构的某个要素视为四个该要素之要素组成之系统（整体）：，四个要素之要素可视为相对这个要素（系统）之要素（部分）：，应当注意系统与要素之间的相对性。无论系统还是要素都是相对的。 二 结构和功能 宇宙万物不仅作为系统由一定要素所构成，而且构成一事物的要素因其相互联系而构成特定的结构，从而具有特定的功能。 结构是事物内在要素的联结方式。结构不仅具有整体性，也具有相对稳定性（根据皮亚杰的观点，结构的各要素互相制约、互为条件且不受外界因素的影响），因而具有转换型（结构的各要素可按一定规则互相替换而不改变结构本身）。注：关于相对稳定性，吾不以为然，吾以为结构之间的要素的关联是要受到外界的干预影响的。 功能是事物由其结构而产生的对外部对象或环境的作用能力，或者说，是事物通过对外部对象或环境的作用而表现出来的性能。 结构与功能之区别：结构属于事物内部的内部联系，而功能则是一事物通过与另一事物发生外部联系而产生或体现出来。 如最上图，这个大的系统的最上面的那个要素的结构是蓝色部分，： ，而这个要素的功能是绿色部分： 。 三 形式与内容 结构作为事物内在要素的联结方式也就是事物的形式，要素就是事物的形式所依存的内容。 所谓内容就是构成事物的一切内在要素的总和。内容有两大类：一是实体方面的（部分、成分），一是属性方面的（内在矛盾、发展趋势）。 所谓形式就是把食物的内在要素组合起来的结构。 形式和内容是有区别的，内容是事物存在的基础，相对于形式来说，它是“实”，是形式这张网上的“结”；形式则是事物存在的结构，相对于内容来说，它是“虚”，是编织内容的“网”。因此，内容和形式的关系可以说是实（结）与虚（网）的关系。 如最上图，这个大的系统的最上面的那个要素的内容即粉红色部分：，而形式实则为对应功能之结构，只不过形式对应的是内容，其实（形式与结构）实质一样，但对应之物不同，故侧重角度略有不同：。 四 本质和现象 现象是事物显现于外的形象或面貌。它是事物本质的诸方面表现，其实质是外部联系，就是说，一事物如果不与一定量的其他事物发生联系或相互作用，就没有现象可言。 本质是事物深藏于内的根本性质，其实质是事物内在的根本要素之必然联系，它是由事物的根本矛盾或特殊矛盾决定的。3.就本质与性质的关系来说，本质通常是就个体事物之为其自身而言的，性质是就个体的类属而言的。虽然本质与性质都很抽象，但性质比本质更抽象。 就本质与结构（形式）的关系来说，结构（形式）相对于功能也相对于要素（内容）而言，但本质仅相对于现象而言。现象不等于功能和要素，所以本质也不同于结构（形式）。本质和结构都很抽象，但相比而言，本质比结构更抽象（结构较本质更具体）。 从根本上说，本质与结构（形式）是一致的。 本质与结构（形式）的一致，在于他们都不能脱离要素（内容）而独立存在。 就本质与规律、趋势（必然性）的关系来说：三者虽然都是抽象的，但本质是从相对静态的角度来深刻认识事物的，他所要揭示的是事物之为事物的当前规定性；而规律和趋势（必然性）则是从相对动态的角度来深刻把握事物的，他所要解释的是事物未来的进程和归宿。不过，本质与规律和趋势（必然性0也是一致的：本质决定规律和趋势（必然性），规律和趋势（必然性）反映本质。就是说，一个事物的本质是怎么样的，其发展的进程（规律）和结局（趋势或必然性）就是怎么样的。 如最上图，系统之现象当如： ，，吾以为现象当为系统呈现出的外部状态。 系统之本质当如： 。 如此，圆圈和线条就构成了事物结构之四个基本环节。即： 圆圈（外）与圆圈（内）构成系统与要素。 圆圈（外）与线条（内）构成现象与本质。 线条（内）与线条（外）构成结构与功能。 线条（内）与圆圈（内）构成形式与内容。 从以上可知，圆圈内与线条外不构成直接联系。 联系的基本形式 联系的环节是要解决联系的主题承担者问题。显然，没有联系的环节，联系是无法想象的，是不可能存在的。但现实事物中的联系，不仅需要作为联系者的联系环节，也需要联系的形式。联系的形式就是要解决事物时怎样联系的问题。 联系的具体形式无限多样，但其基本形式是有限的。联系的基本形式，依其复杂程度可分为两类：相对简单的联系形式和相对复杂的联系形式。 相对简单的联系形式——内部联系和外部联系、纵向联系和横向联系、直接联系和间接联系。 相对复杂的联系形式——必然联系和偶然联系、因果联系和非因果联系。 所谓必然联系，就是事物在发展过程中所表现出的确定不移的趋势，它是事物内在的直接的本质的稳定的联系。必然联系的首要特征是确定性或稳定性，因为必然联系或必然性根源于事物的根本矛盾。也正因为如此，必然联系在事物存在的全局或发展的全程中居于支配地位。 所谓偶然联系，就是事物在发展过程中所表现出的并非确定不移的趋势（可以出现，也可以不出现；可以早出现，也可以晚出现；可以这样出现，也可以那样出现），它是事物外在的非本质的不稳定的联系。偶然联系的首要特征是不确定性或不稳定性，因为偶然联系或偶然性根源于事物的非根本矛盾或外部矛盾。也正因为如此，偶然联系在事物存在的全局或发展的全程中居于被支配的地位。 偶然联系和必然联系不仅同时存在于一个事物的发展过程之中，而且二者都有其具体形式。偶然联系（偶然现象）的具体形式在事物发展过程的开始、中间和结果三个基本阶段中都可能出现或存在。必然联系的具体形式主要有：有先后的历时性必然联系（因果联系）与无先后的共时性必然联系（函数关系）。 要知道某一事物或现象是原因还是结果，必须把它放在特定关系中才行。 可以把原因定义为能引起（能生）一定事物的事物（实体、状态、性质、过程），而结果可以定义为被一定事物引起（所生）的事物（实体、状态、性质、过程）。 因果联系有两个基本特征：（1）先后性（2）必然性。 因果联系是有先后性的必然联系。 世界万物是处于普遍联系之中的，没有孤立存在的事物。但普遍联系的事物之联系的环节和形式是多样性的，联系的类型也是多样的。联系的基本类型主要有：局部联系与全局联系，暂时联系与长久联系，简单联系与复杂联系，紧密联系与松散联系，客观联系与主观联系，主要联系（本质的联系）与次要联系（非本质的联系），等等。","categories":[{"name":"其他","slug":"其他","permalink":"http://www.iamlightsmile.com/categories/其他/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"http://www.iamlightsmile.com/tags/哲学/"}]},{"title":"事物变化之缘由之己见","slug":"《智慧之根》笔记与心得（1）事物变化之缘由之己见","date":"2018-03-03T05:20:02.000Z","updated":"2020-01-18T11:50:13.786Z","comments":true,"path":"articles/《智慧之根》笔记与心得（1）事物变化之缘由之己见/","link":"","permalink":"http://www.iamlightsmile.com/articles/《智慧之根》笔记与心得（1）事物变化之缘由之己见/","excerpt":"&emsp;&emsp;唯物辩证法之基础思想在于事物——世间的万事万物都是彼此联系和不断发展的。而矛盾是最深刻最本质的联系，同时矛盾是事物变化发展的根本动力。那么到底何为矛盾，又为何矛盾？矛盾矛盾，以子之矛攻子之盾，虽然唯物辩证法中的矛盾并非现实的实物的矛和盾，但其中精妙也在于此，否则为何意译为矛盾呢。 &emsp;&emsp;吾之前不能理解矛盾之到底为何物遂去图书馆查阅相关书籍，然余性驽智愚，未尝更愈明晓也。 &emsp;&emsp;观本书p115处似有朦胧浅薄之理解，矛盾是既对立又同一的双重关系或属性，换句话说应当是一个事物的两个相反相成的性质或属性吧。也可看作是两个事物彼此之间相反相成，但是当这两个事物作为要素构成一个整体时，或者同时作为属性构成于一个统一的事物时，即又可看做是一个事物的内部矛盾。","text":"&emsp;&emsp;唯物辩证法之基础思想在于事物——世间的万事万物都是彼此联系和不断发展的。而矛盾是最深刻最本质的联系，同时矛盾是事物变化发展的根本动力。那么到底何为矛盾，又为何矛盾？矛盾矛盾，以子之矛攻子之盾，虽然唯物辩证法中的矛盾并非现实的实物的矛和盾，但其中精妙也在于此，否则为何意译为矛盾呢。 &emsp;&emsp;吾之前不能理解矛盾之到底为何物遂去图书馆查阅相关书籍，然余性驽智愚，未尝更愈明晓也。 &emsp;&emsp;观本书p115处似有朦胧浅薄之理解，矛盾是既对立又同一的双重关系或属性，换句话说应当是一个事物的两个相反相成的性质或属性吧。也可看作是两个事物彼此之间相反相成，但是当这两个事物作为要素构成一个整体时，或者同时作为属性构成于一个统一的事物时，即又可看做是一个事物的内部矛盾。 &emsp;&emsp;书中云矛盾之基本属性关系有二：1.对立性和同一性2.普遍性和特殊性。 &emsp;&emsp;书中p117页所提矛盾之对立性是事物内部两个根本相反方面的对立性。以鄙之愚见当为若一事物有a属性同时又具有！（非）a属性，则这个a和！a当为一对矛盾。拿人类性别这一抽象事物举例吧，人类性别包含男，女，双性，非男非女四个类别。之前只知晓男和女两种类别，后面两种是近来才发现和命名的。So，男之所以为男，正是因为女的存在，女的照样也是如此。正如老子《道德经》所云：”世人皆知美之为美 斯恶已 皆知善之为善 斯不善已“。这里怎么理解呢？在我看来应该是无论男和女作为一种抽象的概念对具体事物的划分抑或美和丑作为抽象概念对认知感觉的划分，他们都是由人们的观念所决定的，换句话说意思就是在没有“男”和“女”这两个概念出来之前，世上自然就是不分男女的，当有了这样的变化或者说是人们的认知需要，才出现了男和女这两个对立而又同一的概念，它们两者自诞生以来便是同时的，无时无刻不相互对立而又同一，对立性体现在男的对立面即为女，女的对立面即为男，同一性体现在男和女所共同组成的整体正是全部人类，更确切的是其性别属性。当然以上概念可能有些不准确，我这里举着个例子并非含有任何性别歧视的含义。 &emsp;&emsp;从另一个角度来看，人的性别属性也是男性或女性，然而更确切的来看应该是既含男性又有女性，何也，万事无绝对也。只是男（女）性的男（女)性基因或男(女）性表现在其所处环境下得到了充分的表达而已。 &emsp;&emsp;从更抽象的角度来理解矛盾的关键抑或核心即4个字“一分为二”。 &emsp;&emsp;正如下图：一条线总能将这个圆分成两部分。然而这条线之划分并非绝对的，两边也是动态发展的，发展过程中，既可能你中有我我中有你，同时也会相互转化。最好的例证既是阴阳太极图： &emsp;&emsp;然而阴阳太极图以其对称形式体现且是静态图，所以要体现其动态变化性应该再加上五行和四象，五行相生相克，当为太极阴阳调和变化之道。 &emsp;&emsp;此即中西关于矛盾观念之相合且高度一致。 而在《和谐辩证法》中，事物之变化当取决于能量供求原理。物质之运动有六大逻辑要素，即物质、能量、数量、结构、程序、信息。而物质有三大显著特征：1.质量实体2.能量母体3.运动载体。而能量作用有三种不同形式：能量相容、能量冲突和能量中立。同时其供求两极正好对应太极阴阳之两化。同时其核心观点当为“能量推动物质运动、物质运动释放能量” 而在看了关于宇宙大爆炸理论、黑洞、奇点以及空心菜创作的《世界就是一个游戏》以及其在腾讯视频中《用道德经破解宇宙起源》的观点和理念让余产生了新的观点和看法。 吾之观念当为宇宙之中当为处处都有能量，而整个宇宙的发展过程，正是宇宙间各能量间从不平衡到平衡的发展过渡过程。而所谓的物质，则是人类可观察的能量的一种特殊形式，可称之为能量的物质外显，同时能量也可以不表现为物质的形式，如场以及我们尚不知晓的形式等等。 吾之理解中，宇宙之始吾不知，宇宙之末吾不晓。或如空心菜般更高层智慧所创造，或如进化论般偶然之所进化，或如为何能量之不平衡至平衡，吾尚不明也。 然吾等人类仅为银河系太阳系地球数百亿年历程之小小一瞬，当有自知之明，而非自傲视己为万物之灵长，敢于天地造化同在。 若宇宙如空心菜所言，自当为一游戏，此生当以修心为主。 若宇宙如大爆炸所云，则另有一可能如高层智慧之一团烟火，自燃时起，至黯时灭。思想观念来源于《黑衣人》 而吾之所见，当为无论物质之外显，抑或思维中抽象之概念，其发展阶段都为自不平衡至平衡发展的状态。而之所以运动不止，发展不断，则是由于外界的作用，使事物又趋于不平衡。","categories":[{"name":"其他","slug":"其他","permalink":"http://www.iamlightsmile.com/categories/其他/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"http://www.iamlightsmile.com/tags/哲学/"}]},{"title":"算法学习笔记（2）数组","slug":"算法学习笔记（2）数组","date":"2018-03-02T09:15:47.000Z","updated":"2020-01-18T11:54:39.167Z","comments":true,"path":"articles/算法学习笔记（2）数组/","link":"","permalink":"http://www.iamlightsmile.com/articles/算法学习笔记（2）数组/","excerpt":"学习自B站算法面试精讲 查找和排序 二分查找 元素交换 排序，中位数 归并 位运算 前缀和的应用 动态规划 排列组合","text":"学习自B站算法面试精讲 查找和排序 二分查找 元素交换 排序，中位数 归并 位运算 前缀和的应用 动态规划 排列组合","categories":[{"name":"计算机","slug":"计算机","permalink":"http://www.iamlightsmile.com/categories/计算机/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://www.iamlightsmile.com/tags/算法/"}]},{"title":"算法学习笔记（1）字符串","slug":"算法学习笔记（1）字符串","date":"2018-03-02T08:18:14.000Z","updated":"2020-01-18T11:54:14.998Z","comments":true,"path":"articles/算法学习笔记（1）字符串/","link":"","permalink":"http://www.iamlightsmile.com/articles/算法学习笔记（1）字符串/","excerpt":"学习自https://www.bilibili.com/video/av11739347/ 算法面试精讲 和数组相关，内容广泛 概念理解：字典序 简单操作：插入、删除字符，旋转 规则判断（罗马数字转换、是否是合法的整数、浮点数） 数字运算（大数加法、二进制加法） 排序、交换（partition过程） 字符计数（hash）：变位词 匹配（正则表达式、全串匹配、KMP、周期判断） 动态规划（LCS、编辑距离、最长回文子串） 搜索（单词变换、排列组合）","text":"学习自https://www.bilibili.com/video/av11739347/ 算法面试精讲 和数组相关，内容广泛 概念理解：字典序 简单操作：插入、删除字符，旋转 规则判断（罗马数字转换、是否是合法的整数、浮点数） 数字运算（大数加法、二进制加法） 排序、交换（partition过程） 字符计数（hash）：变位词 匹配（正则表达式、全串匹配、KMP、周期判断） 动态规划（LCS、编辑距离、最长回文子串） 搜索（单词变换、排列组合）","categories":[{"name":"计算机","slug":"计算机","permalink":"http://www.iamlightsmile.com/categories/计算机/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://www.iamlightsmile.com/tags/算法/"}]},{"title":"浏览器插件小试","slug":"浏览器插件小试","date":"2017-12-25T02:40:27.000Z","updated":"2020-01-18T11:52:57.637Z","comments":true,"path":"articles/浏览器插件小试/","link":"","permalink":"http://www.iamlightsmile.com/articles/浏览器插件小试/","excerpt":"由于时间比较久远，现在浏览器插件编写的工作都已经忘记了一大半，不过之前获取的只是图片的绝对地址，用起来还是不太方便，并且比如说插件的title、description、icon等都是原来的如testMenu等比较low的，于是后来又修改了一下，包括以上的项目属性，以及目前复制到剪贴板的直接是Markdown中的图片地址格式，如! [image_title] (image_absolute_path)的格式，并且已经把相关的源码上传到我的GitHub上面，链接地址为：https://github.com/smilelight/GithubImagePace 。","text":"由于时间比较久远，现在浏览器插件编写的工作都已经忘记了一大半，不过之前获取的只是图片的绝对地址，用起来还是不太方便，并且比如说插件的title、description、icon等都是原来的如testMenu等比较low的，于是后来又修改了一下，包括以上的项目属性，以及目前复制到剪贴板的直接是Markdown中的图片地址格式，如! [image_title] (image_absolute_path)的格式，并且已经把相关的源码上传到我的GitHub上面，链接地址为：https://github.com/smilelight/GithubImagePace 。 欢迎有需求的看客下载、使用、交流、分享等。","categories":[{"name":"计算机","slug":"计算机","permalink":"http://www.iamlightsmile.com/categories/计算机/"}],"tags":[{"name":"浏览器插件","slug":"浏览器插件","permalink":"http://www.iamlightsmile.com/tags/浏览器插件/"}]},{"title":"关于Markdown引用图片地址的尝试","slug":"关于Markdown引用图片地址的尝试","date":"2017-12-24T14:43:44.000Z","updated":"2020-01-18T11:52:02.503Z","comments":true,"path":"articles/关于Markdown引用图片地址的尝试/","link":"","permalink":"http://www.iamlightsmile.com/articles/关于Markdown引用图片地址的尝试/","excerpt":"前两天某刻突然想到学习不能只有输入，更应该有输出，有时历程和心得更需要记录下来，于是就萌发起了写博客的念头，如今写博客的平台很多，比如博客园、CSDN、简书、新浪博客，甚至知乎等等，也可以通过GitHub pages来实现，甚至于购买云服务器搭建自己的博客网站。由于个人知识浅薄，并且想要拥有更高的自由度，以及一些其他因素限制，最终选择了通过GitHub pages+hexo来搭建自己的个人博客站点，借助于网上丰富详致的相关搭建博客教程终于把自己的小窝搭建起来了，吼吼！","text":"前两天某刻突然想到学习不能只有输入，更应该有输出，有时历程和心得更需要记录下来，于是就萌发起了写博客的念头，如今写博客的平台很多，比如博客园、CSDN、简书、新浪博客，甚至知乎等等，也可以通过GitHub pages来实现，甚至于购买云服务器搭建自己的博客网站。由于个人知识浅薄，并且想要拥有更高的自由度，以及一些其他因素限制，最终选择了通过GitHub pages+hexo来搭建自己的个人博客站点，借助于网上丰富详致的相关搭建博客教程终于把自己的小窝搭建起来了，吼吼！ 随后学习一些Markdown的语法发现这个图片的链接还真是一个问题，网上搜索的结果主要是通过七牛云啥的云图网站来实现的，然而一方面可能有数据量的限制，另外还要注册一些信息啥的，好屌麻烦，于是就想能不能直接通过GitHub仓库来实现呢？经过简单的分析之后，发现这个是可以实现的： 首先在GitHub上新建自己的图片仓库，以后的图片都可以放到这个里面。 随后可以把仓库克隆到本地计算机文件系统中，需要添加图片时，可以通过创建相关文件夹，然后在里面放入需要链接的图片。 通过Git命令实现仓库的提交。 123git add .git commit -m \"change the images\"git push 通过对应GitHub上图片资源绝对地址的引用实现自己Markdown文章图片的引用工作。 在实际应用中，以上第1步只需要做一次，而每次需要在Markdown文章引用图片时，都需要做第4步，同时视是否需要引入新的图片可能也需要2、3步的工作。 在具体实现的过程中，发现第3步和第四步存在着一些问题和待优化之处。如第3步的提交过程中，可以通过浏览器的GitHub仓库页面实现添加，也可以通过本地的Git命令调用，本地的Git命令调用也可分为图形式的命令调用和shell下的命令句调用，以上无论哪种操作，都比较繁琐，这是绝对不行的。 由于通过Git命令的操作主要就是:123git add .git commit -m \"change the images\"git push 这三步，所以很容易可以想到通过编写批处理文件来完成这样重复的工作。 所以我们可以创建一个名字为auto.bat的文件放到本地仓库的根目录下，里面的内容就是：123git add .git commit -m \"change the images\"git push 经过测试发现，如果能把命令行的显示尽量隐藏掉就好了，于是可以在开头加上一个@echo off关闭命令的回显，然而毕竟Git提交是将本地数据提交到远端，需要有一个过程，同时也应该有一个结果提示，所以基本上不可避免的还是会弹出显示上传结果的shell界面，如： 然而，其工作一旦完成，便自动退出，也算可以接受的吧。 以后把要上传的图片放进该文件夹下，然后双击auto.bat文件就可以啦！ 而在第4步下，发现直接通过右键获取图片链接地址，得到的并不是图片的绝对链接地址，不是很准确，直接拿来引用的话不行，我们还需要对路径进行进一步的处理才可以。 如：这张图片，如果直接复制的话，我们将得到的路径为:https://github.com/smilelight/images/blob/master/lightsmile.png(通过右击链接)或者https://github.com/smilelight/images/blob/master/lightsmile.png?raw=true(通过右击图片)，而其实际路径可以为：https://github.com/smilelight/images/raw/master/lightsmile.png或者https://raw.githubusercontent.com/smilelight/images/master/lightsmile.png或者https://github.com/smilelight/images/blob/master/lightsmile.png?raw=true。因此我们具体要做的工作也很简单，就是原本得到的路径转化为有效的绝对路径，我这里采取的策略是将其转化为第一种有效路径，即如果路径带有?raw=true，我就把它去掉，然后通过字符串替换，将blob替换为raw。工作是知道怎么做，可是到底怎么具体实现呢？写一个桌面小程序？之前查看知乎上有人就自己写了插件，我想我也可以试一试啊！说做就做，于是就上网寻找关于编写chormium拓展插件的博客教程和视频资源，经过一系列的尝试和探索之后，终于完成了功能简洁、有时还会报错的小插件。。。 如图： 这是在测试右键菜单的小插件的基础上编写的，名字懒得改了，反正也是自己用着玩的。它的功能是在GitHub网站下右击链接或图片，可以复制该图片的有效地址到剪贴板中，同时在浏览器的右下角或者左下角弹出notification(通知)如下： 经过测试发现确实是可以工作的，并且在不是GitHub下的网站下，右键是不会弹出这个菜单项的。关于我的具体的插件编写工作请参考我的另外一篇博文。","categories":[{"name":"计算机","slug":"计算机","permalink":"http://www.iamlightsmile.com/categories/计算机/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"http://www.iamlightsmile.com/tags/markdown/"},{"name":"浏览器插件","slug":"浏览器插件","permalink":"http://www.iamlightsmile.com/tags/浏览器插件/"},{"name":"github","slug":"github","permalink":"http://www.iamlightsmile.com/tags/github/"}]},{"title":"哲学小记","slug":"哲学小记","date":"2017-12-24T14:05:25.000Z","updated":"2020-01-18T11:55:51.552Z","comments":true,"path":"articles/哲学小记/","link":"","permalink":"http://www.iamlightsmile.com/articles/哲学小记/","excerpt":"&emsp;&emsp;人类社会永恒不变的主题便是生存与发展，如何能够更好的生存和发展，成为人类文明最强大、最根本的进步驱动力。 &emsp;&emsp;我们生活的世界是一个具体的现实的世界，它是非常复杂的，而人类智慧虽然发展迅速，但仍只能通过思维理解一些明显的客观规律，这里的理解也是相对于我们的思维逻辑而言的，世界的真正规律可能并不是这个样子，只是恰好被描述的比较准确罢了。 &emsp;&emsp;我们观察任何事物都是站在某个角度或某些角度上的，不能够全面透彻具体的了解某个事物，我们的逻辑便是不完全逻辑。而全面的又是困难的，有时也是没有必要的。","text":"&emsp;&emsp;人类社会永恒不变的主题便是生存与发展，如何能够更好的生存和发展，成为人类文明最强大、最根本的进步驱动力。 &emsp;&emsp;我们生活的世界是一个具体的现实的世界，它是非常复杂的，而人类智慧虽然发展迅速，但仍只能通过思维理解一些明显的客观规律，这里的理解也是相对于我们的思维逻辑而言的，世界的真正规律可能并不是这个样子，只是恰好被描述的比较准确罢了。 &emsp;&emsp;我们观察任何事物都是站在某个角度或某些角度上的，不能够全面透彻具体的了解某个事物，我们的逻辑便是不完全逻辑。而全面的又是困难的，有时也是没有必要的。 &emsp;&emsp;我们之所以会在某一认知系统中去定义一些事物，是因为它的属性不同于该认知系统中的其他事物，我们需要标记以加以区分，从此该标记就指代某个或一类事物，这种标记是人为规定的。 &emsp;&emsp;定义的标准和来源或来自于与系统中某些已定义事物的相同之处，抑或不同之处，符合某种映射规律，抑或简单的无逻辑映射。在复杂事物有机整体的定义上，也是自简单的无逻辑映射构建出复杂的有逻辑映射。有无逻辑是指事物之间是否存在某些定性的或者定量的关系，而这关系的确立也是建立在定义和观察之上的。 &emsp;&emsp;唯有建立在定义的基础上，方能进行逻辑活动，推演出某种事物内部或者事物与事物之间的某种定量的或者定性的属性或关系，即“规律”，也可以理解为具体的“道”，在此基础上，我们去适应和遵守甚至利用这种规律为我们所服务。 &emsp;&emsp;从某种程度上讲，我们认识任何事物的根本目的都是“为我所用”，为了解决某种问题，为了达到某种目的。 &emsp;&emsp;定义的基础和关键就在于抽象，抽象是目前为止我们人类认识世界的最强大的工具。 何为抽象？ 抽象，即特征提取并加以泛化的过程。 &emsp;&emsp;用自己的话说，就是我们在看待事物和考虑问题时，把重点只放在事物的相关属性上，而不去关注那些无关概念上，实现问题的由复杂到简单、由现象到本质的转化和事物的从特殊到一般的概念延伸和规律拓展，由此所得到的认识和规律适用于一系列的具有这样的本质的共性的事物，而不依赖于他们相互分别的非本质的个性。 &emsp;&emsp;抽象的意义在于它通过某些角度剥离出事物在某一问题或领域中的关键属性并屏蔽掉其他的不相关的或者相对不重要的属性，降低该事物在该问题域中的复杂程度，使得人们能够关注于事物的关键点从而实现问题聚焦的事物对象的简化工作，从而便于问题的解决。 &emsp;&emsp;许多事情能够抽象为数学问题，是因为存在某个具体的定义的量化标准，而那些过于复杂的，只能通过观察和试验来解决，只能做定性的抽象，抽象的具体了便是各具体科学，抽象的抽象了便是哲学。从这个角度而言，哲学可以描述数学，而数学无法描述哲学。 定义与抽象的关系 定性的抽象的尽头是哲学 定量的抽象的尽头是数学","categories":[{"name":"其他","slug":"其他","permalink":"http://www.iamlightsmile.com/categories/其他/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"http://www.iamlightsmile.com/tags/哲学/"},{"name":"抽象","slug":"抽象","permalink":"http://www.iamlightsmile.com/tags/抽象/"}]},{"title":"lua解析","slug":"lua解析","date":"2017-12-22T02:12:05.000Z","updated":"2020-01-18T11:56:52.713Z","comments":true,"path":"articles/lua解析/","link":"","permalink":"http://www.iamlightsmile.com/articles/lua解析/","excerpt":"本lua版本为5.2.1 在lua的源码中，lua.c 实现了可执行的解释器，用于解释执行.out文件，luac.c 实现了字节码的编译器，用于将.lua文件编译为.out文件，即字节码文件。更加宏观的东西，则在打印的两份文档里，此处不详述，由于整个读入解析到解释执行的过程是先从读入.lua文件开始的，所以我这份lua源码解析大业便先从这luac.c文件的阅读学习开始了，以下是它的main程序源代码。","text":"本lua版本为5.2.1 在lua的源码中，lua.c 实现了可执行的解释器，用于解释执行.out文件，luac.c 实现了字节码的编译器，用于将.lua文件编译为.out文件，即字节码文件。更加宏观的东西，则在打印的两份文档里，此处不详述，由于整个读入解析到解释执行的过程是先从读入.lua文件开始的，所以我这份lua源码解析大业便先从这luac.c文件的阅读学习开始了，以下是它的main程序源代码。 123456789101112131415int main(int argc, char* argv[])&#123; lua_State* L; int i=doargs(argc,argv); argc-=i; argv+=i; if (argc&lt;=0) usage(\"no input files given\"); L=luaL_newstate(); if (L==NULL) fatal(\"cannot create state: not enough memory\"); lua_pushcfunction(L,&amp;pmain); lua_pushinteger(L,argc); lua_pushlightuserdata(L,argv); if (lua_pcall(L,2,0,0)!=LUA_OK) fatal(lua_tostring(L,-1)); lua_close(L); return EXIT_SUCCESS;&#125; tip1：在C语言中，函数内部的局部变量需要在开头定义首先先定义了一个代表lua虚拟机的数据结构lua_State，然后执行参数解析工作，即调用doargs函数，并将命令行参数传了进去以下是其源代码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#define IS(s) (strcmp(argv[i],s)==0)static int doargs(int argc, char* argv[])&#123; int i; int version=0; if (argv[0]!=NULL &amp;&amp; *argv[0]!=0) progname=argv[0]; for (i=1; i&lt;argc; i++) &#123; if (*argv[i]!='-') /* end of options; keep it */ break; else if (IS(\"--\")) /* end of options; skip it */ &#123; ++i; if (version) ++version; break; &#125; else if (IS(\"-\")) /* end of options; use stdin */ break; else if (IS(\"-l\")) /* list */ ++listing; else if (IS(\"-o\")) /* output file */ &#123; output=argv[++i]; if (output==NULL || *output==0 || (*output=='-' &amp;&amp; output[1]!=0)) usage(\"'-o' needs argument\"); if (IS(\"-\")) output=NULL; &#125; else if (IS(\"-p\")) /* parse only */ dumping=0; else if (IS(\"-s\")) /* strip debug information */ stripping=1; else if (IS(\"-v\")) /* show version */ ++version; else /* unknown option */ usage(argv[i]); &#125; if (i==argc &amp;&amp; (listing || !dumping)) &#123; dumping=0; argv[--i]=Output; &#125; if (version) &#123; printf(\"%s\\n\",LUA_COPYRIGHT); if (version==argc-1) exit(EXIT_SUCCESS); &#125; return i;&#125; 在说明doargs函数之前，先列出在luac.c文件中前面的局部变量：123456789#define PROGNAME \"luac\" /* default program name */#define OUTPUT PROGNAME \".out\" /* default output file */static int listing=0; /* list bytecodes? */static int dumping=1; /* dump bytecodes? */static int stripping=0; /* strip debug information? */static char Output[]=&#123; OUTPUT &#125;; /* default output file name */static const char* output=Output; /* actual output file name */static const char* progname=PROGNAME; /* actual program name */ 未完待续……","categories":[{"name":"计算机","slug":"计算机","permalink":"http://www.iamlightsmile.com/categories/计算机/"}],"tags":[{"name":"lua","slug":"lua","permalink":"http://www.iamlightsmile.com/tags/lua/"}]}]}