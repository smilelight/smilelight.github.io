{"meta":{"title":"lightsmile's Blog","subtitle":"lightsmile","description":"this is a description","author":"lightsmile","url":"https://www.iamlightsmile.com","root":"/"},"pages":[{"title":"","date":"2020-05-01T04:04:44.982Z","updated":"2020-05-01T04:04:44.982Z","comments":true,"path":"404.html","permalink":"https://www.iamlightsmile.com/404.html","excerpt":"","text":"闲人免进 嘻嘻！就是不给你看！！！"},{"title":"404 Not Found","date":"2020-05-01T04:04:44.982Z","updated":"2020-05-01T04:04:44.982Z","comments":true,"path":"404.html","permalink":"https://www.iamlightsmile.com/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"所有分类","date":"2020-05-01T04:03:14.936Z","updated":"2020-05-01T04:03:14.936Z","comments":true,"path":"categories/index.html","permalink":"https://www.iamlightsmile.com/categories/index.html","excerpt":"","text":""},{"title":"关于","date":"2020-05-05T14:18:17.790Z","updated":"2020-05-05T14:18:17.790Z","comments":true,"path":"about/index.html","permalink":"https://www.iamlightsmile.com/about/index.html","excerpt":"","text":"基础信息略 专业技能与程度 专业技能 所学程度 备注 自然语言处理 中等 工作后主要工作方向 知识图谱 基础 工作后主要工作方向相关 深度学习 基础 工作后主要工作方向相关 机器学习 基础 工作后主要工作方向相关 数据结构与算法 基础 大学课程水平 Android开发 基础 大学自学，几门课程大作业都是开发的Android应用，有后台可联网的非demo 前端 略知一二 曾学过一段时间，写了一个用于获取Github图片地址的浏览器插件，以及结合aardio写了个mini电商系统 桌面开发 基础 大学自学，主要使用aardio语言，个人很喜欢 小程序 略知一二 在前端的基础上，编写了了todoList作为个人毕业设计 Linux 略知一二 工作后主要在Linux环境下开发 Java 基础 大学课程，曾开发demo管理系统 Python 中等 工作后主要工作语言 个人评价 自学能力较强 责任心比较重 沟通能力良好 自我驱动比较强 相关证书网易云课堂-AI工程师（自然语言处理方向）微专业 其他相关 个人博客站点 Github 简书 知乎 联系方式 手机：15172335885 QQ：1459679436 邮箱：iamlightsmile@qq.com 、iamlightsmile@gmail.com"},{"title":"friends","date":"2017-12-09T05:16:32.000Z","updated":"2019-01-07T03:33:32.703Z","comments":true,"path":"friends/index.html","permalink":"https://www.iamlightsmile.com/friends/index.html","excerpt":"","text":"。。。暂时还没有。。。"},{"title":"所有标签","date":"2020-05-01T04:03:05.164Z","updated":"2020-05-01T04:03:05.164Z","comments":true,"path":"tags/index.html","permalink":"https://www.iamlightsmile.com/tags/index.html","excerpt":"","text":""},{"title":"projects","date":"2017-12-09T05:16:32.000Z","updated":"2019-04-04T01:42:21.040Z","comments":true,"path":"projects/index.html","permalink":"https://www.iamlightsmile.com/projects/index.html","excerpt":"","text":"项目主要包括： 项目名称 简介 相关技术 开发语言 lightNLP 自然语言处理深度学习框架 NLP，深度学习 Python lightKG 知识图谱深度学习框架 KG，深度学习 Python todolist 微信小程序：微计划日程管理 微信小程序 JavaScript GithubImagePace 获取Github图片路径用作Markdown地址的浏览器插件 浏览器插件 JavaScript SchoolInfoPublishSystem Android App：校园信息发布系统 Android Java MyShoppingWeb 网上购物数据库demo系统 aardio aardio 1.lightNLP基于Pytorch和torchtext的自然语言处理深度学习框架，包含序列标注、文本分类、句子关系、文本生成、结构分析、五大功能模块，已实现了命名实体识别、中文分词、词性标注、语义角色标注、情感分析、关系抽取、语言模型、文本相似度、文本蕴含、依存句法分析等功能。框架功能丰富，开箱可用，极易上手！基本都是学习他人实现然后自己修改融合到框架中，没有细致调参，且有不少Bug～ 2.lightKG基于Pytorch和torchtext的知识图谱深度学习框架，包含知识表示学习、实体识别与链接、实体关系抽取、事件检测与抽取、知识存储与查询、知识推理六大功能模块，已实现了命名实体识别、关系抽取、事件抽取、表示学习等功能。框架功能丰富，开箱可用，极易上手！基本都是学习他人实现然后自己修改融合到框架中，没有细致调参，且有不少Bug～ 3.todolist微信小程序:微计划日程管理 4.GithubImagePace我的获取GitHub图片绝对路径用于Markdown文档图片的浏览器插件 5.QCloudSDKJS腾讯云SDK for JS 6.SchoolInfoPublishSystemAndroid App:校园信息发布系统 7.MyShoppingWebaardio 数据库作业：网上购物数据库综合系统"}],"posts":[{"title":"使用docker遇到的问题","slug":"使用docker遇到的问题","date":"2020-10-17T11:14:13.000Z","updated":"2020-10-17T16:53:25.970Z","comments":true,"path":"articles/使用docker遇到的问题/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E4%BD%BF%E7%94%A8docker%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"1.容器内文件无法删除问题描述最近使用docker部署项目，结果发现docker里的文件无法删除，于是开始Google寻求解决方案。","text":"1.容器内文件无法删除问题描述最近使用docker部署项目，结果发现docker里的文件无法删除，于是开始Google寻求解决方案。 探索过程刚开始搜到Docker容器内文件无法删除 | Escape，还以为是Centos7本身的bug，但是还是怀疑这种常见的问题应该早就被修复掉了，不应该像文档中那么麻烦。 之前的问题使用的是公司的内网服务器，Centos7系统；然而自己在自己的腾讯云Centos7系统上也测试了一下删除文件，发现就没有问题。同时自己在使用docker的neo4j容器时遇到了访问文件受限的问题，根据错误信息发现了该issue：uid and gid change · Issue #266 · neo4j/docker-neo4j，发现里面提到了docker版本的bug。发现自己服务器上的docker版本比较新，同时检查了下公司内网服务器中的docker版本还挺老旧的。于是网上搜索docker升级命令，找到了Docker 更新版本 - 自由早晚乱余生 - 博客园。这篇文档写的很详细，在遇到的问题部分中提到了Linux内核版本的问题，自己又查看对比了下自己服务器和内网机内核版本，发现差别还真挺大的。内网机版本号才300多，而自己的都900多了。其中文档提到版本号514是个坎。 解决方案升级系统内核版本+升级docker版本就可以解决该问题。 2.debian操作系统离线安装docker以及docker-compose问题描述不知道怎么离线安装，网上找教程即可。 探索过程找到的两篇文章： 基于凝思磐石&amp;debian内网环境搭建docker集群_解忧小童子-CSDN博客 debian 10.x (buster) 离线安装docker及卸载 - Nihaorz - 博客园 其中第一篇同时提到了安装docker和docker-compose，第二篇只提到了安装docker但是更加详细。 解决方案参照上面第二篇文档安装docker，参照上面第一篇文档安装docker-compose。","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://www.iamlightsmile.com/tags/docker/"}]},{"title":"Docker常用命令","slug":"Docker常用命令","date":"2020-10-14T07:06:18.000Z","updated":"2020-10-14T07:06:18.327Z","comments":true,"path":"articles/Docker常用命令/","link":"","permalink":"https://www.iamlightsmile.com/articles/Docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"知识库学习心得随记","slug":"知识库学习心得随记","date":"2020-10-10T08:13:47.000Z","updated":"2020-10-10T08:28:41.012Z","comments":true,"path":"articles/知识库学习心得随记/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E7%9F%A5%E8%AF%86%E5%BA%93%E5%AD%A6%E4%B9%A0%E5%BF%83%E5%BE%97%E9%9A%8F%E8%AE%B0/","excerpt":"最近在看一些知识库的项目，自己小有体会，这里简单记录一下。","text":"最近在看一些知识库的项目，自己小有体会，这里简单记录一下。 近几个月来，出于项目需要，自己简单学习了下Elasticsearch，并且重新学习了下Neo4j。我发现看的知识库的项目所使用的数据库不尽相同，有基于Neo4j的，有基于Elasticsearch的，有基于MongoDB的，这不禁令我反思。 这些数据库的相似之处在于都非关系型数据库，不同之处在于各自所更能适配的数据类型不同。Neo4j更适配的数据是那些数据类型简单但之间关系复杂多样化的，Elasticsearch更适配的数据或者说场景是待检索的数据尤其是需要定制复杂规则过滤排序的数据，而MongoDB则更加通用一些。 在实际项目中，对于数据量比较小或者业务场景比较简单的情况下，其实这三种数据库基本都能完成需求；而只有当数据的量级很大（比如在上百万条）以及业务场景比较复杂的情况下，三种各自的优劣才能比较明显的体现出来。数据库之间也没有通用的优劣高低之分，只有哪个更适配任务的数据类型和场景之分。","categories":[{"name":"知识图谱","slug":"知识图谱","permalink":"https://www.iamlightsmile.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"}],"tags":[{"name":"知识库","slug":"知识库","permalink":"https://www.iamlightsmile.com/tags/%E7%9F%A5%E8%AF%86%E5%BA%93/"}]},{"title":"Neo4j使用小记","slug":"Neo4j使用小记","date":"2020-10-10T07:54:55.000Z","updated":"2020-10-10T08:28:41.012Z","comments":true,"path":"articles/Neo4j使用小记/","link":"","permalink":"https://www.iamlightsmile.com/articles/Neo4j%E4%BD%BF%E7%94%A8%E5%B0%8F%E8%AE%B0/","excerpt":"使用社区版Neo4j时有一些注意事项，这里简单小记一下。","text":"使用社区版Neo4j时有一些注意事项，这里简单小记一下。 1.一台机器启动多个Neo4j数据库最好的方式，甚至是唯一的选择是使用Docker。 现在版本（4.0以上）的Neo4j貌似不能使用拷贝程序到不同目录设置不同端口执行了。 我们可以在Neo4j社区版中创建多个数据库，但是同时只能使用一个。 如图，只有默认数据库和系统数据库可以切换，其他的数据库的状态是未连接的。 如果需要创建多个数据库，那么我们只需要在neo4j的配置文件即neo4j.conf中dbms.default_database=baike一行设置新的数据库名并重启neo4j即可，如前句中为baike。 相应的，如果需要切换数据库，则只能先修改neo4j.conf配置文件的default_database选项，然后重启neo4j。 2.Neo4j使用的Apoc需要配套版本具体在Releases · neo4j-contrib/neo4j-apoc-procedures页下载。","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"Neo4j","slug":"Neo4j","permalink":"https://www.iamlightsmile.com/tags/Neo4j/"}]},{"title":"配置VSCode-Remote-Container","slug":"配置VSCode-Remote-Container","date":"2020-09-15T14:37:28.000Z","updated":"2020-10-10T08:10:56.180Z","comments":true,"path":"articles/配置VSCode-Remote-Container/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E9%85%8D%E7%BD%AEVSCode-Remote-Container/","excerpt":"0.前言我服了，vscode确实太香了。","text":"0.前言我服了，vscode确实太香了。 1.远程主机配置 注意：以下基于CentOS7环境。 1.1 安装docker一键安装脚本： curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 可参考：CentOS Docker 安装 | 菜鸟教程 1.2 配置docker在远程主机上： 创建文件daemon.json到目录/etc/docker: {&quot;hosts&quot;: [&quot;tcp://0.0.0.0:2375&quot;, &quot;unix:///var/run/docker.sock&quot;]} 创建文件/etc/systemd/system/docker.service.d/override.conf: [Service] ExecStart= ExecStart=/usr/bin/dockerd 重启docker： systemctl daemon-reload systemctl restart docker.service 2.本地桌面配置 注意：以下基于Windows10桌面专业版环境。 2.1 安装OpenSSL略，自带了。 2.2 生成ssh秘钥对略，参见：配置VSCode-Remote-SSH - lightsmile’s Blog 注意，如我的~/.ssh/config中部分内容为： Host tencent_cloud HostName xx.xx.xx.xx PreferredAuthentications publickey User root IdentitiesOnly yes # Port 22 IdentityFile ~/.ssh/tencent_cloud_desktop 使用ssh免密登录的时候命令应该为： ssh tencent_cloud 2.3 安装docker下载docker.exe 并配置路径（其实配不配都可以，因为我把这个路径放到环境变量里进入shell还是没找到2333~。） 2.4 配置docker服务创建一个context： docker context create &lt;context name&gt; --docker &quot;host=ssh://&lt;user&gt;@&lt;host&gt;&quot; 以我上面的ssh为例，上面的命令可以为： docker context create tencent_cloud --docker &quot;host=ssh://tencent_cloud&quot; 切换到上面的context： docker context use &lt;context name&gt; 以上面生成的context：tencent_cloud为例，上面的指令为： docker context use tencent_cloud 测试一下： docker info 这里会输出和在远程主机上运行 docker info 一样的结果， 实际上这里docker本地只是一个客户端，连接到远程主机上的docker服务。 2.5 安装remote-container插件在拓展插件里搜索remote container并安装。 安装完成后，在vscode设置中搜索remote docker path，设置为之前下载的docker的路径（默认就是docker命令，我这里命令行里找不到，所以需要手动配置） 3.开始项目3.1 启动容器docker run -d --name &lt;container name&gt; -v ~/newproj:/workspaces/newproj &lt;image tag&gt; tail -f /dev/null 注意： 这里要挂载项目目录到容器中方便保存文件。tail -f 这个命令是为了让容器保持运行。 3.2 vscode访问远程容器 打开VSCode，按下ctrl+shift+p运行docker contexts use, 选择上面创建的docker context. 按下ctrl+shift+p运行Remote-Containers:Attach to Running Container..., 选择上面创建的容器名字。 在新打开的vscode窗口中环境即上面的容器内部，现在可以尽情搬砖了。 注意： 可以连接的容器必须是正在持续运行着的的容器。（即使用类似tail -f /dev/null命令创建的容器）。 4.后记本文主要是拾人牙慧，原文为：开发环境代码化: VSCode远程Docker容器作为开发环境 - 个人文章 - SegmentFault 思否。但自己在实践过程中遇到了一些问题，比如ssh免密登陆，同时本着“输出是最好的学习”的原则，故记录之。 5.参考 开发环境代码化: VSCode远程Docker容器作为开发环境 - 个人文章 - SegmentFault 思否 Docker 查看镜像信息_犬小哈-CSDN博客 CentOS Docker 安装 | 菜鸟教程 SSH Config 那些你所知道和不知道的事 | Deepzz’s Blog","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.iamlightsmile.com/tags/Docker/"},{"name":"vscode","slug":"vscode","permalink":"https://www.iamlightsmile.com/tags/vscode/"}]},{"title":"centos安装LibreOffice","slug":"centos安装LibreOffice","date":"2020-09-15T06:43:52.000Z","updated":"2020-09-15T08:03:05.529Z","comments":true,"path":"articles/centos安装LibreOffice/","link":"","permalink":"https://www.iamlightsmile.com/articles/centos%E5%AE%89%E8%A3%85LibreOffice/","excerpt":"0.前言最近的工作涉及到文档处理与转换，需要用到LibreOffice，所以这里简单记录下在centos环境下安装过程。","text":"0.前言最近的工作涉及到文档处理与转换，需要用到LibreOffice，所以这里简单记录下在centos环境下安装过程。 1.下载并解压安装包1.1 下载安装包官网中文下载页：下载 LibreOffice | LibreOffice 简体中文官方网站 - 自由免费的办公套件 我们需要安装主安装程序以及中文语言安装包和中文离线帮助文件安装包，这里列出6.4.6版本的中文镜像源链接： 主程序链接：https://mirrors.nju.edu.cn/tdf/libreoffice/stable/6.4.6/rpm/x86_64/LibreOffice_6.4.6_Linux_x86-64_rpm.tar.gz 中文语言包链接：https://mirrors.nju.edu.cn/tdf/libreoffice/stable/6.4.6/rpm/x86_64/LibreOffice_6.4.6_Linux_x86-64_rpm_langpack_zh-CN.tar.gz 中文离线帮助文件链接：https://mirrors.nju.edu.cn/tdf/libreoffice/stable/6.4.6/rpm/x86_64/LibreOffice_6.4.6_Linux_x86-64_rpm_helppack_zh-CN.tar.gz 1.2 解压安装包将安装包放置到合适的位置并且解压。 2.安装$ sudo yum install ./LibreOffice_6.x.x_Linux_x86_rpm/RPMS/*.rpm /* 安装主安装程序的所有rpm包 */ $ sudo yum install ./LibreOffice_6.x.x_Linux_x86_rpm_langpack_zh-CN/RPMS/*.rpm /* 安装中文语言包中的所有rpm包 */ $ sudo yum install ./LibreOffice_6.x.x_Linux_x86_rpm_helppack_zh-CN/RPMS/*.rpm /* 安装中文离线帮助文件中的所有rpm包 */ 3.依赖3.1 查看安装位置whereis libreoffice 得到如下输出： libreoffice: /usr/bin/libreoffice6.4 /usr/lib64/libreoffice 3.2 安装依赖执行libreoffice6.4报库文件找不到的错误，需要安装一些库文件： yum install cairo -y yum install cups-libs -y yum install libSM -y 4.测试4.1 查看版本libreoffice6.4 --version 得到如下结果： LibreOffice 6.4.6.2 0ce51a4fd21bff07a5c061082cc82c5ed232f115 4.2 创建软链接由于联动的其他程序设置的libreoffice路径为/usr/bin/soffice，所以这里创建一个软链： ln -s /opt/libreoffice6.4/program/soffice /usr/bin/soffice 5.参考 CentOS7 安装 LibreOffice | 公孙二狗 Linux 下的安装方法 | LibreOffice 简体中文官方网站 - 自由免费的办公套件 linux软链接的创建、删除和更新_鲁不迅的专栏-CSDN博客","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"centos","slug":"centos","permalink":"https://www.iamlightsmile.com/tags/centos/"}]},{"title":"Linux常用命令","slug":"Linux常用命令","date":"2020-09-10T00:45:02.000Z","updated":"2020-09-15T06:42:26.425Z","comments":true,"path":"articles/Linux常用命令/","link":"","permalink":"https://www.iamlightsmile.com/articles/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"注意：以下命令都是在CentOS上执行，在Ubuntu或其他发行版部分有所不同。","text":"注意：以下命令都是在CentOS上执行，在Ubuntu或其他发行版部分有所不同。 1.系统相关命令1.1 查看系统版本(base) ➜ ~ cat /etc/redhat-release CentOS Linux release 7.7.1908 (Core) (base) ➜ ~ cat /proc/version Linux version 3.10.0-957.21.3.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-36) (GCC) ) #1 SMP Tue Jun 18 16:35:19 UTC 2019","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.iamlightsmile.com/tags/Linux/"}]},{"title":"创建带有ik分词器的Elasticsearch容器","slug":"创建带有ik分词器的Elasticsearch容器","date":"2020-09-09T09:08:02.000Z","updated":"2020-09-09T09:52:04.317Z","comments":true,"path":"articles/创建带有ik分词器的Elasticsearch容器/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E5%88%9B%E5%BB%BA%E5%B8%A6%E6%9C%89ik%E5%88%86%E8%AF%8D%E5%99%A8%E7%9A%84Elasticsearch%E5%AE%B9%E5%99%A8/","excerpt":"0.前言自己目前在学习探索Docker技术，这里简单实践一下创建带有ik分词器的Elasticsearch容器，涉及Dockerfile和docker-compose的使用。","text":"0.前言自己目前在学习探索Docker技术，这里简单实践一下创建带有ik分词器的Elasticsearch容器，涉及Dockerfile和docker-compose的使用。 1.创建容器1.1 编写Dockerfile新建elasticsearch目录并在其内创建Dockerfile文件 mkdir elasticsearch &amp;&amp; elasticsearch touch Dockerfile Dockerfile中内容如下： FROM elasticsearch:7.7.1 RUN yes | ./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.7.1/elasticsearch-analysis-ik-7.7.1.zip 1.2 编写docker-compose.yml在elasticsearch文件夹同级目录下创建docker-compose.yml文件，内容为： version: &#39;3&#39; services: es-ik: build: ./elasticsearch image: elasticsearch-ik:7.7.1 container_name: es_ik environment: - discovery.type=single-node ports: - 9201:9200 - 9301:9300 上面的端口映射到Host主机的9201和9301是因为系统上已经有Elasticsearch在运行了并且使用了默认的端口，这里需要再换一下端口。 1.3 打包镜像上面的目录结构如下： . ├── docker-compose.yml └── elasticsearch ├── Dockerfile ├── elasticsearch-analysis-ik-7.7.1.zip └── test.es 执行如下命令以构建镜像： docker-compose build 执行docker images可以看到镜像已经成功创建： [root@localhost ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE elasticsearch-ik 7.7.1 1812e4f405c5 3 hours ago 814 MB 2.测试容器2.1 启动容器执行如下命令以启动容器： docker-compose up 2.2 查看容器启动状态[root@localhost Docker]# ls docker-compose.yml elasticsearch [root@localhost Docker]# docker-compose ps Name Command State Ports ----------------------------------------------------------------------------------------------- es_ik /tini -- /usr/local/bin/do ... Up 0.0.0.0:9201-&gt;9200/tcp, 0.0.0.0:9301-&gt;9300/tcp 2.3 测试elasticsearch服务这里我是用的是VSCode的Elasticsearch for VSCode插件，该插件允许我们编写.es文件向es执行查询请求。 如test.es内容如下： POST _analyze { &quot;analyzer&quot;: &quot;ik_smart&quot;, &quot;text&quot;: &quot;中华人民共和国&quot; } POST _analyze { &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;text&quot;: &quot;中华人民共和国&quot; } 如图： 请求结果如下： { &quot;tokens&quot;: [ { &quot;token&quot;: &quot;中华人民共和国&quot;, &quot;start_offset&quot;: 0, &quot;end_offset&quot;: 7, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 0 }, { &quot;token&quot;: &quot;中华人民&quot;, &quot;start_offset&quot;: 0, &quot;end_offset&quot;: 4, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 1 }, { &quot;token&quot;: &quot;中华&quot;, &quot;start_offset&quot;: 0, &quot;end_offset&quot;: 2, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 2 }, { &quot;token&quot;: &quot;华人&quot;, &quot;start_offset&quot;: 1, &quot;end_offset&quot;: 3, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 3 }, { &quot;token&quot;: &quot;人民共和国&quot;, &quot;start_offset&quot;: 2, &quot;end_offset&quot;: 7, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 4 }, { &quot;token&quot;: &quot;人民&quot;, &quot;start_offset&quot;: 2, &quot;end_offset&quot;: 4, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 5 }, { &quot;token&quot;: &quot;共和国&quot;, &quot;start_offset&quot;: 4, &quot;end_offset&quot;: 7, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 6 }, { &quot;token&quot;: &quot;共和&quot;, &quot;start_offset&quot;: 4, &quot;end_offset&quot;: 6, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 7 }, { &quot;token&quot;: &quot;国&quot;, &quot;start_offset&quot;: 6, &quot;end_offset&quot;: 7, &quot;type&quot;: &quot;CN_CHAR&quot;, &quot;position&quot;: 8 } ] } 3.参考 Docker Compose | 菜鸟教程 Docker Compose 配置文件详解 - 简书 基于docker的elasticsearch中文分词及同义词配置 - 简书","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.iamlightsmile.com/tags/Docker/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://www.iamlightsmile.com/tags/Elasticsearch/"}]},{"title":"深度学习代码常见流程","slug":"深度学习代码常见流程","date":"2020-09-08T01:18:47.000Z","updated":"2020-09-08T02:39:09.625Z","comments":true,"path":"articles/深度学习代码常见流程/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81%E5%B8%B8%E8%A7%81%E6%B5%81%E7%A8%8B/","excerpt":"0.概览目前自己在深度学习这方面有一定的积累，一些代码流程都有一定的套路和相应的标准，这里自己简单梳理一下。 我们这里假设输入为已标注数据，输出为训练的模型，不考虑标注前数据处理部分已经代码上线部署环节。 大致的流程包括： 数据预处理 编写神经网络模型 编写数据加载部分代码 编写模型训练预测代码","text":"0.概览目前自己在深度学习这方面有一定的积累，一些代码流程都有一定的套路和相应的标准，这里自己简单梳理一下。 我们这里假设输入为已标注数据，输出为训练的模型，不考虑标注前数据处理部分已经代码上线部署环节。 大致的流程包括： 数据预处理 编写神经网络模型 编写数据加载部分代码 编写模型训练预测代码 1.数据预处理对标注数据进行处理，包括特征预处理、数据清洗等，将数据（可能是txt格式、Excel文件等）转化为程序可直接读取的常见的数据集类型（如csv）。如在csv文件中，每行是一个样本（sample），每列为该样本特征（feature）或标签（label）。 如tes.csv： fuck,shit,label &quot;a&quot;,1.2,&quot;a&quot; &quot;b&quot;,2,&quot;b&quot; &quot;a&quot;,1.2,&quot;a&quot; &quot;b&quot;,2,&quot;b&quot; &quot;a&quot;,1.2,&quot;a&quot; &quot;b&quot;,2,&quot;b&quot; &quot;a&quot;,1.2,&quot;a&quot; &quot;b&quot;,2,&quot;b&quot; &quot;a&quot;,1.2,&quot;a&quot; &quot;b&quot;,2,&quot;b&quot; 2.编写神经网络模型对于特定的任务，我们可以选择既有的框架，这样就不需要重写模型。然而当既有的框架模型不满足我们的需求时，我们就需要去自定义去编写神经网络模型。 以Pytorch为例，模型需要继承自torch.nn.Module类并实现forward方法。 3.编写数据加载部分代码数据预处理的结果为数据集文件，我们需要对其进行读取、分割并转化为向量格式。 以Pytorch为例，我们需要编写一个继承自torch.utils.data.Dataset类的类并实现其__getitem__方法和__len__方法。该类作为数据集抽象的接口向外部提供数据。 Dataset类的输出一般不作为模型的输入，中间还需要一个torch.utis.data.DataLoader。 DataLoader接收dataset、batch_size、collate_fn、drop_last、shuffle、sampler等参数，各参数含义为dataset:待加载数据集（类型为torch.utils.data.Dataset）、batch_size:批处理数量大小、collate_fn:数据收集函数（用于将一系列sample转化为Tensor）、drop_last:是否丢弃最后不满一个batch_size的batch、shuffle:是否对数据再进行一次shuffle、sampler:数据采样器（类型为torch.utils.data.Sampler），其中各参数之间可能相互冲突不能一起用，具体使用请参见Pytorch官网教程。 Dataloader的输出应该被作为可以直接传递给模型的Tensor类型，以mini-batch，具体在Python代码中为for-in的形式被调用。 4.编写模型训练预测代码在生成Module和DataLoader之后，我们还需要指定损失函数（如torch.nn.functional.cross_entropy（交叉熵损失函数））和优化器（如torch.optim.Adam）。 更高级的，我们还可以去设置学习率调度器(如torch.optim.lr_scheduler.StepLR)，设置EarlyStopping和断点重训等功能。 在模型训练完之后我们还需要将其持久化到硬盘中，可以选择保存整个模型对象或者只包含其参数信息。 上面的训练部分由于比较通用，各框架也可能会将其抽象为Trainer对象。","categories":[{"name":"深度学习","slug":"深度学习","permalink":"https://www.iamlightsmile.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"https://www.iamlightsmile.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"完整机器学习项目的工作流程（转）","slug":"完整机器学习项目的工作流程（转）","date":"2020-09-08T00:52:14.000Z","updated":"2020-09-08T02:41:07.127Z","comments":true,"path":"articles/完整机器学习项目的工作流程（转）/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E5%AE%8C%E6%95%B4%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%EF%BC%88%E8%BD%AC%EF%BC%89/","excerpt":"本文章转自完整机器学习项目的工作流程 - 知乎。 1.抽象成数学问题明确问题是进行机器学习的第一步。机器学习的训练过程通常都是一件非常耗时的事情，胡乱尝试时间成本是非常高的。 这里的抽象成数学问题，指的我们明确我们可以获得什么样的数据，目标是一个分类还是回归或者是聚类的问题。即明确输入和输出以及任务类型。","text":"本文章转自完整机器学习项目的工作流程 - 知乎。 1.抽象成数学问题明确问题是进行机器学习的第一步。机器学习的训练过程通常都是一件非常耗时的事情，胡乱尝试时间成本是非常高的。 这里的抽象成数学问题，指的我们明确我们可以获得什么样的数据，目标是一个分类还是回归或者是聚类的问题。即明确输入和输出以及任务类型。 2.获取数据数据决定了机器学习结果的上限，而算法只是尽可能逼近这个上限。 数据要有代表性，否则必然会过拟合。 而且对于分类问题，数据偏斜不能过于严重，不同类别的数据数量不要有数个数量级的差距。 而且还要对数据的量级有一个评估，多少个样本，多少个特征，可以估算出其对内存的消耗程度，判断训练过程中内存是否能够放得下。如果放不下就得考虑改进算法或者使用一些降维的技巧了。如果数据量实在太大，那就要考虑分布式了。 3.特征预处理与特征选择良好的数据要能够提取出良好的特征才能真正发挥效力。 特征预处理、数据清洗是很关键的步骤，往往能够使得算法的效果和性能得到显著提高。归一化、离散化、因子化、缺失值处理、去除共线性等，数据挖掘过程中很多时间就花在它们上面。这些工作简单可复制，收益稳定可预期，是机器学习的基础必备步骤。 筛选出显著特征、摒弃非显著特征，需要机器学习工程师反复理解业务。这对很多结果有决定性的影响。特征选择好了，非常简单的算法也能得出良好、稳定的结果。这需要运用特征有效性分析的相关技术，如相关系数、卡方检验、平均互信息、条件熵、后验概率、逻辑回归权重等方法。 4.训练模型与调优直到这一步才用到我们上面说的算法进行训练。现在很多算法都能够封装成黑盒供人使用。但是真正考验水平的是调整这些算法的（超）参数，使得结果变得更加优良。这需要我们对算法的原理有深入的理解。理解越深入，就越能发现问题的症结，提出良好的调优方案。 5.模型诊断如何确定模型调优的方向与思路呢？这就需要对模型进行诊断的技术。 过拟合、欠拟合 判断是模型诊断中至关重要的一步。常见的方法如交叉验证，绘制学习曲线等。过拟合的基本调优思路是增加数据量，降低模型复杂度。欠拟合的基本调优思路是提高特征数量和质量，增加模型复杂度。 误差分析 也是机器学习至关重要的步骤。通过观察误差样本，全面分析误差产生误差的原因:是参数的问题还是算法选择的问题，是特征的问题还是数据本身的问题…… 诊断后的模型需要进行调优，调优后的新模型需要重新进行诊断，这是一个反复迭代不断逼近的过程，需要不断地尝试， 进而达到最优状态。 6.模型融合一般来说，模型融合后都能使得效果有一定提升。而且效果很好。 工程上，主要提升算法准确度的方法是分别在模型的前端（特征清洗和预处理，不同的采样模式）与后端（模型融合）上下功夫。因为他们比较标准可复制，效果比较稳定。而直接调参的工作不会很多，毕竟大量数据训练起来太慢了，而且效果难以保证。 7.上线运行这一部分内容主要跟工程实现的相关性比较大。工程上是结果导向，模型在线上运行的效果直接决定模型的成败。 不单纯包括其准确程度、误差等情况，还包括其运行的速度(时间复杂度)、资源消耗程度（空间复杂度）、稳定性是否可接受。 8.最后这些工作流程主要是工程实践上总结出的一些经验。并不是每个项目都包含完整的一个流程。这里的部分只是一个指导性的说明，只有大家自己多实践，多积累项目经验，才会有自己更深刻的认识。","categories":[{"name":"深度学习","slug":"深度学习","permalink":"https://www.iamlightsmile.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://www.iamlightsmile.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"centos安装mongodb","slug":"centos安装mongodb","date":"2020-09-06T07:54:30.000Z","updated":"2020-09-15T06:45:17.271Z","comments":true,"path":"articles/centos安装mongodb/","link":"","permalink":"https://www.iamlightsmile.com/articles/centos%E5%AE%89%E8%A3%85mongodb/","excerpt":"","text":"安装方式详情参见在CentOS 7上安装MongoDB - 云+社区 - 腾讯云，只是貌似最新的版本是4.4，即需要将添加MongoDB源部分的3.2都换成4.4。 另外更精简的文档：Centos7 yum安装mongodb实现步骤详解_MongoDB_脚本之家。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"centos","slug":"centos","permalink":"https://www.iamlightsmile.com/tags/centos/"},{"name":"mongodb","slug":"mongodb","permalink":"https://www.iamlightsmile.com/tags/mongodb/"}]},{"title":"配置VSCode-Remote-SSH","slug":"配置VSCode-Remote-SSH","date":"2020-09-05T08:15:15.000Z","updated":"2020-10-10T08:10:56.193Z","comments":true,"path":"articles/配置VSCode-Remote-SSH/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E9%85%8D%E7%BD%AEVSCode-Remote-SSH/","excerpt":"0.前言在写前一篇文档调研使用brat的时候，由于涉及到操作服务器中文件，然而直接通过命令行操作实在是有些不太方便，毕竟vim不咋熟练，自己突然想到使用vscode可以配置remote开发。于是趁此机会也尝试着配置一下，这里简单记录一下。","text":"0.前言在写前一篇文档调研使用brat的时候，由于涉及到操作服务器中文件，然而直接通过命令行操作实在是有些不太方便，毕竟vim不咋熟练，自己突然想到使用vscode可以配置remote开发。于是趁此机会也尝试着配置一下，这里简单记录一下。 1.配置VSCode Remote-SSH1.1 安装Remote-SSH插件在拓展里搜索”remote”，然后安装”Remote-SSH”插件。 在安装完成之后，侧边栏会多出一个选项，如图： 点击之后，其会从一些默认位置自动读取系统已有的一些ssh配置信息，如图： 2.配置远程服务器2.1 添加远程服务器配置信息我们可以在config文件中继续添加配置，格式如图： 2.2 配置ssh连接注意：以下命令均是在Git Bash下执行的。 2.2.1 切换目录至ssh目录cd ~/.ssh 2.2.2 生成ssh公钥ssh-keygen 2.2.3 将公钥存储至远程主机假如1.3.2步生成的公钥名称为id_rsa.pub，假设远程主机ip地址为12.34.56.78，用户名为root ssh-copy-id -i id_rsa.pub root@12.34.56.78 3.连接至远程服务器在上述过程配置完成之后，便可以连接至远程服务器了。如图点击红圈内的图标： 连接成功后如图所示： 如果还不明白的可以继续看下面的参考文章。 -1.参考 VSCode Remote 体验 | 远程Linux环境开发真香 - 知乎 服务器免密登录:ssh公钥配置 - 简书 ssh配置文件详解 - 简书","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"vscode","slug":"vscode","permalink":"https://www.iamlightsmile.com/tags/vscode/"},{"name":"ssh","slug":"ssh","permalink":"https://www.iamlightsmile.com/tags/ssh/"}]},{"title":"centos下brat安装使用","slug":"centos下brat安装使用","date":"2020-09-05T02:09:50.000Z","updated":"2020-09-07T00:40:01.188Z","comments":true,"path":"articles/centos下brat安装使用/","link":"","permalink":"https://www.iamlightsmile.com/articles/centos%E4%B8%8Bbrat%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/","excerpt":"-1.更新发现现在brat直接Python3就可以使用，只是brat官网上和Github上最新release版本还停留在2012年，然而brat近几年有所更新，所以我们可以直接clone Github上的brat的最新源码进行使用hhh。 0.前言0.1 背景近日简单调研一下NLP标注工具brat的使用，其官网示例中可以标注的任务包括命名实体识别、事件抽取、指代消解、依存句法、成分句法等等。","text":"-1.更新发现现在brat直接Python3就可以使用，只是brat官网上和Github上最新release版本还停留在2012年，然而brat近几年有所更新，所以我们可以直接clone Github上的brat的最新源码进行使用hhh。 0.前言0.1 背景近日简单调研一下NLP标注工具brat的使用，其官网示例中可以标注的任务包括命名实体识别、事件抽取、指代消解、依存句法、成分句法等等。 0.2 brat介绍brat是使用Python2开发的文本标注工具，只支持在Unix-like环境下使用，同时最新版v1.3提供两种使用方式，即：using CGI和standalone server，第一种方式官方推荐使用Apache2服务器，并提供了简单的配置教程；第二种模式更新，但可能有更多潜在的问题。另外其实也可以通过Docker使用，这种方法相对而言更加方便。 0.3 个人使用方式我个人使用的是第一种方式，关键是我自己试了试第二种，没有成功，所以只能拿第一种搞了。网上的教程既有将brat当server端用的，也有简单的在localhost环境下使用的。由于自己的笔记本系统是Win10，所以选择在腾讯云服务器Cnetos7上搭建brat。 1.brat相关信息1.1 brat相关网址 brat官网：brat rapid annotation tool brat安装说明：Installation - brat rapid annotation tool brat手册网址：Manual - brat rapid annotation tool brat github地址：nlplab/brat: brat rapid annotation tool (brat) - for all your textual annotation needs 2.brat安装说明：以下命令在root用户下运行，如普通用户请自行在部分命令前面加sudo。 2.1 安装Apache由于brat需要借助Apache提供cgi访问，所以我们首先需要安装apache。 安装命令如下： yum install httpd 启动Apache systemctl start httpd.service Apache的默认配置： Apache默认将网站的根目录指向/var/www/html 默认的主配置文件/etc/httpd/conf/httpd.conf 配置存储在的/etc/httpd/conf.d/目录 更多关于CentOS下安装Apache请参考CentOS 7下Apache的安装 - 简书 2.2 初步配置Apache（视情况可略过）由于自己的服务器上已经安装了Nginx，而Apache和Nginx都默认关联80端口，所以这里需要做一些调整，例如将Apache的监听端口设置为8080。而由于自己的frp程序已经关联了8080端口，所以自己这里将Apache的监听端口设置为8088。 具体配置请参考：CentOS下nginx与apache如何共存_weixin_42912498的博客-CSDN博客 2.3 下载brat我们可以通过官网下载brat，也可以通过Github下载brat。 在下载完成后，我们需要将brat移动至var/www/html目录，并解压重命名目录为brat。 由于brat目录内的所有内容要被外网用户通过Apache访问到，所以我们需要配置brat目录的权限，具体命令为： chmod 777 -R /var/www/html/brat 2.4 配置Apache编辑/etc/httpd/conf/httpd.conf文件。 2.4.1 添加brat配置在&lt;Directory &quot;/var/www/html&quot;&gt;...&lt;/Directory&gt;配置后添加如下内容： # add brat &lt;Directory &quot;/var/www/html/brat&quot;&gt; AllowOverride Options Indexes FileInfo Limit Require all granted AddType application/xhtml+xml .xhtml AddType font/ttf .ttf Options +ExecCGI AddHandler cgi-script .cgi &lt;/Directory&gt; 如图： 2.4.2 添加cgi配置在第55行内容大约为# Example:# LoadModule foo_module modules/mod_foo.so后面补充： LoadModule cgi_module modules/mod_cgi.so LoadModule cgid_module modules/mod_cgid.so 如图： 2.4.3 重启Apachesystemctl restart httpd.service 2.5 查看配置结果在浏览器输入相应网址如图（以我个人网址为例）： 便说明Apache服务配置成功了。 在浏览器输入http://lightsmile.cn:8088/brat（以我个人网址为例）得到如下结果，便说明brat已经配置成功： 3.brat使用3.1 一些相关文章 你爱我吗？企鹅风讯利用BRAT进行中文情感分析语料标注掌握玩家心 - 腾讯WeTest NLP标注工具brat 配置文件说明 - JadePeng - 博客园 Zhong__CentOS7安装配置Brat(初级)_Zhong的博客-CSDN博客 BRAT的安装、配置、标注操作 | 码农家园 3.2 配置brat中文环境如前所述，brat目录为/var/www/html/brat，我们需要更改/var/www/html/brat/server/src/projectconfig.py中的第162行，具体为： n = re.sub(r&#39;[^a-zA-Z\\u4e00-\\u9fa5&lt;&gt;,0-9_-]&#39;, &#39;_&#39;, n) 如图： 3.3 待标记语料配置3.3.1 放置带标记语料将待标注的语料（txt）格式放入到brat的data目录中。 如： (base) ➜ brat cd data (base) ➜ data ls examples tests tutorials (base) ➜ data ls tests annotation.conf fuck.ann fuck.txt tools.conf 其中的fuck.txt就是待标记的纯文本语料，内容为： 曾经沧海难为水，除却巫山不是云。 何当共剪西窗烛，却话巴山夜雨时。 毛泽东出生于湖南。 3.3.2 创建ann文件对于所有的待标记语料，brat要求必须有同名的ann文件（brat会将标注结果存放在该文件中，而brat不会自动创建，需要用户手动创建）。 我们可以在brat目录下执行如下命令来批量创建ann文件。 find data -name &#39;*.txt&#39; | sed -e &#39;s|\\.txt|.ann|g&#39; | xargs touch 3.3.3 配置标注信息我们可以在txt和ann同级目录中增加conf文件来对标注项目进行配置，具体详情参考上面提到的brat配置文件说明。 比如说上面的和fuck.txt同级的annotation.conf文件中的内容为： [spans] Place Person [relations] Place-in Arg1:Person, Arg2:Place [events] [attributes] 同时也可以在tools.conf文件中设置记录标注过程日志，如： [options] Annotation-log logfile:./log_history.log 3.4 对语料进行标注具体标注过程略，标注界面如图： 3.5 查看并导出标注结果我们可以点击data菜单项来查看标注结果，如图： 点击ann即可打开新的页面，查看当前ann格式的标注结果，如图： 此内容和与fuck.txt同目录的fuck.ann内容一致。 点击Download tar.gz按钮则可以将当前标注结果下载下来。 4.注意事项4.1 无法加载标注文件可能是由于文件权限原因，当放置新的标注文件到data目录中时，仍然需要改变文件的访问权限。具体来说，我们可以通过如下命令来执行： chmod 777 -R /var/www/html/brat 5.参考 CentOS 7下Apache的安装 - 简书 CentOS下nginx与apache如何共存_weixin_42912498的博客-CSDN博客 Apache配置文件httpd.conf详解 - 简书 文本标注工具brat简介 - 云+社区 - 腾讯云","categories":[{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/tags/NLP/"}]},{"title":"damedane视频制作教程","slug":"damedane视频制作教程","date":"2020-08-30T02:43:21.000Z","updated":"2020-09-06T07:57:52.108Z","comments":true,"path":"articles/damedane视频制作教程/","link":"","permalink":"https://www.iamlightsmile.com/articles/damedane%E8%A7%86%E9%A2%91%E5%88%B6%E4%BD%9C%E6%95%99%E7%A8%8B/","excerpt":"0.前言近日在B站上接触到了一些换脸演唱的视频，觉得还有点意思，发现不少视频都是没几个粉的用户上传的，这让我意识到或许制作这个的门槛并不高，后来偶然间看到了相关教程，于是乎自己也尝试着搞了搞。","text":"0.前言近日在B站上接触到了一些换脸演唱的视频，觉得还有点意思，发现不少视频都是没几个粉的用户上传的，这让我意识到或许制作这个的门槛并不高，后来偶然间看到了相关教程，于是乎自己也尝试着搞了搞。 1.参考视频 最详细简洁的方法教你如何轻松做damedane梗！_哔哩哔哩 (゜-゜)つロ 干杯~-bilibili 教你轻松做出damedane梗图，会不会翻墙都可以！_哔哩哔哩 (゜-゜)つロ 干杯~-bilibili 2.使用方案如下图： 对于程序猿来说，自然是选择方法一了。 3.使用教程3.1 拷贝脚本到colab中脚本链接为：first-order-model-demo.ipynb - Colaboratory。 该脚本中包含代码运行逻辑所有流程。 我们可以选择直接编辑拷贝的ipynb文件，或者自己再新建一个ipynb文件，这里我选择的是新创建文件train_image.ipynb。 3.2 上传资源文件将想要制作的源图片和源视频上传到Google Drive中，这里需要注意的是上传的最好是256*256的png格式的图片（如果不是的话，可以先使用图片编辑工具将图片转换成相应的格式） 如图我这里将图片放到了Images目录： 将视频放到了Videos目录： 3.3 拷贝模型文件我们还需要将模型文件拷贝到Google Drive中。只需要拷贝两个tar文件就好，如图，放到相应的目录（自己随意，后续代码中对应上即可）： 3.4 启动环境并执行脚本打开之前创建的train_image.ipynb文件，然后系统便会分配RAM和磁盘供程序运行，由于Colab默认不会为环境配置GPU或者TPU，所以我们这里需要手动设置一下。 如下图： step1： 克隆仓库到colab依次输入并执行以下指令 !git clone https://github.com/AliaksandrSiarohin/first-order-model cd first-order-model 如图： step2: 查看GPU信息!nvidia-smi 如图： step3: 挂载Google drive到Colabfrom google.colab import drive drive.mount(&#39;/content/gdrive&#39;) 如图： 其中会涉及到使用Google账户授权，只要点击确认并复制相应的验证码到指定位置处运行即可。 step4: 加载驱动视频和源图像import imageio import numpy as np import matplotlib.pyplot as plt import matplotlib.animation as animation from skimage.transform import resize from IPython.display import HTML import warnings warnings.filterwarnings(&quot;ignore&quot;) source_image = imageio.imread(&#39;/content/gdrive/My Drive/Images/xiao_ke.png&#39;) driving_video = imageio.mimread(&#39;/content/gdrive/My Drive/Videos/bakamitai_template.mp4&#39;) #Resize image and video to 256x256 source_image = resize(source_image, (256, 256))[..., :3] driving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video] def display(source, driving, generated=None): fig = plt.figure(figsize=(8 + 4 * (generated is not None), 6)) ims = [] for i in range(len(driving)): cols = [source] cols.append(driving[i]) if generated is not None: cols.append(generated[i]) im = plt.imshow(np.concatenate(cols, axis=1), animated=True) plt.axis(&#39;off&#39;) ims.append([im]) ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000) plt.close() return ani # HTML(display(source_image, driving_video).to_html5_video()) 上面的source_image和driving_video的路径根据自己的情况进行设置。 另外我们可以看到上面脚本是有一个将图像和视频都变为256*256的操作，这里我们为了更好的效果可以提前将图片剪辑为相应的格式。 之后的display方法是定义了通过matplotlib库将图片和视频展示的方法，这里的效果大致如： step5: 创建并加载模型from demo import load_checkpoints generator, kp_detector = load_checkpoints(config_path=&#39;config/vox-256.yaml&#39;, checkpoint_path=&#39;/content/gdrive/My Drive/first-order-motion-model/vox-cpk.pth.tar&#39;) 最开始切换路径的目的就在于能够直接引用到demo的load_checkpoints函数并且对应到配置文件config/vox-256.yaml。 step6: 执行动画生成到这里终于到了我们最想看到的环节。 from demo import make_animation from skimage import img_as_ubyte predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=True) #save resulting video imageio.mimsave(&#39;../generated.mp4&#39;, [img_as_ubyte(frame) for frame in predictions]) #video can be downloaded from /content folder HTML(display(source_image, driving_video, predictions).to_html5_video()) 如图： 根据相对路径关系../generated.mp4我们也可以发现生成的视频文件就在当前环境下,即： 将生成的mp4下载到本地即可。 4.视频后期处理我们下载得到的generated.mp4并不能直接使用，时长不仅增加了3倍，并且也没有了声音。所以只能通过后期视频编辑再将视频调整为正常倍速并添加源视频音轨，实现正常的转换效果。 关于从mp4中提取音频，我这里用了arctime软件，该软件主要是配字幕的，自己之前使用过（本来以为有视频添加音频的功能，结果没有，这里只提了声音）由于自己的电脑比较渣，所以这里使用了B站提供的云剪辑功能，对视频进行了加工处理。 如图： 最终效果：女装maybe激情献唱_哔哩哔哩 (゜-゜)つロ 干杯~-bilibili","categories":[{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"damedane","slug":"damedane","permalink":"https://www.iamlightsmile.com/tags/damedane/"}]},{"title":"DGL使用初体验","slug":"DGL使用初体验","date":"2020-08-27T15:39:32.000Z","updated":"2020-09-05T07:37:11.024Z","comments":true,"path":"articles/DGL使用初体验/","link":"","permalink":"https://www.iamlightsmile.com/articles/DGL%E4%BD%BF%E7%94%A8%E5%88%9D%E4%BD%93%E9%AA%8C/","excerpt":"0.前言近来工作不算忙，工作时间主要在忙解析文档的工作，期间经历了从手撸规则到编写机器学习模型再到深度学习模型（从全连接到Bi-LSTM-CRF）的转变，自己对深度学习的应用框架编写和落地有了更多的理解，尤其是如何在对任务深入理解之上将其建模为机器学习分类任务的流程，之后会另起文章详述，此处不表。 知识图谱和深度学习相结合的一个点就是图神经网络模型（GNN），这里自己也算开始接触并开启实践之旅了。","text":"0.前言近来工作不算忙，工作时间主要在忙解析文档的工作，期间经历了从手撸规则到编写机器学习模型再到深度学习模型（从全连接到Bi-LSTM-CRF）的转变，自己对深度学习的应用框架编写和落地有了更多的理解，尤其是如何在对任务深入理解之上将其建模为机器学习分类任务的流程，之后会另起文章详述，此处不表。 知识图谱和深度学习相结合的一个点就是图神经网络模型（GNN），这里自己也算开始接触并开启实践之旅了。 1.DGL简单使用1.1 DGL介绍DGL是一个易于使用，高性能和可扩展的Python包，用于深入学习图形。DGL与框架无关，这意味着如果一个深度图模型是端到端应用程序的一个组件，那么其余的逻辑可以在任何主要框架中实现，比如PyTorch、Apache MXNet或TensorFlow。 Github地址：dmlc/dgl: Python package built to ease deep learning on graph, on top of existing DL frameworks. 1.2 示例代码说明:以下代码在jupyter notebook中运行，且主要搬运自DGL at a Glance — DGL 0.5.0 documentation 引入依赖库import dgl import numpy as np 使用DGL创建图def build_karate_club_graph(): # All 78 edges are stored in two numpy arrays. One for source endpoints # while the other for destination endpoints. src = np.array([1, 2, 2, 3, 3, 3, 4, 5, 6, 6, 6, 7, 7, 7, 7, 8, 8, 9, 10, 10, 10, 11, 12, 12, 13, 13, 13, 13, 16, 16, 17, 17, 19, 19, 21, 21, 25, 25, 27, 27, 27, 28, 29, 29, 30, 30, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33]) dst = np.array([0, 0, 1, 0, 1, 2, 0, 0, 0, 4, 5, 0, 1, 2, 3, 0, 2, 2, 0, 4, 5, 0, 0, 3, 0, 1, 2, 3, 5, 6, 0, 1, 0, 1, 0, 1, 23, 24, 2, 23, 24, 2, 23, 26, 1, 8, 0, 24, 25, 28, 2, 8, 14, 15, 18, 20, 22, 23, 29, 30, 31, 8, 9, 13, 14, 15, 18, 19, 20, 22, 23, 26, 27, 28, 29, 30, 31, 32]) # Edges are directional in DGL; Make them bi-directional. u = np.concatenate([src, dst]) v = np.concatenate([dst, src]) # Construct a DGLGraph return dgl.DGLGraph((u, v)) G = build_karate_club_graph() print(&#39;We have %d nodes.&#39; % G.number_of_nodes()) print(&#39;We have %d edges.&#39; % G.number_of_edges()) 输出： We have 34 nodes. We have 156 edges. 查看图结构import networkx as nx # Since the actual graph is undirected, we convert it for visualization # purpose. nx_G = G.to_networkx().to_undirected() # Kamada-Kawaii layout usually looks pretty for arbitrary graphs pos = nx.kamada_kawai_layout(nx_G) nx.draw(nx_G, pos, with_labels=True, node_color=[[.2, .5, .7]]) 输出： 为节点或边分配特征import torch import torch.nn as nn import torch.nn.functional as F embed = nn.Embedding(34, 5) # 34 nodes with embedding dim equal to 5 G.ndata[&#39;feat&#39;] = embed.weight # print out node 2&#39;s input feature print(G.ndata[&#39;feat&#39;][2]) # print out node 10 and 11&#39;s input features print(G.ndata[&#39;feat&#39;][[10, 11]]) 定义一个图卷积神经网络（GCN）from dgl.nn.pytorch import GraphConv class GCN(nn.Module): def __init__(self, in_feats, hidden_size, num_classes): super(GCN, self).__init__() self.conv1 = GraphConv(in_feats, hidden_size) self.conv2 = GraphConv(hidden_size, num_classes) def forward(self, g, inputs): h = self.conv1(g, inputs) h = torch.relu(h) h = self.conv2(g, h) return h # The first layer transforms input features of size of 5 to a hidden size of 5. # The second layer transforms the hidden layer and produces output features of # size 2, corresponding to the two groups of the karate club. net = GCN(5, 5, 2) 数据准备和初始化inputs = embed.weight labeled_nodes = torch.tensor([0, 33]) # only the instructor and the president nodes are labeled labels = torch.tensor([0, 1]) # their labels are different 训练模型训练代码： import itertools optimizer = torch.optim.Adam(itertools.chain(net.parameters(), embed.parameters()), lr=0.01) all_logits = [] for epoch in range(50): logits = net(G, inputs) # we save the logits for visualization later all_logits.append(logits.detach()) logp = F.log_softmax(logits, 1) # we only compute loss for labeled nodes loss = F.nll_loss(logp[labeled_nodes], labels) optimizer.zero_grad() loss.backward() optimizer.step() print(&#39;Epoch %d | Loss: %.4f&#39; % (epoch, loss.item())) 输出： Epoch 0 | Loss: 0.8586 Epoch 1 | Loss: 0.8109 Epoch 2 | Loss: 0.7692 Epoch 3 | Loss: 0.7338 Epoch 4 | Loss: 0.7082 Epoch 5 | Loss: 0.6831 Epoch 6 | Loss: 0.6582 Epoch 7 | Loss: 0.6352 Epoch 8 | Loss: 0.6149 Epoch 9 | Loss: 0.5956 Epoch 10 | Loss: 0.5762 Epoch 11 | Loss: 0.5572 Epoch 12 | Loss: 0.5374 Epoch 13 | Loss: 0.5179 Epoch 14 | Loss: 0.4981 Epoch 15 | Loss: 0.4777 Epoch 16 | Loss: 0.4574 Epoch 17 | Loss: 0.4363 Epoch 18 | Loss: 0.4148 Epoch 19 | Loss: 0.3934 Epoch 20 | Loss: 0.3716 Epoch 21 | Loss: 0.3494 Epoch 22 | Loss: 0.3266 Epoch 23 | Loss: 0.3034 Epoch 24 | Loss: 0.2805 Epoch 25 | Loss: 0.2589 Epoch 26 | Loss: 0.2377 Epoch 27 | Loss: 0.2172 Epoch 28 | Loss: 0.1975 Epoch 29 | Loss: 0.1790 Epoch 30 | Loss: 0.1615 Epoch 31 | Loss: 0.1451 Epoch 32 | Loss: 0.1297 Epoch 33 | Loss: 0.1156 Epoch 34 | Loss: 0.1028 Epoch 35 | Loss: 0.0912 Epoch 36 | Loss: 0.0809 Epoch 37 | Loss: 0.0721 Epoch 38 | Loss: 0.0642 Epoch 39 | Loss: 0.0572 Epoch 40 | Loss: 0.0510 Epoch 41 | Loss: 0.0455 Epoch 42 | Loss: 0.0407 Epoch 43 | Loss: 0.0364 Epoch 44 | Loss: 0.0327 Epoch 45 | Loss: 0.0294 Epoch 46 | Loss: 0.0266 Epoch 47 | Loss: 0.0241 Epoch 48 | Loss: 0.0218 Epoch 49 | Loss: 0.0199 可视化%matplotlib inline import matplotlib.pyplot as plt def draw(i): cls1color = &#39;#00FFFF&#39; cls2color = &#39;#FF00FF&#39; pos = {} colors = [] for v in range(34): pos[v] = all_logits[i][v].numpy() cls = pos[v].argmax() colors.append(cls1color if cls else cls2color) ax.cla() ax.axis(&#39;off&#39;) ax.set_title(&#39;Epoch: %d&#39; % i) nx.draw_networkx(nx_G.to_undirected(), pos, node_color=colors, with_labels=True, node_size=300, ax=ax) fig = plt.figure(dpi=150) fig.clf() ax = fig.subplots() draw(0) # draw the prediction of the first epoch plt.show() plt.close() 初始图节点状态： 动画效果： %matplotlib inline from matplotlib import animation, rc from IPython.display import HTML rc(&#39;animation&#39;, html=&#39;html5&#39;) ani = animation.FuncAnimation(fig, draw, frames=len(all_logits), interval=200) plt.show() # HTML(ani.to_html5_video()) # 将动画转为h5 video，和下面两种方式都行 HTML(ani.to_jshtml()) # 可视化效果更佳，且好像不依赖ffmpeg？ 如图： 2.遇到的问题2.1 无法实现动画效果发现报Matplotlib-Animation “No MovieWriters Available”的错误，后来通过stackoverflow找到了解决方案，即下载ffmpeg并配置环境变量。 3.参考 DGL at a Glance — DGL 0.5.0 documentation dmlc/dgl: Python package built to ease deep learning on graph, on top of existing DL frameworks. python - Matplotlib-Animation “No MovieWriters Available” - Stack Overflow python - Inline animations in Jupyter - Stack Overflow 在 jupyter notebook 中使用 matplotlib 绘图的注意事项_WeiSenhui的博客-CSDN博客","categories":[{"name":"知识图谱","slug":"知识图谱","permalink":"https://www.iamlightsmile.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"}],"tags":[{"name":"GNN","slug":"GNN","permalink":"https://www.iamlightsmile.com/tags/GNN/"}]},{"title":"“八佰”之我见","slug":"“八佰”之我见","date":"2020-08-25T14:52:02.000Z","updated":"2020-08-26T01:14:54.915Z","comments":true,"path":"articles/“八佰”之我见/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E2%80%9C%E5%85%AB%E4%BD%B0%E2%80%9D%E4%B9%8B%E6%88%91%E8%A7%81/","excerpt":"最近上映了新的电影《八佰》，不过我没去看，有意思的是网上相关的评论近似呈现两边倒的态势。自昨天开始我也不自觉的站批评《八佰》这条路，不过到了今天晚上看了更多的评论之后自己有了新的理解，并且对于其中不少现象的困惑也都几近明了，这里简单做一个整理记录。","text":"最近上映了新的电影《八佰》，不过我没去看，有意思的是网上相关的评论近似呈现两边倒的态势。自昨天开始我也不自觉的站批评《八佰》这条路，不过到了今天晚上看了更多的评论之后自己有了新的理解，并且对于其中不少现象的困惑也都几近明了，这里简单做一个整理记录。 以我在B站最喜欢的up主马督工的评论【睡前消息158】明明是重口味玄幻电影，《八佰》何必自称历史大片_哔哩哔哩 (゜-゜)つロ 干杯~-bilibili为例，他认为《八佰》可以算重口味玄幻电影，而不应该自称为历史大片，并且导演犯了历史虚无主义的错误，在电影里宣扬的是英雄史观而非人民史观。同样的，余亮老师在自己的评论余亮X萧武·对谈《八佰》：管虎不清楚该选什么路，但我们应该清楚【从书说起】_哔哩哔哩 (゜-゜)つロ 干杯~-bilibili里也做出了类似的评价，认为导演管虎不清楚该选什么路。 看了他们的评论之后我第一时间的想法是大佬毕竟是大佬，能看出这么多门道，这么看来这个《八佰》确实应该被批判，导演管虎的屁股歪了，华谊为了捞钱自救简直不择手段。 这两条视频下面的评论主要是批判《八佰》、批判管虎、批判华谊，然而还是有一些评论相对温和，认为我们的态度不应该太苛刻，看了之后有启发有感动，还是要继续支持的。 这时我的困惑便是，为什么同样的视频，大家的理解和态度竟有着如此大的差别呢？那些人为什么要站支持《八佰》呢？他们又错在哪里呢？ 在看了一些更加中性客观的评论之后，我才渐渐醒悟，上面的困惑自然就迎刃而解了。 关于“为什么同样的视频，大家的理解和态度竟有着如此大的差别”。正如”一千个读者心中有一千个哈姆雷特”， 我们首先需要承认的是人和人之间都存在着或大或小的思想层次、价值观念、阶级财富上的差异。有的人学识渊博，有的人大字不识一个；有的人偏爱阳春白雪，有的人只懂下里巴人；有的人信仰马克思主义，有的人追求美国自由主义；有的人自出生落地便是资产阶级，有的人穷苦一生不知何为阶级。 具体来说，我们可以粗略地将参与评论的大众分为三个层级，九大类别。三大层级包括知识水平有限，看电影看个热闹其实看不出啥门道的普通大众层（最底层）、导演管虎（打个比方）等所在的知识水平相对丰富，看电影能看出些门道的普通知识分子层（中层）、马督工等所在的知识水平丰富，见解深入深刻的高级知识分子层（高层）。其中每一层大致包括支持、中立、反对三大类别，共计九大类别。 如图： 其中最广泛普遍的普通大众在第一层，他们中更多的其实可能并不太了解这个电影背后所关联的历史事件，并不知道四行仓库，也并不知道谢晋元是谁，所以他们是以仰视的视角、相对放松的姿态去看这个电影。他们所知道的是《八佰》是改编自真实历史事件的战争片，他们可能并不太了解和在乎电影中故事的虚构性。 而站在第三层的督工们则是以俯视的视角去看这场电影，他们知道“八百壮士”的故事流传至今，几个版本的来龙去脉，他们可以发现哪些虚构加工不太符合逻辑，他们可以主观的看到电影的逻辑架构和主题思想乃至于导演所想表达的东西以及掺杂的私货，尽管这些看法不一定是正确的。 所以说当第二层和第三层的部分群体所从电影中看到的与自己的价值观念（偏右派）相符时，会发出支持的声音，认为反对者不应该对《八佰》太苛刻，电影创作应该相对自由，允许有不同的思想，不同的声音；当第二层和第三层的部分群体所从电影中看到的与自己的价值观念（偏右派）相背时，会发出批判的声音，其论点主要包括虚构加工成分过多、历史虚无主义、英雄史观而非人民史观等。 第一层的部分群体也分左派和右派，但是他们并看不到太多的如第三层的所能看到的东西，所以该层的非左的群体中部分发出支持的声音，理由是他们可以从电影中收获感动，体会到爱国主义、家国情怀，看到小人物的蜕变成长；而该层的以左派为主的部分群体则发出批判的声音，理由主要包括导演团体未采访谢晋元之子而是采访了孙元良之子秦汉、过度营销爱国主义以及继承自第二三层反对者们的理由等。 上面的分析也解释了部分人为什么会站支持《八佰》。而关于他们错在哪里的答案则是其实他们并没有错，或者说对错其实本来就是一个相对主观的概念，屁股不同，看到的自然不一样，每个人有自己的想法是再正常不过的事情。 而我原本的身份是处在第一层的反对者，然而现在是既反对又支持，即更加辩证的客观中立。然而抛却以上提到的反对和支持的理由，自己延伸出的想法则是虽然从商业的角度去看，这部电影是华谊和大众普通观影者（好评率占多数）的双赢，然而从社会意识的角度去看，除却爱国主义以外，电影中确实潜移默化地表示了些许非马克思主义的意识形态。 从理论上来说，马克思主义和新自由主义都是被历史实践验证过的与时俱进发展的主义，但是由于我们国家的政治主体是社会主义国家，走的是具有中国特色的社会主义道路，然而如果我们的国民所受到的新自由主义的影响越多越深，那么我们的国民对马克思主义和社会主义的否定和怀疑也就越多，这并不利于我们坚持走这一条正确的、历史验证过可行的社会主义道路。 换句话说，对于资产阶级而言，资本主义道路和资本主义社会是相比于社会主义道路和社会主义社会更合适的土壤，资本家和资产阶级以及相关附庸在一个国家中虽然只占相对少部分，但是其背后的财力以及其所把持的媒体通道却每时每刻都在影响着国家的运转以及国民的脑子，所以在我们这个社会主义国家成长起来的资本家跃迁到资产阶级之后，受利益驱使是有着想改变国家政治形态的倾向的，而这与外部势力相结合的终极目标便是内部社会主义政权崩溃瓦解与国家政治形态和平演变。 然而可能有人会想，我虽然不是资产阶级，但是觉得资本主义社会也没什么不好的啊。问题的关键在于就算我们改走资本主义社会，融入整个资本主义体系，我们的社会发展阶段也没有过渡到美国西欧那样的发达形态，我们的人口资源比还是很低，美国欧洲也不会把我们当做真正的朋友，他们不会允许这样的潜在的威胁存在，他们只会利用各种手段来分裂中国，使中国处于四分五裂的状态长期内战，以实现对他们的威胁最小化，我们的下场可能比如今战乱地区的人们过得还惨，回到民国军阀乱战的状态。当丧失掉独立自主之后，丧权辱国也必然随之而来。就算我们做最好的打算，我们华人在美国的待遇也永远做不了一等公民，看看如今的美国黑人，争取了上百年的权益到现在其实也不过如此，因为尊严和地位永远是取决于实力的。","categories":[{"name":"随念","slug":"随念","permalink":"https://www.iamlightsmile.com/categories/%E9%9A%8F%E5%BF%B5/"}],"tags":[{"name":"杂谈","slug":"杂谈","permalink":"https://www.iamlightsmile.com/tags/%E6%9D%82%E8%B0%88/"}]},{"title":"使用nginx搭建简单文件服务器","slug":"使用nginx搭建简单文件服务器","date":"2020-08-16T02:24:31.000Z","updated":"2020-08-16T03:04:25.316Z","comments":true,"path":"articles/使用nginx搭建简单文件服务器/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E4%BD%BF%E7%94%A8nginx%E6%90%AD%E5%BB%BA%E7%AE%80%E5%8D%95%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1%E5%99%A8/","excerpt":"0. 前言我们有多种通过网络给别人发送文件的方式，包括QQ文件分享、微信文件分享、网盘链接分享、邮件附件分享、文件服务器URL链接等。","text":"0. 前言我们有多种通过网络给别人发送文件的方式，包括QQ文件分享、微信文件分享、网盘链接分享、邮件附件分享、文件服务器URL链接等。 其中QQ文件分享和微信文件分享的前提是双方互加了好友，而在给陌生人分享文件的场景下这种方式自然不太适用了。 而网盘链接分享则需要先将文件上传到百度云网盘等各类网盘工具中，其中百度云网盘毕竟大厂保证但是速度偏慢，而其他的网盘或许没过几天就倒闭了。 通过邮件附件的方式比较方便，但是针对的仅是一对一的场景，虽然也可以通过转发或同时抄送多人的方式实现一对多，但当涉及到文件更新的时候，还需要再次发送邮件，也比较麻烦。 而至于文件服务器URL链接，主要包括自行搭建和通过第三方网站转存两种方式，具体比如说Linux系统镜像源和Pip源网站等。 近来涉及到在Github上和某库开发者分享测试文件，之前通过邮件附件方式，之后又需要分享，感觉不够方便，正好自己有在腾讯云上购买云服务器，所以就计划用nginx自己搭一下文件服务器啦。 1. 搭建流程1.1 安装Nginx略 1.2 添加配置信息在nginx的配置文件中，视自己情况添加如下信息，以我自己的为例： server { client_max_body_size 4G; listen 5666; # 选择绑定的端口 server_name www.lightsmile.cn; root /root/data/share; # 想要分享的文件路径 charset utf-8; # 中文名文件不乱码 # auth_basic &quot;Restricted&quot;; # 增加密码授权 # auth_basic_user_file /etc/nginx/pass_file; # 密码路径 location / { autoindex on; # 显示索引 autoindex_exact_size on; # 显示大小 autoindex_localtime on; # 显示时间 } } 1.3 设置访问验证略，自己这里尝试了不过失败了，一直循环提示输入密码，虽然输入的是对的，所以就不献丑了。 1.4 重启nginxnginx -s reload 1.5 查看效果如图： 其中服务器中相应的文件信息： 2. 参考 利用nginx搭建小型的文件服务器 - 简书","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://www.iamlightsmile.com/tags/nginx/"}]},{"title":"科学上网简单汇总","slug":"科学上网简单汇总","date":"2020-07-31T03:25:57.000Z","updated":"2020-07-31T06:15:31.567Z","comments":true,"path":"articles/科学上网简单汇总/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E7%AE%80%E5%8D%95%E6%B1%87%E6%80%BB/","excerpt":"科学上网总结 自建服务器 使用翻墙软件 使用浏览器插件","text":"科学上网总结 自建服务器 使用翻墙软件 使用浏览器插件 自建服务器自建服务器是指购买部署在大陆以外（包括国外、香港等）的服务器服务，然后自己搭建如Shadowsocks、V2ray、Brook等工具实现代理服务。优点是隐私性比较好，但是搭建成本较高，自己得懂一些计算机尤其是Linux系统知识。在之前的话，这算是一个比较好的方案，但是现在国家的墙实在是越来越严，几乎很快就能封锁端口和ip，所以现在这条路其实已经很难走了。 使用翻墙软件传统的比如说蓝灯，新发现的比如说pandaVPN，网上搜了一下，18年刚成立的，评价看起来还可以，比如：PandaVPN 评价 - 最好翻墙软件評價 2020 | BestVPNforChina、最好用的VPN翻墙软件推荐（2020中国VPN实测）- VPNDada，这是官网：PandaVPN - 全球最快&amp;最具隐私安全的VPN，这是国内网站（可能链接已经失效）：PandaVPN - 全球最快&amp;最具隐私安全的VPN。在网上搜索了一番之后，发现ExpressVPN：高速、安全和匿名的VPN服务 | ExpressVPN评价一直都很高，但是之前一直没有了解到也没有使用过。 使用浏览器插件比如Hoxx VPN Proxy - Chrome 网上应用店和SetupVPN - Lifetime Free VPN - Chrome 网上应用店，但是发现网上有一篇文章lyyx0000 / Twitter说两个工具同出一源，我自己装了一下发现是挺像的。 相关VPN知识 参考网址：有靠谱的VPN推荐吗? - CNode技术社区 1. 翻墙基本认识翻墙是为了不影响学习与工作，不是去诋毁中国和中国人。 你要明白世界的媒体是受西方控制的，舆论战里众多西方媒体是进攻的一方，而非西方阵营的国家只能选择防守，我们不说墙的存在对你我个人是好或不好，方便与不方便，如果说这个，当大概是不好也不方便，但也得明白防火墙存在在政治与国家安全上的‘合理性’。 绝大多数西方媒体都带有浓烈的意识形态企图，它们绝对不是“公正中立”的，明白这一点的中国人会越来越多。选择性报道，恶意扭曲的例子并不少，甚至一度还有“中国共产党镇压狗”的奇葩新闻，西方媒体说谎作恶，无所不用其极。翻墙绝对不是为了去做西方媒体的喉舌，你只要被绕进去，就很难看到全部的事实了。翻墙是首先是为了不影响个人学习与工作，其次是为了更好地学习和工作，还当然有娱乐：）Googe，Youtube，Facebook，Twitter上都有大量有益的信息可以看。况且前面说了，对个人来说，墙的门槛实际上并没有你想的那么高，墙的存在并不能阻止你获得这些信息。 不要假设“翻墙后”的必然选择是搞些猎奇反动的事情，翻墙后有很多有趣、有意义的东西可以看。有一些免费翻墙工具背后是美国国会支持的，典型代表是曾经流行的自由门，就有美国国会几百万美金的拨款，自由门绝对不是唯一一款，这种免费VPN会向用户不停推送反动信息，好在几年前被封了。 不要分发分享自建VPN，SSR机场，脚本等 国内有些小朋友看到搭建SSR这么容易，就去建机场，这是典型的作死，可以自行去搜机场主或者站长被请抓的新闻。个人VPN，SSR你自己用，请保持低调。不要到微信、微博这些地方去分发，除非你很想喝茶。分发分享自建VPN，SSR机场是犯法的。 2. VPN与加密代理中国的翻墙软件目前就两大类：一是VPN（OpenVPN等多种协议），二是加密代理（HTTPS，SOCKS5）。 VPN分免费的和付费的，绝大多数都有自己的加密和混淆算法，以绕过防火墙侦测。这个东西需要大量技术与人力的投入，所以几乎所有免费VPN和绝大多数小的付费VPN厂商都做不到长期稳定翻墙，因为它们的加密和数据混淆算法在防火墙的DPI（Deep Packet Inspection）面前不堪一击。剩下的VPN厂商都是有技术实力和预算来持续更新算法的。而且，中国国内的VPN大多数都关了，国外大多数VPN官网被墙，也无法购买。剩下的也只有那些重视中国VPN市场的大的厂商才能持续更新中国VPN镜像站了。 加密代理的技术五花八门，蓝灯，SS，SSR，V2Ray，Brook，WireGuard。目前中国网民里蓝灯和SSR有较多人使用，V2Ray，Brook，WireGuard技术门槛比较高，还很小众。蓝灯作为一个免费+付费的代理翻墙服务，口碑还好。自己搭建的SSR私服非常多，国外VPS服务商那里被封禁的IP也特别多。 所以现在能推荐的翻墙软件，无非国外的VPN大厂商，还有靠谱一点的SSR节点。但总的来说，付费VPN的长期翻墙能力更有保障，毕竟人家一个公司的人力与技术投入进去的。现在中国能推荐的VPN翻墙软件很少。 3. 翻墙软件常见问题为什么个人数据会泄露一旦连接到网络，运营商（ISP）就可以窥探你的所有流量。这就是互联网的运行原理，在访问某个网站之前，你必须向ISP 发出请求，请求通过后，就可以按指示接收网点。所以，你在线完成的所有操作都是在ISP眼皮底下进行的。除非你使用VPN。 翻墙软件的工作原理当你连接VPN时，你的客户端会首先连接到一个远程VPN服务器，这个服务器会修改你的IP 地址并对你发送或接收的所有数据进行加密。这种设置避免了窥探者或网络犯罪分子看到你的浏览记录。‎ 近期VPN现状随着近几年大规模的VPN封锁，大部VPN都已阵亡。以下是一些观察和建议： 国内的VPN已经全部阵亡，就不要考虑了 国外的VPN大部分也不能用了 免费VPN大部分都不好用（但很多付费VPN提供免费VPN试用） 如果懂技术，可以通过自己搭建SSR、WireGuard、V2Ray、Trogan等办法实现翻墙科学上网 如果不懂技术，最简单的办法是购买在中国好用的国外付费VPN。 VPN推荐 VPN 品牌 VPN 评测 优惠链接 ExpressVPN ExpressVPN评测 &gt;&gt;&gt;ExpressVPN优惠链接&lt;&lt;&lt; NordVPN NordVPN评测 &gt;&gt;&gt;NordVPN优惠链接&lt;&lt;&lt; VyprVPN VyprVPN评测 &gt;&gt;&gt;VyprVPN优惠链接&lt;&lt;&lt; PureVPN PureVPN评测 &gt;&gt;&gt;PureVPN优惠链接&lt;&lt;&lt;","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"科学上网","slug":"科学上网","permalink":"https://www.iamlightsmile.com/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"}]},{"title":"VMware中挂载共享文件夹","slug":"VMware中挂载共享文件夹","date":"2020-07-08T06:39:26.000Z","updated":"2020-07-08T07:12:33.380Z","comments":true,"path":"articles/VMware中挂载共享文件夹/","link":"","permalink":"https://www.iamlightsmile.com/articles/VMware%E4%B8%AD%E6%8C%82%E8%BD%BD%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E5%A4%B9/","excerpt":"0.前言现在自己开发主要用Windows系统，但是还是要去Linux系统去测试一下是否能跑通，目前公司的配置实在一言难尽，只能自己在笔记本里搞虚拟机。 由于涉及到文件共享，所以需要挂载共享文件夹，本来说已经在设置界面设置了，但是没想到只在第一次有效，之后就再也不行了。","text":"0.前言现在自己开发主要用Windows系统，但是还是要去Linux系统去测试一下是否能跑通，目前公司的配置实在一言难尽，只能自己在笔记本里搞虚拟机。 由于涉及到文件共享，所以需要挂载共享文件夹，本来说已经在设置界面设置了，但是没想到只在第一次有效，之后就再也不行了。 1.过程在网上搜索相关教程之后发现由于时效问题系统更迭也不管用，不过最终还是在VMware官网即在 Linux 客户机中装载共享文件夹找到了合适的指令。 即： 之后在Linux虚拟系统中执行的指令操作如下： ➜ ~ vmware-hgfsclient fromHost ➜ ~ uname -a Linux ubuntu 5.4.0-40-generic #44-Ubuntu SMP Tue Jun 23 00:01:04 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux ➜ ~ vmhgfs-fuse .host:/ /home/lightsmile/Shares -o subtype=vmhgfs-fuse,allow_other fusermount: option allow_other only allowed if &#39;user_allow_other&#39; is set in /etc/fuse.conf ➜ ~ nano /etc/fuse.conf ➜ ~ sudo nano /etc/fuse.conf ➜ ~ vmhgfs-fuse .host:/ /home/lightsmile/Shares -o subtype=vmhgfs-fuse,allow_other ➜ ~ ls Desktop Downloads Music Public snap Templates Documents miniconda3 Pictures Shares Software Videos ➜ ~ ls Shares fromHost 其间提示要修改/etc/fuse.conf文件，即把那一行注释去掉，如图： !edit_fuse_file 然后便可以重新访问共享的文件夹了，如图： 3.设置全局永久生效为了可以使得该设置一直生效，而不是每次开机后重启，我们可以将那一行命令放入.bashrc或者.zshrc中，但是我这里为了使得全局生效，所以在/etc/profile.d文件夹下新建了一个脚本名为set_share_file.sh，并设置里面的内容为： vmhgfs-fuse .host:/ /home/lightsmile/Shares -o subtype=vmhgfs-fuse,allow_other 然后就可以啦。","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"VMware","slug":"VMware","permalink":"https://www.iamlightsmile.com/tags/VMware/"}]},{"title":"Windows走终端代理","slug":"Windows走终端代理","date":"2020-06-29T08:13:24.000Z","updated":"2020-06-29T08:27:56.062Z","comments":true,"path":"articles/Windows走终端代理/","link":"","permalink":"https://www.iamlightsmile.com/articles/Windows%E8%B5%B0%E7%BB%88%E7%AB%AF%E4%BB%A3%E7%90%86/","excerpt":"0. 前言最近的墙可真严。 自己更新了Python包，要上传到Pypi上去，发现传不了了。终端提示：Uploading distributions to https://upload.pypi.org/legacy/，自己无法ping通upload.pypi.org，但是可以ping通pypi.org，这就很尴尬了。","text":"0. 前言最近的墙可真严。 自己更新了Python包，要上传到Pypi上去，发现传不了了。终端提示：Uploading distributions to https://upload.pypi.org/legacy/，自己无法ping通upload.pypi.org，但是可以ping通pypi.org，这就很尴尬了。 于是想着只能走终端代理了，网上找了些教程，大致试了一下，发现可行~ 1. 配置如在终端中设置： # http协议代理 set http_proxy=http://127.0.0.1:1080 set https_proxy=http://127.0.0.1:1080 # socks5协议代理 set http_proxy=socks5://127.0.0.1:1080 set https_proxy=socks5://127.0.0.1:1080 具体协议与端口请结合自己情况设置。 2. 参考具体内容与教程可自行参考下面所附链接。 让终端走代理的几种方法 | fazero 给 Windows 的终端配置代理 | zcdll’s Blog 代理链工具：proxychains | Howie’s Notes Win/Linux 命令行、终端和 Git 代理设置 | G2EX","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}]},{"title":"使用frp轻松实现内网穿透","slug":"使用frp轻松实现内网穿透","date":"2020-06-29T02:07:07.000Z","updated":"2020-07-11T04:18:42.636Z","comments":true,"path":"articles/使用frp轻松实现内网穿透/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E4%BD%BF%E7%94%A8frp%E8%BD%BB%E6%9D%BE%E5%AE%9E%E7%8E%B0%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/","excerpt":"0. 前言由于种种原因，希望可以通过外网访问自己的笔记本电脑搭建的Web服务，而这正是内网穿透所做的事情，hhh，自己之前找了关于Nginx实现反向代理的教程，发现呼呼扯一堆不是自己想要的，于是又找，终于找到了一篇写的比较详细完整的教程：windows下基于frp的内网穿透部署 - 知乎和理想中的工具：frp。","text":"0. 前言由于种种原因，希望可以通过外网访问自己的笔记本电脑搭建的Web服务，而这正是内网穿透所做的事情，hhh，自己之前找了关于Nginx实现反向代理的教程，发现呼呼扯一堆不是自己想要的，于是又找，终于找到了一篇写的比较详细完整的教程：windows下基于frp的内网穿透部署 - 知乎和理想中的工具：frp。 1. 原理1.1 frp简介frp 是一个可用于内网穿透的高性能的反向代理应用，支持 tcp, udp 协议，为 http 和 https 应用协议提供了额外的能力，且尝试性支持了点对点穿透。 1.2 需求及原理 2. 搭建流程2.1 下载运行程序在Releases · fatedier/frp界面分别下载对应架构的服务端程序和客户端程序，以我的为例： 其中标红的是需要下载的压缩程序，文件名含linux的是服务端，含windows的是客户端，因为我的腾讯云服务器上装的是Centos7，而我的笔记本则是Windows10系统。 分别将这两个文件放到服务器和笔记本的适当位置（没有要求，自己看着来） 2.2 配置服务端（公网反向代理端）2.2.1 修改frps.ini文件设置 http 访问端口为 8080： # frps.ini [common] bind_port = 7000 vhost_http_port = 8080 2.2.2 启动frps在程序所在目录运行以下命令： ./frps -c ./frps.ini 当然以上的命令是前台运行的，一退出就挂掉了，所以实际上我们需要后台执行该程序，也就是要运行以下命令： nohup ./frps -c ./frps.ini &gt; frps.log 2&gt;&amp;1 &amp; 这样frps程序便会在后台运行，并且会将程序输出重定向到frps.log文件 2.3 配置客户端（内网机，实际访问端）2.3.1 修改frpc.ini文件假设 frps 所在的服务器的 IP 为 x.x.x.x，local_port 为本地机器上 web 服务对应的端口, 绑定自定义域名 www.yourdomain.com: # frpc.ini [common] server_addr = x.x.x.x server_port = 7000 [web] type = http local_port = 80 custom_domains = www.yourdomain.com 注意：如果没有自定义域名，可以将上面的custom_domains字段内容设置为服务器的ip地址，即server_addr字段的内容，这样也可以直接通过ip访问内网服务 我自己的配置是： 2.3.2 启动frpc./frpc -c ./frpc.ini 以我自己的为例，则是： ./frpc.exe -c ./frpc.ini 如下图： 3. 测试服务我们使用Python下的Flask环境搭建一个最简单的Web服务： from flask import Flask app = Flask(__name__) @app.route(&#39;/&#39;) def hello_world(): return &#39;Hello World!&#39; if __name__ == &#39;__main__&#39;: app.run(port=8080) 注意: 服务端口一定要对应的上 本地与外网访问结果如下图： 4. 参考 windows下基于frp的内网穿透部署 - 知乎 frp/README_zh.md at master · fatedier/frp","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"frp","slug":"frp","permalink":"https://www.iamlightsmile.com/tags/frp/"},{"name":"内网穿透","slug":"内网穿透","permalink":"https://www.iamlightsmile.com/tags/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"}]},{"title":"给网站添加SSL认证（Nginx服务器）","slug":"给网站添加SSL认证（Nginx服务器）","date":"2020-06-29T02:04:29.000Z","updated":"2020-06-29T02:06:42.700Z","comments":true,"path":"articles/给网站添加SSL认证（Nginx服务器）/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E7%BB%99%E7%BD%91%E7%AB%99%E6%B7%BB%E5%8A%A0SSL%E8%AE%A4%E8%AF%81%EF%BC%88Nginx%E6%9C%8D%E5%8A%A1%E5%99%A8%EF%BC%89/","excerpt":"0. 前言自己的国内博客网站一直都是只有http访问方式，突然在看的一篇忘了讲啥的文章提到腾讯云可以免费申请SSL证书，于是自己也去操作了，没想到可能就间隔2、3个小时就申请成功了，然后按照文档进行配置就可以了。","text":"0. 前言自己的国内博客网站一直都是只有http访问方式，突然在看的一篇忘了讲啥的文章提到腾讯云可以免费申请SSL证书，于是自己也去操作了，没想到可能就间隔2、3个小时就申请成功了，然后按照文档进行配置就可以了。 主要参考的文档：SSL 证书 Nginx 服务器证书安装 - 最佳实践 - 文档中心 - 腾讯云 下面以自己在腾讯云注册的lightsmile.cn为例演示说明一下。 1. 配置流程1.1 将证书下载并拷贝至服务器证书如何申请此处不表，在腾讯云的SSL证书业务界面，可以将证书相关信息以zip压缩包形式下载下来，如： 里面的Nginx目录下的就是我们需要放置到服务器的内容。 放置到Nginx安装目录，如图： 1.2 修改nginx.conf内容以我的配置为例： server { listen 80 default_server; listen [::]:80 default_server; server_name www.lightsmile.cn; #把http的域名请求转成https return 301 https://$host$request_uri; } # Settings for a TLS enabled server. # server { listen 443 ssl http2 default_server; listen [::]:443 ssl http2 default_server; server_name www.lightsmile.cn; root /root/data/www/hexo; index index.html index.htm; ssl_certificate 1_www.lightsmile.cn_bundle.crt; ssl_certificate_key 2_www.lightsmile.cn.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; ssl_session_cache shared:SSL:1m; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / { index index.html index.htm; } error_page 404 /404.html; location = /40x.html { } error_page 500 502 503 504 /50x.html; location = /50x.html { } } 上面的配置中，添加了HTTP 自动跳转 HTTPS 的安全配置（具体细节也可以参考上面的腾讯云文档） 1.3 验证配置文件并重启Nginx然后，验证配置文件是否有问题： ./nginx -t 若无问题，重启Nginx即可： ./nginx -s reload 2. 参考 SSL 证书 Nginx 服务器证书安装 - 最佳实践 - 文档中心 - 腾讯云","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"SSL","slug":"SSL","permalink":"https://www.iamlightsmile.com/tags/SSL/"}]},{"title":"Python按需生成依赖文件","slug":"Python按需生成依赖文件","date":"2020-06-23T02:10:52.000Z","updated":"2020-06-23T02:51:12.758Z","comments":true,"path":"articles/Python按需生成依赖文件/","link":"","permalink":"https://www.iamlightsmile.com/articles/Python%E6%8C%89%E9%9C%80%E7%94%9F%E6%88%90%E4%BE%9D%E8%B5%96%E6%96%87%E4%BB%B6/","excerpt":"如果使用常规的pip freeze &gt; requirements.txt，会将环境中的依赖包全部都导入，一般而言这不是我们想要的结果。我们可以用pipreqs库按需生成项目所需的依赖文件，使用方式如下：","text":"如果使用常规的pip freeze &gt; requirements.txt，会将环境中的依赖包全部都导入，一般而言这不是我们想要的结果。我们可以用pipreqs库按需生成项目所需的依赖文件，使用方式如下： # 安装库 pip install pipreqs # 在当前目录生成 pipreqs . --encoding=utf8 --force # 安装requirements.txt依赖文件 pip install -r requirements.txt 注意 --encoding=utf8 为使用utf8编码，不然可能会报UnicodeDecodeError: ‘gbk’ codec can’t decode byte 0xae in position 406: illegal multibyte sequence 的错误。--force 强制执行，当成目录下的requirements.txt存在时覆盖。 如下图，便可轻松生成项目所需的requirements.txt文件了，只不过由于程序要在项目中一个文件一个文件去找，所以时间可能有点慢。。。 参考：python生成requirements.txt的两种方法_python_脚本之家","categories":[{"name":"Python","slug":"Python","permalink":"https://www.iamlightsmile.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://www.iamlightsmile.com/tags/Python/"}]},{"title":"一道面试算法题（动态规划）","slug":"一道面试算法题（动态规划）","date":"2020-05-12T09:18:19.000Z","updated":"2020-05-12T09:59:19.651Z","comments":true,"path":"articles/一道面试算法题（动态规划）/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E4%B8%80%E9%81%93%E9%9D%A2%E8%AF%95%E7%AE%97%E6%B3%95%E9%A2%98%EF%BC%88%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%EF%BC%89/","excerpt":"昨天参加了一场网上技术面试，通过腾讯会议平台。面试官问了两道算法题，都没答上来，-_-||。看来自己必须要高度重视算法基础，多刷多积累算法题了。","text":"昨天参加了一场网上技术面试，通过腾讯会议平台。面试官问了两道算法题，都没答上来，-_-||。看来自己必须要高度重视算法基础，多刷多积累算法题了。 面试结束后，自己在网上搜索了第一道题目以及其解法，才恍然大悟原来这就是动态规划，下面是题目介绍： 题目：将一个数组分成两部分，不要求两部分所包含的元素个数相等，要求使得这两个部分的和的差值最小。比如对于数组{1,0,1,7,2,4}，可以分成{1,0,1,2,4}和{7}，使得这两部分的差值最小。 当时面试官是口述这道题，我的理解应该是得到这两个数组的具体内容，而不仅仅是这其中的差值，而网上看到的解法基本上都是仅仅求得差值，所以自己在理解他人实现后增加了完整的代码，这里简单记录一下。同时激励自己多刷刷算法题呀！ def solution(arr): target = sum(arr) // 2 # 初始化动态规划二维矩阵 matrix = [[0]*(target+1) for i in range(len(arr)+1)] # 求解主算法 for i in range(1, len(arr)+1): for j in range(1, target+1): if j &gt;= arr[i-1]: matrix[i][j] = max(matrix[i-1][j], matrix[i-1][j-arr[i-1]] + arr[i-1]) else: matrix[i][j] = matrix[i-1][j] # 初始化两个数组 a = [] # 存储目标元素 b = [] # 存储其他元素 n = target # 反向求解得到数组具体值 for m in range(len(arr), 0, -1): if arr[m-1] &lt;= n and matrix[m-1][n] &lt; matrix[m-1][n-arr[m-1]] + arr[m-1]: a.append(arr[m-1]) n -= arr[m-1] else: b.append(arr[m-1]) return matrix[-1][-1], a, b arr = [1, 0, 1, 7, 2, 4] res = solution(arr) print(res) 参考 0-1背包问题及Python代码实现 - 简书 将数组分成两部分，使得这两部分的和的差最小_C/C++_Swartz2015的专栏-CSDN博客 数组分为两部分，使得其和相差最小 - ranjiewen - 博客园 把一个数组分为两部分使得其和相差最小 - 知乎","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://www.iamlightsmile.com/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"使用CDN为网站提速","slug":"使用CDN为网站提速","date":"2020-05-02T12:14:01.000Z","updated":"2020-05-02T12:22:55.365Z","comments":true,"path":"articles/使用CDN为网站提速/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E4%BD%BF%E7%94%A8CDN%E4%B8%BA%E7%BD%91%E7%AB%99%E6%8F%90%E9%80%9F/","excerpt":"由于要设置博客站点的图标，而ico文件不能直接拖到图床工具中上传，于是也参考学习了一下使用CDN的方式。","text":"由于要设置博客站点的图标，而ico文件不能直接拖到图床工具中上传，于是也参考学习了一下使用CDN的方式。 主要参考学习文章为：免费CDN：jsDelivr+Github 使用方法_网络_TRHX’S BLOG-CSDN博客 其中步骤主要包括： 新建Github项目 将资源放到项目中 发布release版本 通过超链访问 重复之话此处不表，此处贴一下截图：","categories":[],"tags":[]},{"title":"记录原来的博客风格","slug":"记录原来的博客风格","date":"2020-05-01T06:27:57.000Z","updated":"2020-05-01T06:39:39.764Z","comments":true,"path":"articles/记录原来的博客风格/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E8%AE%B0%E5%BD%95%E5%8E%9F%E6%9D%A5%E7%9A%84%E5%8D%9A%E5%AE%A2%E9%A3%8E%E6%A0%BC/","excerpt":"原来的博客用了很长时间的material-X的风格，可是最近突然觉得有些喧闹，并且雪花爆炸特效等挺消耗电脑，最终的浏览体验并不好，所以这里把那些效果去掉，现在用的是原作者在material-X基础上升级的Volantis主题。 然而在这里还是放两张截图，也算保存纪念一下吧。","text":"原来的博客用了很长时间的material-X的风格，可是最近突然觉得有些喧闹，并且雪花爆炸特效等挺消耗电脑，最终的浏览体验并不好，所以这里把那些效果去掉，现在用的是原作者在material-X基础上升级的Volantis主题。 然而在这里还是放两张截图，也算保存纪念一下吧。","categories":[{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[]},{"title":"C++常用数据结构操作示例","slug":"C++常用数据结构操作示例","date":"2020-05-01T01:45:31.000Z","updated":"2020-06-29T06:40:58.368Z","comments":true,"path":"articles/C++常用数据结构操作示例/","link":"","permalink":"https://www.iamlightsmile.com/articles/C++%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%93%8D%E4%BD%9C%E7%A4%BA%E4%BE%8B/","excerpt":"0. 前言由于自己使用Python居多，对C++并不太熟悉，但是最近在刷算法题，所以这里简单整理总结一下C++常用数据结构的操作函数，以便方便查阅检索。","text":"0. 前言由于自己使用Python居多，对C++并不太熟悉，但是最近在刷算法题，所以这里简单整理总结一下C++常用数据结构的操作函数，以便方便查阅检索。 s 1. C++标准库常用数据结构常用数据结构如下： string vector list queue和priority_queue set map stack 2. 常用数据结构操作示例1. string//header file : &lt;string&gt; //declaration string s = &quot;hello world!&quot;; // visit by subscript char c = s[2];//l const char cc = s.at(6);//w // get the length of the string int length = s.length();//12 int size = s.size();//12 // the string is empty or not bool is_empty = s.empty();//0 // concat strings string t = &quot;c++&quot;; s.append(t);//hello world!c++ s += &quot;Python!&quot;;//hello world!c++Python! // get substring string sub_str = s.substr(0, 5);//hello // find substring int pos = s.find(&quot;world&quot;);//6 // insert operation s.insert(0, &quot;Hi!&quot;);//Hi!hello world!c++Python! // compare operation string other = &quot;NLP&quot;; bool cmp = other &lt; s;//0 // visit element by iterator for (auto i: s) { cout &lt;&lt; i &lt;&lt; endl; } 2. vector// header file :&lt;vector&gt; // declaration vector&lt;int&gt; vec {2, 3, 4}; //[2, 3, 4] // size of vector int size = vec.size(); //3 // the vector is empty or not bool is_empty = vec.empty(); // 0 // visit by subscript auto e = vec.at(2);//4 int m = vec[1];//3 cout &lt;&lt; e &lt;&lt; m &lt;&lt; endl; // append element at back vec.push_back(5); // [2, 3, 4, 5] // delete the last element vec.pop_back();//[2, 3, 4] // insert an element by iterator vec.insert(vec.begin(), 1); //[1, 2, 3, 4] // visit the first element and the last element cout &lt;&lt; vec.front() &lt;&lt; vec.back() &lt;&lt; endl; // 14 // visit by iterator auto iter = vec.begin(); while (iter != vec.end()) { cout &lt;&lt; *iter &lt;&lt; endl; iter += 1; } // delete element by iterator auto item = vec.erase(vec.end() -2); cout &lt;&lt; *item &lt;&lt; endl;//4 for (auto i: vec) { cout &lt;&lt; i &lt;&lt; endl; } 3. queue// header file: &lt;queue&gt; //declaration, can&#39;t initiate with assignment statement. queue&lt;int&gt; que; // add element to the back of queue for (int i = 0; i &lt; 3; i++) { que.push(i); } //que: {0, 1, 2} // get the size of queue int size = que.size();//3 // if the queue is empty or not bool is_empty = que.empty();//0 // delete the element at the first position que.pop();//que: {1, 2} // get the first element auto first = que.front();//1 // get the last element auto last = que.back();//2 cout &lt;&lt; first &lt;&lt; last &lt;&lt; endl; 4. map//header file :&lt;map&gt; //declaration map&lt;int, int&gt; m; //add element to map for (int i = 0; i &lt; 3; i++) { m[i] = i + 2; } m.insert({5, 8}); //visit the element by auto+for for (auto i: m) { printf(&quot;%d : %d\\n&quot;, i.first, i.second); } //whether the map is empty or not bool is_empty = m.empty();//0 //get the size of map int size = m.size();//4 // get the count of element int count = m.count(2);//1 // search item by key auto item = m.find(count); printf(&quot;%d : %d\\n&quot;, item-&gt;first, item-&gt;second); // if not find, the value would equal to map.end() auto ss = m.find(9); cout &lt;&lt; (ss == m.end()) &lt;&lt; endl;//1 // get element by [] operator int sk = m[10];//0 if the key not exists, then init cout &lt;&lt; sk &lt;&lt; endl;//0 map&lt;string, string&gt; str_map; str_map.insert({&quot;hello&quot;, &quot;world&quot;}); cout &lt;&lt; &quot;begin&quot; &lt;&lt; str_map[&quot;python&quot;] &lt;&lt; &quot;end&quot; &lt;&lt; endl;//beginend 5. set// header file :&lt;set&gt; // declaration set&lt;int&gt; ss; // insert element ss.insert(3); // whether element is in the set or not bool is_in = ss.count(4);//0 // get the size fo set int size = ss.size();//1 // whether the set is empty or not bool is_empty = ss.empty();//0 cout &lt;&lt; is_in &lt;&lt; size &lt;&lt; is_empty &lt;&lt; endl; 6. stack// header file: &lt;stack&gt; //declaration stack&lt;int&gt; stk; // insert element stk.push(3); stk.push(4); // get the top element int top = stk.top();//4 // get the size of stack int size = stk.size();//2 // out of the stack, no return stk.pop(); cout &lt;&lt; top &lt;&lt; size &lt;&lt; stk.top() &lt;&lt; endl;//423 7. list//header file: &lt;list&gt; //declaration list&lt;int&gt; lst; // add element at back lst.push_back(4);//{4} lst.push_back(5);//{4, 5} // add element at front lst.push_front(3);//{3, 4, 5} for (auto i: lst) { cout &lt;&lt; i &lt;&lt; endl; } // get the size of list int size = lst.size();//3 // delete element, the iterator of list doesn&#39;t implement the + or - operator // since C++17, we can use advance(lst.begin(), 2) to get the iterator of specific position easily lst.erase(++lst.begin());//{3, 5} printf(&quot;front:%d, back:%d&quot;, lst.front(), lst.back());//front:3, back:5 8. priority_queuepriority_queue并没有提供迭代器访问，只可以访问top元素。 //header file: &lt;queue&gt; //declaration priority_queue&lt;int&gt; pq; // push data to pq for (int i = 1; i &lt; 7; i++) { pq.push(i); } // whether the pq is empty or not bool is_empty = pq.empty();//0 // get the size of pq int size = pq.size();//6 // get the top element int top = pq.top();//6 // remove the top element pq.pop(); cout &lt;&lt; pq.top() &lt;&lt; endl;//5 参考 c++string类的常用方法详解_c/c++_monkey_D_feilong的博客-CSDN博客 C++ vector容器用法 - 简书 c++ queue的使用 - 简书 c++ map set 详解 - 简书 C++ stack 使用 - 简书 C++ STL std::list的使用 - 简书 STL之list和vector - 简书 C++ STL 之 priority_queue 与堆 - 简书","categories":[],"tags":[]},{"title":"从多人运动说起","slug":"从多人运动说起","date":"2020-04-25T16:53:09.000Z","updated":"2020-04-25T16:59:32.330Z","comments":true,"path":"articles/从多人运动说起/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E4%BB%8E%E5%A4%9A%E4%BA%BA%E8%BF%90%E5%8A%A8%E8%AF%B4%E8%B5%B7/","excerpt":"近日罗志祥和其前女友分手之事成了热点事件，大批吃瓜群众纷纷表示涌入。 周扬青肯定是作为一个受害者，但是罗志祥是否真的应当受千夫所指、受众人口诛笔伐吗？ 需要声明的是，我对这起事件并不有多少了解，所以并不会妄加推断。既不会作为一个给罗志祥洗白的写手，也不会做一个维护周扬青的看客，而是更多的从自认为的更客观更理性的角度来去分析一下这件事情。","text":"近日罗志祥和其前女友分手之事成了热点事件，大批吃瓜群众纷纷表示涌入。 周扬青肯定是作为一个受害者，但是罗志祥是否真的应当受千夫所指、受众人口诛笔伐吗？ 需要声明的是，我对这起事件并不有多少了解，所以并不会妄加推断。既不会作为一个给罗志祥洗白的写手，也不会做一个维护周扬青的看客，而是更多的从自认为的更客观更理性的角度来去分析一下这件事情。 保持不正当男女关系的艺人在娱乐圈或并不少见，普通群众看到的仅仅只是一起起被曝出的案例而已，同样比如说：吴亦凡。 许多人包括明星在内，当满足： 自己或配偶经常出门在外且在外时间多达几周几月的 自己有一定的金钱、权势，且由于工作性质，偶尔或经常会遇到一些姿色还不错的异性或者异性下属 自己外貌形象俱佳，颇受异性欢迎爱慕 等等 如何在不违法也不违背良心的前提下不断满足自己的情感需求和性需求，尤其是在上面的易导致出轨的环境土壤中。 那些和罗某、吴某上床的女孩子们是否也认为自己上当受骗？可能有不少天真的女孩子会期盼自己也能够有一份灰姑娘的爱情，她们的白马王子年轻有为、身材修挺、貌美肤白、有情有义、感情专一、甜言蜜语只哄自己，而自己则蒙上天眷顾，是最幸运的人。有一个这样的梦很正常，本是无可非议，然而现实是：这样般配吗？自己配得上他吗？虽然两情相悦固然重要，但是门当户对才是关键之处，这里的门户并不单纯指物质上的财富地位等。同时社会中，往往越上面的人，看的越现实。如果只觉得自己尽职尽责，做了应该做的，便会得到所期望的应有的回报，那只是把现实看得太简单了。所以如梦幻泡影，终究有破碎的那一天。更现实的是，往往有许多人并不把出轨和乱搞男女关系视为违背良心的不该做之事，他们只是你情我愿，若你不是当事人或相关者，那与你何干？更更现实的是，这样做真的有错吗，或者说违法吗？ 在不涉及自身利益的情况下，我们大多数人作为吃瓜群众的思维习惯往往是为弱者发声。指出这一现象并不是在否定这种做法，而是说“弱”者也未必永远都是“善”的一方，而“强”者也未必永远都是“恶”的一方，比如说：老人碰瓷。 许多时候当我们对某些热点事件做出自己的反馈时，往往得到的信息并不全面，当我们得到部分信息之后，我们常常直接结合已有的先验知识得到先入为主的主观且偏见的推论判断，而这种推论判断也并不意味着总是不够合理，还是要更具体的辩证地来看待。 我们知道每个人都是复杂的多面的生物，我们看到的往往只是几面而已，看到的好与坏都是个体的真实的一部分。如果单纯地仅由片面的看到的好与坏而武断的得出这个人整体如何是有失偏颇而不够合理的。 作为一个素来秉持雨我无瓜的普通民众而言，更多的还是惊叹且佩服于罗志祥的时间管理以及精力分配上的天赋和能力。 而从这个娱乐圈事件延伸开来，简单谈一下自己相对于娱乐圈的某些看法。 如今是一个全民娱乐、遍地流量的时代。不客观的来说，我觉得周某某出狱引来不少网红公司高价聘用事件是对这个社会相当大的讽刺！ 记得在刚上大学开始用智能机，开始使用微信和微博后，经过一段时间我发现微信客户端所推送的腾讯新闻和以及微博客户端所推送的新浪新闻中娱乐相关的新闻的比重也忒大了些，而其中实事或社会热点相关新闻的占比并不算太大，并且部分新闻用语措辞也不够专业，关键的还不是掺杂了主观的评论观点，而是某些评论观点甚至于说比较偏颇，带有负面的消极的唯金钱论的感情色彩。接触久了实在令我感到反感，所以就把这两个默认的资讯通道全都取关，而令我感到有些震惊害怕的是这两个平台承载的中国上亿的普通用户每天生活在这种潜移默化的影响之下会受到多少认知倾向价值观方面等的影响，尤其是其中一些文化程度较低的、世界观价值观并不太客观完善的用户以及那些正在成长中的三观未全的中小学生们。从这个角度出发，我认为某种程度上现在整个社会普通民众的接收大众信息的渠道正在被娱乐媒体、资本势力等所把持着，而关键是这些渠道所发出的声音更代表、更符合哪些利益团体的利益，究竟是姓“社”还是姓“资”。 前一段时间肖战事件闹得沸沸扬扬，就连最近甚至也还有一些余波。每个粉丝喜欢ta的偶像自然有ta的道理，但是表达喜欢和支持的方式应该是尽量理性的。纵观整个事件，我觉得很有必要指出的是：那些以爱之名做出各种事件的粉丝的出发点大多都是为了自己心目中喜欢的明星，而那些针锋相对迎头反抗的原本八竿子都打不着的井水不犯河水的众人们大多其实也并不是反肖战，而是反那些粉丝，反那些粉丝不够理性的举动损害了他们的合法利益，虽然也不排除某些出于利益而别有用心的人在里面发弹药搅浑水的可能性。所以说，很大程度上肖战粉丝所不愿意看到的现在的情形其实是由她们亲手造成的。 我们可能对演员太苛刻，而对网红太宽容。还记得被封杀的以前比较喜欢的演员黄海波，对比现在闹出各种丑闻息影一段时间便可轻松复出的明星，我觉得这就是一种不公平。再如范冰冰等明星的天价片酬对比许多科技国企基层人员微薄的薪水、以及原来的小孩子的理想大多是当一名科学家对比现在的许多小孩子们都想着成为一名主播网红明星等，不得不说这种现象背后的社会风气问题很严重，虽说片酬薪水是由市场所决定的，但是市场也是受资本所操控影响的。 在如今的社会时代，似乎追求物质、浮躁之风较之以往更浓，某种程度上那些资本也要来承担一部分责任。但是话说回来，如今的这个局面，社会整体、普通民众、资本团体乃至国家相互复杂钩织在一起，谁都脱不开关系。就比如说，我认为现在社会中许多有关中小学生的负面热点事件都脱离不开应试教育四字的原因。某种程度上，正是这种应试教育所导致的社会和家长压迫学生正常心身发展、只使其一心关注考试科目知识成绩，而缺乏对孩子的身心健康教育，也不尊重和注重培养孩子的意愿兴趣，使其并未能建立起更好的三观而误行错事，。其中既有家长的失职，学校的管理方式不当，也有整个社会的风气所致。俗话说，宜疏不宜堵，不能正常身心发展的孩子们只能将更多的好奇心和精力放到日常生活中更容易接触到的新闻和媒体中，比如量贩的小生明星、全民娱乐的吃鸡农药等等。 记得前不久有一个B站UP主被吸血很惨的事情，跟着热点了解了一下什么叫做MCN机构。说实话，在我看来。某些签约的UP主和不少签约的演员明星一样，某种程度上都是其签约公司和机构的一根根的细化的资本触手，不断地引诱、吸取着大众的注意力和手中的钱包，一如《倩女幽魂》中的众女妖和操控她们吸食男人精魄的千年树妖，虽然也可以将它们之间的关系视为互相成就、互利共生的关系。当然这样说或许并不恰当，因为许多明星或UP主的作品确实是受大众喜爱的，以及人们能够从他们创作的作品中打发时光、收获快乐、汲取营养等。从这个角度来看，那么这些明星和UP主和关注支持他们的粉丝之间也构成一种互利共生的关系。","categories":[{"name":"随念","slug":"随念","permalink":"https://www.iamlightsmile.com/categories/%E9%9A%8F%E5%BF%B5/"}],"tags":[{"name":"杂谈","slug":"杂谈","permalink":"https://www.iamlightsmile.com/tags/%E6%9D%82%E8%B0%88/"}]},{"title":"使用Brook科学上网教程","slug":"使用Brook科学上网教程","date":"2020-04-07T13:40:51.000Z","updated":"2020-04-25T01:26:46.407Z","comments":true,"path":"articles/使用Brook科学上网教程/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E4%BD%BF%E7%94%A8Brook%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E6%95%99%E7%A8%8B/","excerpt":"0.更新IP又被封了，难受。 Brook协议也不能用了，估计是这个协议也不能翻墙了。理由如：代理服务器还可以访问没有被墙、并且其他协议比如ss也不行了，憋了两天受不了了搞了V2ray可以了。哎，真香。 之前自己使用搬瓦工+SSR一键搭建脚本或者借助同学的vpn以实现科学上网，然而前两天突然同学的也出了问题。后在Github中大浪淘沙，终于寻觅到了一个很全面的科学上网教程：Alvin9999/new-pac: 科学上网/自由上网/翻墙/软件/方法，免费shadowsocks/ss/ssr/v2ray/goflyway账号，vps一键搭建脚本/教程。如今相对而言，SS、SSR那一套技术相对落后，并且使用范围与流传时间比较广，所以导致更加容易被墙。后有v2ray和brook技术，相对更先进小众，所以暂时比较安全。这里拾人牙慧，简单说一下配置流程。","text":"0.更新IP又被封了，难受。 Brook协议也不能用了，估计是这个协议也不能翻墙了。理由如：代理服务器还可以访问没有被墙、并且其他协议比如ss也不行了，憋了两天受不了了搞了V2ray可以了。哎，真香。 之前自己使用搬瓦工+SSR一键搭建脚本或者借助同学的vpn以实现科学上网，然而前两天突然同学的也出了问题。后在Github中大浪淘沙，终于寻觅到了一个很全面的科学上网教程：Alvin9999/new-pac: 科学上网/自由上网/翻墙/软件/方法，免费shadowsocks/ss/ssr/v2ray/goflyway账号，vps一键搭建脚本/教程。如今相对而言，SS、SSR那一套技术相对落后，并且使用范围与流传时间比较广，所以导致更加容易被墙。后有v2ray和brook技术，相对更先进小众，所以暂时比较安全。这里拾人牙慧，简单说一下配置流程。 1.Brook简介Brook是一款新兴的代理软件，其版本横垮Windows、安卓、iOS、MacOS、Linux等多个系统平台，功能类似于我们经常使用的Shadowsocks/ShadowsocksR。Brook 的目标是简单易用、傻瓜化、速度快（新协议）。通过在服务器端安装Brook服务器端，同时在本地设备中使用Brook客户端，两者成功连接之后，可以为我们提供科学上网服务。如果你想在SS/SSR/V2ray之外，尝试一种新的代理软件，那么Brook是一个不错的选择！ 2.在服务器安装Brook购买国外服务器之类略去不表。 在服务端执行如下命令： wget -N --no-check-certificate wget -N --no-check-certificate https://raw.githubusercontent.com/ToyoDAdoubi/doubi/master/brook.sh chmod +x brook.sh ./brook.sh 然后根据提示安装，其中端口视自己情况设置（如无特殊或小白不懂，只需默认回车即可），密码可以自己设置也可以选择默认。如果一切顺利，则最终有类似如下输出： 在参考的教程中，有一步一键加速VPS服务器，不过我试了一下，发现系统好像已经默认安装了？所以这里就不再叙述这一步了。 3.在客户端安装Brook下面以Windows为例： 从Releases · txthinking/brook中找到对应自己平台的客户端安装文件，包括Linux、Mac、Windows、Android等等。 作者（应该是作者的作品）为Windows系统写了一个配套的GUI辅助工具Brook Tools，需要配合Brook Windows命令行版客户端使用。 在按照教程下载了客户端文件和压缩文件后，进行解压缩操作，并打开软件，填写服务器代理相关信息，设置代理方式即可。 设置完成后，如下图所示： 自己同时也试了下Android的Apk，发现试了几次无法正常运行，报PlantformException之类的，不过刚才试了一下发现终于也成功了！ 如下图： 然后便又可以轻松愉快的上网啦！ 4.参考 自建brook服务器教程 · Alvin9999/new-pac Wiki 自建v2ray服务器教程 · Alvin9999/new-pac Wiki v2ray各平台图文使用教程 · Alvin9999/new-pac Wiki","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"科学上网","slug":"科学上网","permalink":"https://www.iamlightsmile.com/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"}]},{"title":"浅谈新冠疫情","slug":"浅谈新冠疫情","date":"2020-03-28T07:03:31.000Z","updated":"2020-03-30T08:31:49.090Z","comments":true,"path":"articles/浅谈新冠疫情/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E6%B5%85%E8%B0%88%E6%96%B0%E5%86%A0%E7%96%AB%E6%83%85/","excerpt":"新型冠状病毒自初始传播到现在已经几个月的时间过去了，期间发生了林林总总的事情，自己略有所感，这里简单谈一下。主要从以下几个方面进行： 暴露了我国的哪些问题 对国家和个人的影响 农村是怎么做的 从疫情出发谈政治体制与自由民主 从疫情出发谈中国舆论环境","text":"新型冠状病毒自初始传播到现在已经几个月的时间过去了，期间发生了林林总总的事情，自己略有所感，这里简单谈一下。主要从以下几个方面进行： 暴露了我国的哪些问题 对国家和个人的影响 农村是怎么做的 从疫情出发谈政治体制与自由民主 从疫情出发谈中国舆论环境 1.暴露了我国的那些问题在应对本次疫情过程中，值得肯定的是我国党中央在充分了解此次疫情情况后做出了十分理智正确的决策，以壮士断腕的手段快速制定实施了区域隔离等政策，虽然这将给国家和许多企业个人带来不小的经济损失，但从长远来看，是正确无比的。同时其他各省医护人员驰援湖北武汉，国外不少国家地区也都捐赠了不少物资，海内外华人华侨也纷纷开展口罩医疗设备购买活动，各尽其力帮助武汉，真是令人感动不已，从某种程度上体现了我们中华民族团结一心、互帮互助的优良品质。 然而不可否认的是在本次疫情应对防范过程中，还是存在着不少问题。比如部分政府官员能力不足、敷衍了事，更有甚者逃之夭夭在国外避难；同时湖北红十字会在接收物资并转发物资的过程中的表现实在是无法让全国人民满意甚至寒心。郭美美事件记忆犹新，在本次疫情过程中，倒是有不少尸位素餐、德不配位者暴露了出来。然而在太平盛世这些害群之马或可偷鸡摸狗，以权谋私。但是也有许多实干之辈显露出来表现卓越，值得国家栽培委任。 2.对国家和个人的影响从国家角度出发，此次疫情既是机遇也是挑战。 诚然，此次疫情会给国家社会带来较大的经济损失，但是并未伤及根本；相反，我国在本次抗击疫情过程中透明公开进展数据的做法以及制定的一系列防御措施以及最终的防御效果都是值得国际社会称赞的。想必经过此次事件，我国更能树立起一个友好互助负责任的大国形象，和英美之辈形成鲜明对比。但是也有不少国家将这次疫情都怪罪到中国头上，加上媒体的大肆渲染，许多网民或对我国有更多的抵触仇恨情绪。 患难显真情，经过本次疫情，我们也可以看出哪些国家是真正的友邻之邦，哪些国家可以做可靠的朋友，哪些国家表里不一，对中国有明显的敌视偏见。 于个人而言，一方面使得许多人的工作生活受到影响。不小中小企业面临着不小的生存压力，但是对于许多人来说，这确实是一个难得的阖家团圆的好机会。就只能宅在家里，每天家人都能陪伴在一起。比如我，呆在家里两个月，竟然涨了10斤多，脸上和肚子上明显都有肉了。 3.农村是怎么做的在疫情刚开始的时候，我也以为最多只是武汉局部的小规模疫情。等到疫情逐步扩散，并且其人传人的能力十分强悍的时候，我也意识到了此次疫情的严重性。所以经常和家里人说尽量少出去。后来县乡村逐渐也都开始隔离政策，禁止各村之间不必要人员流通。但不得不说的是，其实在农村内部，这种走街串巷的事情还是很难避免。大部分人都无法意识到此次疫情的严重性，尤其是40岁以上的他们基本上没有上过大学，上过高中的也只是少数，由于缺乏科学认识，更多的还是依照他们长久以来建立的一套根深蒂固的思维模式去思考，即没有可怕的事情发生在他们身边周围，他们是不会感到恐惧的，所以不少人还是喜欢串门，聚堆闲聊，带着一种麻木和自信。庆幸的是，由于国家的管控力度比较到位，所以中国的大部分农村省份还是比较安全，许多县市这几个月来一例都没有。 4.从疫情出发谈政治体制与自由民主其实我不应该谈这些比较敏感的事情，但是还是想简单的聊一聊。在强大的病毒面前，那些欧美国家人民所高举的自由民主的大旗非但不能起到抵抗作用，反而某种程度上起到了推波助澜的效果。由于政府对国家各层级的掌控力度实在不够，导致无法指定强有力的隔离政策并在各区域推行实施；同时，许多国家都对这场疫情没有引起足够的重视，认为大肆在China流行的病毒无论如何都不太传播至他们的温柔之邦，何况较早的就已经实施禁止中国人入境的政策了；待疫情小规模在其国内传播时，可能是各媒体没有尽到该尽的责任，一如特朗普总统一般对其不屑一顾，认为该病毒大约只等同于流感，只是中国粗鄙之邦发展中国家人口又多医疗条件又差罢了，其傲慢与偏见之程度更甚于我国个别农村；待政府制定相关政策后，还是有些人认为隔离此举有悖人理，等同监禁，一点也不符合德先生和赛先生的教义。 话说回来，这也不能说明我国的中国共产党领导下的具有中国特色的社会主义体制就优于欧美的资本主义下的各联邦制、民主制、君主立宪制等，只能说一方水土养一方人民，我们只能在更加具体的条件下的事件中，去谈某些相对的优劣。否则脱离实际谈理论，更甚于脱了裤子放屁。 5.从疫情出发谈中国舆论环境或许还是我的采集样本不够客观全面而言，所以这里大多都是自己的一面之词。 以B站为例，我总觉得其中的许多自媒体视频及其相关评论都不太客观，有着比较强烈的政治色彩和很主观偏见的看法。诚然，在我国许多媒体的熏陶之下，许多人都对于那些欧美国家尤其是美国都有着比较强的敌视情绪，大家都口呼特朗普总统建国同志，身负卧底大业，一心只图中华复兴。我认为许多时候类似这种事情做媒体的还是要适可而止，不然会将很多人不同程度的洗脑，形成比较主观的偏见，虽然于国家社会而言，短期来看不见得是坏事；但是于民族振兴、人才培养的角度考虑的话，或许此举并不甚高明。 6.后记以上的内容许多都是浅尝辄止，随意寥寥几句，以后或有补充，或有更改删减。","categories":[{"name":"随念","slug":"随念","permalink":"https://www.iamlightsmile.com/categories/%E9%9A%8F%E5%BF%B5/"}],"tags":[{"name":"随念","slug":"随念","permalink":"https://www.iamlightsmile.com/tags/%E9%9A%8F%E5%BF%B5/"}]},{"title":"找轮子","slug":"找轮子","date":"2020-03-04T02:21:11.000Z","updated":"2020-03-04T02:54:36.244Z","comments":true,"path":"articles/找轮子/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E6%89%BE%E8%BD%AE%E5%AD%90/","excerpt":"最近接触较多的是工程方面的东西。具体来说，之前计划做一个标注系统，后端要基于Python，而GUI选择前端HTML那一套，通过restful接口通信。","text":"最近接触较多的是工程方面的东西。具体来说，之前计划做一个标注系统，后端要基于Python，而GUI选择前端HTML那一套，通过restful接口通信。 关于后端框架，有Tornado、Django、Flask，自己相对更熟悉Flask，所以选择了Flask。关于前端框架，大致主要有Vue和React等，自己更喜欢Vue的那一套风格，于是选择了Vue。在选定Flask+Vue之后，google相关教程，找几个案例学习一下就大致知道具体怎么个流程了。 然而自己觉得当前这种开发效率有些过低，觉得应该是有基于Flask的更符合restful风格的库，而Vue也有更优雅的封装api函数的方式以及业内较多使用的开源组件库，于是通过搜索发现了flask-restful框架，以及Element-UI组件库。后来自己便基于这两个开发了相当简洁的标注框架。目前自己的关注点又到了知识图谱的可视化方面，具体如应该采用什么前端库将图谱的数据展示出来。经过搜索查询，发现了D3.js这个库，可是却发现这个库的api似乎有些过于底层，并不能通过几行代码直接调用比较上层的接口从而实现数据的展示。经过不断地google搜索，终于发现了阿里出品的图可视化框架：antvis/G6: ♾ A Graph Visualization Framework in JavaScript，找到了满意的符合自己需求的轮子。 于是自己有所感，程序员圈经常流行的一句话：“不要重复造轮子”。这句话有其道理，然而这个结论的适应前提有两个：1.有自己造轮子的意愿能力需求 2.有现成的可用的轮子可用。在这两个条件前提都满足时，才能将“不要重复造轮子”作为决策建议。然而有时我们可能不知道有这个轮子，所以由于信息缺失，导致无法做出不重复造轮子的决策，而是自己哼哧哼哧，费心费力，又不能做出比较好的东西。所以这时候就体现出找轮子、知道轮子的重要性了，只有当见多识广，见过接触过更多的轮子之后，我们才能够基于充分的信息做出更加合理的决策，站在巨人前辈的肩膀上，使用他们开发的优秀的工具框架，乘他们的凉。","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}]},{"title":"从工作中学到的","slug":"从工作中学到的","date":"2020-03-03T11:09:46.000Z","updated":"2020-03-03T13:03:17.140Z","comments":true,"path":"articles/从工作中学到的/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E4%BB%8E%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%AD%A6%E5%88%B0%E7%9A%84/","excerpt":"自己在18年6月份从学校毕业后去一家位于北京的初创的自然语言处理小公司工作，然后共计工作了半年时间，其间自己收获甚多，今天又有了新的感触理解，这里小小的总结一下，也算是简单的缅怀一下曾经走过的一段路。","text":"自己在18年6月份从学校毕业后去一家位于北京的初创的自然语言处理小公司工作，然后共计工作了半年时间，其间自己收获甚多，今天又有了新的感触理解，这里小小的总结一下，也算是简单的缅怀一下曾经走过的一段路。 在工作前自己对自然语言处理所理解的十分粗浅，对深度学习和机器学习也只是略懂一点点，算法实现能力也很弱，稍微还算可以的是自己在大学期间也算认真开发过Java和Android项目，所以工程能力和代码阅读能力还算可以。 所以必须要说明的是自己还是非常感谢Boss张总给我这次工作的机会的，当时在学校通过一次远程面试基本谈妥了。然而我最感谢的人还是我的上司曾总，从他这里我学到了不少东西，虽然还是由于自己的无知和缺陷曾给我们组的工作进展带来了不少的麻烦。 自己在上一份工作中十分喜欢的是当时组内相对轻松自由的气氛以及上司和蔼可亲和我们打成一片，经常一块去外面聚餐闲聊。 在工作中也得到了几位前辈的耐心帮助，这也使得自己比较好的度过了适应阶段，学到了非常基础而又十分重要的项目管理、开发工具使用、Linux环境配置等知识。同时自己也认识了好几位非常好的同事，也从他们身上学到了许多有用的知识以及更加关键的做人的道理。 然而自己毕竟底子薄弱，并且很致命的一点是在工作中遇到了困难无法尽快解决卡在那里也不知道尽快找Boss帮忙，所以常常每周的任务都完成的既不好，也不及时。 虽然本人的实习工资很低，但是毕竟能做自己很感兴趣的工作就已经很满足了，所以也算乐在其中，同时自己特别不能忍每天花费较多时间在上下班的路程上，所以尽管租房费用相对较高，但是自己还是找了相对比较近的小区租房。自己也在HR那里淘了一辆二手自行车，同时公司规定超过10点以后报销车费，自己刚开始平时也没啥事，所以就在公司经常加班熬夜，比之前段时间很火的996也不相上下甚至犹有过之。但是客观来说，其实自己并没有感觉有多累，一方面我认为其实大家的开发效率可能并没有那么高，另一方面也并不是时时刻刻都在工作，所以精力耗费并没有那么严重。从其他角度考虑则是自己刚毕业工作，正处于快速学习期，并不像那些工作多年需要养家糊口的要分心在许多事情上，同时自己也没有对象，并没有太多必要的时间精力去耗费。最关键的则是，我认为每天工作多长时间甚至于挣多少对于自己并没有那么关键，更重要的则是能够在其中积累和学习到哪些知识能力，这些知识经验能力才是一个人以后发展的根本保证，这些类似道理自己也曾听某位滴滴平台的打车师傅提起，自己虽然也懂，但是他也是谆谆教诲，自己也挺感激。 我最开始的任务大致是负责一个项目中关键词抽取模块的维护优化工作，大致即不断地寻找bad case，然后根据case总结分析，然后制定相应的规则去过滤和优化结果。最开始我只需要将规则写到固定的地方，并不需要对整个项目有完整的了解，也并不需要认真阅读整个项目的源码。所以自己经常都是朦朦胧胧，一脸懵逼，并且稍微觉得当前的工作和自己之前所期待的不太一样，有点失望。 后来甲方还是觉得效果不够好，同时自己也对项目有了更多的了解，所以又开始对项目进行小规模的重构并且系统地添加更多的规则、以及引入其他的一些评价指标等。在这个过程中自己许多时候都是谨小慎微的探索尝试，对于工程的实践能力有了可见的提升然而进展缓慢。 然而关键词抽取效果还是未能让甲方满意，于是公司安排另一名也负责相关任务的同事来协助我推进项目的快速推进，在他的建议和要求之下我们一起整个模块进行了完整的重构，其中我负责大部分内容，不少代码重写，同时也引入了新的内容，自己在这个过程中工程实践能力得到了显著的提高。 同时自己也参与到一个知识图谱项目中，最开始负责实体识别的优化工作，然而由于个人原因出现较大纰漏，后来转而负责实体链接的相关工作。在这个过程中，自己经常和本组其他同事交流探讨，同时申请其他组提供帮助，以及联系了好几家标注公司洽谈数据标注的工作，自己的各方面能力都有了不小的提升，同时自己逐渐地积累起了初步的将算法模块化、写成库的意识和能力。 后来由于平时较忙，同时自己对许多自然语言处理任务理解的还是不够，又希望能够在这个领域深造有所成就，后来就有了辞职考研的念头并最终执行。 现在回想起来自己在短短半年的工作中学到的不算多，但也不算少，和刚去公司相比，无论是对任务项目的理解，还是算法工程实践能力都有了很大的提升。其中，我感触特别深、认为相当重要的一点是“小步快跑，快速迭代”的工程理念，从小了说这是一个更加科学的项目开发模式，从大了说这是更加合理的做人做事的原则方法。 因为原来的自己总是希望力求完美，凡事多求万事俱备之后才有所行动，这种认知观念曾经给我的学习工作生活带来了很大的困扰，现在回想起来，当时许多错误的决策的根源都是这种思维。 后来在开发的lightNLP以及其他项目框架的背后都有“小步快跑，快速迭代”的深刻思想，个人受益很多。 关于“小步快跑，快速迭代”的介绍，简书上有篇文章：“小步快跑、快速迭代” 可用于工作的好方法 - 简书。 这篇随念就先写到这里，以后啥时候有想写的再补充。","categories":[{"name":"随念","slug":"随念","permalink":"https://www.iamlightsmile.com/categories/%E9%9A%8F%E5%BF%B5/"}],"tags":[{"name":"工程思想","slug":"工程思想","permalink":"https://www.iamlightsmile.com/tags/%E5%B7%A5%E7%A8%8B%E6%80%9D%E6%83%B3/"}]},{"title":"浅谈中文分词与自然语言处理","slug":"浅谈中文分词与自然语言处理","date":"2020-02-03T02:17:49.000Z","updated":"2020-02-06T05:04:26.823Z","comments":true,"path":"articles/浅谈中文分词与自然语言处理/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E6%B5%85%E8%B0%88%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/","excerpt":"最近出于兴趣和需要，重新回顾中文分词技术，期间有些心得，以及一些关于自然语言处理的浅薄之见，这里简单分享一下。","text":"最近出于兴趣和需要，重新回顾中文分词技术，期间有些心得，以及一些关于自然语言处理的浅薄之见，这里简单分享一下。 首先，中文分词_百度百科里面简单介绍了其中主要的分词算法以及相应的优缺点，包括字符匹配法、统计法以及理解法，其中字符匹配法和统计法比较流行且可以取到相对不错的效果，而理解法则相对比较复杂高级，但是我认为这才是真正解决中文分词任务的根本算法。 如今用于中文分词的算法和模型虽算不上比比皆是，但也算是唾手可得，开源的如jieba、ltp、Hanlp等等，提供中文分词服务的如腾讯云、百度大脑、讯飞AI平台等，以及其他如Jiagu等。 其实这些平台算法的差距并不算太大，分词准确率基本上都是在80%以上，然而在98%以下（这里胡诌个数），在一些不太严格的应用场景下基本已经够用了，只要挑一个在自己的业务场景下表现最好的即可。 在我看来，对于中文分词这项任务而言，最关键最核心的其实并不是算法模型，这些都不是所谓的瓶颈，最重要的其实是高质量、大规模的词典。对于字符匹配法而言，词典是基础，没有词典自然连分都分不出来；对于统计学习法而言，其效果一方面取决于算法和模型的选择，一方面取决于其训练数据的数量与质量，需要堆人力物力，比如找专门的标注公司标注数据等。但是就算是人标的数据，也难免有所错误遗漏，所以在有错误的训练数据下，模型也不可能学的太好，同时训练数据再大，也难以覆盖全部语料，总会出现OOV，总有些句子会训练不到，此时还强求模型可以做到“举一反三”有些不切实际。 词条中还提到了关于中文分词的技术难点：歧义识别与新词识别，关于歧义识别，上面并没有提具体的解决思路，对于新词识别而言，这又是自然语言处理领域很基础并且很重要的点，可以参见一下我之前的文章：《NLP基础任务之新词发现探索之路》 | lightsmile’s Blog，也有另一个思路，比如说爬取网上一些网站的相关条目，比如百度百科等。 简单看了一下jieba、ansj_seg、Jiagu的分词词典，发现其中jieba的词典质量最差，其中不少词性都是错误的，Jiagu的词典还算不错，就是一些新词不全，ansi_seg的没有细看。 尽管这些工具在一些评测数据的结果可以达到90以上的成绩，但是在我看来，还是不够的，我觉得中文分词这个基础而又艰巨的任务还是要到99%以上才可以，否则分词都分不对，那些在分词基础之上的任务更是不行，毕竟词是基本的语义单元。 然而在现在深度学习盛行的潮流下，许多任务如文本分类、命名实体识别等并不一定需要依赖于分词，直接基于字符（char）的Embedding也可以取得不错的效果，并且也可以规避OOV（out of vocabulary words，未登录词）的问题。 但是深度学习，尤其是监督学习的很关键之处是得有大规模的高质量训练数据，不然巧妇难为无米之炊，再好的模型也难以从垃圾中学到有用的知识。 话说回来，虽然自然语言处理是计算机科学与其他领域的交叉学科，深度学习、机器学习算是人工智能的一部分，然而许多时候往往十分依赖人工，而所谓的智能其实也不智能。 无论是计算机视觉领域里的图像分类还是自然语言处理领域的文本分类，其任务都是学习一个从输入$x$映射到输出或者说标签$y$的函数$f$，具体来说就是将$x$表征为多维向量$X$，将$y$表征为多维向量$Y$，然后让$X$进入一个模型进行一系列的运算后得到一个$Y^{‘}$，通过不断地比较$Y^{‘}$和$Y$的值并调整模型的参数使模型的运算结果$Y^{‘}$更为准确即更加贴近$Y$（过程有点类似于“猜数字”游戏），从而最终得到一个近似函数$f{‘}$，我们就可以用来代替未知的$f$用于预测未来的样本$x$，得到它对应的$y$。 我们可以发现，以上学习算法确实可以得到能够解决问题的模型，然而局限之处在于它也只能做这个任务，即对输入$x$预测$y$，别的啥也干不了。 同时在基于深度学习的自然语言处理模型中，基本套路都是Embedding+Encoder+Decoder，其中Embedding是基于字还是基于词，是使用预训练词向量还是随机初始化，这些选择所导致的效果的差异都随着训练轮数的增加而最终减小。然而，由于梯度下降以及解空间的特点，基于bert的效果确实是要比Word2Vec的要好，那些词向量确实比Word2Vec的嵌入了（或者说学到了）更多的语言知识。 关于模型的选择和取舍，工业界和学术界的标准其实差别很大。学术界里有的论文是开创性的，而许多论文其实都是在原来基础上小修小改，将最近的较新的思想和算法一堆，实验结果比原来指标高一点又是一篇文章，程序运行占用多大内存、跑了多长时间这些都不是主要因素，也就是一切向指标看齐。 而工业界则更加看重的是性价比，不同的公司、不同的部门、不同的阶段其主要矛盾不同。比如说Facebook之前出的fastText，尽管模型很简单，最终效果可能比不上一些其他复杂的模型，但是其训练速度超快、基于CPU就可以，并且可以很方便地对模型进行压缩。许多时候，一些指标高低差几个点并没有那么关键，模型大小、训练时间、预测时间在很多时候是比较关键的因素，除非由于甲方或客户不满意，或者家大业大，有的是资源，那么这时候效果和指标又成为主要矛盾，这时的优化可能要以一定的时间和空间为代价。 原来的自然语言处理各任务基本上都构建在分词的基础之上，粗略来说有一个语法、语义到语用的递进的过程。这一层一层的任务虽然耦合的很好，但是这种Pipline将会导致下层的错误都将会被积累到上层，其直接影响就是越到上层其准确率越低，甚至低到惨不忍睹的程度。然而在表示学习，尤其是深度学习崛起以后，其强大的特征学习能力，使得现在的模型多为end-to-end模型，其结果是一方面可以使得相关人员摆脱繁琐的特征工程，可以将特征提取与组合设计的工作交给神经网络模型去隐形完成，大大解放了生产力；令一方面可以将模型视为整体的一部分，即它的输入直接对应原始输入，它的输出直接是我们想要的结果，有点直达病灶的意思，摆脱了原来Pipline错误累积的困境。 不过我个人看来成也end-to-end，败也end-to-end，虽然简化了任务，但是有点太过开门见山，得到的模型一个个都是彼此孤立的，各做各的事情，然而从整体论的角度来看它们都是整个自然语言处理系统的一部分，一些特征本来是可以共享，一些结果是彼此相互依赖的。这也又涉及到参数共享、多任务学习等概念，不细表。由于神经网络的可解释性较差，这使得模型更加像一个黑盒，训练调参的过程更像是在炼丹，因为谁也不知道具体能炼出个什么玩意儿。 如下图很形象地诠释了这一现状： 下面就深度学习下的自然语言处理四大任务进行简单对比（都是个人浅薄之见，难免有不足之处，还望海涵）。自然语言处理四大任务分别是：序列标注、文本分类、句子关系、文本生成。 序列标注序列标注任务的原始语料是一连串的句子，经过标注后的语料格式大概如下（以命名实体识别为例）： 清 B_Time 明 I_Time 是 O 人 B_Person 们 I_Person 祭 O 扫 O 先 B_Person 人 I_Person ， O 怀 O 念 O 追 O 思 O 的 O 日 B_Time 子 I_Time 。 O 我们可以发现，每一行的格式都是一个字符以及它所对应的类别，如B_{type}、O，那么对于每一个字符模型需要预测的类别数量总计为2*len(types) + 1，其中2是指BI这种标注规范，len(types)指类型种类的数量（如人名、地名、机构名共三种），1是指O。可以发现模型需要拟合的函数的值域还是很小的，即O(len(types))。 文本分类文本分类任务的标注语料格式大概如下（以情感极性分析为例）： label text 0 0 备胎是硬伤！ 1 0 要说不满意的话，那就是动力了，1.5自然吸气发动机对这款车有种小马拉大车的感觉。如今天气这么热，上路肯定得开空调，开了后动力明显感觉有些不给力不过空调制冷效果还是不错的。 2 0 油耗显示13升还多一点，希望慢慢下降。没有倒车雷达真可恨 3 0 空调不太凉，应该是小问题。 4 0 1、后排座椅不能平放；2、科技感不强，还不如百万帝豪，最希望增加车联网的车机。像你好博越一样。3、全景摄像头不清楚，晚上基本上用处不大 5 1 车子外观好看，车内空间大。 6 1 最满意的真的不只一点，概括一下最满意的就是性价比了。ps:虽然没有s7性价比高(原厂记录仪,绿净) 7 0 底盘调教的很低，坐的感觉有些别扭，视角不是很好。 8 0 开空调时，一档起步动力不足。车子做工有点马虎。 每一行的格式都包含原始文本以及它所对应的类别（或者说标签），我们可以发现模型需要预测的类别数量总计为len(types)，即类型种类的数量（以新闻语料分类，如娱乐、军事、科技、体育等），可以发现模型需要拟合的函数的值域也是较小的，即O(len(types))。 句子关系句子关系任务的标注语料格式大致如下（以语句相似度为例）： 1 怎么更改花呗手机号码 我的花呗是以前的手机号码，怎么更改成现在的支付宝的号码手机号 1 2 也开不了花呗，就这样了？完事了 真的嘛？就是花呗付款 0 3 花呗冻结以后还能开通吗 我的条件可以开通花呗借款吗 0 4 如何得知关闭借呗 想永久关闭借呗 0 5 花呗扫码付钱 二维码扫描可以用花呗吗 0 6 花呗逾期后不能分期吗 我这个 逾期后还完了 最低还款 后 能分期吗 0 7 花呗分期清空 花呗分期查询 0 8 借呗逾期短信通知 如何购买花呗短信通知 0 9 借呗即将到期要还的账单还能分期吗 借呗要分期还，是吗 0 10 花呗为什么不能支付手机交易 花呗透支了为什么不可以继续用了 0 每一行都是两个句子以及它们的关系（1代表语义相同，0代表语义不同），我们可以发现模型需要预测的类别数量总计为len(relations)，即关系种类的数量，可以发现模型需要拟合的函数的值域也是较小的，即O(len(relations))。 文本生成文本生成任务的标注语料格式大致如下(以机器翻译为例）： Hi. 嗨。 Hi. 你好。 Run. 你用跑的。 Wait! 等等！ Hello! 你好。 I try. 让我来。 I won! 我赢了。 Oh no! 不会吧。 Cheers! 干杯! He ran. 他跑了。 我们可以发现每一行都是源语言句子以及目标语言的对应翻译。虽然此时模型和序列标注模型一样都需要对于单个样本预测多次，但是序列标注模型需要预测的次数直接等于字符的数量，是确定的，但是文本生成任务模型需要预测的次数是不确定的，并且每次预测的值域都是目标语言所有word（或者character）所组成的整体集合，即O(len(words))，其规模可能是十万级或百万级的。因此我们很容易发现文本生成任务的难度和复杂程度是要远远高于其他任务的。对话任务如生成式闲聊机器人更是如此。 可能是之前的AlphaGo过于吸引广大群众的眼球，做相关业务的公司吹的太厉害，以及“人工智能”、“深度学习”这几个词听起来逼格满满，导致许多外行人认为现在的人工智能已经发展到很厉害的层次，并且可以做各种各样的事情，似乎无所不能。但是内行人心里却明白：“什么人工智能，人工智障吧”、“所谓人工智能，多是智能不够，人工来凑”。外行人看不到深度模型算法的局限性，如许多模型的精度并不能达到那么高；也看不到深度模型算法的前提条件，如高质量、大规模的数据集，他们以为模型大约聪明到随便喂点数据便成为终结者般的存在。这也就导致了他们刚开始预期很高，然而在投资或找到外包后发现效果远远不能达到预期，大失所望而潦草结束或撤资离场的局面。 如下一张图大概有点这个意思： 统观学术界与工业界，和计算机视觉领域相比，自然语言处理这种更深层次的、涉及到认知智能的领域的进展虽悠久但缓慢，并且许多任务目前为止距离真正商用还有很大的距离。然而正是科学史上如阿基米德、牛顿等伟大人物与其他相对无名之辈默默耕耘，前赴后继，才使得如今之人类齐享先辈之成果，即所谓“前人栽树后人乘凉”也。 我辈也无需悲观，须戒骄戒躁，搞算法的就多己见、少盲从，少水论文；搞工程的就多积累经验，提升实践能力，多做高质量的项目。功夫不负有心人。","categories":[{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/tags/NLP/"}]},{"title":"《论文解读-Never-Ending Learning》","slug":"《论文解读-Never-Ending-Learning》","date":"2020-01-31T10:21:49.000Z","updated":"2020-05-01T08:55:46.984Z","comments":true,"path":"articles/《论文解读-Never-Ending-Learning》/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E3%80%8A%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-Never-Ending-Learning%E3%80%8B/","excerpt":"当前自己仅是简单翻译一下。 0. 论文出处1. 概要虽然人们多年来从不同的经验中学习了许多不同类型的知识，但是大多数当前的机器学习系统仅仅从一个数据集中获得一个函数或数据模型。 我们为机器学习提出了一个永不停歇的学习范式，以更好地反映由人类执行的更有雄心和更广泛的学习类型。 作为一个案例研究，我们描述了永不停息的语言学习者(NELL)，它实现了永不停息的学习者所期望的一些特性，我们讨论了所学到的教训。 NELL从2010年1月开始每天24小时学习网络阅读，到目前为止，它已经掌握了8000多万个信心加权信念(例如，随茶、饼干)的知识库。 NELL还学会了数百万的特性和参数，使它能够从网上阅读这些信念。 此外，它还学会了对这些信念进行推理以推断出新的信念，并能够通过综合新的关系谓词来扩展其本体。 可以通过 http://rtw.ml.cmu.edu 在线跟踪NELL，也可以通过@CMUNELL在Twitter上跟踪它。","text":"当前自己仅是简单翻译一下。 0. 论文出处1. 概要虽然人们多年来从不同的经验中学习了许多不同类型的知识，但是大多数当前的机器学习系统仅仅从一个数据集中获得一个函数或数据模型。 我们为机器学习提出了一个永不停歇的学习范式，以更好地反映由人类执行的更有雄心和更广泛的学习类型。 作为一个案例研究，我们描述了永不停息的语言学习者(NELL)，它实现了永不停息的学习者所期望的一些特性，我们讨论了所学到的教训。 NELL从2010年1月开始每天24小时学习网络阅读，到目前为止，它已经掌握了8000多万个信心加权信念(例如，随茶、饼干)的知识库。 NELL还学会了数百万的特性和参数，使它能够从网上阅读这些信念。 此外，它还学会了对这些信念进行推理以推断出新的信念，并能够通过综合新的关系谓词来扩展其本体。 可以通过 http://rtw.ml.cmu.edu 在线跟踪NELL，也可以通过@CMUNELL在Twitter上跟踪它。 2. 引言机器学习是人工智能的一个非常成功的分支，机器学习软件现在被广泛应用于从垃圾邮件过滤、语音识别、信用卡欺诈检测到人脸识别的任务中。 尽管取得了这样的成功，但与人类学习相比，今天计算机学习的方式仍然出奇地狭隘。 本文探索了一种新的机器学习范式，它更紧密地模拟了人类学习的多样性、能力和累积性。我们称这种替代范式为无止境的学习（never-ending learning）。 为了说明这一点，请注意，在上面的每个示例中，计算机只学习单个函数来独立执行单个任务，通常是从该函数的输入和输出的人工标记的训练示例中学习。例如，在垃圾邮件过滤中，训练示例包括特定的电子邮件和每个邮件的垃圾邮件或非垃圾邮件标签。 这种学习方式通常被称为监督函数逼近，因为抽象的学习问题是逼近某个未知函数f : X → Y(例如，垃圾邮件过滤器)，给定该函数的输入/输出对{}。 其他的机器学习范例也存在(例如，无监督聚类、主题建模)，但是这些范例通常也只从单个数据集获取单个函数或数据模型。 与这些在短时间内从组织良好的数据集中学习单个函数的范例不同，人类学习许多不同的函数(例如，多年来积累了丰富的经验，使用广泛的背景知识从早期的经验中学习来指导后续的学习。 这篇论文的主题是，我们永远不会真正理解机器或人类的学习，除非我们可以建立一个计算机程序，向人类那样： 学习许多不同类型的知识或功能 从多年的多样化，大多是自我监督的经验 在一种分阶段的课程模式中，以前学到的知识使我们能够学习更多类型的知识， 自我反省和形成新的表现形式和新的学习任务的能力使学习者避免遇到学习瓶颈并停滞不前。 我们把这种学习模式称为“永无止境的学习”。这篇论文的贡献在于: 更精确地定义了永无止境的学习范式 以一个名为“永不停息的语言学习者”(NELL)的计算机程序为例，该程序实现了其中的一些功能，并且在四年多的时间里每天24小时地学习阅读web 识别来自NELL的长处和短处许多关键的设计特点对任何永无止境的学习系统都很重要 3. 相关工作略 4. Never-Ending Learning非正式地说，我们将一个永不停息的学习主体定义为一个系统，它像人类一样，从多年多样的、主要是自我监督的经验中学习多种类型的知识，使用先前学习的知识来改进随后的学习，并进行充分的自我反思，以避免学习时的表现停滞不前。代理所面临的永无止境的学习问题包括一组学习任务，以及将它们的解决方案耦合在一起的约束。 5. never-ending learning problem形式化定义 其中： 表示一个never-ending learning problem 表示学习任务的集合，即，其中表示给定的表现性评价任务，表示性能度量，表示特定类型的经验 表示上述学习任务的解决方案之间的耦合约束所组成的集合，即，其中是两个或多个学习任务上的实值函数，表示约束的满足程度，是学习任务上的一个指数向量，指定的参数。 的具体含义是定义要学习的函数即的域和范围上的值所组成的对，即 的具体含义是，即定义了对于第i个学习任务的最优学习函数：，其中表示从到所有可能函数的集合。 具体示例：略 6. Never-Ending Learning的定义 学习许多不同类型的知识；也就是说，包含了许多的学习任务 从多年的多样化，大多是自我监督的经验；也就是说，学习所基于的经验实际上是多种多样的，而且大部分是由系统本身提供的 在一种分阶段的课程模式中，以前学到的知识使我们能够学习更多类型的知识；也就是说，不同的学习任务不需要同时解决-解决一个有助于解决下一个 自我反省和形成新的表现形式和新的学习任务的能力使学习者避免遇到学习瓶颈并停滞不前；也就是说，学习者自身可能会添加新的学习任务和新的耦合约束来帮助解决给定的学习问题。 7. NELL的输入-输出规范初始输入： 一个定义了类别(例如，体育，运动员)和二元关系(例如，AthletePlaysSport(x,y))的初始本体 每个类别和关系大约有12个标记的训练示例(例如，运动的示例可能包括名词短语棒球和足球) 网络(最初的5亿个网页来自ClueWeb 2009集合(Callan和Hoy 2009)，每天访问100,000个谷歌API搜索查询) 偶尔与人交互(例如，通过NELL的公共网站http://rtw.ml.cmu.edu) NELL每天24小时不间断地做： 阅读(从网上提取)更多的信念，并删除旧的错误信念，以填充一个不断增长的知识库，其中包含每个信念的置信度和出处 学会比前一天读得更好 NELL从2010年1月开始，每天从网络中提取更多的信念，然后重新训练自己以提高自己的能力。到目前为止，结果是一个拥有超过8000万个相互关联的信念的知识库(参见下图)，连同数以百万计的已学过的短语、形态特征和网页结构，NELL现在用来从网络中提取信念。NELL现在也正在学习对它所提取的知识进行推理，以推断出它还没有读过的新信念，并且它现在能够对它最初手工提供的本体提出扩展。 8. NELL的学习任务NELL将学习超过2500个不同的学习任务，其中每个任务都有其对应的，具体来说NELL将对学习到对应的映射函数：。这些学习任务大致可以分为以下几个大类： 类别分类：根据语义类别对名词短语进行分类的函数(例如，一个用于对给定的名词短语是否与食物相关进行分类的布尔值函数)。NELL在其本体中为280个类别中的每个类别学习不同的布尔函数，允许名词短语指代多个语义类别中的实体(例如，apple既可以指代食品，也可以指代公司)。根据名词短语的五种不同视角(五种不同的Xi)，NELL对每个类别学习了多达五种不同的预测Yi的功能，分别是： 名词短语的特征(例如，名词短语是否以字符串“…自治市”结尾)。这是由CML系统(Carlson et al. 2010b)执行的，它通过具有数千个字符串特征的向量表示名词短语。 在2009年ClueWeb2009文本语料库(Callan and Hoy 2009)的5亿个英语网页中，这个名词短语周围的文本上下文分布情况(例如，名词短语N在“N的市长”的上下文中出现的频率)。这是由CPL系统执行的(Carlson et al. 2010b)。 通过主动的网络搜索，在这个名词短语周围发现的文本上下文分布。这是由OpenEval系统(Samadi、Veloso和Blum 2013)执行的，它使用与上述CPL系统稍微不同的上下文特性，并使用实时web搜索来收集这些信息。 包含名词短语的网页的HTML结构(例如，名词短语是否出现在HTML列表中，与其他已知的城市一起)。这是由SEAL系统完成的(Wang和Cohen 2007)。 当名词短语被提供给图像搜索引擎时，与该名词短语相关的视觉图像。这是由NEIL系统(Chen, Shrivastava, and Gupta 2013)执行的，并且只适用于NELL的本体类别的子集(例如，不适用于音乐类型)。 关系分类：根据名词短语对对它们是否满足给定的关系进行分类的函数(例如，将这对名词短语&lt;“Pittsburgh”,”U.S.”&gt;是否满足“CityLocatedInCountry(x,y)”关系进行分类)。NELL在其本体论中为327个关系中的每个关系学习不同的布尔值分类函数。对于每个关系，NELL根据输入名词短语对的不同特征视图学习三个不同的分类函数。具体来说，它使用了两种分类方法:CPL和OpenEval，这两种方法是根据网页上两个名词短语之间的文本上下文分布情况来进行分类;它使用了基于网页HTML结构的SEAL分类方法。 实体解析：根据名词短语对是否为同义词(例如，NYC和Big Apple是否可以指同一个实体)对其进行分类的函数。这种分类方法在(Krishnamurthy和Mitchell 2011)中有描述。对于NELL的280个类别中的每一个，它联合训练两个同义词分类器:一个基于两个名词短语之间的字符串相似性，另一个基于它们提取的信念的相似性。 信念三元组之间的推理规则：将NELL的当前知识库映射到应该添加到其知识库中的新信念的函数。对于NELL’s本体中的每个关系，其对应的功能由PRA系统学习到的限制性Horn子句规则集合表示(Lao, Mitchell, and Cohen 2011;Gardner等，2014)。 上面的每个函数表示一个NELL中的性能任务，每个函数映射到获取该函数的学习任务，给定某种类型的经验和在学习期间要优化的性能度量。 在所有情况下,只有一个除外,经验的组成： 人工标注训练的例子(NELL本体中每个实体和关系都有十几个标记示例,以及通过NELL网站贡献了一段时间的标注实例) 一组对应NELL当前的知识库的NELL自标记训练例子 大量未标记的web文本。 唯一的例外是通过视觉图像学习，这是由NEIL系统通过它自己的训练程序来处理的。 NELL的耦合约束NELL的永无止境的学习任务的第二个组成部分是连接其学习任务的耦合约束集。NELL的耦合约束分为五组： 多视角的协同训练的耦合。NELL的对名词短语进行类别分类(以及对名词短语进行关系分类)的多个方法提供了一个自然的协同训练的机制 (Blum and Mitchell 1998), 其中属于同一类别的可替换的众多分类器应该在给定同一输入的预测结果一致，尽管它们的预测基于不同的名词短语特征。 子集/超集耦合。当一个新的类别被添加到NELL的本体论时，它的直接父类(超集)是明确的(例如，饮料被声明为食物的子集)。当类别C1作为类别C2的一个子集添加时，NELL使用耦合约束。这将学习预测C1的任务和学习预测C2的任务结合起来。 多标签互斥耦合。当类别C被添加到NELL的本体论中时，已知与类别C不相交(相互排斥)的类别也是明确的(例如，饮料被声明为与情感、城市等相互排斥)。这些互斥约束通常继承自更一般的类，但是可以由显式断言覆盖。当类别C1被声明为与C2互斥时，NELL采用约束。 将关系耦合到它们的参数类型。当一个关系被添加到NELL的本体时，编辑者必须指定它的参数的类型(例如，zooInCity(x,y)分别需要Zoo和City类型的参数)。NELL使用这些参数类型声明作为其类别和关系分类器之间的耦合约束。 Horn子句耦合。每当NELL学习一个Horn子句规则，从现有的信念中推断出新的知识库信念时，该规则作为一个耦合约束来增强NELL的永不结束学习问题。例如，当NELL学习具有概率p的形式的规则时，该规则作为一个新的概率耦合约束作用于学习关系R1、R2和R3的函数。每个习得的Horn子句都要求从名词短语对映射到R1、R2和R3关系标签的习得函数与此Horn子句一致;因此，它们类似于NELL的子集/超集耦合约束，它要求从名词短语到类别标签的映射函数应该与子集/超集约束一致。NELL’s never ending learning problem包含超过2500个学习任务，相互关联的耦合约束超过100万个。事实上，NELL的永无止境的学习问题是开放的，因为NELL有能力以习得的Horn子句(如上所述)的形式添加新的一致性约束和新的学习任务，为其本体发明新的谓词(如下所述)。 9 NELL的软件体系结构 NELL的增长知识库(KB)作为一个共享的黑板，通过它的各种阅读和推理模块相互作用。NELL的学习周期使用当前的知识库迭代地重新训练这些软件模块，然后使用这些改进的模块更新知识库。 10 NELL的学习方法和架构NELL的软件架构，如上图所示，包括一个知识库(KB)，它充当一个黑板，通过它NELL的各种学习和推理模块进行通信。如图所示，这些软件模块与前一节中提到的不同类型函数的学习方法(CPL、CML、SEAL、OpenEval、PRA、NEIL)紧密映射，使得NELL的各种学习任务在这些模块之间进行了划分。 NELL的学习是对EM的一种近似NELL处于一个无限循环中，类似于EM算法的半监督学习，在每次迭代中执行类似于m的步骤。在类似的步骤中，每个读取和推断模块都建议对知识库进行更新(添加和删除特定的信念，以及特定的信任和来源信息)。知识整合器(KI)既记录这些单独的建议，又对知识库中分配给每个潜在信念的置信度做出最终决定。然后，在类似m的步骤中，使用特定于模块的学习算法，使用这个精练的知识库对每个软件模块进行再培训。其结果是一个大规模的耦合培训系统，其中数千个学习任务通过共享知识库和耦合约束由彼此的结果引导。 注意！对于NELL系统而言，一个完整的EM算法是不切实际的。NELL经常考虑数千万个名词短语，在名词短语对中产生了$10^{17}$个潜在的关系断言。在每一个类似E的步骤上估计每一个潜在断言的概率是不切实际的。相反，NELL只构造和考虑它最确信的信念，限制每个软件模块仅为任何给定迭代上的任何给定谓词建议有限数量的新候选信念。这使得NELL能够灵活地操作，同时保留在多次迭代中添加数百万个新信念的能力。 NELL中的知识集成器知识集成器(KI)集成知识库更新的传入建议。为了提高效率，KI只考虑适度的信心候选信念，并使用一致性约束和信念的完整图的有限子图重新评估信心。例如，KI考虑当前知识库中的所有信念，以确保新的关系断言满足参数类型，但不考虑在相同的迭代中对这些参数类型的信念进行可能的更新。 在多次迭代中，约束的影响通过信念和约束的图更广泛地传播。最近(Pujara et al. 2013)证明了一种更有效的算法来解决KI所面临的联合推理问题;我们现在正在升级NELL的KI来使用这个实现。 在NELL中添加学习任务和本体扩展NELL有能力通过使用OntExt系统发明新的关系谓词来扩展其本体(Mohamed, Hruschka Jr.和Mitchell 2011)。OntExt考虑了NELL当前本体论中的每一对范畴，以寻找经常讨论的范畴范畴之间关系的证据。 提取提及两个类别的已知实例的句子（例如：对于类别对&lt;药物，疾病&gt;而言，如果百忧解和偏头痛已经在在NELL当前的知识库中，那么句子百忧解可能导致偏头痛可能被抽取出来 从提取的句子中，通过上下文共现矩阵建立上下文，然后将相关的上下文聚在一起。每个集群对应于两个输入类别实例之间可能的新关系。 在允许新的关系(例如，DrugHasSideEffect(x,y))被添加到NELL的本体之前，使用一个经过训练的分类器，并进行最后阶段的人工筛选。 OntExt为NELL的本体增加了62个新的关系。注意，每个新关系都会衍生出相关的新学习任务，包括三个新任务:学习如何分类哪些名词短语对满足该关系(基于名词短语对的不同观点)，以及一个学习Horn子句规则的任务，以从其他关系中推断出该新关系。 11 实证性评估我们对NELL进行实验评估的主要目标是了解NELL在阅读能力、知识库大小和质量方面随着时间的推移在多大程度上得到了提高。 首先，考虑NELL的KB随时间的增长，从2010年1月开始到2014年11月，NELL已经完成了886次迭代。 NELL的KB很明显在增长，尽管它的高自信信念比它的全部信念增长得更慢。还要注意，在最近的迭代中，高度自信信念的增长有所减少。 这部分是由于NELL已经在他的本体论中渗透了一些范畴和关系。例如，对于类别Country，它在前几百次迭代中提取了大多数实际的国家名称。 第二，考虑NELL阅读能力的准确性。为了评估这一点，我们应用了NELL在其历史上不同迭代中获得的不同版本，从一组固定的文本数据中提取信念，这些文本数据包括2009年ClueWeb2009语料库中的5亿个英语网页，以及截至2014年11月14日的万维网。 然后我们手动评估这些不同历史版本的NELL所提取的信念的准确性，以NELL内尔的阅读能力的发展。为了获得随时间变化的不同版本的NELL，我们依赖于这样一个事实，即NELL在任何给定时间的状态完全由其KB决定。 特别地，在第i次迭代中，对于给定的NELL的KB，我们首先让NELL在KB加上未标记的文本上训练自己，然后让它将其训练过的方法应用到一组固定的未标记的web文本上，从而提出一组排序排序的信心加权信念。我们评估了这些信念的准确性，以衡量NELL在不同的时间点演变的能力。 12 NELL的可优化之处 向NELL添加一个自我反省功能，使它能够检测在什么地方做得好，在什么地方做得不好，什么时候它已经充分地填充了任何给定的类别或关系，使它能够以一种更有针对性的方式分配其工作 扩展NELL用于提取信念的数据范围，例如通过包括英语、图像数据和Twitter之外的语言 通过更多地依赖于发明新的关系和类别的自动化算法，以及将其他开源本体(如DBpedia)合并到NELL的本体来极大地扩展NELL的本体 将新一代的微型阅读方法（可以对单个句子和文本段落进行深度语义分析的方法）添加到NELL中，因此不需要依赖网络冗余来实现准确阅读。 我们目前正在积极探索这些方向。 13 可以从NELL学到的NELL是一个学习代理，它演示了一些我们认为对任何永无止境的学习系统都很重要的特性，尽管它也有局限性。根据我们与NELL的经验，我们为任何永无止境的学习系统推荐了四个有用的设计特性： 为了实现成功的半监督学习，需要结合许多不同学习任务的训练:NELL成功地从少量的监督中学习了数千种功能的主要原因是，它被设计成同时学习数千种不同的功能，这些功能被大量的耦合约束紧密地连接在一起。当其中一个学习任务开始取得进展时，耦合约束允许所学习的信息约束其他任务的后续学习。 允许代理学习额外的耦合约束:由于耦合对许多函数的训练至关重要，通过自动学习额外的耦合约束可以获得很大的收益。在NELL中，这是通过数据挖掘NELL的KB来学习限制形式的概率性Horn子句来实现的。NELL已经学会了成千上万个概率性的Horn子句，它用这些子句来推断它还没有读过的新的KB信念。作为创造新的信念的一个副作用，这些新的信念后来被用来重新训练NELL的阅读功能，这些Horn子句也作为耦合约束来进一步约束和指导NELL的阅读功能的后续学习。 学习新的表示方法，它涵盖了初始表示之外的相关现象:为了不断改进，并避免在性能上达到稳定状态，一个永不停止的学习系统可能需要将其表示扩展到最初提供的之外。NELL有一种原始但已经有用的能力来扩展它的表示，方法是在现有类别(例如，river,city)之间提出新的关系谓词(例如，RiverFlowsThroughCity(x,y))。NELL所引入的每一种新关系都会导致新的学习任务，如学习从文本中提取这种关系，以及学习从其他信念中推断这种关系的实例。 将一系列的学习任务组织成一门容易却越来越难的课程:给定一组复杂的学习任务，通常会出现这样的情况:有些学习任务比较容易，有些则为其他任务提供了必要的知识。在NELL中，随着时间的推移，我们通过手动引入新的学习任务类型来改进系统。在NELL的头六个月里，它唯一的任务就是把名词短语分成不同的类别，把名词短语对分成不同的关系。后来，一旦它在这些方面达到了某种程度的能力，并相应地增加了它的知识库，它就可以面对更具挑战性的任务。至此，我们介绍了对知识库进行数据挖掘以发现有用的Horn子句规则的任务，以及基于NELL的类别实例知识发现新的关系谓词的任务。一个关键的开放研究问题是学习主体本身如何形成一个有用的学习任务课程。 NELL的一些限制 自我反省和明确的学习目标。目前，NELL在监督自身表现和进步方面的能力非常薄弱。例如，它没有注意到它在过去一年中没有学到任何有用的国家类别的新成员，它继续研究这个问题，尽管它在这方面的知识已经饱和。此外，它没有尝试将其学习努力分配给那些特别有生产力的任务(例如，收集新的web文本来描述那些它只有低信心信念的实体)。很明显，开发一种自我反省的能力来监控和估计自己的准确性，并根据感知到的需求计划具体的学习行动，将允许系统更有效地使用其计算工作。 普遍的可塑性。虽然NELL能够通过学习改变许多方面的行为，但它的其他部分的行为是固定不变的。例如NELL检测名词短语的方法是一个固定的程序，不开放的学习。在设计不断学习的代理时，重要的是理解如何构建代理，使其尽可能多的行为是可塑的，是可以学习的。否则，代理将面临性能停滞不前的风险，在这种情况下，进一步的改进需要对系统中本身无法修改的部分进行修改。 表示和推理。目前，NELL使用一种简单的基于框架的知识表示，并通过PRA推理系统进行扩展，该推理系统基于受限的Horn子句执行可处理但有限类型的推理。NELL的能力已经受到限制，部分原因是它缺乏更强大的推理组件:目前缺乏表示和推理时间和空间的方法。因此，表征和可处理推理的核心AI问题也是不断学习的代理的核心研究问题。 关于never-ending learning的一些重要的的概念和理论问题 一致性和正确性之间的关系。一个自主学习代理永远无法真正感知它是否正确，它最多只能检测到它的内部一致性。例如，即使它观察到它的预测(例如，内尔斯习得Horn子句预测的新信念)与它所感知的一致(例如，内尔从文本中读到的内容)，它也不能区分所观察到的一致性是由于正确的预测，还是不正确的感知。这对于理解永无止境的学习很重要，因为它建议组织学习代理随着时间的推移变得越来越一致，而这正是NELL如何使用其一致性约束来指导学习。因此，一个关键的开放理论问题是，在什么条件下可以保证一个越来越一致的学习代理同时也是一个越来越正确的代理?(Platanios, Blum, and Mitchell 2014)为这个方向提供了一个步骤，通过提供一种方法，不久将允许NELL根据所观察到的其学习函数之间的一致性率来估计其准确性，但是对于这个基本的理论问题还有很多需要了解的地方。 趋同在理论上和实践中都是必然的。对于永不停息的学习代理而言，第二个基本问题是，什么样的代理体系结构能够充分保证代理原则上能够生成一系列自修改，从而将其从初始状态转换为日益高性能的代理，而不会达到性能瓶颈?注意，这可能需要体系结构支持普遍的可塑性、改变其表示的能力等。这里的一个问题是，架构是否有足够的自修改操作来允许它在原则上对自身产生不断改进的修改。其次，相关的问题是它的学习机制是否会做出这些潜在的改变，在可处理的计算量和训练经验下，在实践中趋同。 致谢略 参考略","categories":[{"name":"知识图谱","slug":"知识图谱","permalink":"https://www.iamlightsmile.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"}],"tags":[{"name":"知识图谱","slug":"知识图谱","permalink":"https://www.iamlightsmile.com/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"}]},{"title":"《论文解读-Toward an Architecture for Never-Ending Language Learning》","slug":"《论文解读-Toward an Architecture for Never-Ending Language Learning》","date":"2020-01-31T10:18:02.000Z","updated":"2020-01-31T10:30:08.479Z","comments":true,"path":"articles/《论文解读-Toward an Architecture for Never-Ending Language Learning》/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E3%80%8A%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-Toward%20an%20Architecture%20for%20Never-Ending%20Language%20Learning%E3%80%8B/","excerpt":"当前自己仅是简单翻译一下。 0. 论文出处1. NELL系统概述NELL（never-ending language learner）系统每天不间断地执行两个任务： 阅读任务:从web文本中提取信息，进一步填充结构化事实和知识的不断增长的知识库。 学习任务:学习阅读，每天都比前一天更好，这是由它的能力证明，回到昨天的文本来源，提取更多的信息更准确","text":"当前自己仅是简单翻译一下。 0. 论文出处1. NELL系统概述NELL（never-ending language learner）系统每天不间断地执行两个任务： 阅读任务:从web文本中提取信息，进一步填充结构化事实和知识的不断增长的知识库。 学习任务:学习阅读，每天都比前一天更好，这是由它的能力证明，回到昨天的文本来源，提取更多的信息更准确 2. 理论基础网络上庞大的信息冗余(例如，许多事实以不同的方式被多次陈述)将使具有正确学习机制的系统获得成功。 3. 研究定位这项研究的一个观点是，它是一个终生学习的案例研究。第二种观点认为，这是一种提高自然语言处理艺术水平的尝试。第三种观点认为，这是开发世界上最大的结构化知识库的一种尝试——反映万维网的事实内容，这将对许多人工智能工作有用。 4. NELL系统掌握的知识类型目前，NELL掌握了两种类型的知识: 关于哪些名词短语指哪些特定语义类别的知识，如城市、公司和运动队; 关于哪些名词短语对满足哪些特定语义关系的知识，如hasOfficesIn(组织、位置)。 5. NELL系统的贡献 构建一个永不停息的学习代理的体系结构的进展，以及一组帮助成功实现该体系结构的设计原则 对该体系结构实现的web级实验评估 这是迄今为止规模最大、最成功的bootstrap学习实现之一 6. 系统组成 一个持续增长的共享的知识库 一系列实现了互补的知识抽取方法的阅读/学习子系统组件 7. 知识库初始定义 1个本体（定义了类别和关系的谓词集合） 这个本体中每个谓词的一些种子示例(例如，一些个示例城市)。 8. 系统目标通过阅读不断地增长知识库，并学习更好地阅读。 9. 系统体系结构 添加到知识库中的类别和关系实例被划分为候选事实和信念。 子系统组件可以从知识库中读取数据并参考其他外部资源(例如文本库或Internet)，然后提出新的候选事实。 组件为每个提议的候选提供一个概率，并提供支持它的源证据的摘要。 知识整合器(KI)检查这些提出的候选事实，并将其中最有力的支持提升到信念状态。 10. 系统工作原理 在我们的初始实现中，这个循环是迭代操作的。在每个迭代中，给定当前的知识库，每个子系统组件都运行到完成，然后KI根据新提出的候选事实做出决定。 知识库在迭代中不断增长，提供了越来越多的信念，然后每个子系统组件使用这些信念来重新训练自己，以便在下一次迭代中更好地阅读。通过这种方式，我们的方法可以被看作是实现了一种耦合的、半监督的学习方法，在这种方法中，多个组件在KI的监督下学习和共享互补类型的知识。 可以将此方法视为期望最大化(EM)算法的近似值，其中E步骤涉及迭代地估计共享知识库中非常大的一组虚拟候选信念的真值，M步骤涉及重新培训各种子系统组件提取方法。 如果标记错误累积，这种迭代学习方法可能会出现问题。为了帮助缓解这个问题，我们将允许系统每天与人进行10-15分钟的交互，以帮助它保持“在正轨上”。“然而，在这里报道的工作中，我们对人力投入的使用有限。 11. 系统设计原则 使用产生不相关错误的子系统组件。 当多个组件出现不相关的错误时，它们都出现相同错误的概率是它们各自错误概率的乘积，从而导致错误率大大降低。 学习多种类型的相关知识。 例如，我们使用一个组件学习从文本资源中提取谓词实例，另一个组件学习从知识库中的其他信念中推断关系实例。这为相同类型的信念提供了多种独立的来源。 使用耦合半监督学习方法来利用正在学习的谓词之间的约束(Carlson et al. 2010)。 为了提供耦合的机会，将类别和关系安排到一个分类法中，该分类法定义哪些类别是其他类别的子集，以及哪些类别对是相互排斥的。另外，指定每个关系参数的期望类别以启用类型检查。子系统组件和KI可以从利用耦合的方法中获益。 将知识库中的高自信信念与低自信候选者区分开来，并保留每种信念的来源证明。 使用统一的知识库表示来捕获候选事实和促进所有类型的信念，并使用可以在此共享表示上操作的关联推理和学习机制。 12. 系统设计到的知识 半监督学习 终身学习 bootstrap学习 耦合半监督学习 13. 系统子系统组件 耦合模式学习器(Coupled Pattern Learner，CPL)：一个用于自由文本的提取器，它学习和使用上下文模式，如“市长的X”和“X发挥Y”提取范畴和关系的实例。CPL使用名词短语和上下文模式之间的共现统计(均使用词性标记序列定义)来学习感兴趣的每个谓词的提取模式，然后使用这些模式来查找每个谓词的其他实例。谓词之间的关系用于过滤过于一般化的模式。Carlson等人(2010)对CPL进行了详细描述。CPL提取的候选实例的概率是使用公式1 0.5 c启发式分配的，其中c是提取候选实例的提升模式的数量。在我们的实验中，CPL作为20亿个句子的语料库的输入，这些句子是使用OpenNLP 包从ClueWeb09数据集中的5亿个网页英语部分提取、标记和后置标签句子生成的(Callan和Hoy 2009)。 耦合密封(Coupled SEAL，CSEAL):一个半结构化的提取器，它使用来自每个类别或关系的信念集查询Internet，然后挖掘列表和表来提取相应谓词的新实例。CSEAL使用互斥关系来提供负面示例，这些示例用于过滤掉过于一般的列表和表。CSEAL也由Carlson等人(2010)描述，它基于Wang和科恩(2009)。给定一组种子实例，CSEAL通过对知识库中的信念进行子抽样并在查询中使用这些抽样的种子来执行查询。CSEAL被配置为为每个类别发出5个查询，为每个关系发出10个查询，并为每个查询获取50个web页面。CSEAL提取的候选事实使用与CPL相同的方法分配概率，只不过c是提取实例的未过滤包装器的数量。 耦合形态分类器(Coupled Morphological Classifier，CMC):一组二元l2正则化逻辑回归模型，每个类别一个，根据不同的形态特征(单词、大写字母、词缀、词性等)对名词短语进行分类。来自知识库的信念被用作训练实例，但是在每个迭代中CMC被限制为至少有100个提升实例的谓词。与CSEAL一样，互斥关系用于识别负面实例。CMC检查其他组件提出的候选事实，并在每次迭代中每个谓词分类多达30个新信念，最小后验概率为0.75。这些启发式度量有助于确保较高的精度。 规则学习器(Rule Learner，RL):类似于FOIL (Quinlan和Cameron-Jones 1993)的一阶关系学习算法，它学习概率性的Horn子句。这些学习到的规则用于从知识库中已经存在的其他关系实例中推断新的关系实例。 14. 知识整合器（KI）我们对知识整合器(KI)的实现使用硬编码的、直观的策略将候选事实提升到信念的状态。从单一来源(后&gt; 0.9)获得高可信度的候选事实将得到提升，而从多个来源获得低可信度的候选事实将得到提升。 KI通过遵守互斥和类型检查信息来利用谓词之间的关系。特别是,候选类别实例不会被提升如果他们已经属于一个互斥的类别；关系实例同样不会提升,除非他们的论元至少属于候选的合适的类别类型(而不是已经被认为是一个类别的实例与适当的类型相互排斥）。 在我们当前的实现中，一旦将候选事实提升为信念，它就永远不会降级。KI被配置为每次迭代每个谓词最多提升250个实例，但是在我们的实验中很少达到这个阈值。 NELL中的KB是基于Tokyo Cabinet2(一种快速、轻量级的键/值存储)的THEO框架表示(Mitchell et al. 1991)的重新实现。知识库可以在一台机器上处理数百万个值。 15. 实验我们实验中使用的输入本体包括123个类别，每个类别有10-15个种子实例和5个CPL种子模式(源自Hearst模式(Hearst 1992))。 类别包括地点(例如，山脉、湖泊、城市、博物馆)、人(例如，科学家、作家、政治家、音乐家)、动物(例如，爬行动物、鸟类、哺乳动物)、组织(例如，公司、大学、网站、运动队)和其他。其中包括55个关系，还有10-15个种子实例和5个负面实例(通常通过屏蔽种子实例的参数生成)。关系捕获不同类别之间的关系(例如，teamPlaysSport、bookWriter、companyProducesProduct)。 在我们的实验中，CPL、CSEAL和CMC每次迭代运行一次。RL在每批10次迭代之后运行，并由人工筛选提议的输出规则。手动批准这些规则只需要几分钟。为了估计NELL生成的知识库中的信念的精度，最后知识库中的信念被随机抽样，并由几个人类裁判进行评估。在作出决定之前，对意见不一致的情况进行了详细的讨论。曾经正确但现在不正确的事实(例如，一个运动队的前教练)被认为是正确的评价，因为NELL目前没有处理其信仰的时间范围。虚假的形容词(如《今日芝加哥论坛报》(today ‘s Chicago Tribune)是被允许的，但很少见。 16. 抽取结果示例 17. 结果略 18. 讨论尽管NELL的持续学习允许它每天提取更多的事实，但提取事实的准确性随着时间的推移而缓慢下降。部分原因是最简单的提取发生在早期的迭代中，而后期的迭代需要更精确的提取器来达到同样的精度。 然而，NELL犯的错误也会导致他学会犯更多的错误。虽然我们认为目前的系统很有前途，但还有许多研究工作要做。 19. 总结我们提出了一个永不停止的语言学习代理的体系结构，并描述了该体系结构的部分实现，它使用四个子系统组件来学习以互补的方式提取知识。在运行了67天之后，这个实现填充了一个包含242,000多个事实的知识库，估计精度为74%。 这些结果说明了使用一组不同的知识提取方法的好处，这些方法适合于学习，并且一个知识库允许存储候选事实和自信的信念。 20. 可以改进之处有许多改进的机会,包括: 反省决定下一步该做什么, 更有效地利用10的15分钟的日常人际互动, 学习新发现的谓词, 学习额外的知识类型语言, 实体级(而不是string-level)建模 更复杂的概率建模的实现。 21. 致谢略 22. 参考略","categories":[{"name":"知识图谱","slug":"知识图谱","permalink":"https://www.iamlightsmile.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"}],"tags":[{"name":"知识图谱","slug":"知识图谱","permalink":"https://www.iamlightsmile.com/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"}]},{"title":"《NLP基础任务之新词发现探索之路》","slug":"《NLP基础任务之新词发现探索之路》","date":"2020-01-26T09:53:09.000Z","updated":"2020-05-01T02:56:47.954Z","comments":true,"path":"articles/《NLP基础任务之新词发现探索之路》/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E3%80%8ANLP%E5%9F%BA%E7%A1%80%E4%BB%BB%E5%8A%A1%E4%B9%8B%E6%96%B0%E8%AF%8D%E5%8F%91%E7%8E%B0%E6%8E%A2%E7%B4%A2%E4%B9%8B%E8%B7%AF%E3%80%8B/","excerpt":"step1：寻找综述没找到太好的综述。","text":"step1：寻找综述没找到太好的综述。 step2：寻找技术博客文章如寻找技术博客（如CSDN与个人博客站点）与文章（如知乎、简书），具体到新词发现任务，如： 基于互信息和左右信息熵的短语提取识别-码农场 互联网时代的社会语言学：基于SNS的文本数据挖掘 | Matrix67: The Aha Moments python3实现互信息和左右熵的新词发现 - 简书 step3：寻找已有实现如从Github上搜索与筛选相关开源项目，如： xylander23/New-Word-Detection: 新词发现算法(NewWordDetection) zhanzecheng/Chinese_segment_augment: python3实现互信息和左右熵的新词发现 step4：结合知识点研读开源项目算法初始思路经过研究以上代码与相关文章，发现主要有2种思路： 不依赖分词，直接进行新词发现，如上面开源项目1 在原有分词基础上进行，如上面开源项目2 相比而言（更多的是感性认识，并没有对比观察多少数据从而建立起有依据的推论），不依赖分词能够避免原有分词错误而引起的后面的错误，而在原有分词基础上进行则更加准确，因为可以依赖于分词结果作为输入特征，个人认为可能方案2（即在原有分词基础上进行）可能会更好些，当然这又受限于分词的准确率。 相关特征识别新词即确定两个词（或多个）是否能够组合成为一个词，主要看词内部的凝固度以及词外部的自由度，其中内部的凝固度可以用点间互信息来衡量，而自由度则可以用左右邻的信息熵来衡量。 大致流程对于所有的候选新词分别计算以上两个特征，通过某种方式组合在一起，或线性加和或幂次乘积来给候选新词打分，同时设定一些阈值过滤掉不符合条件的候选词，并将所有过滤后的候选词按分数高低降序排序，从而得到最终的结果。 step5：改进与整合原有项目自己主要参考项目2，但发现存在一些不足，如： 没有实现开箱即用的接口 数据结构设计不合理，比如遍历自定义的类所组成的列表进行匹配查找，耗时较多 虽然将引入外部词典数据进行初始化构建的模型进行了pickle持久化操作，但是其实没必要 不能很好地多次调用，每次调用都需要初始化或读取持久化的对象，耗时较长。 经过不断实践与探索，基本上比较好地解决了以上问题，同时在过程中也考虑了很多问题，如： 基于分词还是不基于分词 是否引入外部词典作为结果排序矫正 是否提供用户自定义词典以及自定义停用词接口 采用何种数据结构，是否照搬项目中数据结构，还是进行优化改进 在每次调用时都需要进行对外部词典数据初始化的过程，使用pickle文件写入读取持久化还是使用deepcopy进行对象拷贝，怎样更快 如何对如互信息与信息熵等统计特征进行加权组合，参数如何选取调整 如何引入其他信息增强发现能力以及矫正能力，比如词性信息（然而结巴的那个词典里面许多词性信息都不准确，比如说将知识的词性标注为动词） 设计一个什么样的接口才能使用户很方便的使用 如何将该新词发现模块与分词系统等较好地整合在一起 如何更好地融入人工校验机制 是否加入机器学习、深度学习等算法，包括有监督、无监督、强化学习、在线学习等 实现smilelight/lightText: 文本处理相关库，目前包括新词发现等功能。 后记当今nlp各任务的各种实现从传统规则到机器学习再到深度学习比比皆是，层出不穷，然而根本就没有完美的算法，没有完美的系统，有的只是不断地改进和优化。 个人心得在进行系统设计时，前期一定要对项目有一个比较清晰的规划，比如它的定位是什么、有哪些可以参考借鉴的已有实现，重要的搭一个能够跑起来的架子，不论啥效果；在中期优化过程中，则需要综合考虑时间空间硬件精度等多种因素，在一方面有所得有时必须建立在在其它某些方面有所失，比如各种时间空间互换、精度与时间空间互换等，在不同的时期不同的场景下主要矛盾不同，因此所对应的最佳策略也不唯一；在整个项目的生命周期中都需要不断考虑项目的拓展性，许多时候多写几个函数，多整几个文件来将不确定的、复杂的实现解耦，便于后续的排查调整。 参考略","categories":[{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/tags/NLP/"},{"name":"新词发现","slug":"新词发现","permalink":"https://www.iamlightsmile.com/tags/%E6%96%B0%E8%AF%8D%E5%8F%91%E7%8E%B0/"}]},{"title":"《国士无双-林俊德》","slug":"《国士无双-林俊德》","date":"2020-01-22T08:33:56.000Z","updated":"2020-01-26T13:38:15.976Z","comments":true,"path":"articles/《国士无双-林俊德》/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E3%80%8A%E5%9B%BD%E5%A3%AB%E6%97%A0%E5%8F%8C-%E6%9E%97%E4%BF%8A%E5%BE%B7%E3%80%8B/","excerpt":"人物简介林俊德（1938年3月13日—2012年5月31日），男，福建永春人，中国爆炸力学与核试验工程领域著名专家、总装备部某试验训练基地研究员，1960年毕业于浙江大学机械系，1993年晋升为少将军衔，2001年当选为中国工程院院士。2018年，经中央军委批准，增加“献身国防科技事业杰出科学家”林俊德为全军挂像英模。 2019年9月25日，入选“最美奋斗者”个人名单。","text":"人物简介林俊德（1938年3月13日—2012年5月31日），男，福建永春人，中国爆炸力学与核试验工程领域著名专家、总装备部某试验训练基地研究员，1960年毕业于浙江大学机械系，1993年晋升为少将军衔，2001年当选为中国工程院院士。2018年，经中央军委批准，增加“献身国防科技事业杰出科学家”林俊德为全军挂像英模。 2019年9月25日，入选“最美奋斗者”个人名单。 参考 林俊德（中国工程院院士）_百度百科","categories":[{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"国士无双","slug":"国士无双","permalink":"https://www.iamlightsmile.com/tags/%E5%9B%BD%E5%A3%AB%E6%97%A0%E5%8F%8C/"}]},{"title":"《国士无双-黄旭华》","slug":"《国士无双-黄旭华》","date":"2020-01-22T08:27:28.000Z","updated":"2020-01-26T13:37:17.467Z","comments":true,"path":"articles/《国士无双-黄旭华》/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E3%80%8A%E5%9B%BD%E5%A3%AB%E6%97%A0%E5%8F%8C-%E9%BB%84%E6%97%AD%E5%8D%8E%E3%80%8B/","excerpt":"人物简介黄旭华，1924年2月24日出生于广东省汕尾市海丰县田墘镇，中国核潜艇之父，原籍广东省揭阳市揭东区玉湖镇新寮村，交通大学1949届校友，中船重工集团公司719研究所研究员、名誉所长，中国第一代攻击型核潜艇和战略导弹核潜艇总设计师。开拓了中国核潜艇的研制领域， 1994年当选为中国工程院院士。湖北省科协荣誉委员，曾任前中国船舶工业总公司719研究所副总工程师、副所长、所长兼代理党委书记、以及核潜艇工程副总设计师、总设计师、研究员、高级工程师等职。","text":"人物简介黄旭华，1924年2月24日出生于广东省汕尾市海丰县田墘镇，中国核潜艇之父，原籍广东省揭阳市揭东区玉湖镇新寮村，交通大学1949届校友，中船重工集团公司719研究所研究员、名誉所长，中国第一代攻击型核潜艇和战略导弹核潜艇总设计师。开拓了中国核潜艇的研制领域， 1994年当选为中国工程院院士。湖北省科协荣誉委员，曾任前中国船舶工业总公司719研究所副总工程师、副所长、所长兼代理党委书记、以及核潜艇工程副总设计师、总设计师、研究员、高级工程师等职。 2014年1月，黄旭华当选中国中央电视台2013年度感动中国十大人物。2017年10月25日，获2017年度何梁何利基金科学与技术成就奖。11月9日，获得第六届全国道德模范敬业奉献类奖项。 黄旭华为中国核潜艇事业的发展做出了重要贡献，在核潜艇水下发射运载火箭的多次海上试验任务中，作为核潜艇工程总设计师、副指挥，开拓了中国核潜艇的研制领域，被誉为中国核潜艇之父。 2020年1月10日，获国家最高科学技术奖。 参考 黄旭华（中国核潜艇之父）_百度百科","categories":[{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"国士无双","slug":"国士无双","permalink":"https://www.iamlightsmile.com/tags/%E5%9B%BD%E5%A3%AB%E6%97%A0%E5%8F%8C/"}]},{"title":"《国士无双-于敏》","slug":"《国士无双-于敏》","date":"2020-01-22T08:17:11.000Z","updated":"2020-01-26T13:37:40.172Z","comments":true,"path":"articles/《国士无双-于敏》/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E3%80%8A%E5%9B%BD%E5%A3%AB%E6%97%A0%E5%8F%8C-%E4%BA%8E%E6%95%8F%E3%80%8B/","excerpt":"人物简介于敏（1926年8月16日—2019年1月16日），出生于河北省宁河县（今天津市宁河区）芦台镇，核物理学家，国家最高科技奖获得者。","text":"人物简介于敏（1926年8月16日—2019年1月16日），出生于河北省宁河县（今天津市宁河区）芦台镇，核物理学家，国家最高科技奖获得者。 1949年毕业于北京大学物理系。1980年当选为中国科学院学部委员（院士）。 原中国工程物理研究院副院长、研究员、高级科学顾问。 在中国氢弹原理突破中解决了一系列基础问题，提出了从原理到构形基本完整的设想，起了关键作用。此后长期领导核武器理论研究、设计，解决了大量理论问题。对中国核武器进一步发展到国际先进水平作出了重要贡献。从20世纪70年代起，在倡导、推动若干高科技项目研究中，发挥了重要作用。 1982年获国家自然科学奖一等奖。1985年、1987年和1989年三次获国家科技进步奖特等奖。1994年获求是基金杰出科学家奖。1999年被国家授予“两弹一星”功勋奖章。1985年荣获“五一劳动奖章”。1987年获“全国劳动模范”称号。2015年获2014年度国家最高科技奖。2018年12月18日，党中央、国务院授予于敏同志改革先锋称号，颁授改革先锋奖章，并获评“国防科技事业改革发展的重要推动者”。2019年1月16日，于敏在北京逝世，享年93岁。2019年9月17日，国家主席习近平签署主席令，授予于敏“共和国勋章”。 参考 于敏（中国“氢弹之父”）_百度百科","categories":[{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"国士无双","slug":"国士无双","permalink":"https://www.iamlightsmile.com/tags/%E5%9B%BD%E5%A3%AB%E6%97%A0%E5%8F%8C/"}]},{"title":"《国士无双-张伯驹》","slug":"《国士无双-张伯驹》","date":"2020-01-22T08:04:22.000Z","updated":"2020-01-26T13:37:44.561Z","comments":true,"path":"articles/《国士无双-张伯驹》/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E3%80%8A%E5%9B%BD%E5%A3%AB%E6%97%A0%E5%8F%8C-%E5%BC%A0%E4%BC%AF%E9%A9%B9%E3%80%8B/","excerpt":"个人简介张伯驹（1898年3月14日—1982年2月26日），原名张家骐，字家骐，号丛碧，别号游春主人、好好先生，河南项城人。爱国民主人士，收藏鉴赏家、书画家、诗词学家、京剧艺术研究家。","text":"个人简介张伯驹（1898年3月14日—1982年2月26日），原名张家骐，字家骐，号丛碧，别号游春主人、好好先生，河南项城人。爱国民主人士，收藏鉴赏家、书画家、诗词学家、京剧艺术研究家。 曾任故宫博物院专门委员、国家文物局鉴定委员会委员，吉林省博物馆副研究员、副馆长，中央文史馆馆员，任燕京大学国文系中国艺术史名誉导师，北京中国画研究会名誉会长，中国书法家协会名誉理事等职。建国初期，张伯驹将多件珍贵文物捐献给国家。 主要著作有《丛碧词》《春游词》《秦游词》《雾中词》《无名词》《续断词》和《氍毹纪梦诗》《氍毹纪梦诗注》《洪宪纪事诗注》及《乱弹音韵辑要》《丛碧书画录》《素月楼联语》等。 参考 张伯驹_百度百科","categories":[{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"国士无双","slug":"国士无双","permalink":"https://www.iamlightsmile.com/tags/%E5%9B%BD%E5%A3%AB%E6%97%A0%E5%8F%8C/"}]},{"title":"本博客分类详情","slug":"本博客分类详情","date":"2020-01-18T11:59:45.000Z","updated":"2020-01-18T12:01:33.167Z","comments":true,"path":"articles/本博客分类详情/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E6%9C%AC%E5%8D%9A%E5%AE%A2%E5%88%86%E7%B1%BB%E8%AF%A6%E6%83%85/","excerpt":"","text":"本博客暂定分类如下： Linux NLP 知识图谱 Python 深度学习 计算机 随念 其他","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"blog","slug":"blog","permalink":"https://www.iamlightsmile.com/tags/blog/"}]},{"title":"light系列库设想架构","slug":"light系列库设想架构","date":"2020-01-08T12:22:20.000Z","updated":"2020-01-31T13:58:00.673Z","comments":true,"path":"articles/light系列库设想架构/","link":"","permalink":"https://www.iamlightsmile.com/articles/light%E7%B3%BB%E5%88%97%E5%BA%93%E8%AE%BE%E6%83%B3%E6%9E%B6%E6%9E%84/","excerpt":"自己开发或整合的一系列light库之间的架构组织关系如图所示：","text":"自己开发或整合的一系列light库之间的架构组织关系如图所示： 整体架构如上图所示，整个light系列库之间的组织架构共分为： 工具层 lightSpider lightUtils lightDict 其他light库 其他工具库 算法层 lightNLP lightKG 通用神经网络模型算法 其他NLP框架 其他KG框架 业务层 lightText lightKB 其他相关业务 界面层 浏览器前端 整个架构的中心都是围绕着自然语言处理和知识图谱两个大的方向。目的是搭一个比较通用的架子，然后可以在上面展开一些尝试性、探索性的实验和业务，根本上是作为自己想法的舞台。 工具层工具层包括lightSpider、lightUtils、lightDict、其他light库以及其他工具库（如NLTK）。 其中lightSpider是用来获取网上的知识（以网上各网站的公开语料）。lightUtils则是一些较通用的工具类库，包含了比如说日志打印、获取系统可用tcp端口等功能。lightDict则包含了一些在网上搜集到的中文的字典词典资料，并且构建了一个lib以方便使用。其他light库则视以后需求增加。 算法层算法层包括lightNLP、lightKG、其他NLP框架（比如说fastNLP）、其他KG框架（比如说OpenNRE）以及其他通用神经网络模型算法，包括但不限于强化学习、对抗学习、终生学习等。 业务层业务层构建于算法层之上包括各种知识图谱任务和自然语言处理技术，比如关键词抽取、文本摘要、文本分类、命名实体识别、信息抽取、文本生成、实体链接、本体分类与构建、知识存储等功能，会用到各种算法知识和技术，包括基于深度学习的、基于机器学习的、基于规则的，基于监督学习的、基于弱监督学习的、基于无监督学习的等等。 界面层（用户层）用户层则主要考虑采用Vue+Flask等技术，在可视化方面主要采用2D层面，但在一些本体与事件展示时更倾向于使用3D效果。","categories":[{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/categories/NLP/"}],"tags":[{"name":"light系列库","slug":"light系列库","permalink":"https://www.iamlightsmile.com/tags/light%E7%B3%BB%E5%88%97%E5%BA%93/"}]},{"title":"centos安装miniconda","slug":"centos安装miniconda","date":"2020-01-07T08:06:09.000Z","updated":"2020-01-18T11:10:36.754Z","comments":true,"path":"articles/centos安装miniconda/","link":"","permalink":"https://www.iamlightsmile.com/articles/centos%E5%AE%89%E8%A3%85miniconda/","excerpt":"","text":"步骤1. 下载minicondacd ~ &amp;&amp; mkdir tmp &amp;&amp; cd tmp wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh 2. 运行miniconda安装脚本sh Miniconda3-latest-Linux-x86_64.sh 3. 验证是否安装成功conda -V 若输出类似conda 4.7.12，说明安装conda环境成功。如提示：zsh：command not find:conda，则需要将conda配置到路径变量中，详情参考zsh：command not find:conda 的详细解决办法 - 简书","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://www.iamlightsmile.com/tags/CentOS/"}]},{"title":"购买国内云服务器与备案注册","slug":"购买国内云服务器与备案注册","date":"2020-01-07T06:50:32.000Z","updated":"2020-01-18T11:14:19.374Z","comments":true,"path":"articles/购买国内云服务器与备案注册/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E8%B4%AD%E4%B9%B0%E5%9B%BD%E5%86%85%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8E%E5%A4%87%E6%A1%88%E6%B3%A8%E5%86%8C/","excerpt":"更新我真傻，真的。没想到腾讯云有120元/年，同样配置的学生优惠活动：腾讯云学生服务器_学生机_云服务器优惠套餐-云+校园 - 腾讯云，只是主机只能选上海或者深圳。并且25岁以下免学生认证，立马我就把之前用了500优惠券+600多买的云服务器给退了。。。 前言突然大发兴致，想要购买国内云服务器，并且配置域名以及备案注册，想要搞事情，具体搞什么还没想好，比如说爬虫或者部署demo之类的。虽然自己也有搬瓦工的服务器，虽然也算物美价廉，但是毕竟不能备案绑定域名，况且内存和国内访问速度都比较慢，还是搞个真正的云服务器比较好。","text":"更新我真傻，真的。没想到腾讯云有120元/年，同样配置的学生优惠活动：腾讯云学生服务器_学生机_云服务器优惠套餐-云+校园 - 腾讯云，只是主机只能选上海或者深圳。并且25岁以下免学生认证，立马我就把之前用了500优惠券+600多买的云服务器给退了。。。 前言突然大发兴致，想要购买国内云服务器，并且配置域名以及备案注册，想要搞事情，具体搞什么还没想好，比如说爬虫或者部署demo之类的。虽然自己也有搬瓦工的服务器，虽然也算物美价廉，但是毕竟不能备案绑定域名，况且内存和国内访问速度都比较慢，还是搞个真正的云服务器比较好。 调研这里主要是比较各厂商（主要是阿里云、腾讯云两家）的云服务器产品的性能和价格。发现网上阿里口碑不错，如果不差钱就选阿里好了，而腾讯云价格相对较低一些，毕竟起步较晚，一些布局和服务等没有阿里云那么完善，只能在价格上搞搞事情了。 虽然各厂商都对新用户有比较大的力度优惠，然而奈何自己都不是。在阿里云上买过域名和OSS，也在腾讯云上买过域名。 下面是阿里云的： 链接地址为：全民云计算_云服务器促销_便宜云服务器活动_阿里云 优惠链接地址：阿里云2020年1月最新优惠信息 - 独特优惠码 下面是腾讯云的： 链接地址为：云服务器选购 - 腾讯云 优惠链接地址：腾讯云优惠券_代金券_云服务器折扣券-腾讯云 其中里面一些优惠确实算是挺大的： 最终左右权衡之后，觉得确实腾讯云的性价比更高一些，况且适合自己以后部署爬虫等需要长时间消耗CPU等资源的应用。 购买域名及备案购买域名自己其实已经有3个域名了，但是都不太合适作为新服务器的域名，于是自己又买了一个域名：lightsmile.cn。哎，感叹一下lightsmile.com这个域名早就被别人买了，并且价格还挺高，所以自己看来短期内无法把它搞到手。 域名买了之后需要实名注册，然后设置解析，具体不表。 备案备案的话，现在其实都算挺方便的。无论是阿里云还是腾讯云，直接在电脑上操作或者使用微信小程序操作，然后上传一些资料，比如个人身份证件图片以及一些必要的备案信息等，然后就可以默默等待审核结果了。 后记不得不说，买个云服务器确实还挺贵的，自己也没有什么资金收入，还得找家里一直要钱。客观对比一下，我发现自己其实和一些大学生年轻人是一样的，只不过他们喜欢把钱投资到喜欢的衣服和鞋子，而我则喜欢购买互联网产品，充一些有助于自己成长的平台的会员。但归根结底都是图自己爽。 虽然有了自己的云服务器之后又可以有一番作为，但是确实还是很肉疼啊。 参考 1核 2G云服务器选择腾讯云还是阿里云？-魏艾斯博客 阿里云和腾讯云哪个好？云服务器如何选择？ - 简书","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://www.iamlightsmile.com/tags/CentOS/"}]},{"title":"高速下载国外数据软件","slug":"高速下载国外数据软件","date":"2020-01-04T05:34:01.000Z","updated":"2020-01-18T11:51:31.935Z","comments":true,"path":"articles/高速下载国外数据软件/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E9%AB%98%E9%80%9F%E4%B8%8B%E8%BD%BD%E5%9B%BD%E5%A4%96%E6%95%B0%E6%8D%AE%E8%BD%AF%E4%BB%B6/","excerpt":"背景很多时候要下载国外网站的数据和软件包的时候默认浏览器下载速度极慢，甚至可能到几k/s，要下载个几M的东西都要花好长时间。","text":"背景很多时候要下载国外网站的数据和软件包的时候默认浏览器下载速度极慢，甚至可能到几k/s，要下载个几M的东西都要花好长时间。 解决方案突然想到自己有办理搬瓦工的服务器呀~。使用代理服务器下载想要的数据，然后再传到自己的电脑不就好了嘛。 使用流程1.获取下载链接地址如图，使用Chrome浏览器下载，然后右键点击URL选择“复制链接地址”。 2.使用代理服务器下载数据如图，使用Xshell等终端软件登录代理服务器，执行wget xxx命令： 3.将数据从代理服务器传至本机如图，使用Xftp等文件传输软件连接至代理服务器，将下载文件传输到本地： 后话虽然在将文件从代理服务器传输到本机的过程中可能速度也不快，但是起码可用了，200k也算可以接受了。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"小窍门","slug":"小窍门","permalink":"https://www.iamlightsmile.com/tags/%E5%B0%8F%E7%AA%8D%E9%97%A8/"}]},{"title":"程序猿注意颈椎保护","slug":"程序猿注意颈椎保护","date":"2020-01-03T12:51:42.000Z","updated":"2020-01-18T11:50:44.702Z","comments":true,"path":"articles/程序猿注意颈椎保护/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E7%A8%8B%E5%BA%8F%E7%8C%BF%E6%B3%A8%E6%84%8F%E9%A2%88%E6%A4%8E%E4%BF%9D%E6%8A%A4/","excerpt":"","text":"下面是一些视频网址和文字教程，在这里分享一下： 亲身实践，颈椎病自愈法 - 知乎 老中医治疗你的颈椎病_哔哩哔哩 (゜-゜)つロ 干杯~-bilibili 10分钟颈椎操颈椎病的自我治疗，每天10分钟，轻松20年！_哔哩哔哩 (゜-゜)つロ 干杯~-bilibili","categories":[{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"颈椎病","slug":"颈椎病","permalink":"https://www.iamlightsmile.com/tags/%E9%A2%88%E6%A4%8E%E7%97%85/"}]},{"title":"简单调研操作Neo4j的Python库","slug":"简单调研操作Neo4j的Python库","date":"2020-01-03T12:49:41.000Z","updated":"2020-01-18T11:52:32.247Z","comments":true,"path":"articles/简单调研操作Neo4j的Python库/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E7%AE%80%E5%8D%95%E8%B0%83%E7%A0%94%E6%93%8D%E4%BD%9CNeo4j%E7%9A%84Python%E5%BA%93/","excerpt":"前言如官网所述，目前用于操作Neo4j的Python库主要包括如下几种： Neo4j Python Driver（官方提供，长期更新支持） Py2neo（非官方看网上教程多数都是这个） Neomodel（也是社区版）","text":"前言如官网所述，目前用于操作Neo4j的Python库主要包括如下几种： Neo4j Python Driver（官方提供，长期更新支持） Py2neo（非官方看网上教程多数都是这个） Neomodel（也是社区版） 对比 对比\\模型 Neo4j Driver Py2neo Neomodel 代码活跃程度 最近更新于一个月内 最近更新于8个月前 不明 国内适用范围 较少 很多 不明 代码特性 一般 简洁 一般 说明文档内容 较少 一般 不明 配套文档版本 最新 最新源码和文档有冲突 不明 结论经过对比，还是先结合源码来学习Py2neo吧。大家都用，并且代码用起来确实比较舒服~并且，本质上也只是一个使用Neo4j的接口，无非语句不通而已，但最终执行的增删改查都是一样的。 参考 The Py2neo v4 Handbook — The Py2neo v4 Handbook Neo4j系列-新手入门（二） - 简书 Neo4j简介及Py2Neo的用法 | 静觅","categories":[{"name":"知识图谱","slug":"知识图谱","permalink":"https://www.iamlightsmile.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://www.iamlightsmile.com/tags/Python/"},{"name":"Neo4j","slug":"Neo4j","permalink":"https://www.iamlightsmile.com/tags/Neo4j/"}]},{"title":"使用ReadtheDocs给项目添加教程文档","slug":"使用ReadtheDocs给项目添加教程文档","date":"2020-01-03T12:43:18.000Z","updated":"2020-01-18T11:54:02.728Z","comments":true,"path":"articles/使用ReadtheDocs给项目添加教程文档/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E4%BD%BF%E7%94%A8ReadtheDocs%E7%BB%99%E9%A1%B9%E7%9B%AE%E6%B7%BB%E5%8A%A0%E6%95%99%E7%A8%8B%E6%96%87%E6%A1%A3/","excerpt":"当开源项目的内容比较多、比较杂的时候，就需要将一些说明性的东西、如教程、文档等东西从README.md文件中剥离出来搞一个文档，许多项目都是如此，于是自己也简单学了一下使用ReadtheDocs。","text":"当开源项目的内容比较多、比较杂的时候，就需要将一些说明性的东西、如教程、文档等东西从README.md文件中剥离出来搞一个文档，许多项目都是如此，于是自己也简单学了一下使用ReadtheDocs。 步骤1.从ReadtheDocs官网注册账号并连接到GithubReadtheDocs官网地址：首页 | Read the Docs 在注册成功后在设置-&gt;已连接的服务中点击Connect to Github： 2.在Github上创建一个项目，如test-cookbook，并将其克隆到本地。3.安装Sphinxpip install sphinx 4.创建工程将路径切换到项目根目录下，执行以下命令： sphinx-quickstart 5.对工程进程配置项目的配置，主要是更改source/conf.py文件。 5.1 更改主题在项目中更改或添加以下代码 import sphinx_rtd_theme html_theme = &quot;sphinx_rtd_theme&quot; html_theme_path = [sphinx_rtd_theme.get_html_theme_path()] 5.2 添加markdown支持首先安装recommonmark pip install recommonmark 并在项目中增加以下代码 from recommonmark.parser import CommonMarkParser source_parsers = { &#39;.md&#39;: CommonMarkParser, } source_suffix = [&#39;.rst&#39;, &#39;.md&#39;] 6.导入到ReadtheDocs在ReadtheDocs个人面板点击Import a Project：然后选择对应的项目，如果项目列表为空或者未显示当前项目，点击右上角等待刷新项目即可： 之后可以对项目进行一些设置，如图： 7.向工程中添加实际教程和文档如新建.rst或.md文件，并修改项目的index.rst等，具体请参考最后的参考链接。 8.生成文档在项目根目录执行 make html 以生成html格式的文档。 可能在生成文档会失败，如遇到Sphinx error: master file [..]/checkouts/latest/contents.rst not found这样的错误，可以参考Sphinx error: master file [..]/checkouts/latest/contents.rst not found · Issue #2569 · readthedocs/readthedocs.org来解决。 9.预览效果进入build/html目录下用浏览器打开其中的index.html来预览项目文档。如： 10.push到Github仓库三连git： git add . git commit -m &quot;update cookbook&quot; git push 11.查看在线效果在ReadtheDocs的项目主页点击阅读文档以查看实际效果： 效果如： 参考 如何用 ReadtheDocs、Sphinx 快速搭建写书环境 - 简书 使用ReadtheDocs托管文档 | 飞污熊博客 Sphinx error: master file [..]/checkouts/latest/contents.rst not found · Issue #2569 · readthedocs/readthedocs.org","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"ReadtheDocs","slug":"ReadtheDocs","permalink":"https://www.iamlightsmile.com/tags/ReadtheDocs/"}]},{"title":"实用命令行工具-Gow","slug":"实用命令行工具-Gow","date":"2020-01-03T12:37:36.000Z","updated":"2020-01-18T11:53:53.602Z","comments":true,"path":"articles/实用命令行工具-Gow/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E5%AE%9E%E7%94%A8%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7-Gow/","excerpt":"Windows和Linux对于程序员来说，就像张爱玲笔下的红玫瑰和白玫瑰。对于有钱的成年人来说，选择自然是“我全都要”，然而对于目前经济窘迫、只有一台爱机的我，鱼和熊掌也许并不是那么容易兼得。","text":"Windows和Linux对于程序员来说，就像张爱玲笔下的红玫瑰和白玫瑰。对于有钱的成年人来说，选择自然是“我全都要”，然而对于目前经济窘迫、只有一台爱机的我，鱼和熊掌也许并不是那么容易兼得。 0.前言Windows除了开发感觉干啥都很方便，而Linux除了开发感觉啥都不方便。Linux的很大的一个很大的优点就在于有大量丰富的命令行工具，能够在命令行里敲几个字就能解决的事情为什么要费力用鼠标点来点去呢？使用键盘的比例越高，往往说明生产效率越高。所以选择Windows作为平时的生活开发系统而言，如果Windows上也能很方便的使用那些命令行工具就很完美了，比如说head、tail等命令。而Gow(Gnu On Windows)恰恰是满足了这一需求点的近乎完美工具。 1.介绍 Gow (Gnu On Windows)是Cygwin的轻量级替代品。它使用了一个方便的Windows安装程序，安装了大约130个非常有用的开源UNIX应用程序，这些程序编译为本机win32二进制文件。它被设计为尽可能小，大约10 MB，而Cygwin根据不同的选项可以运行超过100 MB。 2.下载下载页：Releases · bmatzelle/gow如图：点击红框中的链接下载然后双击安装即可，非常简单易用~ 3.使用示例如图：","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"开发工具","slug":"开发工具","permalink":"https://www.iamlightsmile.com/tags/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"},{"name":"Windows","slug":"Windows","permalink":"https://www.iamlightsmile.com/tags/Windows/"}]},{"title":"常用自然语言处理框架之StanfordNLP使用","slug":"常用自然语言处理框架之StanfordNLP使用","date":"2020-01-03T02:37:57.000Z","updated":"2020-05-01T05:47:45.051Z","comments":true,"path":"articles/常用自然语言处理框架之StanfordNLP使用/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E5%B8%B8%E7%94%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BStanfordNLP%E4%BD%BF%E7%94%A8/","excerpt":"使用","text":"使用 import stanfordnlp # stanfordnlp.download(&#39;zh&#39;) 从网络上下载模型文件，超级慢 zh_nlp = stanfordnlp.Pipeline(lang=&#39;zh&#39;, models_dir=r&quot;D:\\Data\\NLP\\model\\stanfordnlp&quot;) text = &quot;清华大学是一所中国的一流大学。&quot; zh_doc = zh_nlp(text) for i, sent in enumerate(zh_doc.sentences): print(&quot;[Sentence {}]&quot;.format(i+1)) for word in sent.words: print(&quot;{:12s}\\t{:12s}\\t{:6s}\\t{:d}\\t{:12s}&quot;.format(\\ word.text, word.lemma, word.pos, word.governor, word.dependency_relation)) print(&quot;&quot;) 首先应该先下载模型，然而如果是直接运行stanfordnlp.download(&#39;zh&#39;)命令，那么下载速度实在是太慢了，后来把它的源码下载下来，找到了对应了文件下载地址，然后使用Chrome下载，发现速度有所提升但是也很慢，最后尝试了一下先使用Xshell登录代理浏览器下载模型，然后使用Xftp将模型传输到本地，结果速度变快了好多，尤其是代理浏览器下载模型的速度超级快，达80M/s，太惊人了。","categories":[{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/tags/NLP/"}]},{"title":"常用自然语言处理框架之StanfordCoreNLP使用","slug":"常用自然语言处理框架之StanfordCoreNLP使用","date":"2020-01-03T02:26:54.000Z","updated":"2020-05-01T05:47:55.715Z","comments":true,"path":"articles/常用自然语言处理框架之StanfordCoreNLP使用/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E5%B8%B8%E7%94%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BStanfordCoreNLP%E4%BD%BF%E7%94%A8/","excerpt":"使用","text":"使用 from stanfordcorenlp import StanfordCoreNLP # 加载模型 nlp = StanfordCoreNLP(r&quot;D:\\Data\\NLP\\model\\stanford_corenlp\\stanford-corenlp-full-2018-10-05&quot;, lang=&#39;zh&#39;) # 使用 text = &quot;清华大学是一所中国的一流大学。&quot; print(&#39;Tokenize:&#39;, nlp.word_tokenize(text)) print(&#39;Part of Speech:&#39;, nlp.pos_tag(text)) print(&#39;Named Entities:&#39;, nlp.ner(text)) print(&#39;Constituency Parsing:&#39;, nlp.parse(text)) print(&#39;Dependency Parsing:&#39;, nlp.dependency_parse(text)) 参考 Python中使用Stanford CoreNLP_Mr番茄蛋的博客-CSDN博客 在Mac OS中安装和使用Stanford NLP - 简书 报错按照网上教程下载模型并且运行代码后没反应，然后搜索网上相关解决方案，找到了关于使用stanfordcorenlp一直运行不报错的解决方法 - monty12 - 博客园，并且设置了logger.DEBUG后发现了类似以下报错信息，然后继续重装Java，经过反复两次发现还是不行。 nitializing native server... INFO:root:java -Xmx4g -cp &quot;F:\\space\\wingide\\stanfordnlp\\*&quot; edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 INFO:root:Server shell PID: 8504 INFO:root:Waiting until the server is available. INFO:root:Waiting until the server is available. 后来从这个网址：Java SE Runtime Environment 8 - Downloads，下载了如下红框中标出的链接重新安装Java之后，才提示安装了64位，并且程序可以正常运行。","categories":[{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/tags/NLP/"}]},{"title":"Github上开源Python仓库维护流程","slug":"Github上开源Python仓库维护流程","date":"2019-12-31T03:51:25.000Z","updated":"2020-01-18T11:56:28.758Z","comments":true,"path":"articles/Github上开源Python仓库维护流程/","link":"","permalink":"https://www.iamlightsmile.com/articles/Github%E4%B8%8A%E5%BC%80%E6%BA%90Python%E4%BB%93%E5%BA%93%E7%BB%B4%E6%8A%A4%E6%B5%81%E7%A8%8B/","excerpt":"stepsstep1： 明确更新缘由比如说有用户提出bug的issue，则可以考虑在空闲时分析问题甚至重现问题以寻找到bug，然后修改代码修复bug。 又如对项目进行重构或增加新的feature等，也相应的修改代码。","text":"stepsstep1： 明确更新缘由比如说有用户提出bug的issue，则可以考虑在空闲时分析问题甚至重现问题以寻找到bug，然后修改代码修复bug。 又如对项目进行重构或增加新的feature等，也相应的修改代码。 step2：对修改后代码进行测试对修改后的项目代码进行测试，以确保问题修复，或代码的修改完善并未影响其他的代码的正常运行。 step3: 根据需要修改项目配置和说明文件 在README.md中做说明。 修改setup.py文件中版本号 step4: 提交代码到Github仓库git的add、commit、push三连。 step5: 编译项目并更新到pypi源中参考我的另一篇文章：python库打包分发 | lightsmile’s Blog step6: 友好回复提出问题的用户遵守“富强、民主、文明、和谐、自由、平等、公正、法治、爱国、敬业、诚信、友善”社会主义核心价值观，和用户进行友好沟通，告知用户已解决问题或其他说明。","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"Github","slug":"Github","permalink":"https://www.iamlightsmile.com/tags/Github/"}]},{"title":"2019回忆总结录","slug":"2019回忆总结录","date":"2019-12-30T12:00:48.000Z","updated":"2020-01-18T11:06:08.993Z","comments":true,"path":"articles/2019回忆总结录/","link":"","permalink":"https://www.iamlightsmile.com/articles/2019%E5%9B%9E%E5%BF%86%E6%80%BB%E7%BB%93%E5%BD%95/","excerpt":"时光匆匆如流水，眨眼间，2019年就这么过去了。距离你好，2019也马上就一年整了。","text":"时光匆匆如流水，眨眼间，2019年就这么过去了。距离你好，2019也马上就一年整了。 总体回顾这一年，也算奋斗和荒废都有。由于要考研以及积累学习，所以在2018年12月底辞职，然后回家。 在1月份，主要是学习Pytorch和torchtext，开始探索看项目源码。同时计划当一个网上的家教老师，平台是掌门，准备了一段时间，结果面试没有通过，妈了个巴子的。 在2月份开始鼓捣Manjaro，期间重装系统多次，真是痛并快乐着，现在回想起来：一方面在探索的过程中遇到困难，解决困难的历程很爽；另一方面说实在的，并没有积累到太多实用的计算机技术，有点浪费时间了（ps：Linux系统还是单独装吧，装个双系统放在普通硬盘里实在是挺慢的，可能和KDE环境占用内存较大也有关系；最近出于学习效率还是回到了Windows的怀抱，啊好香啊）。其间报了个上海的创意编程（就是教Scratch）老师，也经历了准备面试、远程面试通过等过程，然而在培训过程中感觉不太好于是主动退出了） 到了3月份，之前在网易云课堂报的自然语言处理工程师微专业开班了，于是主要是学习课程资源，积累相关知识；同时开始在Github上寻觅使用Pytorch实现的nlp任务的实现（最开始是文本分类，之后是命名实体识别），开始了不断学习源码之路；其间萌生了用torchtext照着实现一遍以增进自己对任务的理解、以及提升自己的实践动手能力的想法，便有了最初的lightNLP。同时也想着开发其他框架供自己使用，如lightKG、lightText、lightUtils。当时的定位主要是： lightNLP：lightNLP基于Pytorch和torchtext是一个深度学习自然语言处理框架，实现了如文本分类、命名实体识别、语句相似度、文本蕴涵、依存句法分析等功能。 lightKG：lightsmile个人的知识图谱框架 lightUtils：lightsmile个人的工具类库 lightText：lightText是中文文本处理框架，在设计上会包含各种词典资源，一些算法的传统或机器学习实现，包含广泛且更高级的功能，如对文本进行分析，抽取出关键词、分类、进行信息抽取等功能，会依赖于lightNLP的深度学习自然语言处理框架、lightKG的知识图谱框架、lightUitls的其他工具类库，以及包含一些词典资源等等各种资源。 到了4月份，还是继续学习网易云课堂的自然语言处理课程，当然重心已经发生了转移，因为感觉自己在Github上寻找各nlp基础任务的简单实现并阅读源码的过程中学到挺多的，更甚于网易云课堂每周一更的录制课程，所以主要还是看代码，重新实现，以及学习微专业课程。 到了5月份，家里有人生病住院，我相对空闲所以去陪护，用去了一段时间。其他主要是继续上课，和看代码和敲代码，以及一些其他娱乐活动？忘了。 剩下的6~12月份，主要是复习备考，期间有认真复习的日子，也有荒废游戏的日子，甚至于连续几天熬夜打游戏，也有熬夜看小说，并没有多刻苦，也并没有很好地执行计划并坚决执行，甚至到了后期每天的真正学习时间反而更短了。 等考完后，发现心情一般，可能是发挥的一般，尤其是数学，考的极差，做了几套往年的真题，感觉还蛮简单的，于是就放松懈怠了，导致有的大题没写，有的只写了第一问，填空和选择也有不会的；也可能是因为自己平时就没有多努力，多刻苦，所以并没有放松解脱自由的感觉。 感谢学妹临考前每天的鼓励，真的挺感动的。 等考完后，本来想说玩游戏放松，可是不知道玩什么；本来想说看小说，可是备考期间也看了；那些本应该在考完后放松的事情让我在备考期间做了个遍，真想狠狠地扇自己！ 同时自己也有太多想做的事，比如学习Vue、学习爬虫、继续完善lightNLP、继续丰富lightKG、学习fastNLP源码、学习Neo4j、阅读知识图谱技术相关论文、阅读自然语言处理相关论文等等，奈何精力有限，只能一步步慢慢来。 不得不说，这一路走来，有奋斗、也有颓废。关于内心的变化，感觉自己变得比以前更现实了，甚至是相当现实了，比去年还是满脑子空想的我相比现实的太多了。心态也更加平和、冷静，抗干扰能力有所提升，内心不会因为外界的言语有多少波动。不会再把精力浪费在认为不值得的人、不值得的事上面。把名看得更淡，把利看得更多。世界观也更加健全完善，看到世界上发生的许多事情新闻都已经很平静了。尽管几乎去年一整年没有和社会打交道，同样积累了些许人生道理。 不管满意与否，今年的历程对今后的道路会有什么影响，路都已经走过了，也不能再回头了。 无论等一个多月之后公布的考研初试成绩如何，无论在今后找工作的道路上遇到多少艰难险阻，我都会继续追求我的自然语言处理和知识图谱的理想永不放弃。 脑子里又回想起当时那个面临继续工作还是辞职考研两个选择的自己，我可以回答他：这条路走的不后悔。毕竟在月亮和六便士面前，我曾经选择了月亮。 2020，继续冲鸭！","categories":[{"name":"随念","slug":"随念","permalink":"https://www.iamlightsmile.com/categories/%E9%9A%8F%E5%BF%B5/"}],"tags":[{"name":"个人","slug":"个人","permalink":"https://www.iamlightsmile.com/tags/%E4%B8%AA%E4%BA%BA/"}]},{"title":"如何理解WordEmbedding？","slug":"如何理解WordEmbedding？","date":"2019-04-22T08:15:12.000Z","updated":"2019-04-22T08:33:36.562Z","comments":true,"path":"articles/如何理解WordEmbedding？/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3WordEmbedding%EF%BC%9F/","excerpt":"之前自己也是懵懵懂懂的不太理解，经过一段时间的学习和思考，感觉自己有了新的认识，所以在这里分享一下，也算自己的总结了。 不谈数学原理，我认为理解Word Embedding可以从以下3个角度来理解。","text":"之前自己也是懵懵懂懂的不太理解，经过一段时间的学习和思考，感觉自己有了新的认识，所以在这里分享一下，也算自己的总结了。 不谈数学原理，我认为理解Word Embedding可以从以下3个角度来理解。 1.背景《深度学习》一书中有以下几句话，略有小改： 简单的机器学习算法的性能在很大程度上依赖于给定数据的表示。 使用机器学习来发掘表示本身的方法即表示学习。 从原始数据中提取高层次、抽象的特征是非常困难的。 深度学习通过其他较简单的表示来表达复杂表示。 我们可以认为不同数学函数的每一次应用都为输入提供了新的表示。 分布式表示的思想是系统的每一个输入都应该由多个特征表示，并且每一个特征都应该参与到多个可能输入的表示。 联结主义的中心思想是当网络把大量简单的计算单元连接在一起时可以实现智能行为。 万能近似定理表明，神经网络可以近似从任何有限离散空间映射到另一个的任意函数。 其实我认为深度学习的应用核心就是上面几句话。 接下来我拿传统的确定性算法、机器学习和深度学习做一个简单的对比。 原来对于一些流程比较清晰简单的任务，我们的做法是编写确定性的算法来实现，而对于那些很复杂的，难以用简单的规则去说明的任务通常束手无策。 机器学习的作用则是直接从数据中去学习，总结规律，但通常我们要花费大量的精力在特征工程上面，同时对于许多任务来说，我们很难知道应该提取哪些特征。而深度学习则表示：特征不用你们整，只要你们给的数据足够好，我保证给你们一个更好的模型。 上面这句话的意思是，原来特征工程的累活我们不用做了，深度学习可以自己学到好的特征，同时万能近似定理也确保了深度神经网络可以保证模型学习效果的上限很高，当前前提是我们给的数据比较好。 以上交代了下背景，接下来言归正传。 自然语言要作为神经网络模型的输入之前，我们首先需要将其映射为计算机可以表示的形式。 独热编码最简单，将每一个字或者词都唯一编码成了01向量，除了维度灾难，我认为最大的缺点就是在这一映射过程中丢掉了许多词或者字的词义和语义特征，除了表示唯一以外，不包含任意其它信息。 这时我们应该思考：那什么样的表示才算好的表示？表示中应该保留哪些特征又如何保留这些特征呢？ 怀着对上面问题的疑问，我们来看一下他山之石。 2.卷积神经网络的工作原理我们都知道卷积神经网络中最主要的部分：卷积层、池化层、激活层的作用就是提取和匹配局部特征，将特征提取结果作为全连接层的输入从而得到最终的输出。 其中的每一个卷积核都可以被视为一个特征过滤器，卷积神经网络通过依次的扫描输入并进行卷积运算提取得到哪些位置可能包含哪些特征的信息，随后这些特征位置信息被进一步的提取从而得到更高级、更抽象的特征。 举个例子，如在识别图片中是否包含人时，卷积神经网络大致的作用原理如首先提取出某些位置是否是横线、竖线还是斜线以及颜色等特征，然后对这些特征进一步组合以得到哪些位置是否包含人脸、上肢、下肢等特征，通过提取到的这些特征，神经网络就可以做出决策得到图片中是否包含人的结果。 通过了解卷积神经网络的工作原理，我们可以知道卷积神经网络的最大作用就是可以自动学习并提取局部特征。对于计算机视觉中的图片而言，最微小的组成单元是一个个的像素点，然后局部组合就得到了线条和颜色块等信息特征；而对于自然语言处理而言，最小的组成单元则是一个个的字符，如英文中的‘a’、汉字中的‘我’等。 许多计算机视觉的预训练模型都是通用的，对于具体任务，我们只需要finetune（精调）或者只学习后面的层就可以了。这其中的原理是学到的模型提取特征的能力是可复用的，不依赖于某一具体任务。同样的，如果我们可以从语料中学到词或者字的词义和语义特征就好了，之后可以直接作为词或者字的表示用于模型训练和预测，这就是词的预训练。两者有异曲同工之妙。 3.Harris提出的分布式假说及Firth对此的阐述和论证Harris曾于1954年提出分布式假说：“上下文相似的词，其语义也相似”，后来又经过Firth对该假说进行阐述和论证，“词的语义由其上下文确定”。基于该思想，我们可以从该词在语料中的上下文学习得到该词的语义，同时也可以得到相同上下文下不同的词之间的联系。 结合上文提到的分布式表示的思想，我们可以想到：我们可以用某个词以及该词所指代的实体所具备的属性和特征来表示该词。 再举个不恰当例子： 如何表示“程序猿”和“单身狗”这两个词呢？假设我们有以下特征向量序列： [ &quot;有头发&quot;, &quot;人傻&quot;, &quot;钱多&quot;, &quot;死得快&quot; ] 我们可以设定: 程序猿 = [0.3, 0.6, 0.6, 0.6] 同样的，我们可以设定： 单身狗 = [0.6, 0.7, 0.3, 0.5] 基于此，我们便得到了“程序猿”和“单身狗”的语义相似度为： \\sqrt{( 1 - \\left| 0.3 - 0.6 \\right|)^2 +( 1 - \\left| 0.6 - 0.7 \\right|)^2 + ( 1 - \\left| 0.6 - 0.3 \\right|)^2 + ( 1 - \\left| 0.6 - 0.5 \\right|)^2} = 0.72从中我们可以得到“程序猿”和“单身狗”这两个词还是挺接近的。 注意：以上具体数值和计算公式是自己瞎掰的。 具体到属性特征有哪些以及具体每个词的分量数值应该是多少，这个神经网络是可以自己去学的，只不过学到的可以被视为潜在语义信息，并不是直观的”有头发”, “人傻”, “钱多”, “死得快”等特征，通常都是不可解释的。 总之，通过类似以上的方式，单词的语义信息就被比较有效的编码和表示起来了。这时我们再回顾一下之前的Word2Vec和最近非常火的BERT，则可以被视为以上思想的工程实践。只不过训练方式和优化目标愈加完善，使得词表示可以包含更多更好的语义表示罢了。 总结机器学习也好，深度学习也罢，其任务目标都是想要学习现实世界中某些量与某些量之间的映射变化关系。只不过有的关系是线性的，比较简单，而有的则极其复杂。对于这些复杂的问题，才是深度学习的用武之地。 许多任务都可以被看作是回归或分类问题，正如老子云：“天下皆知美之为美，斯恶已。”，美丑两端即定义一个维度。 对于神经网络的理解，也可以从还原论的哲学思想来入手。 参考 Word Embeddings: Encoding Lexical Semantics [透析]卷积神经网络CNN究竟是怎样一步一步工作的？ 通俗理解word2vec 自然语言处理—-文本表示","categories":[{"name":"深度学习","slug":"深度学习","permalink":"https://www.iamlightsmile.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/tags/NLP/"},{"name":"深度学习","slug":"深度学习","permalink":"https://www.iamlightsmile.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"大学数学与深度学习","slug":"大学数学与深度学习","date":"2019-04-22T07:45:42.000Z","updated":"2020-01-18T11:50:57.832Z","comments":true,"path":"articles/大学数学与深度学习/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E5%A4%A7%E5%AD%A6%E6%95%B0%E5%AD%A6%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/","excerpt":"我们都知道，世间的万事万物都是彼此联系和不断发展的。而我们要生存发展进步，则要不断地去尝试探索理解彼此之间到底是如何联系和发展的，要得到那些定性和定量的规律，哲学和数学以及其他学问在此基础上产生不断进化繁衍。 而事物与事物之间的关联法则与映射关系即对应于数学中函数这一概念，函数即是定义和研究自变量和因变量之间的映射关系的。","text":"我们都知道，世间的万事万物都是彼此联系和不断发展的。而我们要生存发展进步，则要不断地去尝试探索理解彼此之间到底是如何联系和发展的，要得到那些定性和定量的规律，哲学和数学以及其他学问在此基础上产生不断进化繁衍。 而事物与事物之间的关联法则与映射关系即对应于数学中函数这一概念，函数即是定义和研究自变量和因变量之间的映射关系的。 事物之间的联系有简单线性的，也有复杂非线性的，对于简单线性的，古人们通过初等数学等知识即可求解，而复杂非线性的则常常无能为力。 而微积分，作为复杂函数计算的有力工具，使得我们可以解决原本无法使用初等数学知识无法解决的问题，进而极大地推动了科学的发展和技术的进步。 然而尽管如此，许多现实中的复杂问题即使是微积分也无能为力，因为我们甚至无法得到其可以用数学公式表达的形式，同时数学作为研究数与形的学问也并非能解决所有问题。 虽然不能直捣黄龙，理解许多世界中的本质规律，但是我们可以通过抽象近似和归纳统计等方式另觅它径，以达曲径通幽之妙。 如通过“以直代曲”的核心思想，我们可以把许多非线性问题近似看作线性问题，从而使用线性代数来研究其规律。 同时我们也可以使用统计学和概率学知识不去细微探索直接探究其本质关联规律，而是在基于统计的基础上跳出局部站在比较宏观的角度建立起现象与现象之间的数学关系，从而得到表层的统计规律。 再如最近很火的神经网络、深度学习等，其本质则是用含有大量参数的神经网络模型不断地优化更新参数，来去尽可能地拟合变量之间的对应关系。","categories":[{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://www.iamlightsmile.com/tags/%E6%95%B0%E5%AD%A6/"}]},{"title":"数理统计学","slug":"数理统计学","date":"2019-04-22T07:28:33.000Z","updated":"2020-01-18T12:15:54.678Z","comments":true,"path":"articles/数理统计学/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E5%AD%A6/","excerpt":"","text":"数理统计学只是从数量表现的层面上来分析问题，完全不触及问题的专业内涵。 数理统计方法是一个中立性的工具，这“中立”的含义是，它既不在任何问题上有何主张，也不维护任何利益或在任何学科中坚持任何学理。 由于数理统计方法只是从表面上的数量关系来分析问题，其结论不可混同于因果关系。","categories":[{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://www.iamlightsmile.com/tags/%E6%95%B0%E5%AD%A6/"}]},{"title":"向量与矩阵","slug":"向量与矩阵","date":"2019-04-22T07:10:37.000Z","updated":"2020-01-18T11:55:38.446Z","comments":true,"path":"articles/向量与矩阵/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E5%90%91%E9%87%8F%E4%B8%8E%E7%9F%A9%E9%98%B5/","excerpt":"线性代数的基本研究单位是向量。 向量可以视为存储信息和结构的基本量。 矩阵既可以视为一组向量的集合，也可以视为一组向量的映射关系。","text":"线性代数的基本研究单位是向量。 向量可以视为存储信息和结构的基本量。 矩阵既可以视为一组向量的集合，也可以视为一组向量的映射关系。","categories":[{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://www.iamlightsmile.com/tags/%E6%95%B0%E5%AD%A6/"}]},{"title":"大学数学基础体系脉络","slug":"大学数学基础体系脉络","date":"2019-04-22T06:50:35.000Z","updated":"2020-01-18T11:50:50.604Z","comments":true,"path":"articles/大学数学基础体系脉络/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E5%A4%A7%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E4%BD%93%E7%B3%BB%E8%84%89%E7%BB%9C/","excerpt":"一般来说，问题总是可以分成两类：连续问题和离散问题。相应的，大学数学中高等数学（也就是说微积分）是用来解决连续问题的，关心的函数的变量可以都非常小；而线性代数则是用来解决离散问题的，关心的是维度。","text":"一般来说，问题总是可以分成两类：连续问题和离散问题。相应的，大学数学中高等数学（也就是说微积分）是用来解决连续问题的，关心的函数的变量可以都非常小；而线性代数则是用来解决离散问题的，关心的是维度。 以下是来自万门大学童哲校长在线性代数两日特训班中所画的简单说明图：","categories":[{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://www.iamlightsmile.com/tags/%E6%95%B0%E5%AD%A6/"}]},{"title":"整体论与还原论","slug":"整体论与还原论","date":"2019-04-22T06:26:43.000Z","updated":"2020-01-18T11:56:13.415Z","comments":true,"path":"articles/整体论与还原论/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E6%95%B4%E4%BD%93%E8%AE%BA%E4%B8%8E%E8%BF%98%E5%8E%9F%E8%AE%BA/","excerpt":"还原论所谓还原，是一种把复杂的系统（或者现象、过程）层层分解为其组成部分的过程。还原论认为，复杂系统可以通过它各个组成部分的行为及其相互作用来加以解释。还原论方法是迄今为止自然科学研究的最基本的方法，人们习惯于以“静止的、孤立的”观点考察组成系统诸要素的行为和性质，然后将这些性质“组装”起来形成对整个系统的描述。例如，为了考察生命，我们首先考察神经系统、消化系统、免疫系统等各个部分的功能和作用，在考察这些系统的时候我们又要了解组成它们的各个器官，要了解器官又必须考察组织，直到最后是对细胞、蛋白质、遗传物质、分子、原子等的考察。现代科学的高度发达表明，还原论是比较合理的研究方法，寻找并研究物质的最基本构件的做法当然是有价值的。","text":"还原论所谓还原，是一种把复杂的系统（或者现象、过程）层层分解为其组成部分的过程。还原论认为，复杂系统可以通过它各个组成部分的行为及其相互作用来加以解释。还原论方法是迄今为止自然科学研究的最基本的方法，人们习惯于以“静止的、孤立的”观点考察组成系统诸要素的行为和性质，然后将这些性质“组装”起来形成对整个系统的描述。例如，为了考察生命，我们首先考察神经系统、消化系统、免疫系统等各个部分的功能和作用，在考察这些系统的时候我们又要了解组成它们的各个器官，要了解器官又必须考察组织，直到最后是对细胞、蛋白质、遗传物质、分子、原子等的考察。现代科学的高度发达表明，还原论是比较合理的研究方法，寻找并研究物质的最基本构件的做法当然是有价值的。 整体论与还原论相反的是整体论，这种哲学认为，将系统打碎成为它的组成部分的做法是受限制的，对于高度复杂的系统，这种做法就行不通，因此我们应该以整体的系统论观点来考察事物。比如考察一台复杂的机器，还原论者可能会立即拿起螺丝刀和扳手将机器拆散成几千、几万个零部件，并分别进行考察，这显然耗时费力，效果还不一定很理想。整体论者不这么干，他们采取比较简单一些的办法，不拆散机器，而是试图启动运行这台机器，输入一些指令性的操作，观察机器的反应，从而建立起输入──输出之间的联系，这样就能了解整台机器的功能。整体论基本上是功能主义者，他们试图了解的主要是系统的整体功能，但对系统如何实现这些功能并不过分操心。这样做可以将问题简化，但当然也有可能会丢失一些比较重要的信息。 还原论与整体论的关系还原论与整体论之争由来已久，并且激发了脑研究和人工智能领域内的大争论。还原论方法将大脑还原为神经元，然后设法将神经元组装成大脑。人工智能的一个学派认为，通过创造元数字电路，我们能够建造越来越复杂的电路，直到我们创造人工智能。这个学派沿着现代电子计算机这条思路，对“智能”的模仿取得了初步的成功，但深入下去就比较令人失望，因为它甚至连模仿大脑的最简单功能，比如模糊记忆，都无法做到。面对人工智能研究的窘境，一些科学家从研究方法上进行反思，认为还原论方法在人工智能的研究方面没有前途，应设法采取一种更加整体的方法对待大脑，不必纠缠于人脑运作中的一些细小环节，应该建立起把大脑视为整体的模型，将大脑的一些基本功能从一开始就建造在这个模型系统里。神经网络理论基本上就是基于这样一种方法而建立起来的理论模型，这是一种功能主义的整体研究方式。这种方式现在看来也是困难重重，不过它才刚刚起步，其未来的前途如何尚未可知。 我的观点是，还原论与整体论作为两种不同的研究方法，它们本身无所谓优劣之分，我们具体选择哪种方法，这完全视乎具体情形，并取决于我们个人的喜好。在某种情形下我们采取还原的方法，在另外的情形下我们可能会采取整体论的方法，这都是可以的。但是，在大多数情况下，人们倾向于采用还原论方法，这比较可靠，也比较能够满足我们寻根究底的好奇心，所以只要有可能，人们总是乐于使用它。 事实上整体论总是只能进行一些初步的研究，一旦深入下去就必须使用还原论的方法。因此，对待自然界，我们总是首先了解其大致的、整体的规律，这是整体论的方法，接着一定要再对它层层进行还原分解，以此考察和研究它的深层次本质规律。例如为了研究人体的生物性状，我们首先了解各个系统，如消化系统、神经系统、免疫系统等的功能，这时候我们是将各个系统当作一个整体来予以研究的；而接着，我们要继续研究组成系统的各器官的功能，再接着是组织、细胞、分子、原子等层面，这便是一个逐层还原的过程。随着层层还原过程的深入，我们对人体的机制就能够得到越来越多的了解。 是的，对那些过于复杂的系统，比如人的大脑，还原论方法到达一定地步之后就会显得异常繁难，人类的心智看来根本就无法做到将其彻底还原，这时候我们不得不退而求其次，对系统的某些细节忽略不计，从而引进一种比较整体的功能主义研究方式。类似地，对于像“视窗”这样复杂的软件系统，整个系统的逻辑是非常复杂的，如果有人想要模拟而不是剽窃这个系统，最好的办法是：在了解它的功能后再另行编制一个具有几乎相同功能的系统。如果妄想将一台装有“视窗”系统的电脑拆散，从物理的角度了解整个系统的逻辑结构，然后再一一复制出来，这肯定极其艰难甚至劳而无功。所以，对人的大脑采取功能主义的整体论方式进行模拟将比还原论方法也许更为行之有效。 但是，即使对复杂系统的研究，人类的心智有时候会变得一筹莫展，这也并不意味着还原论就没有价值。因为我们需要知道：系统的表现为什么会是这样？如果我们将一部哪怕最简单的计算器拿到古代，古代的科学家也可能被迫采取整体论的方式对它进行研究，他们或许能了解其主要功能，知道它可以用于数字计算，但他们必然不清楚：它为什么会是这样的呢？这时候，他们将会多么的遗憾。对人体的研究，虽然我们很难用原子和分子的行为来计算和推导出人的行为，但我们至少希望通过原子和分子的行为来解释和理解人的行为。很显然，我们需要能够直接描述复杂系统的整体定律，所以我们有化学定律、有混沌定律、有经济学定律和社会学定律，但这些定律不会是最基本的定律，我们会问为什么？为什么这些定律是这个样子？这时候，这些定律需要用个体行为来进行解释，需要用 “部分”的行为来进行解释。 还原论的方法肯定是最基本的科学方法。但由于混沌学说的巨大成功，一些人对整体论产生了过分的自信，在今天的很大部分科学哲学家眼里，还原论变成了坏东西，他们为整体论欢呼雀跃，却想法设法要与还原论划清界限。他们走得太远了，他们将整体论的作用过于夸大了，我们有些哲学家甚至还将整体论当作哲学本体论概念来进行介绍，煞有介事地探讨起“世界是简单还是复杂的”这样一些哲学命题来。他们的道理是，整体不等于部分之和，因此自然界是不可彻底还原的，因此整体论才是最优等的哲学。 有这样一个关于还原论的笑话：老师带学生走进实验室，指着一排玻璃仪器，说那是一个人，因为玻璃瓶里装着人的所有组成物质，包括水、碳、脂肪、蛋白质……。这个笑话的实质是说，还原论者只会将“部分”简单地累加起来形成整体，却愚蠢地并不考虑“部分”之间的相互作用。 我以为，认为还原论忽视了部分之间的相互作用，这样的指责毫无根据。还原论并不忽视“部分”之间的相互作用，相反，还原的目的正是为了更好地考察这种相互作用。通过还原，“部分”之间的相互作用变成了每个“部分”的边界条件，变成了每个“部分”的输入和输出，这使得我们能更精确地考察这种作用，并建立起将这些相互作用联系起来的方程。整体确实不等于部分之和，但整体必定等于部分及其相互作用之和。 有些人认为整体论的定律才是最基本的定律，而个体的行为要通过整体的行为来解释，甚至对人类社会也必须采取整体论的方法，认为如果只考察个体，则可能忽略掉人类社会这个群体的一些性质。这种说法是相当奇怪的，人类社会的所有性质归根结底都可以从个体性质及其相互作用而得到解释，虽然我们为了方便起见，可能采取整体论的研究方式，但肯定只有这种整体论的方式才有可能丢失一些重要的信息，而还原论的方式不会。 我们经常听到这样的训诫：使用还原论要谨慎从事。使用整体论更需谨慎从事。如果只是弄出一个整体论的定律，而个体层次发生的事情都以这个整体的行为来进行解释，这样的理论体系是难以令人信服的。 不过，还原论方法虽为我们所偏爱，但还原的过程必然只能进行到一定的层次，这不仅仅因为我们的心智不够，还有更重要的原因：自然界是不可以彻底还原的。 我们知道，世界是普遍联系的，世界上每个事物都和其他每个事物联系着。但事物之间的联系是怎样实现的呢？传统观点认为：不同的东西通过大量的中介过程统一起来，这就是说，事物之间的联系是层层递进的，是定域性的，任何物体只和其邻近产生即时联系，事物的超距作用是不可能的。世界的可还原性就建立在这样的宇宙绘景中，在这样的宇宙中，我们原则上可以将任何系统从宇宙中孤立出来进行考察，这个系统的边界条件是稳定的、可知的，我们可以通过边界条件的变化掌握和了解这个系统的性质和运行规律。将系统孤立的过程就是一个还原的过程，我们可以将大系统分割成一个个的小系统，小系统再细分为更小的系统，这样层层细分下去，从而我们所处的世界至少在理论上是可以彻底还原的。 然而，量子理论表明，世界的联系并不是定域性的。宇宙中的一切物质都存在着即时的普遍联系。在量子理论中，一切事物的运动都应该用波函数来描述，而波函数是遍布整个宇宙的。我现在坐在椅子上，我的身体伴随着有一个波函数，可以肯定这个波函数的值主要集中在我身体占有的空间内，接近100%，但不可能等于100%，在宇宙的其他地方，比如在火星上也会分布有我的波函数，虽然它们的值很小，非常接近于零，但不可能等于零。如果我的身体有任何的运动或变化，比如我动一下手指头，那么伴随我身体的波函数必然也要发生变化，而这个变化产生的影响将会遍布整个宇宙！火星上的一块石头如果“足够”地灵敏，它将会“感受”到这种影响，这种影响虽然非常非常之小，非常非常接近于零，但毕竟不等于零。在这样的宇宙绘景中，宇宙是一个不可分割的整体，如果我们一定要将某个时空孤立起来进行考察，那么由于宇宙中任何的变化都对它有影响，从而它的边界条件将会是整个宇宙！这个边界条件显然是不可知的。而且，外界对系统的作用也并不局限在边界，而是“深入”到系统内的每一个“部分”，这样系统内部的作用“场”也是不可知的。因此，这样的分割还原就变得没有任何实质性的意义。 所以，当我们用还原论的方法对事物进行考察的时候，我们实际上忽略了事物之间联系的量子效应。这样的“忽略”在通常情况下不会有什么问题，毕竟我的波函数在离开我身体哪怕只有一微米的地方就将衰减到几乎为零，它太小了，完全可以忽略不计。但是在那些必须考虑量子效应的地方，比如亚原子领域、比如宇宙“创生”的过程，这样的忽略就不能允许，这时候我们不能再采用还原论的研究方法，我们必须将整个宇宙都作为一个整体来考察。 很显然，只有在局域性不能忽略的地方，还原论才原则上不可行；在不必考虑局域性的地方，还原论原则上可行！ 那么，在还原论原则上不可行的亚原子领域，还原论就没有价值了吗？我认为，还原论仍然有重大的价值。因为，即便是存在非局域性，导致还原论原则上不可行的领域，我们还是需要了解个体的性质，要通过个体的行为来理解（而不是推导）整体的行为。 参考资源 整体论 还原论 刘劲杨：论整体论与还原论之争","categories":[{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://www.iamlightsmile.com/tags/%E5%93%B2%E5%AD%A6/"},{"name":"抽象","slug":"抽象","permalink":"https://www.iamlightsmile.com/tags/%E6%8A%BD%E8%B1%A1/"}]},{"title":"线性代数","slug":"线性代数","date":"2019-04-22T06:26:05.000Z","updated":"2020-01-18T11:55:30.373Z","comments":true,"path":"articles/线性代数/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/","excerpt":"基本介绍线性代数是研究线性空间及其线性映射的，或者说各种线性结构和态射。 价值由于线性结构非常常见，所以线性代数的价值也相当大。","text":"基本介绍线性代数是研究线性空间及其线性映射的，或者说各种线性结构和态射。 价值由于线性结构非常常见，所以线性代数的价值也相当大。 意义和地位线性代数在数学、物理学和技术学科中有各种重要应用，因而它在各种代数分支中占居首要地位。在计算机广泛应用的今天，计算机图形学、计算机辅助设计、密码学、虚拟现实等技术无不以线性代数为其理论和算法基础的一部分。线性代数所体现的几何观念与代数方法之间的联系，从具体概念抽象出来的公理化方法以及严谨的逻辑推证、巧妙的归纳综合等，对于强化人们的数学训练，增益科学智能是非常有用的。随着科学的发展，我们不仅要研究单个变量之间的关系，还要进一步研究多个变量之间的关系，各种实际问题在大多数情况下可以线性化，而由于计算机的发展，线性化了的问题又可以被计算出来，线性代数正是解决这些问题的有力工具。线性代数的计算方法也是计算数学里一个很重要的内容。线性代数的含义随数学的发展而不断扩大。线性代数的理论和方法已经渗透到数学的许多分支，同时也是理论物理和理论化学所不可缺少的代数基础知识。 “以直代曲”是人们处理很多数学问题时一个很自然的思想。很多实际问题的处理，最后往往归结为线性问题，它比较容易处理。因此，线性代数在工程技术和国民经济的许多领域都有着广泛的应用，是一门基本的和重要的学科。 如果进入科研领域，你就会发现，只要不是线性的东西，我们基本都不会！线性是人类少数可以研究得非常透彻的数学基础性框架。学好线性代数，你就掌握了绝大多数可解问题的钥匙。有了这把钥匙，再加上相应的知识补充，你就可以求解相应的问题。可以说，不学线性代数，你就漏过了95%的人类智慧！非线性的问题极为困难，我们并没有足够多的通用的性质和定理用于求解具体问题。如果能够把非线性的问题化为线性的，这是我们一定要走的方向！ 事实上，微积分“以直代曲”的思想就是将整体非线性化为局部线性的一个经典的例子，尽管高等数学在定义微分时并没有用到一点线性代数的内容。许多非线性问题的处理――譬如流形、微分几何等，最后往往转化为线性问题。包括科学研究中，非线性模型通常也可以被近似为线性模型。随着研究对象的复杂化与抽象化，对非线性问题线性化，以及对线性问题的求解，就难免涉及到线性代数的术语和方法了。从这个意义上，线性代数可以被认为是许多近、现代数学分支的共同基础。 参考 线性代数 把非线性转化成线性","categories":[{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://www.iamlightsmile.com/tags/%E6%95%B0%E5%AD%A6/"}]},{"title":"概率论与数理统计","slug":"概率论与数理统计","date":"2019-04-22T06:25:41.000Z","updated":"2020-01-18T11:51:07.211Z","comments":true,"path":"articles/概率论与数理统计/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/","excerpt":"概率论与数理统计的核心是利用微积分工具研究随机现象背后的客观规律性。","text":"概率论与数理统计的核心是利用微积分工具研究随机现象背后的客观规律性。","categories":[{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://www.iamlightsmile.com/tags/%E6%95%B0%E5%AD%A6/"}]},{"title":"微积分","slug":"微积分","date":"2019-04-22T04:04:24.000Z","updated":"2020-01-18T11:55:09.259Z","comments":true,"path":"articles/微积分/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E5%BE%AE%E7%A7%AF%E5%88%86/","excerpt":"1.极限设函数$f(x)$在点$x_0$的某一去心邻域内有定义。若存在常数$A$，对于任意给定的$\\epsilon&gt;0$（不论它多么小），总存在正数$\\delta$，使得当$0&lt;|x-x_0|&lt;\\delta$时，对应的函数值$f(x)$都满足不等式$|f(x)-A|&lt;\\epsilon$，则$A$就叫函数$f(x)$当$x\\to x_0$时的极限，记为 \\lim_{x\\to x_0}f(x)=A或 f(x)\\to A,(x\\to x_0)写成$\\epsilon-\\delta$语言是：$\\lim_{x\\to x_0}f(x)=A\\Leftrightarrow \\forall \\epsilon&gt;0,\\exists \\delta&gt;0$，当$0&lt;|x-x_0|&lt;\\delta$时，$|f(x)-A|&lt;\\epsilon$。","text":"1.极限设函数$f(x)$在点$x_0$的某一去心邻域内有定义。若存在常数$A$，对于任意给定的$\\epsilon&gt;0$（不论它多么小），总存在正数$\\delta$，使得当$0&lt;|x-x_0|&lt;\\delta$时，对应的函数值$f(x)$都满足不等式$|f(x)-A|&lt;\\epsilon$，则$A$就叫函数$f(x)$当$x\\to x_0$时的极限，记为 \\lim_{x\\to x_0}f(x)=A或 f(x)\\to A,(x\\to x_0)写成$\\epsilon-\\delta$语言是：$\\lim_{x\\to x_0}f(x)=A\\Leftrightarrow \\forall \\epsilon&gt;0,\\exists \\delta&gt;0$，当$0&lt;|x-x_0|&lt;\\delta$时，$|f(x)-A|&lt;\\epsilon$。 2.导数参见《高数18讲》p51页 1.导数的概念。 3.增量增量亦称改变量，指的是在一段时间内，自变量取不同的值所对应的函数值之差。 4.微分参见《高数18讲》p53页 5.微分的概念。 自己的浅解微分是相对于某点而言，变量的线形近似增量。 微分的意义参见《高数18讲》p53页中 6.可微的判别【注】(1)。 参考 微分符号 dx、dy 表示什么含义？ - 马同学的回答 - 知乎 积分中dx的意义是什么？ 5.积分参见《高数18讲》p110页 1.原函数与不定积分。 自己浅解微分之和即积分 6.微积分基本定理自己浅解","categories":[{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://www.iamlightsmile.com/tags/%E6%95%B0%E5%AD%A6/"}]},{"title":"Hexo主题继续优化","slug":"Hexo主题继续优化","date":"2019-04-03T16:13:11.000Z","updated":"2020-01-18T11:56:46.446Z","comments":true,"path":"articles/Hexo主题继续优化/","link":"","permalink":"https://www.iamlightsmile.com/articles/Hexo%E4%B8%BB%E9%A2%98%E7%BB%A7%E7%BB%AD%E4%BC%98%E5%8C%96/","excerpt":"本次优化的方向主要围绕以下几点来展开： 自定义背景文字颜色 添加雪花特效 添加爆炸特效 添加输入特效 我当前使用的主题还是比较流行、作者一直在维护的主题Material-X.","text":"本次优化的方向主要围绕以下几点来展开： 自定义背景文字颜色 添加雪花特效 添加爆炸特效 添加输入特效 我当前使用的主题还是比较流行、作者一直在维护的主题Material-X. 自定义背景文字颜色参见Material-X doc中配色描述，将背景和文字颜色设置为暗色主题，同时将主题设置为深绿色，效果如图所示： 注意：如果是单纯修改以上内容，其实并不能生效，还要关闭主题的_config.yml文件中的cdn服务，如下图所示： 添加雪花特效从站长之家找到的JS制作雪花飘落背景动画特效, 下载后将两个js放入source目录下的js目录中，并在layout目录下的layout.ejs中添加相关script路径，如下图所示： 添加爆炸特效发现生如夏花的博客的点击效果比较炫酷，查看其发布的文章并没有介绍具体实现，于是查看其网页源码，得到了对应的fireworks.js文件，同雪花特效一样添加到指定路径并配置路径，如下图所示： 添加输入特效发现搅拌糖对主题进行了炫酷的DIY，如背景切换，滑动栏自定义等，同上查看了其网页源码，得到cooltext.js文件，同雪花特效一样添加到指定路径并配置路径，如下图所示： 经过以上步骤，hexo主题又得到了进一步的自定义优化。 ps：花了许多时间排查看板娘插件是如何出现的，自己只是安装的依赖库，并没有配置，然而却被渲染到最终的生成页面中，真是百思不得其解，由于个人不太喜欢二次元，同时手机端看起来体验不好（占了很大的空间），最终选择将依赖库移除从而去除掉了看板娘效果。","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.iamlightsmile.com/tags/Hexo/"},{"name":"blog","slug":"blog","permalink":"https://www.iamlightsmile.com/tags/blog/"}]},{"title":"Manjaro下数据备份","slug":"Manjaro下数据备份","date":"2019-04-03T06:25:51.000Z","updated":"2020-01-18T11:57:51.931Z","comments":true,"path":"articles/Manjaro下数据备份/","link":"","permalink":"https://www.iamlightsmile.com/articles/Manjaro%E4%B8%8B%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD/","excerpt":"Linux一时爽，崩后火葬场；Manjaro一时爽，一直用一直爽。 以下简单介绍几种manjaro下进行数据备份的方案选择以及一些使用流程。其中自己编写的使用流程如下 使用百度云盘+ baidupcs-go 使用Google Drive MEGA 使用sftp直连数据备份方案 物理介质 自己搭建私有云 选择网盘服务商 其他方案","text":"Linux一时爽，崩后火葬场；Manjaro一时爽，一直用一直爽。 以下简单介绍几种manjaro下进行数据备份的方案选择以及一些使用流程。其中自己编写的使用流程如下 使用百度云盘+ baidupcs-go 使用Google Drive MEGA 使用sftp直连数据备份方案 物理介质 自己搭建私有云 选择网盘服务商 其他方案 物理介质1. 移动硬盘优势：离线存储，简洁快速，数据安全劣势：丢失无法找回，不能自动同步 2. 移动U盘优势：离线存储，简洁快速，数据安全劣势：丢失无法找回，不能自动同步 自己搭建私有云1. Owncloud优势：数据安全劣势：搭建成本高搭建教程： 如何搭建私密云存储之ownCloud 2. NextCloud优势：数据安全劣势：搭建成本高搭建教程: Ubuntu16.04 搭建NextCloud私有云3. Seafile优势：数据安全劣势：搭建成本高搭建教程： 部署Seafile搭建自己的网盘 选择网盘服务商1. 百度网盘优势：容量大劣势：限速，建议使用 BaiduPCS-Go工具进行管理 2. Google Drive优势：跨平台劣势：需要翻墙，容量小 3. MEGA优势：Linux下使用体验好劣势： 坚果云优势：劣势：容量小 其他方案1. 有道云笔记（VIP版）和印象笔记相比，虽然网页剪裁的功能弱了一些，但是在界面上和markdown支持上都是要优于印象笔记的优势：劣势： 2. 使用sftp连接远程服务器优势：劣势： 使用流程百度网盘+BaiduPCS-Go安装baidupcs-goyay -S baidupcs-go-bin 启动baidupcs 如图所示： 登录BaiduPCS-Go &gt; login 然后输入自己的账号密码，进行验证之后便登录成功了，如图： 使用输入-h可查看相关指令，下载起来速度很快。 BaiduPCS-Go &gt; -h 可参考 BaiduPCS-Go | 百度网盘命令行工具（基于 Go） Google Drive安装kio-gdriveyay -S kio-gdrive 使用在安装成功后，此时再打开Dolphin（即文件管理器），会发现远程网络中多了一个文件夹，如图：之后我们双击它，得到如图：上图左侧的账号是我之前添加的，此时也可点击 下方+添加Google账号然后选中要同步的账号，选中，如下图所示，然后点击确定。之后右下角提示正在同步文件夹，稍等片刻便可同步成功了，如图： 可参考 KIO GDriveMEGA注册账号登录官网注册账号，填写个人信息，然后打开邮箱进行验证，随后下载客户端应用（对于manjaro来说，直接通过pacman下载就可以，就是这么方便，当然也可以先下载安装包，然后通过pacman -U来安装） 安装yay -S megasync 设置个人信息首先[Alt] + [Space]打开plasma搜索，输入megasync打开MEGA客户端，然后输入邮箱密码，接着设置同步目录，其他设置自己看情况。如下图： 可参考 网盘可以良心到什么程度? 试试MEGA吧! 使用sftp直连使用方式很简单，如下图：双击连接网络文件夹，选择安全Shell，点击Next填写网络文件夹信息，然后点击保存并连接如果填写无误的话，就连接成功了，如图：","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"Manjaro","slug":"Manjaro","permalink":"https://www.iamlightsmile.com/tags/Manjaro/"}]},{"title":"Manjaro下vscode中zsh乱码","slug":"Manjaro下vscode中zsh乱码","date":"2019-04-03T06:24:25.000Z","updated":"2020-01-18T11:58:01.102Z","comments":true,"path":"articles/Manjaro下vscode中zsh乱码/","link":"","permalink":"https://www.iamlightsmile.com/articles/Manjaro%E4%B8%8Bvscode%E4%B8%ADzsh%E4%B9%B1%E7%A0%81/","excerpt":"解决方案","text":"解决方案 下载Menlo for Powerline字体git clone https://github.com/abertsch/Menlo-for-Powerline.git 将字体放到ttf文件夹中cd Menlo-for-Powerline sudo cp *.ttf* /usr/share/fonts/TTF/ sudo fc-cache -f -v # 刷新字体 设置vscode中终端的字体为Menlo for Powerline参考 在Ubuntu 18.04系统下vscode中zsh乱码的解决方法","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"Manjaro","slug":"Manjaro","permalink":"https://www.iamlightsmile.com/tags/Manjaro/"}]},{"title":"torchtext安装","slug":"torchtext安装","date":"2019-04-03T06:20:52.000Z","updated":"2020-01-18T11:58:39.823Z","comments":true,"path":"articles/torchtext安装/","link":"","permalink":"https://www.iamlightsmile.com/articles/torchtext%E5%AE%89%E8%A3%85/","excerpt":"","text":"使用如下命令安装torchtext pip install https://github.com/pytorch/text/archive/master.zip","categories":[{"name":"深度学习","slug":"深度学习","permalink":"https://www.iamlightsmile.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/tags/NLP/"},{"name":"深度学习","slug":"深度学习","permalink":"https://www.iamlightsmile.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"Pytorch","slug":"Pytorch","permalink":"https://www.iamlightsmile.com/tags/Pytorch/"}]},{"title":"Manjaro下截屏及设置快捷键","slug":"Manjaro下截屏及设置快捷键","date":"2019-04-03T06:19:40.000Z","updated":"2020-01-18T11:57:38.064Z","comments":true,"path":"articles/Manjaro下截屏及设置快捷键/","link":"","permalink":"https://www.iamlightsmile.com/articles/Manjaro%E4%B8%8B%E6%88%AA%E5%B1%8F%E5%8F%8A%E8%AE%BE%E7%BD%AE%E5%BF%AB%E6%8D%B7%E9%94%AE/","excerpt":"我认为当前Manjaro下最好的截屏工具要属deepin-screenshot了。","text":"我认为当前Manjaro下最好的截屏工具要属deepin-screenshot了。 下载安装yay -S deepin-screenshot 配置系统快捷键在【系统设置】-【工作区】-【自定义快捷键】中，点击【编辑】-【新建】-【全局快捷键】-【命令/URL：】然后填写动作名称，如我这里是Deepin截图,然后分别填写注释（非必须）、触发器和动作，如下图： 然后就可以尽情使用啦，不得不感慨deepin真的挺强挺好的！","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"Manjaro","slug":"Manjaro","permalink":"https://www.iamlightsmile.com/tags/Manjaro/"}]},{"title":"Manjaro下安装使用kenlm","slug":"Manjaro下安装使用kenlm","date":"2019-04-03T06:18:33.000Z","updated":"2020-01-18T11:57:28.664Z","comments":true,"path":"articles/Manjaro下安装使用kenlm/","link":"","permalink":"https://www.iamlightsmile.com/articles/Manjaro%E4%B8%8B%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8kenlm/","excerpt":"kenlm是一个linux下快速轻量的语言模型训练工具。","text":"kenlm是一个linux下快速轻量的语言模型训练工具。 下载git clone https://github.com/kpu/kenlm.git 或者 wget https://kheafield.com/code/kenlm.tar.gz | tar xz 安装依赖yay -S boost eigen 编译安装以上两种来源区别我也不是很清楚，没有细究。 mkdir kenlm/build cd kenlm/build cmake .. make -j8 make install 安装Python库以上下载的文件中有python安装脚本setup.py文件，执行 python setup.py install 或者， pip install https://github.com/kpu/kenlm/archive/master.zip 或者从pypi源安装， pip install kenlm 训练模型准备训练数据首先我们需要有一个分好词的语料文件，如： 训练然后使用以下命令训练： lmplz -o 3 &lt;pku_training.utf8&gt; lm_ng3.arpa 其中-o参数指明n-gram语法为3，&lt;&gt;中的为训练语料路径，后面跟模型保存路径 模型压缩对模型压缩可以提高加载速度，不压缩也可以 build_binary -s lm_ng3.arpa lm_ng3.bin 使用Python接口import kenlm import jieba model = kenlm.LanguageModel(&#39;./lm_ng3.bin&#39;) sent_1 = &#39;哈哈，我是李磊，你好呀&#39; sent_2 = &#39;安赛飞啊，诶爱尔兰&#39; def process(sent): return &#39; &#39;.join(jieba.cut(sent)) print(model.score(process(sent_1)) print(model.score(process(sent_2)) 结果输出： -40.40456008911133 -47.40667724609375 其中，分数越小，句子分数越低，越”不像“一个句子。 参考 kenlm kenlm语言模型相关，c++、python相关接口 网易云课堂-微专业-AI工程师（自然语言处理方向）","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"Manjaro","slug":"Manjaro","permalink":"https://www.iamlightsmile.com/tags/Manjaro/"}]},{"title":"Manjaro系统报错集锦","slug":"Manjaro系统报错集锦","date":"2019-04-03T06:17:26.000Z","updated":"2020-01-18T11:57:16.687Z","comments":true,"path":"articles/Manjaro系统报错集锦/","link":"","permalink":"https://www.iamlightsmile.com/articles/Manjaro%E7%B3%BB%E7%BB%9F%E6%8A%A5%E9%94%99%E9%9B%86%E9%94%A6/","excerpt":"以下是自己在使用manjaro系统中遇到的错误和相应的解决方案 unable to initialize decompress status for section .debug_info以及file not recognized: file format not recognized 进入grub rescue模式","text":"以下是自己在使用manjaro系统中遇到的错误和相应的解决方案 unable to initialize decompress status for section .debug_info以及file not recognized: file format not recognized 进入grub rescue模式 1. unable to initialize decompress status for section .debug_info以及file not recognized: file format not recognized错误出处在安装kenlm库以及allennlp时报的安装错误; 更新：在安装scrapy框架及其依赖库twisted时也报了同样的错误，解决方法一样。 报错截图 解决方案从arch包源下载旧版的bintools,然后降级安装,如图: 参考 [SOLVED]unable to initialize decompress status for section .debug_info 2. 进入grub rescue模式错误出处在系统启动过程中由于目录分区映射及挂载失败导致 解决方案注意:我这里boot目录和根目录分别挂载在不同分区,所以后续路径可能和其他参考有所不同，在使用时视实际情况而定 确定boot目录和根目录位置# ls查看一下设备状态，可使用tab键自动补全，并有各分区提示信息 grub rescue&gt; ls hd0, (hd0, gpt1), (hd0, gpt2), (hd0, gpt3) grub rescue&gt; ls (hd0,gpt3)/ ./ ../ lost+found/ 通过查看找到boot目录和root目录所在分区，比如分别为gpt1和gpt2 设置grub的启动分区和路径```grub rescue&gt; set root=(hd0,gpt1) #设置grub启动分区grub rescue&gt; set prefix=(hd0,gpt1)/grub #设置grub启动路径 查看一下设置情况,直接输入set可以查看root和prefix的配置grub rescue&gt; setprefix=(hd0,gpt1)/grubroot=hd0,gpt1 3. 加载基本模块 grub rescue&gt; insmod normal #加载基本模块 4. 进入正常模式 grub rescue&gt; normal #进入普通模式，出现菜单，如果加载grub.cfg（错误的）可能出现问题，按shift可以出现菜单，之后按c键进入控制台 进入正常模式后就会出现grub&gt;这样的提示符，在这里支持的命令就非常多了。 5. 引导系统 grub&gt; set root=(hd0,gpt1) #设置正常启动分区grub&gt; linux /vmlinuz-4.19-x86_64 ro text root=/dev/sda2 #加载内核，进入控制台模式grub&gt; initrd /intel-ucode.img /initramfs-4.19-x86_64.img #加载initrd.imggrub&gt; boot #引导 6. 更新grub 进入系统后，先更新grubupdate-grub #更新 修改grub.cfg后，再执行installgrub-install /dev/sda #安装```注意:注意上面的是sda，硬盘号，而不是具体某个分区号，如sda1 参考 grub rescue救援模式的处理 Ubuntu开机出现grub rescue模式修复方法 Ubuntu启动问题以及Grub Rescue修复方法","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"Manjaro","slug":"Manjaro","permalink":"https://www.iamlightsmile.com/tags/Manjaro/"}]},{"title":"Tensorflow编译血泪史","slug":"Tensorflow编译血泪史","date":"2019-04-03T06:14:59.000Z","updated":"2020-01-18T11:58:32.128Z","comments":true,"path":"articles/Tensorflow编译血泪史/","link":"","permalink":"https://www.iamlightsmile.com/articles/Tensorflow%E7%BC%96%E8%AF%91%E8%A1%80%E6%B3%AA%E5%8F%B2/","excerpt":"为了安装tensorflow，导致我Linux系统重装，Windows系统差点也没了，哎。。。","text":"为了安装tensorflow，导致我Linux系统重装，Windows系统差点也没了，哎。。。 本人笔记本电脑有一个256 SSD和1TB机械硬盘，固态装C盘，机械硬盘装D、E和F，各330G，系统为Win10，显卡为NVIDIA1060。后来打算装manjaro双系统，进行编程和机器学习、深度学习的开发工作，于是F盘分了一半约160G给manjaro系统，其中根目录和家目录等单独划分分区挂载，根目录分区大小为30G，此是前话。 在安装tensorflow之前自己先装了pytorch，因为觉得这个框架代码更优雅，代码风格自己更喜欢。后来在安装tensorflow时发现还挺麻烦，需要独立cuda和cudnn库，不同版本的tensorflow依赖于不同版本的cuda和cudnn，而cuda和cudnn依赖于gcc，如下图所示。 而manjaro系统属于arch系，各软件包滚动更新速度很快，基本总是保持最新，比如系统默认python环境竟然时3.7.2，我的个乖乖，自己的系统里安装的gcc是此时最新的8.2.1，与cuda所需的gcc6冲突，如果要装gcc6还要卸载gcc8，而其他软件包会依赖于gcc8，况且安装旧版本包这种行为一点都不arch，于是使用tensorflow官方预编译好的whl文件安装就不太现实了，只能自己在本机上编译构建了，幸好网上搜到了一篇最近的、讲得很好很详细、和自己情况正相符的一篇帖子：编译 Tensorflow 1.10 + CUDA9.2 + MKL，在这里向作者由衷的表示感谢！ 于是便红红火火按照教程开始来装了，于是问题旧开始出现了。首先问题是当下载了tensorflow源码之后发现自己不能切换安装版本，如果选择默认master以外的分支，则报无法引用到/tensorflow/tools/bazel.rc文件的错误，于是只能在master分支装吧，不管了。如图： 同时发现自己访问github下载文件的速度太慢了，导致bazel程序运行失败，后来找到了相关博客如git clone速度太慢的解决办法进行配置，发现还是未解决，自己在命令前加proxychains代理也不行，因为是程序内部调用系统网络去下载文件，代理命令无效，经过多次尝试后，自己打算通过浏览器下载一个文件试试，如https://github.com/bazelbuild/rules_closure/archive/9889e2348259a5aad7e805547c1a0cf311cfcd91.tar.gz,发现下载的挺快的，是因为代理，而自己直接调用wget命令发现好慢，同时还发现了该文件的最终下载域名为：codeload.github.com，后来自己参考那个教程在https://www.ipaddress.com/里搜索得到了对应的ip并将其和ip加到hosts文件中，如图所示：速度一下就快了不少，虽说只有几十k，但是也比之前的几十几百b强，同时安装也不报下载文件失败访问不了文件的错误了。 后来又遇到：invalid conversion from &#39;const char*&#39; to &#39;char*&#39;这样的代码error，于是网上找到了invalid conversion from ‘const char‘ to ‘char‘ 的解决方法这篇文章，于是便修改了报错处的源码，重新继续编译，看着编译进行的挺顺利，自己还蛮开心的，可谁知命运给自己开的玩笑才刚刚开始。 经过了漫长的编译时间，突然又报错了，说是什么文件访问失败，没有剩余空间了，当时我就蒙了，这是咋回事，后来发现：根目录所在分区满了，安装过程中所有文件都保存在根目录所在分区，即已经到了30G了，使用df -h命令查看所在分区使用率已经到了100%，我擦！！！ 这可如何是好，没想到编译个tensorflow这么占存储空间，后来网上查找相关案例和解决方案，暂时只是把用不到的大软件卸载了，如Clion，发现效果不明显，还是占用了29G多，于是心想：老子不装了，不装了还不行吗，回归pytorch，pytorch才是老纸的真爱，卸载之后发现：使用率还是90%，这这这，后来想到满了那就扩充啊，于是就在网上找扩充根目录分区的方法教程，然而历史说明正是这一步开始使我踏进了深渊。 网上搜了不少方法，发现许多都不好使，同时分区满了我装个软件都装不了了，感觉要炸！发现有个说法说在拓展分区之前要先挂载，于是我就尝试着把根目录所在分区给挂载掉了，在卸载时还提示错误，说device is busy，于是网上找到类似如linux umount命令介绍与device is busy解决方法的答案，于是敲下了罪恶的umount -l /，后来系统崩了，重启，发现又好了，哈哈。 后来就想着硬盘F盘还有剩余空间，想划分出来给根目录所在分区，经过尝试之后发现直接划分不行，因为自己没有搞lvm，不能通过卷组或逻辑卷相关的指令操作来进行，后来发现了一个可行的法子是把硬盘中根目录所在分区位置后面的空间腾出来，然后便可以扩充了，把原来的数据放到其他位置就可以了，于是通过这样的操作进行了var挂载分区的移动，感觉还不错，其中主要参考的是linux(manjaro)磁盘迁移/opt /home,而在进行boot分区的移动时发现自己未成功进行boot分区的重新挂载，于是系统又崩了，重启也报错了，进入grub rescue模式中，此时有点慌了，后来找到类似该篇博客grub rescue救援模式的处理所说内容,重新挂载了boot目录，并且重新生成grub配置文件，于是问题解决了。 之后在进行home分区的操作时自己忘记了备份，直接挂载和格式化掉了（通过 mkfs.ext4 /dev/sda*)，发现出了问题之后重新登录都登录不了，因为相关用户信息都没了，只能进入命令行界面，同时home目录为空，后来在各分区找了半天发现没有找到备份，这时自己真的慌掉了，还有不少数据呢，比如项目代码、还有博客环境配置和博客原文件等，找了半天都没能找到可行的办法，因为系统都登录不进去，连修复软件啥的都安装不了，况且天色已晚，于是就先睡了。 等到第二天自己想到可以在window系统上安装然后修复那个分区的数据吧？于是先尝试了DiskGenius软件，发现好像它识别的分区不全，并且也只能恢复文件，会丢失文件名等信息，这样也仅是得到一些文件，不是整体的恢复分区，而后又下载了testdisk软件，经过一阵蒙蔽的操作之后，发现自己的D盘和E盘也不见了，赶忙重启发现还是没有，由于许多软件都是安装在D盘上，所以导致window系统下的环境也出问题了，要炸啊，幸亏自己的chrome浏览器在C盘装的，又下载了DiskGenius，发现还要注册，还挺麻烦，于是又尝试下了绿色破解版，经过扫描，找到了丢失的D盘和E盘，只是其他数据全部都没有了（指manjaro系统下全部信息）。哎，一声长叹之后只能重新再装系统了。 只是可惜了当时探索了不少软件，同时还有不少有用的数据资料，还有自己最新的代码，以及最新的博客环境配置文件和最新的博客原文件。 而后再划分分区安装的时候，有了之前的教训和探索，自己对分区的理解更加深刻，于是在划分时感觉熟悉了好多，把整个300G空间全部给新系统了，同时多分配了一些空间给根目录和var目录所在分区。后来重装系统，还好自己当时写了安装记录的博客在网上可以看，于是又重新安装配置环境，配置NVIDIA独显，配置科学上网，后来心想以后再做记录先只在简书和有道上吧，自己的博客先不管了吧，毕竟环境也丢了，能找到的是好久之前的了，要配置还挺麻烦，博客内容自己自己也增删改的比较多，再捡起来比较耗时，于是暂时就不考虑维护自己的博客了，之前也尝试在知乎专栏和简书上写文章，发现简书支持Markdown效果很好，而知乎则导入效果很差，于是便最终选择了简书作为最终的自己发布内容的平台啦。 后来重新参考之前提到的编译tensorflow的那篇文章，还是只能master分支，还是要配置hosts文件中github对应域名和ip，不过编译的还挺顺利的，不过还是要好久，最终吃了个晚饭，回来发现又报错了，我真的快要崩溃了，报ImportError: No module named keras.preprocessing的错误，后来我就想是不是版本问题，于是切换r1.12和r1.10，发现还是报bazel.rc文件的错，于是又切换回master分支，继续网上找相关问题和答案，并在github上成功找到了答案：1.10 build fails with “No module named ‘keras_applications’” ,即通过pip安装keras_applications和keras_preprocessing这两个库。 后来重新执行编译命令，又等待了好一会儿（比之前快多了，因为有缓存之前的编译结果），终于成功了哈哈哈！后来经过测试，发现编译成功，tensorflow已经被正常安装在自己的pip列表中了。以下是耗时截图： 安装tensorflow的whl包后，发现安装的就是现行版r1.12。。。 这里是分区使用率截图： 相比而言，pytorch安装就要简单许多了，并且提供了许多预编译好的可选。 在这里自己简单记录一下心酸的历程，也提醒各位看客同样需要编译tensorflow时留意自己的分区使用率～","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"Manjaro","slug":"Manjaro","permalink":"https://www.iamlightsmile.com/tags/Manjaro/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"https://www.iamlightsmile.com/tags/Tensorflow/"}]},{"title":"Manjaro下使用图床工具PicGo","slug":"Manjaro下使用图床工具PicGo","date":"2019-04-03T06:12:47.000Z","updated":"2020-01-18T11:57:44.478Z","comments":true,"path":"articles/Manjaro下使用图床工具PicGo/","link":"","permalink":"https://www.iamlightsmile.com/articles/Manjaro%E4%B8%8B%E4%BD%BF%E7%94%A8%E5%9B%BE%E5%BA%8A%E5%B7%A5%E5%85%B7PicGo/","excerpt":"0. 前言在这里简单吐槽以下简书的锁定文章的功能，真是日了狗了！ 因为觉得简书的锁定的文章的功能太恶心，不想受制于人，于是想回到自己的个人博客-Github Pages + Hexo，于是此时图床的问题就来了，原来自己的主要实现逻辑是将图片首先先上传到Github的一个仓库中，写了一个auto_run.sh，然后在浏览器中右击图片得到Markdown格式下的图片连接（自己写了一个浏览器插件），但是还是有些麻烦。","text":"0. 前言在这里简单吐槽以下简书的锁定文章的功能，真是日了狗了！ 因为觉得简书的锁定的文章的功能太恶心，不想受制于人，于是想回到自己的个人博客-Github Pages + Hexo，于是此时图床的问题就来了，原来自己的主要实现逻辑是将图片首先先上传到Github的一个仓库中，写了一个auto_run.sh，然后在浏览器中右击图片得到Markdown格式下的图片连接（自己写了一个浏览器插件），但是还是有些麻烦。 后来网上搜索相关图床工具，得到的方案如下： 搭建私有图床如：使用Chevereto搭建免费私有图床 使用付费图床或免费图床，同时可以配合开源跨平台的的工具PicGo付费的如：又拍云、腾讯云、阿里云、七牛云、微博免费的如：Github 其他相对非主流方案 权衡之后选择使用第二种方案，对于图床而言，自己选择Github，因为有的图床存储还要求备案，如七牛云，很是麻烦。 1. 下载安装PicGo使用如下命令： yay -S picgo-appimage 这里对于arch系来说不算友好，因为如Windows平台、Mac平台以及其他主流Linux系统如Ubuntu等等都有预编译安装包，而对于arch而言要自己下载编译得到appimage形式的可执行软件包。 2. 设置Github仓库略，可参考最后链接给出文章。 3. 设置仓库信息略，可参考最后链接给出文章。不过我这里不知为何设置网络代理并没有成功,同时实际使用时复制速度挺慢的，不知为何。 4. 上传测试 5. 下载其他依赖如果要使用快捷上传的粘贴板功能时，如图： 还需要下载xclip包 yay -S xclip 6. 总结发现PicGo这个软件还真是挺不错的，同时还了解了appimage这种软件形式 7. 参考 Install Appimage under Arch Linux 图床工具的使用—-PicGo PicGo+GitHub图床，让Markdown飞","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"Manjaro","slug":"Manjaro","permalink":"https://www.iamlightsmile.com/tags/Manjaro/"}]},{"title":"python库打包分发","slug":"python库打包分发","date":"2019-02-02T05:11:46.000Z","updated":"2020-01-06T01:32:28.998Z","comments":true,"path":"articles/python库打包分发/","link":"","permalink":"https://www.iamlightsmile.com/articles/python%E5%BA%93%E6%89%93%E5%8C%85%E5%88%86%E5%8F%91/","excerpt":"Python库打包分发主要有以下步骤： 注册PyPI账号（执行一次） 安装打包分发工具（执行一次） 编写setup.py文件 通过命令打包分发","text":"Python库打包分发主要有以下步骤： 注册PyPI账号（执行一次） 安装打包分发工具（执行一次） 编写setup.py文件 通过命令打包分发 1.注册PyPI账号进入PyPI的官网，进去注册账号密码，绑定邮箱等。 在成功注册账号之后，创建～/.pypirc文件，在文件中配置自己的PyPI访问地址和账号密码等信息，如下： [distutils] index-servers = pypi [pypi] username:xxx password:xxx 2.安装打包分发工具这里通过twine来打包安装。 通过以下命令下载： pip install twine 3.编写setup.py文件格式不再详述，具体查看参考1. 举例如： from distutils.core import setup import setuptools with open(&#39;./README.md&#39;, &#39;r&#39;, encoding=&#39;utf8&#39;) as f: long_description = f.read() with open(&#39;./requirements.txt&#39;, &#39;r&#39;, encoding=&#39;utf8&#39;) as f: install_requires = list(map(lambda x: x.strip(), f.readlines())) setup( name=&#39;lightNLP&#39;, version=&#39;0.3.2.0&#39;, description=&quot;lightsmile&#39;s nlp library&quot;, author=&#39;lightsmile&#39;, author_email=&#39;iamlightsmile@gmail.com&#39;, url=&#39;https://github.com/smilelight/lightNLP&#39;, packages=setuptools.find_packages(), install_requires=install_requires, long_description=long_description, long_description_content_type=&#39;text/markdown&#39;, license=&#39;Apache-2.0&#39;, classifiers=[ &#39;Development Status :: 4 - Beta&#39;, &#39;Operating System :: OS Independent&#39;, &#39;Intended Audience :: Developers&#39;, &#39;License :: OSI Approved :: BSD License&#39;, &#39;Programming Language :: Python&#39;, &#39;Programming Language :: Python :: 3&#39;, &#39;Programming Language :: Python :: 3.6&#39;, &#39;Programming Language :: Python :: 3.7&#39;, &#39;Topic :: Software Development :: Libraries&#39; ], ) 4.通过命令打包分发打包在setup.py文件目录下执行： python setup.py sdist bdist_wheel 如果报error: invalid command &#39;bdist_wheel&#39;的错的话，可以执行以下命令： pip install wheel 分发在setup.py文件目录下执行： twine upload dist/* 后记之后便可以登录PyPI网站查看自己的projects了。需要注意的是新建包的名字不能在忽视大小写情况下和其他包重复。 参考 Python 库打包分发(setup.py 编写)简易指南 pypi twine Why is python setup.py saying invalid command ‘bdist_wheel’ on Travis CI? - Stack Overflow","categories":[{"name":"Python","slug":"Python","permalink":"https://www.iamlightsmile.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://www.iamlightsmile.com/tags/Python/"}]},{"title":"Manjaro设置交换分区","slug":"Manjaro设置交换分区","date":"2019-01-24T05:11:13.000Z","updated":"2020-01-18T11:57:04.397Z","comments":true,"path":"articles/Manjaro设置交换分区/","link":"","permalink":"https://www.iamlightsmile.com/articles/Manjaro%E8%AE%BE%E7%BD%AE%E4%BA%A4%E6%8D%A2%E5%88%86%E5%8C%BA/","excerpt":"0.前言在安装Manjaro系统的时候发现自己没有设置交换分区，用htop命令发现是空的，所以这里通过后续的命令配置交换分区。","text":"0.前言在安装Manjaro系统的时候发现自己没有设置交换分区，用htop命令发现是空的，所以这里通过后续的命令配置交换分区。 1.查看磁盘信息使用 sudo fdisk -l 得到如下信息： 2.查看挂载状态使用 sudo blkid -o list 得到如下信息： 3.设置交换分区使用 mkswap /dev/sd** 其中**用具体某个分区名替换，如： 4.启用交换分区使用 swapon /dev/sd** 其中**用具体某个分区名替换，如： 5.查看交换分区状态使用 swapon -s 或者 free -m 如： 6.总结至此便设置交换分区成功了。 7.参考 Swap (简体中文)) Linux系统下如何查看所有存储设备（磁盘分区）","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"Manjaro","slug":"Manjaro","permalink":"https://www.iamlightsmile.com/tags/Manjaro/"}]},{"title":"人生苦短，我用Manjaro！","slug":"人生苦短，我用Manjaro！","date":"2019-01-23T05:10:46.000Z","updated":"2020-05-02T12:22:46.842Z","comments":true,"path":"articles/人生苦短，我用Manjaro！/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E4%BA%BA%E7%94%9F%E8%8B%A6%E7%9F%AD%EF%BC%8C%E6%88%91%E7%94%A8Manjaro%EF%BC%81/","excerpt":"想必每一个程序员心里都有一个Linux。 更新:为了便于自己下次重装系统时更方便一些，这里再把过程详细记录一下。","text":"想必每一个程序员心里都有一个Linux。 更新:为了便于自己下次重装系统时更方便一些，这里再把过程详细记录一下。 0.前言一直想学Linux，之前尝试了Ubuntu和centos，虽然两者非常大众化只是觉得有点丑，后来通过搜索了解到了Arch Linux和Manjaro，简单查看之后，觉得非常喜欢Manjaro的众多特性，于是就想着自己装一下，作为自己以后常用的Linux系统来工作。 关于Manjaro的桌面主题，主要有XFce、Gnome、KDE，同时还有社区版Deepin等，简单的对比之后，决定使用KDE，因为感觉功能更丰富。 之前在公司自己尝试着使用虚拟机装了一版，简单尝试了一下，体验还不错，只是不能使用Nvidia显卡来跑GPU程序，这就比较不爽了，毕竟是虚拟机里的东西，到底不如真机下爽快。 趁着这段时间在家相对空闲，同时Windows10下面的Pytorch突然报错（后来通过pip重新安装已修复），有点不能忍，于是打算在自己的电脑上折腾一下双系统：Windows 10 + Manjaro（KDE）。 根据我的个人体验而言，如果机子配置还可以的话，还是选择KDE版本吧，使用起来比Gnome版还是要方便高级，deepin的没试，不过风格也还不错的。 整体下来流程如下： 下载Manjaro系统镜像文件 制作启动盘及划分efi分区 安装系统 基本配置 安装常用应用 科学上网 使用Nvidia独显 系统安装过程中常见问题 更换主题 添加桌面小部件 1.下载Manjaro系统镜像文件从此处选择下载：https://www.manjaro.cn/153 建议选择中科大的镜像源，好像清华的有些时间没更新了呢。 2.制作启动盘及划分efi分区此处仅介绍Windows环境下 从rufus官网下载启动盘刻录工具 选择ISO镜像刻录到U盘，注意选择DD模式 使用diskpart划分efi分区 详情可参考此教程：manjaro双系统双硬盘的安装 3.安装系统 在电脑启动时，按F2进入BIOS系统设置，设置boot启动顺序 随后F10启动系统，按F12后选择USB启动 在进入Manjaro的boot页面时，可以选择lang为中文，driver这里我选择不开源的nonfree版本好像不行，所以我选择了默认的free版本 在分区划分时可以选择并存安装或取代一个分区，这里自己选择手动分区，划分以下分区： 挂载路径 中文目录 建议大小(至少) 其他说明 / 根目录 40G 略 /boot 启动目录 500M 略 /boot/efi 啥意思不重要 10M 略 /home 家目录 40G 平时自己的数据资料等都放下这个目录下面 /var 变量分区 30G 存放在正常运行的系统中其内容不断变化的文件 /srv 服务进程相关 10G 存放服务进程所需的数据文件和一些服务的执行脚本 /opt 其他软件安装目录 30G 发行版附加的一些软件包，如anaconda、pycharm的安装目录 注意： 不要单独挂载/usr目录到单独的分区，我就是因为这个导致了错误重装系统 如果要安装一些比较大型的软件和包时，那么建议多划分一些磁盘大小给根目录，我有两次是因为拓展根目录重装的系统 注意保留一个分区作为swap交换分区，空间大小为内存大小的一半比较合适（其实我也不是很清楚，好像其他资料有这么说） 系统安装流程可以主要参考：manjaro双系统双硬盘的安装。 关于磁盘分配可参考：manjaro 安装分区以及配置方案 4.基本配置在安装完系统后重启可能进不去桌面，此时可以在Grub菜单启动界面按[E]编辑，并在后面加上（注意空格）nouveau.modeset=1 acpi_osi=! acpi_osi=&#39;Windows 2009&#39;，然后按F10进入系统，在进入系统之后，修改grub的配置文件sudo nano /etc/default/grub，比如我的系统中部分参数如下：，随后使用sudo update-grub命令更新grub文件，在之后使用如果还是不能进入系统甚至进入grub rescue模式，原因可能是分区挂载映射问题等，可以参考我的另一篇文章。 在进入系统后要做一些常规配置。 配置更新源并更新系统 配置中国mirrorssudo pacman-mirrors -i -c China -m rank 随后在出现的窗口中选择更新源，我选择了所有。。。哈哈 添加archlinuxcn和antergos库在/etc/pacman.conf后面添加以下内容：```[archlinuxcn]SigLevel = TrustAllServer = https://mirrors.tuna.tsinghua.edu.cn/archlinuxcn/$arch [antergos]SigLevel = TrustAllServer = https://mirrors.tuna.tsinghua.edu.cn/antergos/$repo/$arch 3. 同步并更新系统 ```bash sudo pacman -Syyu 安装archlinuxcn签名钥匙&amp;antergos签名钥匙sudo pacman -S archlinuxcn-keyring antergos-keyring 安装配置中文输入法 安装搜狗拼音输入法和fcitx管理工具:sudo pacman -S fcitx-sougoupinyin sudo pacman -S fcitx-im sudo pacman -S fcitx-configtool 添加配置~/.xprofile文件：export GTK_MODULE=fcitx export QT_IM_MODULE=fcitx export XMODIFIERS=&quot;@im=fcitx&quot; 可参考：Manjaro linux 安装与配置 5.安装常见应用可参考：Manjaro安装后你需要这样做 以下是一些我的常用应用列表： 软件名称 软件说明 typora Markdown编辑软件 deepin-screenshot Deepin截图工具，相对很好用 latte-dock Dock栏 tmux 终端复用工具 bat 终端文件查看工具 gitkraken 跨平台git可视化操作软件 shadowsocks-qt5 科学上网 visual-studio-code-bin VSCode htop 进程查看工具 neofetch 终端查看配置 zsh 好用的shell yay 比pacman更全更好用 google-chrome chrome浏览器 pycharm 强大的Python集成开发环境 anaconda 数据科学集成环境 electronic-wechat Linux下的微信 netease-cloud-music 网易云音乐 ncdu 磁盘占用分析器 xflux flux护眼程序 redshift 同flux,护眼程序 其他的还可以安装deepin系列的微信、QQ和迅雷，只不过我这里不知为何没有安装成功。 如果有道云笔记有Linux版就爽歪歪了。 6.科学上网 使用yay -S shadowsocks-qt5安装shadowsocks软件，选择qt时直接enter选择所有 打开shadowsocks软件，填写配置信息，或者从图片导入等，然后测试延迟，点击连接，对于某一个连接，可以选择程序启动时自动连接，并且可以设置程序在系统登录时启动。如图： Shadowsocks pac代理 安装genpacpip install genpac 命令行生成pac文件genpac --proxy=&quot;SOCKS5 127.0.0.1:1080&quot; --gfwlist-proxy=&quot;SOCKS5 127.0.0.1:1080&quot; -o autoproxy.pac --gfwlist-url=&quot;https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt&quot; 设置系统自动代理在设置—&gt;网络设置—&gt;代理设置中选择自动代理，URL填写生成的PAC文件地址，file://文件路径/文件名(可以直接把文件拖到URL栏),如图：不过说实在的，不知为何我这里并没有代理成功，玉于是选择了全局代理：可参考：Manjaro17.0.1(xfce)+SS+PAC模式配置笔记linux PAC 自动代理 规则设置 终端代理 安装Proxychainsyay -S proxychains-ng 编辑proxychains配置将最后面的socks4 127.0.0.1 9095 改为 socks5 127.0.0.1 1080如图： 可参考： Manjaro安装记录 7.使用Nvidia独显使用bumblebee版1. 安装驱动及第三方程序在[系统设置]-[硬件设定]里面选择紫色框住的video-hybrid-intel-nvidia-bumblebee，右键点击安装（不得不提真的超方便啊，和其他系统或发行版相比；注意我这里的显卡是1060，如果是9*0的版本，可能安装的是下面390xx的那个版本） 2. 修改配置文件 修改/etc/bumblebee/bumblebee.conf文件将Driver的值设置为nvidia，来让其使用nvidia驱动，其次将nvidia配置下的PMMethod的值设置为bbswitch，让它使用刚刚安装的bbswitch来进行显卡的切换。 修改（没有则新建）/etc/modprobe.d/bbswitch.conf文件添加options bbswitch load_state=0 unload_state=0来设置bbswitch的状态。 重启电脑，不然系统还不知道bbswitch模块 加载bbswitch模块modprobe bbswitch 将用户添加到bumblebee组中gpasswd -a username bumblebee 上面的username替换为自己的用户名，如我的是lightsmile 设置bumblebeed服务为开机自启systemctl enable bumblebeed 启用bumblebeed服务systemctl start bumblebeed 切换使用独显和集显。 打开独立显卡命令：sudo tee /proc/acpi/bbswitch &lt;&lt;&lt; ON 关闭独立显卡命令：sudo tee /proc/acpi/bbswitch &lt;&lt;&lt; OFF 查看nvidia显卡相关信息nvidia-smi 如图所示： 可参考：arch如何使用独显和Manjaro linux 安装与配置 8.系统安装过程中常见问题常见问题可参考：Manjaro linux 安装与配置 9.更换主题自己探索如图所示： 10.添加桌面小部件自己探索桌面右键，选择添加部件，然后在左侧的部件栏中自行选择想要添加的部件，然后可以在桌面中拖放，选择位置，如图： 11.小彩蛋1. 吃豆人 打开/etc/pacman.conf文件 在“# Misc options”部分，去掉“Color”前的“#”。 添加“ILoveCandy”。12.后记 最初后记安装系统容易，不过配置nvidia驱动则比较麻烦，笔者前前后后重装了不下十余次系统，苦心人天不负，最终得以成功安装，真是坑了个爹啦！ 不过最终桌面效果如下，也算小有所获啦～ 新版后记Linux一时爽，崩后火葬场。望大家小心谨慎使用系统，注意及时数据备份，要不是用于编程开发，还是Windows爸爸管着好啊！ 13.参考 Manjaro安装与基本配置 linux PAC 自动代理 规则设置 pyCharm最新2019激活码 manjaro安装及设置 人生苦短，我用Manjaro Bumblebee (简体中文) - ArchWiki) Manjaro安装以及美化教程 Manjaro安装后你需要这样做 Manjaro Deepin安装使用分享 安装Arch Linux之后要做的几件事情 我的 Manjaro🐧 - 网上冲浪指南 Manjaro linux 安装与配置 arch如何使用独显","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.iamlightsmile.com/categories/Linux/"}],"tags":[{"name":"Manjaro","slug":"Manjaro","permalink":"https://www.iamlightsmile.com/tags/Manjaro/"}]},{"title":"个性化hexo主题","slug":"个性化hexo主题","date":"2019-01-07T02:48:35.000Z","updated":"2020-01-18T11:51:48.008Z","comments":true,"path":"articles/个性化hexo主题/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E4%B8%AA%E6%80%A7%E5%8C%96hexo%E4%B8%BB%E9%A2%98/","excerpt":"个性化hexo主题1. 换Material X主题原来自己用的是indigo主题，还是蛮material的，只是后来发现material x的主题更好看，插件更加丰富一些，于是就探索切换了一番，哈哈哈。","text":"个性化hexo主题1. 换Material X主题原来自己用的是indigo主题，还是蛮material的，只是后来发现material x的主题更好看，插件更加丰富一些，于是就探索切换了一番，哈哈哈。 1. 下载主题，设置切换首先把主题下下来，然后在config文件里设置 2. 参考使用文档，添加小部件2. 增加Google统计之前看别人的博客下面有网站运行时间，很是羡慕，猜测是统计插件的原因，后来按照教程探索增加Google Analytics 统计功能，发现并不是这个原因，不过可以更详致的统计网站信息了，虽然现在只有自己看。。。 3. 增加运行时间网上搜索到教程，然后照搬小改完成，原来只是增加一个script脚本，逐渐理解其原理。 4. 增加转载说明参考别人写的个性化hexo博客里有一部分提到了此节，于是将其迁到了ejs中，发现只不过是一段模板代码，初步理解一小点hexo框架原理 5. 增加点击红心功能也是照搬教程，原来也是一段script脚本而已。 6. 增加canvas以及3D效果这个也可以实现，不过考虑实用，并没有加入 7. 增加live2d看板娘效果此技术看起来还是不错的，由于自己本身并不是二次元爱好者，所以就不考虑加入此功能了。 参考网址： 二次元live2d看板娘效果中的web前端技术 给hexo博客增加live2d看板卡通人物动画","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"blog","slug":"blog","permalink":"https://www.iamlightsmile.com/tags/blog/"},{"name":"hexo","slug":"hexo","permalink":"https://www.iamlightsmile.com/tags/hexo/"}]},{"title":"统计学重要知识点","slug":"统计学重要知识点","date":"2019-01-06T04:36:57.000Z","updated":"2020-01-18T11:55:03.596Z","comments":true,"path":"articles/统计学重要知识点/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9/","excerpt":"统计学重要知识点1. 概念 概率：概率是一个事件发生、一种情况出现的可能性大小的数量指标，介于0与1之间。 分布：分布包括离散分布和连续分布，用来表述随机变量取值的概率规律。 概率密度函数（probability density function，PDF）： 在数学中，连续型随机变量的概率密度函数（在不至于混淆时可以简称为密度函数）是一个描述这个随机变量的输出值，在某个确定的取值点附近的可能性的函数。当概率密度函数存在时，累计分布函数式概率密度函数的积分。 累积分布函数（cumulative distribution function，CDF）：又叫分布函数，是概率密度函数的积分，能完整描述一个实随机变量X的概率分布，一般以大写“CDF”标记。","text":"统计学重要知识点1. 概念 概率：概率是一个事件发生、一种情况出现的可能性大小的数量指标，介于0与1之间。 分布：分布包括离散分布和连续分布，用来表述随机变量取值的概率规律。 概率密度函数（probability density function，PDF）： 在数学中，连续型随机变量的概率密度函数（在不至于混淆时可以简称为密度函数）是一个描述这个随机变量的输出值，在某个确定的取值点附近的可能性的函数。当概率密度函数存在时，累计分布函数式概率密度函数的积分。 累积分布函数（cumulative distribution function，CDF）：又叫分布函数，是概率密度函数的积分，能完整描述一个实随机变量X的概率分布，一般以大写“CDF”标记。 伯努利分布（零一分布、两点分布、0-1分布）伯努利试验成功的次数服从伯努利分布 二项分布： 重复n次独立的伯努利试验 泊松分布: 在二项分布的伯努利试验中，如果试验次数n很大，二项分布的概率p很小，且乘积$\\lambda=np$比较适中，则事件出现的次数的概率可以用泊松分布来逼近。事实上，二项分布可以看做泊松分布在离散时间上的对应物。同样的，泊松分布也可看为二项分布在特殊情况下的极限。 大数定律: 在数学与统计学中，大数定律又称大数法则、大数律，是描述相当多次数重复实验的结果的定律。根据这个定律知道，样本数量越多，则其算术平均值就有越高的概率接近期望值。大数定律很重要，因为它“说明”了一些随机事件的均值的长期稳定性。 正态分布: 正态分布又名高斯分布，是一个非常常见的连续概率分布。正态分布是自然科学与行为科学的定量现象的一个方便模型。各种各样的心理学测试分数和物理现象比如光子计数都被发现近似地服从正态分布，尽管这些现象的根本原因经常是未知的，理论上可以证明如果把许多小作用加起来看做一个变量，那么这个变量服从正态分布。 中心极限定理： 中心极限定理是指概率论中讨论随机变量序列部分和分布渐进于正态分布的一类定理。这组定理是数理统计学和误差分析的理论基础，指出了大量随机变量近似服从正态分布的条件。它是概率论中最重要的一类定理，有广泛的实际应用背景。在自然界与生产中，一些现象受到许多相互独立的随机因素的影响，如果每个因素所产生的影响都很微小时，总的影响可以看作是服从正态分布的。中心极限定理就是从数学上证明了这一现象。 离散分布：离散分布描述离散随机变量的每个值的发生概率，如伯努利分布、二项分布、泊松分布。离散随机变量是指具有可计数的值的随机变量，例如非负整数的列表。在离散概率分布中，离散随机变量的每个可能值可与一个非零概率想关联。因此，离散概率分布通常具有表格形式。 连续分布：连续分布描述连续随机变量的可能值的概率，例如正太分布。连续随机变量是一组无限且不可计数的可能值（称为范围）的随机变量。连续随机变量（X）的概率被定义为其PDF曲线下的面积。因此，只有值范围才能具有非零的概率。连续随机变量等于某个值的概率始终为零。 2. 相关1. 概率分布的种类 概率分布要么是连续概率分布，要么是离散概率分布，这取决于它们是定理连续变量还是离散变量的概率。 2. 大数定理和中心极限定理的联系和区别 大数定律（LLN）和中心极限定理（CLT）的联系与区别在于： 共同点：都是用来描述独立同分布（i.i.d）的随机变量的和的渐近表现（asymptotic behavior） 区别：它们描述的是在不同的收敛速度（convergence rate）之下的表现，其次LLN前提条件弱一点：$E(|X|) &lt; \\infty$，CLT条件强一点:$E(X^2) &lt; \\infty$。 假设有n个i.i.d的随机变量，令它们的和为$S_p = \\sum^{n}_{i=1}X_i$.大数定律（以其中弱大数定律为例）说的是$\\frac{1}{n}S_n - E(X) \\underrightarrow{P} 0$.中心极限定理说的是$\\sqrt{n}(\\frac{1}{n}S_n - E(X)) \\underrightarrow{D} N(0,E)$.作者：Detian Deng；来源：知乎；原文链接 大数定律讨论的是依概率收敛，中心极限定理涉及按分布收敛（按分布收敛比点点收敛弱很多啊）。私以为搞清楚随机变量序列的收敛性就是为了方便在样本量很大情况下计算概率。。。 大数定律是说随机变量序列的算术平均以概率收敛到其均值的算术平均。比较经典的运用就是用频率确定概率，比如估计不合格品率，抽样的不合格品比例就是可以作为总体的不合格品率估计值。 中心极限定理说的是给出随机变量和的分布函数在什么条件下收敛到正太分布。比较熟悉的比如用来估计误差，误差基本上都是由这样那样大大小小微小因素叠加的，这些个因素相加就是总的误差，这个时候就要用到参数估计和假设检验了，在认为误差近似正太分布情况下，给出误差上限下限，置信度，判断质量是否达到要求等等工作就可以做了。作者：yyylll；来源：知乎；原文链接 大数定律揭示了大量随机变量的平均结果，但没有涉及到随即变量的分布的问题。而中心极限定理说明的是在一定条件下，大量随机独立变量的平均数是以正态分布为极限的。 3. 泊松分布的现实意义 马同学的讲解：泊松分布的现实意义是什么，为什么现实生活多数服从于泊松分布？ 先说结论：泊松分布是二项分布n很大而p很小时的一种极限形式二项分布是说，已知某件事情发生的概率是p，那么做n次试验，事情发生的次数就服从于二项分布。泊松分布是指某段连续的时间内某件事情发生的次数，而且“某件事情”发生所用的时间是可以忽略的。例如，在五分钟内，电子元件遭受脉冲的次数，就服从于泊松分布。假如你把“连续的时间”分割成无数小份，那么每个小份之间都是相互独立的。在每个很小的时间区间内，电子元件都有可能“遭受到脉冲”或者“没有遭受到脉冲”，这就可以被认为是一个p很小的二项分布。而因为“连续的时间”被分割成无穷多份，因此n(试验次数)很大。所以，泊松分布可以认为是二项分布的一种极限形式。因为二项分布其实就是一个最最简单的“发生”与“不发生”的分布，它可以描述非常多的随机的自然界现象，因此其极限形式泊松分布自然也是非常有用的。作者：ctian；来源：知乎；原文链接 4. 理解概率分布函数和概率密度函数 产品经理马忠信的讲解： 应该如何理解概率分布函数和概率密度函数？ 3. 参考 连续和离散分布 泊松分布 为什么我觉得大数定理和中心极限定理是矛盾的？ 中心极限定理 中心极限定理 正态分布 二项分布、泊松分布、正态分布的关系","categories":[{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://www.iamlightsmile.com/tags/%E6%95%B0%E5%AD%A6/"},{"name":"统计学","slug":"统计学","permalink":"https://www.iamlightsmile.com/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6/"}]},{"title":"概念集锦","slug":"概念集锦","date":"2019-01-05T09:54:10.000Z","updated":"2020-01-18T11:51:22.411Z","comments":true,"path":"articles/概念集锦/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E6%A6%82%E5%BF%B5%E9%9B%86%E9%94%A6/","excerpt":"数学 数学是利用符号研究数量、结构、变化以及空间等概念的一门学科，从某种角度看属于形式科学的一种。数学透过抽象化和逻辑推理的使用，由计数、计算、量度和对物体形状及运动的观察而产生。数学家们拓展这些概念，为了公式化新的猜想以及从选定的公理及定理中建立起严谨推导出的定理。","text":"数学 数学是利用符号研究数量、结构、变化以及空间等概念的一门学科，从某种角度看属于形式科学的一种。数学透过抽象化和逻辑推理的使用，由计数、计算、量度和对物体形状及运动的观察而产生。数学家们拓展这些概念，为了公式化新的猜想以及从选定的公理及定理中建立起严谨推导出的定理。 函数 函数，在数学中，为两集合间的一种对应关系：输入值集合中的每项元素皆能对应唯一一项输入值集合中的元素。 决定论 决定论，是一种哲学立场，认为每个事件的发生，包括人类的认知、举止、决定和行动，都有条件决定它发生，而非另外的事件发生。决定论认为，自然界和人类世界中普遍存在一种客观规律和因果关系。一切结果都是由先前的某种原因导致的，或者是可以根据前提条件来预测未来可能出现的结果。其重要观点即是：“有其因必有其果。”或黑格尔的“凡是合乎理性的东西都是现实的，凡是现实的东西都是合乎理性的。”","categories":[{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://www.iamlightsmile.com/tags/%E5%93%B2%E5%AD%A6/"}]},{"title":"你好，2019","slug":"你好，2019","date":"2019-01-01T14:41:46.000Z","updated":"2020-01-18T11:40:41.180Z","comments":true,"path":"articles/你好，2019/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E4%BD%A0%E5%A5%BD%EF%BC%8C2019/","excerpt":"再见，2018.","text":"再见，2018. 终于领悟到，自己早就已经成年，已经步入社会，该是个成熟的成年人了，不再是小孩子了。 要学会一个人照顾好自己，经营好自己，不要发脾气，不要因畏惧而胆怯。 要学会先做应该做的事，再做自己想做的事。 独自在外，要有一个人远航的心理准备，没有家和学校这样的避风港，许多事就算不想做也要去做，不要再想当然的随意而为了，要学会对自己负责，称为真正心理成熟的成年人。 凡事要做好规划，目标要明确，要有强大的执行力作为支撑，要有强大的意志力做燃料。 不要再去讲黑白对错了，社会永远都是森林法则，弱肉强食，规律如此，何来对错？学会适应这个法则吧，努力变强，什么都会有的。 不要再执念于过去了，回忆再美好也只是曾经，现在再悔恨也于事无补，把视角向前看吧。 不要再惦记喜欢的人了，现在的你配不上她。 不喜欢的饭就算难以下胃也要吃下去，不要饿肚子。 不要只有想法而不付出行动，想法谁都有，最终还是行动说明一切。 该向游戏和网络小说说再见了，不要再把精力放到没有意义的事情上去了。 过去曾经幼稚的孩子，也该死掉了。 你好，2019.","categories":[{"name":"随念","slug":"随念","permalink":"https://www.iamlightsmile.com/categories/%E9%9A%8F%E5%BF%B5/"}],"tags":[{"name":"个人","slug":"个人","permalink":"https://www.iamlightsmile.com/tags/%E4%B8%AA%E4%BA%BA/"}]},{"title":"自然语言处理（1）基本概念","slug":"自然语言处理（1）基本概念","date":"2018-05-26T14:23:47.000Z","updated":"2020-01-18T11:10:59.678Z","comments":true,"path":"articles/自然语言处理（1）基本概念/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%881%EF%BC%89%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/","excerpt":"自然语言处理（Natural Language Processing，NLP）：自然语言处理是人工智能和语言学领域的分支学科，主要研究如何让计算机处理和运用自然语言。 自然语言处理广义上分为两大部分，第一部分是自然语言理解，是指让电脑“懂”人类的语言；第二部分为自然语言生成，是指把计算机数据转化为自然语言。","text":"自然语言处理（Natural Language Processing，NLP）：自然语言处理是人工智能和语言学领域的分支学科，主要研究如何让计算机处理和运用自然语言。 自然语言处理广义上分为两大部分，第一部分是自然语言理解，是指让电脑“懂”人类的语言；第二部分为自然语言生成，是指把计算机数据转化为自然语言。 自然语言处理研究的内容： 机器翻译（machine translation，MT）：实现一种语言到另一种语言的自动翻译。 自动文摘（automatic summarizing或automatic abstracting）：将原文档的主要内容和含义自动归纳、提炼出来，形成摘要或缩写。 信息检索（information retrieval）：信息检索也称情报检索，就是利用计算机系统从海量文档中找到符合用户需要的相关文档。面向两种或两种以上语言的信息检索叫做跨语言信息检索（cross-language/trans-lingual information retrieval）。 文档分类（document categorization/classification）：文档分类也称文本分类（text categorization/classification）或信息分类（information categorization/classification），其目的就是利用计算机系统对大量的文档按照一定的分类标准（例如，根据主题或内容划分等）实现自动归类。 问答系统（question-answering system）：通过计算机系统对用户提出的问题的理解，利用自动推理等手段，在有关知识资源中自动求解答案并做出相应的回答。 信息过滤（information filtering）：通过计算机系统自动识别和过滤那些满足特定条件的文档信息。通常指网络有害信息的自动识别和过滤，主要用于信息安全和防护、网络内容管理等。 信息收取（information extraction）：指从文本中收取出特定的事件（event）或事实信息，有时候又称事件抽取（event extraction）。 文本挖掘（text mining）：有时又称数据挖掘（data mining），是指从文本（多指网络文本）中获取高质量信息的过程。 舆情分析（public opinion analysis）：舆情是指在一定的社会空间内，围绕中介性社会事件的发生、发展和变化，民众对社会管理者产生和持有的社会政治态度。 隐喻计算（metaphorical computation）：“隐喻”就是用乙事物或其某种特征来描述甲事物的语言现象。简要的讲，隐喻计算就是研究自然语言语句或篇章中隐喻修辞的理解方法。 文字编辑和自动校对（automatic proofreading）：对文字拼写、用词，甚至语法、文档格式等进行自动检查、校对和编排。 作文自动评分：对作文质量和写作水平进行自动评价和打分。 光读字符识别（optical character recognition，OCR）：通过计算机系统对印刷体或手写体等文字进行自动识别，将其转换成计算机可以处理的电子文本，简称字符识别或文字识别。 语音识别（speech recognition）：将输入计算机的语音信号识别转换成书面语表示。 文语转换（text-to-speech conversion）：将书面文本自动转换成对应的语音表征，又称语音合成（speech synthesis）。 说话人识别/认证/验证（speaker recognition/identification/verification）：对一说话人的言语样本做声学分析，依据推断（确定或验证）说话人的身份。（摘自《统计自然语言处理》（第2版）） 自然语言处理涉及的几个层次：形态学（morphology）、语法学（syntax）、语义学（semantics）、语用学（pragmatics）。","categories":[{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/tags/NLP/"}]},{"title":"腾讯云SDKforJS开发实战","slug":"腾讯云SDKforJS开发实战","date":"2018-04-21T07:31:34.000Z","updated":"2020-01-18T11:27:41.121Z","comments":true,"path":"articles/腾讯云SDKforJS开发实战/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E8%85%BE%E8%AE%AF%E4%BA%91SDKforJS%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98/","excerpt":"前面曾经提到过的，我想要把自然语言处理相关的技术接入到我的毕设微信小程序里面。 由于腾讯云未提供JS的SDK，要自己编写HTTP请求来实现，之前觉得比较麻烦，相关说明文档没有整明白，不想尝试，后来觉得既然是自己选择的路，那么无论再苦再累，都要坚持走下去，无论结果是什么，也算对得起当初自己的豪情壮志了。","text":"前面曾经提到过的，我想要把自然语言处理相关的技术接入到我的毕设微信小程序里面。 由于腾讯云未提供JS的SDK，要自己编写HTTP请求来实现，之前觉得比较麻烦，相关说明文档没有整明白，不想尝试，后来觉得既然是自己选择的路，那么无论再苦再累，都要坚持走下去，无论结果是什么，也算对得起当初自己的豪情壮志了。 再贴一下我的参考文档：腾讯云文智自然语言处理API链接 大致了解了签名方法和技术之后，我就在网上搜关于JS的HmacSHA256加密和Base64编码的函数库，发现了Crypto.js，在官网上吧zip文件下下来之后，参照一篇文章细说CryptoJs使用（微信小程序加密解密)把core.js和sha256.js和enc-base64.js的内容放到一个叫crypto.js文件中，最后再加上module.exports = CryptoJS。（话说我之前看截图里是module.export = CryptoJS，我也就照搬下来，试了半天结果总是不行，后来发现export后面还有个s，真是尬） 随后测试了一下这个函数库，经过测试发现加密的结果与API文档中的样例一致，然后就开始下一步了。 关于具体的格式我也不是很清楚，经过大胆尝试之后总是说有问题，后来只能去学习Python SDK的源码了。 通过源码的探索，我了解到了从最初的传参到生成URL的整体过程，同时也注意到了一些文档中并没有提到的细节和注意事项。然而经过测试之后还是提示说鉴权失败，我真是日了狗了。不过最终我还是成功了，下面是几个记录： 我下载的SDK是Python SDK，而我要编写的是JS代码。其中的time获取函数不同，其中Python中为int(time.time()),获取到的是整数时间戳，而JS中的则为Date.now()获取到的是以毫秒为单位的所以要做进一步的转化为Math.floor(Date.now()/1000) 同时要使用SDK必须要带要有版本号如SDK_PYTHON_2.0.13，如果没有则提示错误信息：Exception ‘Version’，而腾讯云中并没有提到这一点，所以我们必须要模拟一个，即加一个这样的参数：RequestClient=SDK_PYTHON_2.0.13 同时最最他妈的坑爹的一点就是腾讯云中明确提到了签名方式用HmacSHA1或者HmacSHA256都可以，只要参数中说明即可，即加上：SignatureMethod: ‘HmacSHA1’即可，而我之前网上搜的大多使用256，所以我也使用256，但是一直报鉴权失败的问题，可是我的签名方式（拿腾讯云提供的demo测试了一下，得到的签名一致）和参数都没有问题，困扰了好久，最终我把Python的SDK源码改了改，如修改当前时间戳Timestamp、修改随机正整数Nonce等，发现了Timestamp不能乱改，和腾讯云的服务器的时间戳间隔不能超过2小时，同时时间戳一定的情况下Nonce不能重复，后来在Python SDK上尝试使用HmacSHA256发现也报错了！我的哥！又改回HmacSHA1发现又没问题了，不会是现在腾讯云后台不支持256吧，然后我把JS的代码相关部分也改成了使用HmacSHA1，皇天不负有心人，终于他妈的成功了！不行你倒是说一声啊，同时具体的一些细节也不交代清楚。 同时还有的是JS实现网络调用的库，因为不同的引擎不同的平台所以实现肯定会有所不同，我最终搜索到了Fly.js这个很好用的库。 简体中文版说明文档链接福利在这里！Flyio帮助文档 不同的环境Fly的入口文件不同。 前面提到了腾讯云没有JS的SDK，而作为读过了Python SDK的程序员，难以控制自己想要编写自己的SDK的冲动，一方面是也算是一个挑战和尝试，一方面是这样也方便了自己的使用，最后好像是莫名的强迫症，如果不做的话实在是受不了。 于是大致样式就开始照搬Python SDK的实现，同时由于自己仅仅是小尝试，简单成功就可以了，至于module的健壮性和架构也就忽略掉了。 我的是在Webstorm上编写调试JS的，引擎是NodeJs。由于报import、from的错，所以只能含泪把es6的语法写成了CommonJS的形式。 最终的成果长成这么个吊样子，文件名为qcloud.js： /*不同的应用平台fly.js的引入方式不同，同时fly的内部实现也略有不同 毕竟不同的平台js的引擎也不同，所以相关网络请求访问的底层实现也会有所不同 比如说浏览器环境中是构造XmlHttpRequest执行ajax调用 而微信小程序则是使用底层api：wx.request函数 node环境依赖http模块及net模块的底层实现 详情参见 https://wendux.github.io/dist/#/doc/flyio/readme 不同环境下文件引入实例： 具体文件自己去找，去下 浏览器环境 const Fly = require(&#39;./fly.umd.min&#39;) 微信小程序环境 const Fly = require(&#39;./fly&#39;) node环境 const Fly=require(&quot;flyio/src/node&quot;)*/ //以下是node环境下引入fly的方式 const Fly = require(&quot;flyio/src/node&quot;); const CryptoJS = require(&#39;./crypto&#39;); function sortKeys(obj) { let newobj = {}; Object.keys(obj).sort().forEach(value =&gt; newobj[value] = obj[value]); return newobj } function codeObj(obj) { let arr = []; for (let k in obj) { arr.push(k + &#39;=&#39; + obj[k]) } return arr.join(&#39;&amp;&#39;) } class QCloud { constructor(){ this.config = { protocol:&#39;https://&#39;, path:&#39;/v2/index.php&#39;, method:&#39;GET&#39;, region:&#39;gz&#39;, domain:&#39;.api.qcloud.com&#39;, requestClient:&#39;SDK_PYTHON_2.0.13&#39;, signatureMethod:&#39;HmacSHA1&#39;, secretId:&#39;&#39;, secretKey:&#39;&#39; } this.params = {} } init(config){ Object.assign(this.config,config); this.fly = new Fly; this.fly.config.baseURL = this.config.protocol+this.config.module+this.config.domain } getParams() { return this.config.method+this.config.module+this.config.domain+ this.config.path+&#39;?&#39;+codeObj(sortKeys(this.params)) } getUrl(action,params){ this.initParams(); this.params.Action = action; Object.assign(this.params,params); this.sign(); return this.config.protocol+this.config.module+this.config.domain+this.config.path+&#39;?&#39;+this.getParams() } use(action,params,fthen,fcatch){ this.initParams(); this.params.Action = action; Object.assign(this.params,params) this.sign() this.request(fthen,fcatch) } sign(){ let pa = this.getParams(); let signnature = CryptoJS.enc.Base64.stringify(CryptoJS.HmacSHA1(pa,this.config.secretKey)); this.params.Signature = signnature } initParams(){ this.params = { Region: this.config.region, Nonce: Math.floor(Math.random()*Number.MAX_SAFE_INTEGER), Timestamp: Math.floor(Date.now()/1000), RequestClient: this.config.requestClient, SignatureMethod: this.config.signatureMethod, SecretId: this.config.secretId, } } request(fthen,fcatch){ this.fly.get(this.config.path,this.params).then(fthen).catch(fcatch) } } module.exports = new QCloud(); 这个不写注释的问题好像确实要改。。。 下面是测试代码文件（testMyModule.js）： const QCloud = require(&#39;./qclooud&#39;) QCloud.init({ module:&#39;wenzhi&#39;, secretId:&#39;自己的secretId&#39;, secretKey:&#39;自己的secretKey&#39; }) let params = { &#39;content&#39;:&#39;人生苦短，please Python。太祖、刘邦、朱元璋哪个更厉害？！&#39; } QCloud.use(&#39;TextClassify&#39;,params,function (responce) { console.log(responce.data) },function (error) { console.log(error) }) 下面是输出结果： {&quot;code&quot;:0,&quot;message&quot;:&quot;&quot;,&quot;codeDesc&quot;:&quot;Success&quot;,&quot;classes&quot;:[{&quot;class&quot;:&quot;\\u6587\\u5316&quot;,&quot;class_num&quot;:61,&quot;conf&quot;:0.713},{&quot;class&quot;:&quot;\\u5386\\u53f2&quot;,&quot;class_num&quot;:95,&quot;conf&quot;:0.221},{&quot;class&quot;:&quot;\\u672a\\u5206\\u7c7b&quot;,&quot;class_num&quot;:0,&quot;conf&quot;:0.066}]} 关于上面\\u问题的出现，我们使用eval函数把json string转成json object就可以了，如： console.log(eval(&#39;(&#39;+responce.data+&#39;)&#39;)) 即可得下面的结果： { code: 0, message: &#39;&#39;, codeDesc: &#39;Success&#39;, classes: [ { class: &#39;文化&#39;, class_num: 61, conf: 0.713 }, { class: &#39;历史&#39;, class_num: 95, conf: 0.221 }, { class: &#39;未分类&#39;, class_num: 0, conf: 0.066 } ] } 因为JS本身异步调用的特点，使得我们对于事件的业务逻辑处理许多时候都是通过回调函数来解决而并非Python常见的同步处理。下面是相关的Python调用示例： from QcloudApi.qcloudapi import QcloudApi from settings import secretId,secretKey import json from pprint import pprint module = &#39;wenzhi&#39; config = { &#39;secretId&#39;: secretId, &#39;secretKey&#39;: secretKey, &#39;Region&#39;: &#39;gz&#39;, &#39;method&#39;: &#39;POST&#39; } action = &#39;TextClassify&#39; #文本分类 params = { &#39;content&#39;:&#39;人生苦短，please Python。太祖、刘邦、朱元璋哪个更厉害？！&#39; } try: service = QcloudApi(module,config) print(service.generateUrl(action,params)) pprint(json.loads(service.call(action,params))) except Exception as e: print(&#39;Exception&#39;,e) 看起来我实现的module还是有点样子的嘛哈哈！ 我已经把相关的源码放到了我的GitHub上，欢迎各位有需要的看客们下载使用！","categories":[{"name":"Python","slug":"Python","permalink":"https://www.iamlightsmile.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://www.iamlightsmile.com/tags/Python/"}]},{"title":"科技发展之小感慨","slug":"科技发展之小感慨","date":"2018-04-21T07:23:00.000Z","updated":"2020-01-18T11:29:29.957Z","comments":true,"path":"articles/科技发展之小感慨/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E7%A7%91%E6%8A%80%E5%8F%91%E5%B1%95%E4%B9%8B%E5%B0%8F%E6%84%9F%E6%85%A8/","excerpt":"现在真的是越来越理解“人生而有涯而知也无涯”了。 现在科技发展的速度这么快，技术更迭周期越来越短，我们这些将来要搞编程的到时候真的是活到老学到老啊！ 比如近几年来大火的人工智能、云计算、大数据、机器学习、深度学习等等，还有物联网和机器人技术等，就在不久的将来，一定会极大的改变人们的生产生活方式。","text":"现在真的是越来越理解“人生而有涯而知也无涯”了。 现在科技发展的速度这么快，技术更迭周期越来越短，我们这些将来要搞编程的到时候真的是活到老学到老啊！ 比如近几年来大火的人工智能、云计算、大数据、机器学习、深度学习等等，还有物联网和机器人技术等，就在不久的将来，一定会极大的改变人们的生产生活方式。 现在发现自己真的是一个井底之蛙，所知甚少。最近接触和了解的一些工具、术语和概念简直让我头大，比如说什么Racket语言、Julia语言、Dart语言、Scala框架、Flink框架、Flutter框架、Scrapy框架等等，虽然从理论上讲这些都是术与器的层面，但是这些东西的技术覆盖面和更迭速度还是有些让我措手不及，感觉要学的东西好多啊。 哎，果然人生最重要的是要学会选择。要想得到什么，就必须要做好失去其他的心理准备。 只有与时俱进，终身学习的人才能不被这个时代落后太远。 相对来讲，如果所从事的职业是医学、法律等知识更迭速度比较慢、半衰期很长的领域，那么可能是经验越丰富越值钱，而我们搞编程的不仅是技术，甚至是思想也会变化。如果不注重培养自己的核心竞争力，稍有不慎，可能就被年轻人迎头赶上，丢掉低级码农的饭碗。 相对而言，搞纯工程以后的道路可能是技术总监、项目经理啥的，如果搞学术，可能自己真的没有这个条件了，另外的出路应该是除了计算机领域之外，去学习和掌握一些其他领域的知识智慧，做一个跨学科的交叉复合型人才，这样不仅可以更好的发展和应用该领域的知识学问，还可以使计算机更好的发挥价值吧？","categories":[{"name":"随念","slug":"随念","permalink":"https://www.iamlightsmile.com/categories/%E9%9A%8F%E5%BF%B5/"}],"tags":[{"name":"个人","slug":"个人","permalink":"https://www.iamlightsmile.com/tags/%E4%B8%AA%E4%BA%BA/"}]},{"title":"自然语言处理与知识图谱相关市场研究","slug":"自然语言处理与知识图谱相关市场研究","date":"2018-04-19T14:15:10.000Z","updated":"2020-01-18T11:10:48.304Z","comments":true,"path":"articles/自然语言处理与知识图谱相关市场研究/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B8%8E%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9B%B8%E5%85%B3%E5%B8%82%E5%9C%BA%E7%A0%94%E7%A9%B6/","excerpt":"经过我的探索，发现现在商用也好，学习也罢，目前提供NLP技术服务的大致分三种： 一种是大学院校的教授、助教和研究生等依托团队的学术背景和技术沉淀，通过创办规模较小的公司提供技术支持，以实现技术变现。服务对象主要为科研院所、政府部门、一些没有精力或没有必要自己去做这方面服务的大公司和一些没有条件或没有必要自己去做的中小型公司。 一种是大公司如Google、Facebook、Microsoft、阿里、腾讯、百度、华为、科大讯飞等，目前也都在这方面发力。其中关于自然语言处理方面在BAT三者之间应该是百度做的最早，目前腾讯的比较成熟，而阿里在这方面才刚刚开始，前两天才公测结束，服务正式上线日期官网说是4月23号。科大讯飞的特点应该主要是语音相关的。华为的不了解。这些公司相关领域技术自己是要自己开拓发展的。 第三种则应该是比较专业，主打自然语言处理及其衍生相关服务的了。基本上创始人和主要的技术人员都是来自国内外知名的大学和公司，有学习相关的专业技术，并有丰富的从业经验，后来自主创业，开辟相关市场，想要在自然语言处理服务领域彻底火起来之前做大做强，多吃点蛋糕。国外的有不少，国内的现在也在发展中，估计目前至少有10家公司在做相关的了。服务对象和第一种基本相同。","text":"经过我的探索，发现现在商用也好，学习也罢，目前提供NLP技术服务的大致分三种： 一种是大学院校的教授、助教和研究生等依托团队的学术背景和技术沉淀，通过创办规模较小的公司提供技术支持，以实现技术变现。服务对象主要为科研院所、政府部门、一些没有精力或没有必要自己去做这方面服务的大公司和一些没有条件或没有必要自己去做的中小型公司。 一种是大公司如Google、Facebook、Microsoft、阿里、腾讯、百度、华为、科大讯飞等，目前也都在这方面发力。其中关于自然语言处理方面在BAT三者之间应该是百度做的最早，目前腾讯的比较成熟，而阿里在这方面才刚刚开始，前两天才公测结束，服务正式上线日期官网说是4月23号。科大讯飞的特点应该主要是语音相关的。华为的不了解。这些公司相关领域技术自己是要自己开拓发展的。 第三种则应该是比较专业，主打自然语言处理及其衍生相关服务的了。基本上创始人和主要的技术人员都是来自国内外知名的大学和公司，有学习相关的专业技术，并有丰富的从业经验，后来自主创业，开辟相关市场，想要在自然语言处理服务领域彻底火起来之前做大做强，多吃点蛋糕。国外的有不少，国内的现在也在发展中，估计目前至少有10家公司在做相关的了。服务对象和第一种基本相同。 除此之外，其他的一些技术公司或大公司中则主要使用公司内部相关研发团队或技术部门主要针对与公司业务的技术和成果做一些辅助工作，不提供外部服务，没有想发展壮大的目标计划，同时种种原因也不想借助他人的服务。 在知识图谱相关应用中，有用于企业决策的，也有用于金融分析的，基本情况应该是基本类似于自然语言处理服务领域。","categories":[{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/tags/NLP/"}]},{"title":"腾讯云-云智自然语言处理API小试","slug":"腾讯云-云智自然语言处理API小试","date":"2018-04-19T13:02:27.000Z","updated":"2020-01-18T11:27:54.512Z","comments":true,"path":"articles/腾讯云-云智自然语言处理API小试/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E8%85%BE%E8%AE%AF%E4%BA%91-%E4%BA%91%E6%99%BA%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86API%E5%B0%8F%E8%AF%95/","excerpt":"前述（妈耶！这是昨天的文章了，昨天晚上写着写着突然断电，而我的电脑是台式机。。。） 今天在忙毕设的事情，毕设项目是做一个微计划日程管理的小程序，目前已经完成了大部分的功能。 其中包括图表统计、时间轴、四象限、小卡片、数据备份和数据还原等功能。不过今天刚通知了说审核失败，理由是身份为个人的开发者不能做备忘录相关的微信小程序。 昨天想着能不能把自己的兴趣（自然语言处理+知识图谱）和毕设结合起来，打算通过调用一些开放的自然语言处理的Restful API接口来处理一些todo、plan、target相关分析统计工作。","text":"前述（妈耶！这是昨天的文章了，昨天晚上写着写着突然断电，而我的电脑是台式机。。。） 今天在忙毕设的事情，毕设项目是做一个微计划日程管理的小程序，目前已经完成了大部分的功能。 其中包括图表统计、时间轴、四象限、小卡片、数据备份和数据还原等功能。不过今天刚通知了说审核失败，理由是身份为个人的开发者不能做备忘录相关的微信小程序。 昨天想着能不能把自己的兴趣（自然语言处理+知识图谱）和毕设结合起来，打算通过调用一些开放的自然语言处理的Restful API接口来处理一些todo、plan、target相关分析统计工作。 哈工大的ltp之前尝试过，不过现在调用的结果还是说未授权的用户，虽然网页上显示我的可使用流量还有18G之多。 复旦的话有知识工场有提供知识图谱的相关Restful API，尝试了一下感觉还可以，蛮不错的，有时间也做个记录。 以上的都是使用的是http，而小程序的request请求只能是https，所以许多方法也就都不实用了。除非自己搭设一个https的服务器，然后转接请求http请求，就和代理差不多。 一些其他公司的服务经过探索后也都是有的，比如说百度、阿里、腾讯、华为等。估计差不多都大同小异，用起来也都差不多。基本上都是提供相关平台语言SDK来服务的，如果是要自己动手去写出http请求的话，还要自己对签名进行处理等等，比较麻烦，目前并不想尝试实践。 由于先搜到的腾讯云，同时由于小程序的缘故刚注册的腾讯云的微信公共平台的账号，所以就在腾讯云上学习探索了。 发现调用的方式其实挺简单的，相关的文章网上也早已经有了。 比如说：腾讯文智自然语言处理-分词API Python小实验和开发者实验室体验之文智自然语言处理SDK by python等。 腾讯云文智自然语言处理API链接：https://cloud.tencent.com/document/api/271 下面简单的贴一下相关的代码。 虽然从逻辑上讲这些重复性的代码可以通过运用相关设计模式经验封装成模块和函数更为合理，但是这里仅是简单的测试，所以也就没继续搞了。 情感分析from QcloudApi.qcloudapi import QcloudApi from settings import secretId,secretKey import json from pprint import pprint module = &#39;wenzhi&#39; config = { &#39;secretId&#39;: secretId, &#39;secretKey&#39;: secretKey, &#39;Region&#39;: &#39;gz&#39;, &#39;method&#39;: &#39;POST&#39; } action = &#39;TextSentiment&#39; #情感分析 params = { &#39;content&#39;: &quot;李亚鹏挺王菲：加油！孩他娘。&quot; } try: service = QcloudApi(module,config) print(service.generateUrl(action,params)) pprint(json.loads(service.call(action,params))) except Exception as e: print(&#39;Exception&#39;,e) 运行结果： https://wenzhi.api.qcloud.com/v2/index.php {&#39;code&#39;: 0, &#39;codeDesc&#39;: &#39;Success&#39;, &#39;message&#39;: &#39;&#39;, &#39;negative&#39;: 0.0051898001693189, &#39;positive&#39;: 0.99481022357941} 其中的settings模块里面装有自己的secretId和secretKey，就两行代码而已： secretId = &#39;自己的secretId&#39; secretKey = &#39;自己的secretKey&#39; 很明显无法打印出有效的URL~因为使用的方法为POST，相关的数据在请求体中而非GET方法中的请求头中。 后面的所有代码只需要修改action和params的值即可 文本抓取action = &#39;ContentGrab&#39;# 文本抓取 params = { &#39;url&#39;: &#39;http://www.iamlightsmile.com&#39; } 运行结果：靠，之前还好好的，现在报错了！ https://wenzhi.api.qcloud.com/v2/index.php {&#39;code&#39;: 4000, &#39;codeDesc&#39;: &#39;InvalidParameter&#39;, &#39;message&#39;: &#39;(-100) service timeout.&#39;} 不知为啥，有时会出现如上的错误，尽管代码没有问题，多尝试几次可能就出现正常的结果了，尽管这种不确定性还是挺烦人的。。。正确结果如下： https://wenzhi.api.qcloud.com/v2/index.php {&#39;code&#39;: 0, &#39;codeDesc&#39;: &#39;Success&#39;, &#39;content&#39;: &#39;lightsmile\\n&#39; &#39;1459679436@qq.com\\n&#39; &quot;lightsmile&#39;s Blog\\n&quot; &quot;lightsmile&#39;s Blog\\n&quot; &#39; lightsmile \\n&#39; &#39;2018-04-18\\n&#39; &#39;GithubPages新尝试\\n&#39; &#39; 由于某些不便明说的原因，我要再申请一个域名，再申请一个GitHub账号，再搞一个GitHub &#39; &#39;Pages。打算用来记录一些不便明说的东西。 &#39; &#39;这次域名的申请不同于之前的在万网的iamlightsmile.com，这次是在腾讯云上申请的，不过都大同小异了。接着等待大概3天左右的实名认证，通过后域名就可以解析可用了。由于只是使用GitHub &#39; &#39;Pages 作为静态网页，不需要另外购置服务器，所以也不... 阅读全文… \\n&#39; &#39;GitHub\\n&#39; &#39;2018-04-17\\n&#39; &#39;学习Python设计模式\\n&#39; &#39; 本书主要参阅的书籍是《精通Python设计模式》 &#39; &#39;本书分为创建型模式、结构型模式、行为型模式三大类，同时又细分为16种模式。具体到每个模式，则通过简单介绍、现实生活中例子、软件应用实例、应用场景、具体代码实现、小结几部分，多个角度加深对某个设计模式的理解。案例贴近生活，代码简单易懂，描述清晰明白，翻译水平上佳，确实算是我认为的好书，同时翻译还将代码上传到GitHub上方便读者下载学习，这里真... &#39; &#39;阅读全文… \\n&#39; &#39;2018-04-14\\n&#39; &#39;推荐阅读书籍\\n&#39; &#39; 此博文作为书籍阅读及相关的记录哲学篇 《和谐辩证法》 《智慧之根》 计算机篇 《统计学习理论基础》 《大数据智能》 &#39; &#39;《统计自然语言处理》（第二版） 《Python自然语言处理》（第2版，没有纸质） 基础篇 《线性代数及其应用》 历史篇小说篇 &#39; &#39;《天行健》 《英雄志》 《国士无双》 思维篇 《如何系统思考》 阅读全文… \\n&#39; &#39;2018-04-07\\n&#39; &#39;哈工大ltp小试\\n&#39; &#39; 今天开始探索学习使用哈工大的LTP（Language Technology Platform）。 这里是官网地址 &#39; &#39;这里是GitHub地址 这里是pyltp的使用文档 &#39; &#39;平台采用的语言是C++，但是也提供了Python和Java的封装。由于本人目前使用Python作为自然语言处理的工具语言，所以以下的探索流程都是使用本人电脑中的Window8.1操作系统的PyCharm集成开发环境，使用的Pyt... &#39; &#39;阅读全文… \\n&#39; &#39;Python\\n&#39; &#39;ltp\\n&#39; &#39;自然语言处理\\n&#39; &#39;2018-04-06\\n&#39; &#39;Scrapy爬取知乎数据小试\\n&#39; &#39; 啊啊啊，没时间写啦，以后有时间再写吧！ 。。。发现今天是周五，不熄灯。。。 &#39; &#39;前两周一直在忙毕设的事情，由于某些原因毕设选择了相对简单的微信小程序，经过奋战之后一些主要的基本功能已经实现多半。 &#39; &#39;自然语言处理的一些最基本的概念已经有所了解，下面想要找点实战项目练练手。由于处理的第一步便是要获取语料，想着以后爬虫这东西肯定是要学的，于是从昨天开始学习相关视频、配置相关环境，今天看了部分，照着Dem... &#39; &#39;阅读全文… \\n&#39; &#39;Scrapy\\n&#39; &#39;爬虫\\n&#39; &#39;2018-04-03\\n&#39; &#39;随想\\n&#39; &#39; 其实这世上哪有什么善恶，有的只是不同环境下不同的选择。 我发现人和人相识的过程基本上都是从他的经历中提取特质然后贴上标签的过程。 &#39; &#39;普天之下又有多少人敢把自己的灵魂放在阳光下炙烤呢？草他妈的！ 阅读全文… \\n&#39; &#39;2018-03-28\\n&#39; &#39;计算机\\n&#39; &#39;微信小程序的component\\n&#39; &#39; &#39; &#39;我发现无法直接在样式即wxss里通过color属性设置icon组件的颜色，是无效的，只能通过在wxml里设置它的color属性为js传入的变量值或者是通过变量值来控制具体的颜色值。 &#39; &#39;我们可以将微信小程序中的components组件视为一个对象，没错，它本来就是一个对象，只是相对而言，它的初始化方法和设置方式不同于在一般的js语言中，它的data属性里是这个对象建立时初始化时的数据，作用域... &#39; &#39;阅读全文… \\n&#39; &#39;微信小程序\\n&#39; &#39;2018-03-19\\n&#39; &#39;计算机\\n&#39; &#39;learnNLTKbyWatchVideo\\n&#39; &#39; The following is learning from the video:NLTK with Python 3 for &#39; &#39;Natural Language Processing.You can watch the videos in &#39; &#39;YouTube,iliibili and the author’s website: pythonprogramming.net &#39; &#39;I use jupyte... 阅读全文… \\n&#39; &#39;NLTK\\n&#39; &#39;Python\\n&#39; &#39;自然语言处理\\n&#39; &#39;2018-03-13\\n&#39; &#39;线性代数与微积分浅解\\n&#39; &#39; &#39; &#39;以前在大一大二时曾学过高等数学（微积分）与线性代数，不过在当时都是被动的学一学，考个分数而已，同时教授一般也都是照本宣科的围绕理论展开，平淡无味的 &#39; &#39;阅读全文… \\n&#39; &#39;2018-03-13\\n&#39; &#39;《自然语言处理综论》学习笔记\\n&#39; &#39; Bill Manaris 关于自然语言处理的定义 阅读全文… \\n&#39; &#39;博客内容遵循 知识共享 署名 - 非商业性 - 相同方式共享 4.0 国际协议\\n&#39; &#39;扫一扫，分享到微信\\n&#39; &#39;{title}\\n&#39; &#39; {tags} \\n&#39; &#39;{date}\\n&#39;, &#39;message&#39;: &#39;&#39;, &#39;title&#39;: &quot;lightsmile&#39;s Blog | lightsmile&quot;} 内容转码action = &#39;ContentTranscode&#39;# 内容转码 params = { &#39;url&#39;: &#39;www.iamlightsmile.com&#39;, &#39;to_html&#39;: 1 } 运行结果： https://wenzhi.api.qcloud.com/v2/index.php {&#39;code&#39;: 0, &#39;codeDesc&#39;: &#39;Success&#39;, &#39;content&#39;: &#39;&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE html PUBLIC &#39; &#39;&quot;-//WAPFORUM//DTD XHTML Mobile 1.0//EN&quot; &#39; &#39;&quot;http://www.wapforum.org/DTD/xhtml-mobile10.dtd&quot;&gt;&lt;html &#39; &#39;xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt;&lt;head&gt;&lt;meta &#39; &#39;http-equiv=&quot;Content-Type&quot; content=&quot;application/xhtml+xml; &#39; &#39;charset=UTF-8&quot;/&gt;&lt;title&gt;lightsmile\\&#39;s Blog | &#39; &#39;lightsmile&lt;/title&gt;&lt;style type=&quot;text/css&quot;&gt;* &#39; &#39;{margin:0;padding:0;}body {font-family: &#39; &#39;Arial,Helvetica,sans-serif;}a {cursor: pointer;text-decoration: &#39; &#39;underline;}body, div, p, a, table, textarea, form, img, ol, ul, &#39; &#39;li, h1, h2, h3, h4, h5, h6 {border:0 none;}#tc_content &#39; &#39;{font-size: 16px;line-height: 25px;word-wrap: break-word;padding: &#39; &#39;5px 6px;overflow: hidden;}&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;div &#39; &#39;id=&quot;tc_content&quot;&gt;&lt;div class=&quot;fold_div&quot;&gt;&lt;a class=&quot;fold_a&quot; &#39; &#39;href=&quot;http://www.iamlightsmile.com##bk=1&amp;pg=1&quot;&gt;[展开]&amp;#160;1459679436@qq.com&amp;#160;&lt;/a&gt;&lt;/div&gt;lightsmile\\&#39;s&amp;#160;Blog&amp;#160;&lt;br &#39; &quot;/&gt;lightsmile&#39;s&amp;#160;Blog&amp;#160;&amp;#160;lightsmile&amp;#160;&lt;br &quot; &#39;/&gt;2018-04-18&amp;#160;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/2018/04/18/GithubPages%E6%96%B0%E5%B0%9D%E8%AF%95/&quot; &#39; &#39;position=&quot;6&quot;&gt;GithubPages新尝试&lt;/a&gt;&amp;#160;由于某些不便明说的原因，我要再申请一个域名，再申请一个GitHub账号，再搞一个GitHub&amp;#160;Pages。打算用来记录一些不便明说的东西。\\n&#39; &#39;这次域名的申请不同于之前的在万网的iamlightsmile.com，这次是在腾讯云上申请的，不过都大同小异了。接着等待大概3天左右的实名认证，通过后域名就可以解析可用了。由于只是使用GitHub&amp;#160;Pages&amp;#160;作为静态网页，不需要另外购置服务器，所以也不...\\n&#39; &#39;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/2018/04/18/GithubPages%E6%96%B0%E5%B0%9D%E8%AF%95/&quot; &#39; &#39;position=&quot;6&quot;&gt;阅读全文…&lt;/a&gt; &lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/tags/GitHub/&quot; &#39; &#39;position=&quot;6&quot;&gt;GitHub&lt;/a&gt; &lt;br /&gt;2018-04-17&amp;#160;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/2018/04/17/%E5%AD%A6%E4%B9%A0Python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/&quot; &#39; &#39;position=&quot;6&quot;&gt;学习Python设计模式&lt;/a&gt; &lt;br &#39; &#39;/&gt;&amp;#160;本书主要参阅的书籍是《精通Python设计模式》\\n&#39; &#39;本书分为创建型模式、结构型模式、行为型模式三大类，同时又细分为16种模式。具体到每个模式，则通过简单介绍、现实生活中例子、软件应用实例、应用场景、具体代码实现、小结几部分，多个角度加深对某个设计模式的理解。案例贴近生活，代码简单易懂，描述清晰明白，翻译水平上佳，确实算是我认为的好书，同时翻译还将代码上传到GitHub上方便读者下载学习，这里真...\\n&#39; &#39;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/2018/04/17/%E5%AD%A6%E4%B9%A0Python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/&quot; &#39; &#39;position=&quot;6&quot;&gt;阅读全文…&lt;/a&gt; &lt;br /&gt;2018-04-14&amp;#160;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/2018/04/14/%E6%8E%A8%E8%8D%90%E9%98%85%E8%AF%BB%E4%B9%A6%E7%B1%8D/&quot; &#39; &#39;position=&quot;6&quot;&gt;推荐阅读书籍&lt;/a&gt; &lt;br /&gt;&amp;#160;此博文作为书籍阅读及相关的记录哲学篇\\n&#39; &#39;《和谐辩证法》\\n&#39; &#39;《智慧之根》\\n&#39; &#39;计算机篇\\n&#39; &#39;《统计学习理论基础》\\n&#39; &#39;《大数据智能》\\n&#39; &#39;《统计自然语言处理》（第二版）\\n&#39; &#39;《Python自然语言处理》（第2版，没有纸质）\\n&#39; &#39;基础篇\\n&#39; &#39;《线性代数及其应用》\\n&#39; &#39;历史篇小说篇\\n&#39; &#39;《天行健》\\n&#39; &#39;《英雄志》\\n&#39; &#39;《国士无双》\\n&#39; &#39;思维篇\\n&#39; &#39;《如何系统思考》\\n&#39; &#39;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/2018/04/14/%E6%8E%A8%E8%8D%90%E9%98%85%E8%AF%BB%E4%B9%A6%E7%B1%8D/&quot; &#39; &#39;position=&quot;6&quot;&gt;阅读全文…&lt;/a&gt; &lt;br /&gt;2018-04-07&amp;#160;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/2018/04/07/%E5%93%88%E5%B7%A5%E5%A4%A7ltp%E5%B0%8F%E8%AF%95/&quot; &#39; &#39;position=&quot;6&quot;&gt;哈工大ltp小试&lt;/a&gt; &lt;br &#39; &#39;/&gt;&amp;#160;今天开始探索学习使用哈工大的LTP（Language&amp;#160;Technology&amp;#160;Platform）。\\n&#39; &#39;这里是官网地址\\n&#39; &#39;这里是GitHub地址\\n&#39; &#39;这里是pyltp的使用文档\\n&#39; &#39;平台采用的语言是C++，但是也提供了Python和Java的封装。由于本人目前使用Python作为自然语言处理的工具语言，所以以下的探索流程都是使用本人电脑中的Window8.1操作系统的PyCharm集成开发环境，使用的Pyt...\\n&#39; &#39;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/2018/04/07/%E5%93%88%E5%B7%A5%E5%A4%A7ltp%E5%B0%8F%E8%AF%95/&quot; &#39; &#39;position=&quot;6&quot;&gt;阅读全文…&lt;/a&gt; &lt;br /&gt;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/tags/Python/&quot; &#39; &#39;position=&quot;6&quot;&gt;Python&lt;/a&gt; &lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/tags/ltp/&quot; &#39; &#39;position=&quot;6&quot;&gt;ltp&lt;/a&gt; &lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/&quot; &#39; &#39;position=&quot;6&quot;&gt;自然语言处理&lt;/a&gt; &lt;br /&gt;2018-04-06&amp;#160;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/2018/04/06/Scrapy%E7%88%AC%E5%8F%96%E7%9F%A5%E4%B9%8E%E6%95%B0%E6%8D%AE%E5%B0%8F%E8%AF%95/&quot; &#39; &#39;position=&quot;6&quot;&gt;Scrapy爬取知乎数据小试&lt;/a&gt; &lt;br /&gt;&amp;#160;啊啊啊，没时间写啦，以后有时间再写吧！\\n&#39; &#39;。。。发现今天是周五，不熄灯。。。\\n&#39; &#39;前两周一直在忙毕设的事情，由于某些原因毕设选择了相对简单的微信小程序，经过奋战之后一些主要的基本功能已经实现多半。\\n&#39; &#39;自然语言处理的一些最基本的概念已经有所了解，下面想要找点实战项目练练手。由于处理的第一步便是要获取语料，想着以后爬虫这东西肯定是要学的，于是从昨天开始学习相关视频、配置相关环境，今天看了部分，照着Dem...\\n&#39; &#39;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/2018/04/06/Scrapy%E7%88%AC%E5%8F%96%E7%9F%A5%E4%B9%8E%E6%95%B0%E6%8D%AE%E5%B0%8F%E8%AF%95/&quot; &#39; &#39;position=&quot;6&quot;&gt;阅读全文…&lt;/a&gt; &lt;br /&gt;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/tags/Scrapy/&quot; &#39; &#39;position=&quot;6&quot;&gt;Scrapy&lt;/a&gt; &lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/tags/%E7%88%AC%E8%99%AB/&quot; &#39; &#39;position=&quot;6&quot;&gt;爬虫&lt;/a&gt; &lt;br /&gt;2018-04-03&amp;#160;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/2018/04/03/%E9%9A%8F%E6%83%B3/&quot; &#39; &#39;position=&quot;6&quot;&gt;随想&lt;/a&gt; &lt;br /&gt;&amp;#160;其实这世上哪有什么善恶，有的只是不同环境下不同的选择。\\n&#39; &#39;我发现人和人相识的过程基本上都是从他的经历中提取特质然后贴上标签的过程。\\n&#39; &#39;普天之下又有多少人敢把自己的灵魂放在阳光下炙烤呢？草他妈的！\\n&#39; &#39;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/2018/04/03/%E9%9A%8F%E6%83%B3/&quot; &#39; &#39;position=&quot;6&quot;&gt;阅读全文…&lt;/a&gt; &lt;br /&gt;2018-03-28&amp;#160;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/&quot; &#39; &#39;position=&quot;6&quot;&gt;计算机&lt;/a&gt; &lt;br /&gt;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/2018/03/28/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%8E%A2%E7%B4%A2%E9%9A%8F%E7%AC%94/&quot; &#39; &#39;position=&quot;6&quot;&gt;微信小程序的component&lt;/a&gt; &lt;br &#39; &#39;/&gt;&amp;#160;我发现无法直接在样式即wxss里通过color属性设置icon组件的颜色，是无效的，只能通过在wxml里设置它的color属性为js传入的变量值或者是通过变量值来控制具体的颜色值。\\n&#39; &#39;我们可以将微信小程序中的components组件视为一个对象，没错，它本来就是一个对象，只是相对而言，它的初始化方法和设置方式不同于在一般的js语言中，它的data属性里是这个对象建立时初始化时的数据，作用域...\\n&#39; &#39;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/2018/03/28/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%8E%A2%E7%B4%A2%E9%9A%8F%E7%AC%94/&quot; &#39; &#39;position=&quot;6&quot;&gt;阅读全文…&lt;/a&gt; &lt;br /&gt;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/tags/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F/&quot; &#39; &#39;position=&quot;6&quot;&gt;微信小程序&lt;/a&gt; &lt;br /&gt;2018-03-19&amp;#160;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/&quot; &#39; &#39;position=&quot;6&quot;&gt;计算机&lt;/a&gt; &lt;br /&gt;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/2018/03/19/learnNLTKbyWatchVideo/&quot; &#39; &#39;position=&quot;6&quot;&gt;learnNLTKbyWatchVideo&lt;/a&gt; &lt;br &#39; &#39;/&gt;&amp;#160;The&amp;#160;following&amp;#160;is&amp;#160;learning&amp;#160;from&amp;#160;the&amp;#160;video:NLTK&amp;#160;with&amp;#160;Python&amp;#160;3&amp;#160;for&amp;#160;Natural&amp;#160;Language&amp;#160;Processing.You&amp;#160;can&amp;#160;watch&amp;#160;the&amp;#160;videos&amp;#160;in&amp;#160;YouTube,iliibili&amp;#160;and&amp;#160;the&amp;#160;author’s&amp;#160;website:&amp;#160;pythonprogramming.net\\n&#39; &#39;I&amp;#160;use&amp;#160;jupyte...\\n&#39; &#39;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/2018/03/19/learnNLTKbyWatchVideo/&quot; &#39; &#39;position=&quot;6&quot;&gt;阅读全文…&lt;/a&gt; &lt;br /&gt;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/tags/NLTK/&quot; &#39; &#39;position=&quot;6&quot;&gt;NLTK&lt;/a&gt; &lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/tags/Python/&quot; &#39; &#39;position=&quot;6&quot;&gt;Python&lt;/a&gt; &lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/&quot; &#39; &#39;position=&quot;6&quot;&gt;自然语言处理&lt;/a&gt; &lt;br /&gt;2018-03-13&amp;#160;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/2018/03/13/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E5%BE%AE%E7%A7%AF%E5%88%86%E6%B5%85%E8%A7%A3/&quot; &#39; &#39;position=&quot;6&quot;&gt;线性代数与微积分浅解&lt;/a&gt; &lt;br &#39; &#39;/&gt;&amp;#160;以前在大一大二时曾学过高等数学（微积分）与线性代数，不过在当时都是被动的学一学，考个分数而已，同时教授一般也都是照本宣科的围绕理论展开，平淡无味的\\n&#39; &#39;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/2018/03/13/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E5%BE%AE%E7%A7%AF%E5%88%86%E6%B5%85%E8%A7%A3/&quot; &#39; &#39;position=&quot;6&quot;&gt;阅读全文…&lt;/a&gt; &lt;br /&gt;2018-03-13&amp;#160;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/2018/03/13/%E3%80%8A%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%BB%BC%E8%AE%BA%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/&quot; &#39; &#39;position=&quot;6&quot;&gt;《自然语言处理综论》学习笔记&lt;/a&gt; &lt;br &#39; &#39;/&gt;&amp;#160;Bill&amp;#160;Manaris&amp;#160;关于自然语言处理的定义\\n&#39; &#39;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/2018/03/13/%E3%80%8A%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%BB%BC%E8%AE%BA%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/&quot; &#39; &#39;position=&quot;6&quot;&gt;阅读全文…&lt;/a&gt; &lt;br /&gt;1&amp;#160;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/page/2/&quot; &#39; &#39;position=&quot;786432&quot;&gt;2&lt;/a&gt; &lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/page/3/&quot; &#39; &#39;position=&quot;786432&quot;&gt;3&lt;/a&gt; &lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/page/4/&quot; &#39; &#39;position=&quot;786432&quot;&gt;4&lt;/a&gt; &lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/page/2/&quot; &#39; &#39;position=&quot;786432&quot;&gt;下一页&lt;/a&gt; &lt;br /&gt;博客内容遵循&amp;#160;&lt;a &#39; &#39;href=&quot;https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh&quot; &#39; &#39;position=&quot;6&quot;&gt;知识共享&amp;#160;署名&amp;#160;-&amp;#160;非商业性&amp;#160;-&amp;#160;相同方式共享&amp;#160;4.0&amp;#160;国际协议&lt;/a&gt; &#39; &#39;&lt;br /&gt;lightsmile&amp;#160;&amp;amp;copy;&amp;#160;2015&amp;#160;-&amp;#160;2018\\n&#39; &#39;Power&amp;#160;by&amp;#160;&lt;a href=&quot;http://hexo.io/&quot; &#39; &#39;position=&quot;6&quot;&gt;Hexo&lt;/a&gt;&amp;#160;Theme&amp;#160;&lt;a &#39; &#39;href=&quot;https://github.com/yscoder/hexo-theme-indigo&quot; &#39; &#39;position=&quot;6&quot;&gt;indigo&lt;/a&gt; &lt;br /&gt;扫一扫，分享到微信&amp;#160;&lt;br /&gt;&lt;a &#39; &#39;href=&quot;http://www.iamlightsmile.com/%7Bpath%7D&quot; &#39; &#39;position=&quot;6&quot;&gt;{title}{tags}{date}&lt;/a&gt; &lt;br /&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;&#39;, &#39;message&#39;: &#39;&#39;} 分词、词性标注、命名实体识别action = &#39;LexicalAnalysis&#39;# 分词、词性标注、命名实体识别 params = { &#39;text&#39;: &quot;我爱洗澡&quot;, &#39;code&#39;: 0x00200000, #0x00200000表示utf-8 &#39;type&#39;: 0 #取值 0 或 1，默认为 0。 0 为基础粒度版分词，倾向于将句子切分的更细，在搜索场景使用为佳。 1 为混合粒度版分词，倾向于保留更多基本短语不被切分开。 } https://wenzhi.api.qcloud.com/v2/index.php {&#39;code&#39;: 0, &#39;codeDesc&#39;: &#39;Success&#39;, &#39;combtokens&#39;: [{&#39;cls&#39;: &#39;短语&#39;, &#39;pos&#39;: 0, &#39;wlen&#39;: &#39;8&#39;, &#39;word&#39;: &#39;我爱洗澡&#39;}], &#39;message&#39;: &#39;&#39;, &#39;tokens&#39;: [{&#39;pos&#39;: 0, &#39;wlen&#39;: &#39;2&#39;, &#39;word&#39;: &#39;我&#39;, &#39;wtype&#39;: &#39;代词&#39;, &#39;wtype_pos&#39;: 27}, {&#39;pos&#39;: 2, &#39;wlen&#39;: &#39;2&#39;, &#39;word&#39;: &#39;爱&#39;, &#39;wtype&#39;: &#39;动词&#39;, &#39;wtype_pos&#39;: 31}, {&#39;pos&#39;: 4, &#39;wlen&#39;: &#39;4&#39;, &#39;word&#39;: &#39;洗澡&#39;, &#39;wtype&#39;: &#39;动词&#39;, &#39;wtype_pos&#39;: 31}]} 文本纠错action = &#39;LexicalCheck&#39; #文本纠错 params = { &#39;text&#39;: &#39;人生苦短，我用Python！哼哼哈嘿！巴啦巴啦小魔仙！&#39; } https://wenzhi.api.qcloud.com/v2/index.php {&#39;code&#39;: 0, &#39;codeDesc&#39;: &#39;Success&#39;, &#39;conf&#39;: 1, &#39;message&#39;: &#39;&#39;, &#39;text&#39;: &#39;人生苦短，我用Python！哼哼哈嘿！巴啦巴啦小魔仙！&#39;, &#39;text_annotate&#39;: &#39;人生苦短，我用Python！哼哼哈嘿！巴啦巴啦小魔仙！&#39;} 同义词action = &#39;LexicalSynonym&#39;# 同义词 params = { &#39;text&#39;: &#39;人生苦短，我用Python。我爱自然语言处理和知识图谱！&#39; } https://wenzhi.api.qcloud.com/v2/index.php {&#39;code&#39;: 0, &#39;codeDesc&#39;: &#39;Success&#39;, &#39;message&#39;: &#39;&#39;, &#39;query&#39;: None, &#39;syns&#39;: [{&#39;word_ori&#39;: {&#39;idx_beg&#39;: 7, &#39;idx_end&#39;: 8, &#39;text&#39;: &#39;爱&#39;}, &#39;word_syns&#39;: [{&#39;conf&#39;: 0.32546776533127, &#39;text&#39;: &#39;最爱&#39;}]}, {&#39;word_ori&#39;: {&#39;idx_beg&#39;: 8, &#39;idx_end&#39;: 9, &#39;text&#39;: &#39;自然&#39;}, &#39;word_syns&#39;: [{&#39;conf&#39;: 0.36934259533882, &#39;text&#39;: &#39;大自然&#39;}]}, {&#39;word_ori&#39;: {&#39;idx_beg&#39;: 11, &#39;idx_end&#39;: 12, &#39;text&#39;: &#39;和&#39;}, &#39;word_syns&#39;: [{&#39;conf&#39;: 0.60000002384186, &#39;text&#39;: &#39;与&#39;}]}, {&#39;word_ori&#39;: {&#39;idx_beg&#39;: 13, &#39;idx_end&#39;: 14, &#39;text&#39;: &#39;图谱&#39;}, &#39;word_syns&#39;: [{&#39;conf&#39;: 0.37899446487427, &#39;text&#39;: &#39;图片&#39;}]}]} 文本分类action = &#39;TextClassify&#39; #文本分类 params = { &#39;content&#39;:&#39;人生苦短，please Python。太祖、刘邦、朱元璋哪个更厉害？！&#39; } https://wenzhi.api.qcloud.com/v2/index.php {&#39;classes&#39;: [{&#39;class&#39;: &#39;文化&#39;, &#39;class_num&#39;: 61, &#39;conf&#39;: 0.713}, {&#39;class&#39;: &#39;历史&#39;, &#39;class_num&#39;: 95, &#39;conf&#39;: 0.221}, {&#39;class&#39;: &#39;未分类&#39;, &#39;class_num&#39;: 0, &#39;conf&#39;: 0.066}], &#39;code&#39;: 0, &#39;codeDesc&#39;: &#39;Success&#39;, &#39;message&#39;: &#39;&#39;} 句法分析action = &#39;TextDependency&#39;# 句法分析 params = { &#39;content&#39;: &#39;我爱自然语言处理&#39; } https://wenzhi.api.qcloud.com/v2/index.php {&#39;code&#39;: 0, &#39;codeDesc&#39;: &#39;Success&#39;, &#39;keywords&#39;: [[{&#39;dep_rel&#39;: &#39;SBV&#39;, &#39;father_id&#39;: 2, &#39;id&#39;: 1, &#39;postag&#39;: &#39;r&#39;, &#39;word&#39;: &#39;我&#39;}, {&#39;dep_rel&#39;: &#39;HED&#39;, &#39;father_id&#39;: 0, &#39;id&#39;: 2, &#39;postag&#39;: &#39;v&#39;, &#39;word&#39;: &#39;爱&#39;}, {&#39;dep_rel&#39;: &#39;VOB&#39;, &#39;father_id&#39;: 2, &#39;id&#39;: 3, &#39;postag&#39;: &#39;n&#39;, &#39;word&#39;: &#39;自然语言&#39;}, {&#39;dep_rel&#39;: &#39;COO&#39;, &#39;father_id&#39;: 2, &#39;id&#39;: 4, &#39;postag&#39;: &#39;v&#39;, &#39;word&#39;: &#39;处理&#39;}]], &#39;message&#39;: &#39;&#39;} 关键词提取action = &#39;TextKeywords&#39; #关键词提取 params = { &#39;title&#39;: &#39;自然语言处理&#39;, &#39;content&#39;: &#39;&#39;&#39;自然语言处理（英语：natural language processing，缩写作 NLP）是人工智能和语言学领域的分支学科。此领域探讨如何处理及运用自然语言；自然语言认知则是指让电脑“懂”人类的语言。 自然语言生成系统把计算机数据转化为自然语言。自然语言理解系统把自然语言转化为计算机程序更易于处理的形式。&#39;&#39;&#39; } https://wenzhi.api.qcloud.com/v2/index.php {&#39;code&#39;: 0, &#39;codeDesc&#39;: &#39;Success&#39;, &#39;keywords&#39;: [{&#39;keyword&#39;: &#39;自然语言&#39;, &#39;score&#39;: 0.57486760616302, &#39;type&#39;: &#39;keyword&#39;}], &#39;message&#39;: &#39;&#39;} 敏感信息识别action = &#39;TextSensitivity&#39; #敏感信息识别 params = { &#39;content&#39;: &quot;中共统治！压迫，人民！续一秒！&quot;, &#39;type&#39;: 2 } https://wenzhi.api.qcloud.com/v2/index.php {&#39;code&#39;: 0, &#39;codeDesc&#39;: &#39;Success&#39;, &#39;message&#39;: &#39;&#39;, &#39;nonsensitive&#39;: 0.37754066879815, &#39;sensitive&#39;: 0.62245933120185}","categories":[{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/tags/NLP/"}]},{"title":"GithubPages新尝试","slug":"GithubPages新尝试","date":"2018-04-18T08:01:53.000Z","updated":"2020-01-18T11:56:36.476Z","comments":true,"path":"articles/GithubPages新尝试/","link":"","permalink":"https://www.iamlightsmile.com/articles/GithubPages%E6%96%B0%E5%B0%9D%E8%AF%95/","excerpt":"由于某些不便明说的原因，我要再申请一个域名，再申请一个GitHub账号，再搞一个GitHub Pages。打算用来记录一些不便明说的东西。 这次域名的申请不同于之前的在万网的iamlightsmile.com，这次是在腾讯云上申请的，不过都大同小异了。接着等待大概3天左右的实名认证，通过后域名就可以解析可用了。由于只是使用GitHub Pages 作为静态网页，不需要另外购置服务器，所以也不需要备案的了，备案真是好屌麻烦！","text":"由于某些不便明说的原因，我要再申请一个域名，再申请一个GitHub账号，再搞一个GitHub Pages。打算用来记录一些不便明说的东西。 这次域名的申请不同于之前的在万网的iamlightsmile.com，这次是在腾讯云上申请的，不过都大同小异了。接着等待大概3天左右的实名认证，通过后域名就可以解析可用了。由于只是使用GitHub Pages 作为静态网页，不需要另外购置服务器，所以也不需要备案的了，备案真是好屌麻烦！ 刚开始还挺顺利的，输入网址后顺利输出了相关内容，由于这次同样想使用Hexo搭建博客平台，所以也将先搭起环境然后设置相关github.io的项目，不过到了设置ssh这里出现了问题，经过测试发现可以访问，但是用hexo deploy时则提示权限受限，后来在网上连找了好久关于ssh的相关内容，不过尝试后发现并不能解决问题，后来在GitHub的settings页面中，在SSH keys下面发现一段比较小的段落，有一个common SSH Problems的超链接，点进去之后研磨了好久终于发现问题所在。 原来是由于我用的自己原来的GitHub账号来更新新创建的GitHub账号仓库的内容，默认的权限不够，只能通过将smilelight添加到该项目的协作者或同一个组织下才行。邀请了smilelight之后发现没有反应，账号下没有通知，也没有邮件提醒，还以为是GitHub的问题，后来把那个邀请链接复制下来之后，发现是一个新的页面，需要点进去点击接受才可以，经过几番磨练之后终于提交成功。 至于为什么Hexo还是用我原来的GitHub账号我就不清楚了，虽然我在这个文件的.git的config中修改了自己的用户名和邮箱，但是身份用的还是smilelight，估计可能Hexo默认或者只能使用全局的Git账号信息吧。","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"Github","slug":"Github","permalink":"https://www.iamlightsmile.com/tags/Github/"}]},{"title":"学习Python设计模式","slug":"学习Python设计模式","date":"2018-04-17T02:16:59.000Z","updated":"2020-01-18T11:26:43.052Z","comments":true,"path":"articles/学习Python设计模式/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E5%AD%A6%E4%B9%A0Python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","excerpt":"本书主要参阅的书籍是《精通Python设计模式》 本书分为创建型模式、结构型模式、行为型模式三大类，同时又细分为16种模式。具体到每个模式，则通过简单介绍、现实生活中例子、软件应用实例、应用场景、具体代码实现、小结几部分，多个角度加深对某个设计模式的理解。案例贴近生活，代码简单易懂，描述清晰明白，翻译水平上佳，确实算是我认为的好书，同时翻译还将代码上传到GitHub上方便读者下载学习，这里真应该点个赞了！","text":"本书主要参阅的书籍是《精通Python设计模式》 本书分为创建型模式、结构型模式、行为型模式三大类，同时又细分为16种模式。具体到每个模式，则通过简单介绍、现实生活中例子、软件应用实例、应用场景、具体代码实现、小结几部分，多个角度加深对某个设计模式的理解。案例贴近生活，代码简单易懂，描述清晰明白，翻译水平上佳，确实算是我认为的好书，同时翻译还将代码上传到GitHub上方便读者下载学习，这里真应该点个赞了！ 我们在学习设计模式的时候不应当仅仅立足于软件开发这一角度，同时应该立足于实际，或者以更加抽象的角度来看待这些设计模式背后的思想。比如针对某个设计模式，我们要明白想通过它实现怎么样的功能，这样设计的好处在哪里，我要提供什么输入，我将得到什么输出，即通过函数或黑盒子的视角从外面看待这个设计模式。同时也要将视角放到该设计模式的内部，可以把具体的某个方法视为车间、某个对象视为工人，将之与现实世界某个应用场景映射起来，分析通过怎么样的一个调度实现了业务的功能，其中的结构优势何在，节省了空间还是时间上的资源等。 笔记摘抄 设计模式的本质是在已有的方案之上发现更好的方案（而不是全新发明）。 设计模式并非是某种高大上或者神秘的东西，而是一些常见的软件工程设计问题的最佳实践方案。 个人认为软件开发技术的学习都应该以实践为前提，只有理解实践过程中遇到的种种问题，才能明白那些技术的本质和目的是什么，因为每种新技术都是因某个/某些问题而出现的。 设计模式一般是描述如何组织代码和使用最佳实践来解决常见的设计问题。 书籍结构创建型模式创建型设计模式处理对象创建相关的问题，目标是当直接创建对象不太方便时，提供更好的方式。 工厂模式工厂背后的思想是简化对象的创建 通过将创建对象的代码和使用对象的代码解耦，工场能够降低应用维护的复杂度。 工厂通常有两种形式：一种是工厂方法，它是一个方法（或以地道的Python数据来说，是一个函数），对不同的输入参数返回不同的对象；第二种是抽象工厂，它是一组用于创建一系列相关事物对象的工厂方法。 工厂方法可以在必要时创建新的对象，从而提高性能和内存使用率。 一个抽象工厂是（逻辑上的）一组工厂方法，其中的每个工厂方法负责产生不同种类的对象。 抽象工厂模式是工厂方法模式的一种泛化。 通常一开始时使用工厂方法，因为它更简单。 工厂方法和抽象工厂设计模式可适用于以下场景： 想要追踪对象莱恩创建时 想要将对象的创建与使用解耦时 想要优化应用的性能和资源占用时 建造者模式建造者模式将一个复杂对象的构造过程与其表现分离，这样，同一个构造过程可用于创建多个不同的表现。 如果我们知道一个对象必须经过多个步骤来创建，并且要求同一个构造过程可以产生不同的表现，就可以使用建造者模式。 建造者模式可适用于以下场景： 想要创建一个复杂对象（对象由多个部分构成，且对象的创建要经过多个不同的步骤，这些步骤也许还需遵从特定的顺序） 要求一个对象能有不同的表现，并希望将对象的构造与表现解耦 想要在某个时间点创建对象，但在稍后的时间点再访问 原型模式原型设计模式用于创建对象的完全副本。 一般创建副本的两种方式： 当创建一个浅副本时，副本依赖引用 当创建一个深副本时，副本复制所有东西 第一种情况下，我们希望提升应用性能和优化内存使用，在对象之间引入数据共享，但需要小心地修改数据，因为所有变更对所有副本都是可见的。 第二种情况下，我们希望能够对一个副本进行更改而不会影响其他对象。 结构型模式结构型设计模式处理一个系统中不同实体（比如，类和对象）之间的关系，关注的是提供一种简单的对象组合方式来创建新功能。 适配器模式适配器模式帮助我们实现两个不兼容接口之间的兼容 开放/封闭原则（open/close principle）是面向对象设计的基本原则之一，声明一个软件实体应该对拓展是开放的，对修改则是封闭的。本质上这意味着我们应该无需修改一个软件实体的源码就能拓展其行为。适配器模式遵从开放/封闭原则。 适配器让一件产品在制造出来之后需要应对新需求之时还能工作。 修饰器模式修饰器模式通常用于拓展一个对象的功能。 一般来说，应用中有些部件是通用的，可应用于其他部件，这样的部件被看作横切关注点。 修饰器模式是实现横切关注点的绝佳方案，因为横切关注点通用但不太适合使用面向对象编程范式来实现。 Python进一步拓展了修饰器的概念，允许我们无需使用继承或组合就能拓展任意可调用对象（函数、方法或类）的行为。 外观模式外观模式有助于隐藏系统所的内部复杂性，并通过一个简化的接口向客户端暴露必要的部分。本质上，外观（Facade）是在已有复杂系统之上实现的一个抽象层。 使用外观模式的最常见理由是为一个复杂系统提供单个简单的入口点。 不把系统的内部功能暴露给客户端代码有一个额外的好处：我们可以改变系统内部代码，但客户端代码不用关心这个改变，也不会受到这个改变的影响。客户端代码不需要进行任何改变。 如果你的系统包含多层，外观模式也能派上用场。你可以为每一层引入一个外观入口点，并让所有层级通过它们的外观相关通信。这提高了层级之间的松耦合性，尽可能保持层级独立。 外观模式是一种隐藏系统复杂性的优雅方式，因为多数情况下客户端代码并不应该关心系统的这些细节。 享元模式作为软件工程师，我们应该编写更好的软件来解决软件问题，而不是要求客户购买更多更好的硬件。 享元模式通过为相似对象引入数据共享来最小化内存使用，提升性能。 一个享元（Flyweight）就是一个包含状态独立的不可变（又称固有的）数据的共享对象。 若想要享元模式有效，需要满足GoF的《设计模式》一书罗列的以下几个条件。 应用需要使用大量的对象。 对象太多，存储/渲染它们的代价太大。 对象ID对于应用不重要。 一般来说，在应用需要创建大量的计算代价大但共享许多属性的对象时，可以使用享元。 模型-视图-控制器模式关注点分离（Separation of Concerns，SoC）原则是软件工程相关的设计原则之一。 SoC原则背后的思想是将一个应用切分成不同的部分，每个部分解决一个单独的关注点。 模型-视图-控制器（Model-View-Controller，MVC）模式是应用到面向对象编程的SOC原则。 其中，模型是核心的部分，代表着应用的信息本源，包含和管理（业务）逻辑、数据、状态以及应用的规则。视图是模型的可视化表现。视图只是展示数据，并不处理数据。控制器是模型与视图之间的链接/粘附。模型与视图之间的所有通信都通过控制器进行。 为了实现模型与其表现之间的解耦，每个视图通常都需要属于它的控制器。（我认为作者想表达的是没有控制器也可以，但是由于视图并不具备处理数据的功能，并且通常每个页面所要处理的业务都会不同，因此这样的模型是高度定制的模型，适用性很差） 在从头开始实现MVC时，请确保创建的模型很智能，控制器很瘦，视图很傻瓜。 可以将具有以下功能的模型视为智能模型： 包含所有的校验/业务规则/逻辑 处理应用的状态 访问应用数据（数据库、云或其他） 不依赖UI可以将符合以下条件的控制器视为瘦控制器： 在用户与视图交互时，更新模型 在模型改变时，更新视图 如果需要，在数据传递给模型/视图之前进行处理 不展示数据 不直接访问应用数据 不包含校验/业务规则/逻辑可以将符合以下条件的视图视为傻瓜视图： 展示数据 允许用户与其交互 仅做最小的数据处理，通常由一种模板语言提供处理能力（例如，使用简单的变量和循环控制） 不存储任何数据 不直接访问应用数据 不包含校验/业务规则/逻辑 使用MVC时，请确保创建智能的模型（核心功能）、瘦控制器（实现视图与模型之间通信的能力）以及傻瓜式的视图（外在表现，最小化逻辑处理） 代理模式四种不同的知名代理类型： 远程代理：实际存在于不同地址空间（例如，某个网络服务器）的对象在本地的代理者。 虚拟代理：用于懒初始化，将一个大计算量对象的创建延迟到真正需要的时候进行。 保护/防护代理：控制对敏感对象的访问。 智能（引用）代理：在对象被访问时执行额外的动作。此类代理的例子包括引用计数和线程安全检查。 现实中，，永远不要执行以下操作： 在源代码中存储密码 以明文形式存储密码 使用一种弱（例如，MD5）或自定义加密形式 行为型模式行为型模式处理对象互联和算法的问题 责任链模式责任链（Chain of Responsibility）模式用于让多个对象来处理单个请求时，或者用于预先不知道应该由哪个对象（来自某个对象链）来处理某个特定请求时。其原则如下所示： 存在一个对象链（链表、树或任何其他便捷的数据结构）。 我们一开始将请求发送给链中的第一个对象。 对象决定其是否要处理该请求。 对象将请求转发给下一个对象。 重复该过程，直到到达链尾。 通过使用责任链模式，我们能让许多对象来处理一个特定请求。在我们预先不知道应该由哪个对象来处理某个请求时，这是有用的。另一个责任链可以派上用场的场景是，在我们知道可能会有多个对象都需要对同一个请求进行处理之时。 这一模式的价值在于解耦。 客户端与所有处理程序（一个处理程序与所有其他处理程序之间也是如此）之间不再是多对多关系，客户端仅需要知道如何与链的起始节点（标头）进行通信。 在无法预先知道处理程序的数量和类型时，该模式有助于对请求/处理事件进行建模。适合使用责任链模式的系统例子包括基于事件的系统、采购系统和运输系统。 命令模式命令设计模式帮助我们将一个操作（撤销、重做、复制、粘贴）封装成一个对象。简而言之，这意味着创建一个类，包含实现该操作所需要的所有逻辑和方法。 这样做的优势如下所述参考： 我们并不需要直接执行一个命令。命令可以按照希望执行。 调用命令的对象与知道如何执行命令的对象解耦。调用者无需知道命令的任何实现细节。 如果有意义，可以把多个命令组织起来，这样调用者能够按顺序执行它们。例如，在实现一个多层撤销命令时，这是很有用的。 解释器模式解释器（Interpreter）模式仅能引起应用的高级用户的兴趣。这是因为解释器模式背后的贮存思想是让非初级用户和领域专家使用一门简单的语言来表达想法。 领域特定语言（Domain Specific Language，DSL）是一种针对一个特定领域的有限表达能力的计算机语言。DSL分为内部DSL和外部DSL。 内部DSL构建在一个宿主编程语言之上。 优势：我们不必担心创建、编译及解析语法，因为这些已经被宿主语言解决掉了。 劣势：会受限于宿主语言的特性。如果宿主语言不具备这些特性，构建一种表达能力强、简洁而且优美的内部DSL是富有挑战性的。 外部DSL不依赖某种宿主语言。DSL的创建者可以决定语言的方方面面（语法、句法等），但也要负责为其创建一个解析器和编译器。为一种新语言创建解析器和编译器是一个非常复杂、长期而又痛苦的过程。 解释器模式仅与内部DSL相关。 观察者模式观察者模式描述单个对象（发布者，又称为主持者或可观察者）与一个或多个对象（订阅者，又称为观察者）之间的发布-订阅关系。 观察者模式背后的思想等同于MVC和关注点分离原则背后的思想，即降低发布者与订阅者之间的耦合度，从而易于在运行时添加/删除订阅者。此外，发布者不关心它的订阅者是谁。它只是将通知发送给所有订阅者。 当我们希望在一个对象（主持者/发布者/可观察者）发生变化时通知/更新另一个或多个对象的时候，通常会使用观察者模式。观察者的数量以及谁是观察者可能会有所不同，也可以（在运行时）动态地改变。 状态模式在很多问题中，有限状态机（通常名为有限状态机）是一个非常方便的状态转换建模（并在必要时以数学方式形式化）工具。 状态机是一个抽象机器，有两个关键部分，状态和转换。状态是指系统的当前（激活）状况。一个状态机在任意时间点只会有一个激活状态。转换是指从一个状态切换到另一个状态，因某个事件或条件的触发而开始。在一个转换发生之前或之后通常会执行一个或多个动作。 状态机带一个不错的特性是可以用图来表现（称为状态图），其中每个状态都是一个节点，每个转换都是两个节点之间的边。 状态模式就是应用到一个特定软件工程问题的状态机。 使用状态模式本质上相当于实现一个状态机来解决特定领域的一个软件问题。 状态设计模式解决的是一定上下文中无限数量状态的完全封装，从而实现更好的可维护性和灵活性。 策略模式策略模式通常用在我们希望对同一个问题透明地使用多种方案时。如果并不存在针对所有输入数据和所有情况的完美算法，那么我们可以使用策略模式，动态地决定在每种情况下应使用哪种算法。 模板模式编写优秀代码的一个要素是避免冗余。 模板模式关注的是消除代码冗余，其思想是我们应该无需改变算法结构就能重新定义一个算法的某个部分。 设计模式是被发现，而不是被发明出来的。","categories":[{"name":"Python","slug":"Python","permalink":"https://www.iamlightsmile.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://www.iamlightsmile.com/tags/Python/"}]},{"title":"哈工大ltp小试","slug":"哈工大ltp小试","date":"2018-04-07T15:28:35.000Z","updated":"2020-01-18T11:52:16.895Z","comments":true,"path":"articles/哈工大ltp小试/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E5%93%88%E5%B7%A5%E5%A4%A7ltp%E5%B0%8F%E8%AF%95/","excerpt":"今天开始探索学习使用哈工大的LTP（Language Technology Platform）。 这里是官网地址 这里是GitHub地址 这里是pyltp的使用文档 平台采用的语言是C++，但是也提供了Python和Java的封装。由于本人目前使用Python作为自然语言处理的工具语言，所以以下的探索流程都是使用本人电脑中的Window8.1操作系统的PyCharm集成开发环境，使用的Python版本是3.6。","text":"今天开始探索学习使用哈工大的LTP（Language Technology Platform）。 这里是官网地址 这里是GitHub地址 这里是pyltp的使用文档 平台采用的语言是C++，但是也提供了Python和Java的封装。由于本人目前使用Python作为自然语言处理的工具语言，所以以下的探索流程都是使用本人电脑中的Window8.1操作系统的PyCharm集成开发环境，使用的Python版本是3.6。 使用流程很简单： 下载最新版本的模型（目前是3.4） 安装pyltp，在命令行输入指令：pip install pyltp。不过我的一直安装失败，总是不成功，后来从网上找了pyltp 3.6的whl文件，然后通过pip install pyltp-0.2.1-cp36-cp36m-win_amd64.whl成功了。 这里有一篇博客专门讲安装的，发现他的界面有点黑客风，挺炫酷的哈~ 通过PyCharm新建Python项目后，整个工程长成这个样子： 不过其中的data文件夹、source文件夹和test文件夹是自己新创建的，其中data文件夹内放置下载的模型，source文件夹放置那个其实也没啥东西的txt文件，test中放置编写的Python代码。 照着使用文档敲的testltp.py内容如下： import pyltp # 分句 from pyltp import SentenceSplitter sents = SentenceSplitter.split(&#39;元芳你怎么看？我就趴窗口上看呗！&#39;) print(&#39;\\n&#39;.join(sents)) # 分词 from pyltp import Segmentor segmentor = Segmentor() segmentor.load(&#39;../data/cws.model&#39;) words = segmentor.segment(&quot;元芳你怎么看&quot;) segmentor.release() print(list(words)) # 词性标注 from pyltp import Postagger postagger = Postagger() postagger.load(&#39;../data/pos.model&#39;) posts = postagger.postag(list(words)) postagger.release() print(list(zip(list(words),list(posts)))) #命名实体识别 from pyltp import NamedEntityRecognizer recognizer = NamedEntityRecognizer() recognizer.load(&#39;../data/ner.model&#39;) nettags = recognizer.recognize(list(words),list(posts)) recognizer.release() print(list(zip(list(words),list(nettags)))) #依存语法分析 from pyltp import Parser parer = Parser() parer.load(&#39;../data/parser.model&#39;) arcs = parer.parse(list(words),list(posts)) parer.release() print(list(zip(list(words),[(arc.head,arc.relation) for arc in arcs]))) #语义角色标注 from pyltp import SementicRoleLabeller labeller = SementicRoleLabeller() labeller.load(&#39;../data/pisrl_win.model&#39;) roles = labeller.label(list(words),list(posts),arcs) labeller.release() for role in roles: print(role.index, &quot;&quot;.join( [&quot;%s:(%d,%d)&quot; % (arg.name, arg.range.start, arg.range.end) for arg in role.arguments])) 其中我的pyltp不知道怎么安装的，竟然成了build-in里的东西了，而不是在site-packages里面。 执行以上代码的结果为： 其中要注意的是这里在语义角色标注中使用的并非pisrl.model而是pisrl_win.model，前者会报错的。 同时由于文档中提到： 于是我又去申请了哈工大的语言云个人账号,经过邮箱激活之后，按照人家的使用文档就要探索一下，不过没想到出现了问题。。。 由于官网提供的Python示例代码使用的是2.7版本，所以这里我使用的是另外的一个网络请求模块：requests，最终的代码testltpCloud.py长成这样： import requests from settings import APIKEY url_get_base = &quot;http://api.ltp-cloud.com/analysis/&quot; args = { &#39;api_key&#39;: APIKEY, &#39;text&#39;: &#39;我是中国人。&#39;, &#39;pattern&#39;: &#39;dp&#39;, &#39;format&#39;: &#39;plain&#39; } # result = urllib.request.urlopen(url_get_base, urllib.parse.urlencode(args)) # POST method result = requests.post(url_get_base,args) print(result.text) 在同路径下的settings.py的内容为： 其中APIKEY的内容是邮件发给你的api_key字符串。 不过运行的结果为： 显示未授权用户，但是我的账户类型是免费的，刚注册的啊，为啥这样，搜了搜没搜出个啥，就先这样吧。 又向目标迈进了一步，嘿嘿，加油！","categories":[{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/categories/NLP/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://www.iamlightsmile.com/tags/Python/"},{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/tags/NLP/"},{"name":"ltp","slug":"ltp","permalink":"https://www.iamlightsmile.com/tags/ltp/"}]},{"title":"Scrapy爬取知乎数据小试","slug":"Scrapy爬取知乎数据小试","date":"2018-04-06T15:06:27.000Z","updated":"2020-01-18T11:58:23.466Z","comments":true,"path":"articles/Scrapy爬取知乎数据小试/","link":"","permalink":"https://www.iamlightsmile.com/articles/Scrapy%E7%88%AC%E5%8F%96%E7%9F%A5%E4%B9%8E%E6%95%B0%E6%8D%AE%E5%B0%8F%E8%AF%95/","excerpt":"啊啊啊，没时间写啦，以后有时间再写吧！ 。。。发现今天是周五，不熄灯。。。 前两周一直在忙毕设的事情，由于某些原因毕设选择了相对简单的微信小程序，经过奋战之后一些主要的基本功能已经实现多半。 自然语言处理的一些最基本的概念已经有所了解，下面想要找点实战项目练练手。由于处理的第一步便是要获取语料，想着以后爬虫这东西肯定是要学的，于是从昨天开始学习相关视频、配置相关环境，今天看了部分，照着Demo练了练小手。","text":"啊啊啊，没时间写啦，以后有时间再写吧！ 。。。发现今天是周五，不熄灯。。。 前两周一直在忙毕设的事情，由于某些原因毕设选择了相对简单的微信小程序，经过奋战之后一些主要的基本功能已经实现多半。 自然语言处理的一些最基本的概念已经有所了解，下面想要找点实战项目练练手。由于处理的第一步便是要获取语料，想着以后爬虫这东西肯定是要学的，于是从昨天开始学习相关视频、配置相关环境，今天看了部分，照着Demo练了练小手。 B站真是个好地方，上面有不少免费的好的视频可以看，虽然版权这方面%&amp;@#￥！@￥……@#￥%……#@￥%##￥@ 这是学习爬虫的视频链接 作者是拿轮子哥vczh作为start_user的，当时还愣了一下，可以的，会玩，想当年自己也关注过轮子哥一段时间，不过看他经常给美女们点赞、抖机灵，后来便取关了。 废话少说，言归正传： 爬虫：请求网站并提取数据的自动化程序。 爬虫的基本流程： 发起请求：通过HTTP库向目标站点发起请求,即发送一个Request,情况请可以包含额外的headers等信息,等待服务器响应。 获取响应内容：如果服务器能正常响应，会得到一个Response，Response的内容便是所要获取的页面内容，内容可能有HTML，Json字符串，二进制数据（如图片视频）等类型。 解析内容：得到的内容可能是HTML，可以用正则表达式、网页解析库进行解析，可呢是Json，可以直接转为Json对象解析，可能是二进制数据，可以做保存或者进一步的处理。 保存数据：保存形式多样，可以存为文本，也可以保存至数据库，或者保存特定格式的文件。 项目所实现的是从首个著名知乎用户（本项目中为vczh）个人信息及其所有关注人、所有粉丝相关信息爬取开始、一直延伸整个关注网，并将结果数据集保存在MongoDB中。 具体来说就是先爬轮子哥的个人信息数据，然后依次爬取他的所有关注人的个人信息以及他的所有粉丝们的个人信息，这样的策略应用到每一个爬虫经过的用户上，从而实现数据的遍历抽取。单纯从Python代码的角度上讲，类似于会重复的深度优先遍历，然而具体的Scrapy引擎内部会如何调度这些Request队列就是人家内部的算法了。 视频的上传时间是18年1月11日，当时从网页中获取到的用户信息相对比较简单、集中、丰富，今天我试了又试，发现可获取到的直接信息变少了。由于只是初步尝试，所以也就按部就班的照样执行，没有做得不偿失的优化了。 Scrapy引擎的框架大致如下： 我们可以看到整个引擎主要是由四部分组成： Scheduler（调度器） Downloader（下载器） Spiders（爬虫） Item Pipeline（项目 管道） 其中Spider中定义了具体的爬虫逻辑，比如我们要怎么爬，爬什么，后面跟着的s表明这通常不是一个Spider，而是通常有多个Spider，我们可以根据不同的具体需求编写对应的Spider。 Spiders之上的是一些Spider Middlewares（即爬虫中间件），有点类似于Python中函数的修饰器，可以对函数进行一些增强和拓展，同样的，我们可以通过这些Spider中间件来丰富和拓展我们编写的小Spider，让它们表现的更给力一些，同时这也可以简化我们的编写逻辑，因为我们只需要在之上套些中间件就可以了，套什么中间件视具体需求而定，比如说冬天穿大衣、夏天穿衬衫等。 当Spider生成好之后，引擎会开始执行这个Spider的内部逻辑，如start_requests方法，和parse方法等等，具体的它会将HTTP的Request请求交给Downloader完成，由Downloader完成从Internet上下载资源数据的具体任务，而Downloader也可以有自己的中间件也就是Downloader Middlewares，可以对Downloader进行改装，增强。 Downloader完成下载后，Scrapy引擎会将Downloader的成果Responses交给之前的Spider，执行它的解析方法。之后视具体情况，Spider可能会爬取更多的数据，相应的会产生更多的Request请求，或者将Response中的数据进行处理，处理为Item，然后转交给Item Pipeline做最后的数据处理工作。 因为爬虫一般不是一个一个的爬，而是通常成百上千乃至上万的爬，Scheduler的主要作用类似于CPU的处理器对这些请求做一个规划调度，先做哪个，后做哪个等等。 Item Pipline 中，Item可以视为一个数据对象的容器，而Pipline则类似Unix系统中的管道，或者更通俗点，就像流水线的的工人，从网上获取原材料之后，Spider这个工人进行加工处理，之后这些Pipline们做做类似贴标签的工作，最终提交正式的产品。 因为我们爬虫的编写都是具有针对性的，知己知彼百战不殆嘛。所以首先要分析知乎相关的数据流通状况： 以上是轮子哥的知乎页面。 首先必须要按F12打开开发者工具，查看Network页面。 对于某个用户的具体信息，如关注人或粉丝列表中的，我们只需要将鼠标请放在某个人的图像上，知乎就会通过Ajax去请求这个人的数据，以Json对象的格式返回给浏览器，同样的，当我们查看关注人列表和粉丝列表时，知乎也是通过Ajax请求返回这些数据对象的，具体的如以下几张图片： 这是轮子哥关注的某个人的信息，观看图右侧我们发现这个人相关信息就在这个Json对象中。而如果要获取到这个Response体中的Json对象，我们只要执行最上面的网络请求就可以了： 还有类似的关注人列表和粉丝列表也都是大概类似的情况，不过情况的url中的参数和内容稍有不同罢了。 关注人列表： 相关请求： 粉丝列表： 相关请求： 其实爬虫这个东西的基本原理很简单，就是执行HTTP请求，处理响应的数据，将这个过程重复化自动化而已。 而基于前面我们所提到的爬取信息的相关策略，我们要做的就是爬轮子哥的数据，然后请求两个列表中其他人的数据，并拓展开来。 整个项目的结构如下： 这里我们需要编写的是zhihu.py、items.py、piplines.py、settings.py 在settings.py中我们进行了请求头、Item Pipline中间件和MongoDB相关的配置。 如下： DEFAULT_REQUEST_HEADERS = { &#39;Accept&#39;: &#39;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#39;, &#39;Accept-Language&#39;: &#39;en&#39;, &#39;User-Agent&#39;: &#39;Mozilla/5.0 (Windows NT 6.3; W…) Gecko/20100101 Firefox/57.0&#39;, &#39;authorization&#39;:&#39; oauth c3cef7c66a1843f8b3a9e6a1e3160e20&#39; } ITEM_PIPELINES = { &#39;zhihuUser.pipelines.MongoPipeline&#39;: 300, } MONGO_URI = &#39;localhost&#39; MONGO_DATABASE = &#39;zhihu&#39; 我们针对Json对象的内容编写的ZhihuUserItem对象： from scrapy import Item,Field class ZhihuUserItem(Item): # define the fields for your item here like: # name = scrapy.Field() id = Field() is_followed = Field() avatar_url_template = Field() user_type = Field() answer_count = Field() is_following = Field() url = Field() url_token = Field() allow_message = Field() articles_count = Field() is_blocking = Field() name = Field() headline = Field() badge = Field() is_advertiser = Field() avatar_url = Field() is_org = Field() gender = Field() follower_count = Field() employments = Field() type = Field() 因为要将数据存储到MongoDB中，所以要进行MongoDB的Item Pipline中间件的编写： import pymongo class MongoPipeline(object): collection_name = &#39;user_info&#39; def __init__(self, mongo_uri, mongo_db): self.mongo_uri = mongo_uri self.mongo_db = mongo_db @classmethod def from_crawler(cls, crawler): return cls( mongo_uri=crawler.settings.get(&#39;MONGO_URI&#39;), mongo_db=crawler.settings.get(&#39;MONGO_DATABASE&#39;) ) def open_spider(self, spider): self.client = pymongo.MongoClient(self.mongo_uri) self.db = self.client[self.mongo_db] def close_spider(self, spider): self.client.close() def process_item(self, item, spider): self.db[self.collection_name].insert_one(dict(item)) # self.db[self.collection_name].update({&#39;url_token&#39;: item[&#39;url_token&#39;]},{&#39;$set&#39;: item},True) 最后是zhihu.py 中 ZhihuSpider的编写： import json import scrapy from scrapy import Request from zhihuUser.items import ZhihuUserItem class ZhihuSpider(scrapy.Spider): name = &#39;zhihu&#39; allowed_domains = [&#39;www.zhihu.com&#39;] start_urls = [&#39;http://www.zhihu.com/&#39;] start_user = &#39;excited-vczh&#39; user_url = &#39;https://www.zhihu.com/api/v4/members/{user}?include={include}&#39; user_query = &#39;allow_message,is_followed,is_following,is_org,is_blocking,employments,answer_count,follower_count,articles_count,gender,badge[?(type=best_answerer)].topics&#39; followees_url = &#39;https://www.zhihu.com/api/v4/members/{user}/followees?include={include}&amp;offset={offset}&amp;limit={limit}&#39; followees_query = &#39;data[*].answer_count,articles_count,gender,follower_count,is_followed,is_following,badge[?(type=best_answerer)].topics&#39; followers_url = &#39;https://www.zhihu.com/api/v4/members/{user}/followers?include={include}&amp;offset={offset}&amp;limit={limit}&#39; followers_query = &#39;data[*].answer_count,articles_count,gender,follower_count,is_followed,is_following,badge[?(type=best_answerer)].topics&#39; def start_requests(self): yield Request(self.user_url.format(user=self.start_user,include=self.user_query),callback=self.parse_user) # yield Request(self.followees_url.format(user=self.start_user,include=self.followees_query,offset=0,limit=20),callback=self.parse_followees) def parse_user(self, response): result = json.loads(response.text) item = ZhihuUserItem() for field in item.fields: if field in result.keys(): item[field] = result.get(field) yield item yield Request(self.followees_url.format(user=result.get(&#39;url_token&#39;), include=self.followees_query, offset=0, limit=20), callback=self.parse_followees) yield Request( self.followers_url.format(user=result.get(&#39;url_token&#39;), include=self.followers_query, offset=0, limit=20), callback=self.parse_followees) # print(json.loads(response.text)) def parse_followees(self, response): result = json.loads(response.text) if &#39;data&#39; in result.keys(): for result in result.get(&#39;data&#39;): yield Request(self.user_url.format(user=result.get(&#39;url_token&#39;),include=self.user_query),callback=self.parse_user) if &#39;paging&#39; in result.keys() and result.get(&#39;paging&#39;).get(&#39;is_end&#39;) == False: next_page = result.get(&#39;paging&#39;).get(&#39;next&#39;) yield Request(next_page,callback=self.parse_followees) def parse_followers(self, response): result = json.loads(response.text) if &#39;data&#39; in result.keys(): for result in result.get(&#39;data&#39;): yield Request(self.user_url.format(user=result.get(&#39;url_token&#39;),include=self.user_query),callback=self.parse_user) if &#39;paging&#39; in result.keys() and result.get(&#39;paging&#39;).get(&#39;is_end&#39;) == False: next_page = result.get(&#39;paging&#39;).get(&#39;next&#39;) yield Request(next_page,callback=self.parse_followers) def parse(self, response): pass 在终端下执行scrapy crawl zhihu后，爬虫便会开始启动，由于这个工程一直爬一直爬，所以让它爬一会做个样子就行了，通过Ctrl+C停止当前任务，随后我们可以通过可视化工具查看到存入MongoDB中的数据： 大功告成！虽然超级简单。。。","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"https://www.iamlightsmile.com/tags/%E7%88%AC%E8%99%AB/"},{"name":"Scrapy","slug":"Scrapy","permalink":"https://www.iamlightsmile.com/tags/Scrapy/"}]},{"title":"微信小程序的component","slug":"微信小程序探索随笔","date":"2018-03-28T09:14:22.000Z","updated":"2020-01-18T11:55:22.874Z","comments":true,"path":"articles/微信小程序探索随笔/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%8E%A2%E7%B4%A2%E9%9A%8F%E7%AC%94/","excerpt":"我发现无法直接在样式即wxss里通过color属性设置icon组件的颜色，是无效的，只能通过在wxml里设置它的color属性为js传入的变量值或者是通过变量值来控制具体的颜色值。","text":"我发现无法直接在样式即wxss里通过color属性设置icon组件的颜色，是无效的，只能通过在wxml里设置它的color属性为js传入的变量值或者是通过变量值来控制具体的颜色值。 我们可以将微信小程序中的components组件视为一个对象，没错，它本来就是一个对象，只是相对而言，它的初始化方法和设置方式不同于在一般的js语言中，它的data属性里是这个对象建立时初始化时的数据，作用域和生命周期伴随着component对象实例，而properties属性效果类似，均可以在component对象内部的函数和方法中使用this.data获取到，只是相对而言，data的数据是组件内部的数据，它是属于组件本身的属性，从设计上讲不取决于外部的应用场景；而properties属性则是暴露在组件外部的属性，它的作用相当于一般的编程语言中我们在new一个对象时做的初始化工作如new People(name=”lightsmile”,sex = false)，也就是说组件的一些业务属性是要通过这些属性接口来实现的，它是根据场景所制订的，具体实例体现在如：&lt;order-by bindtap=&quot;handOrderTap&quot; id=&quot;fuck&quot; test=&quot;{{5}}&quot; data-tes=&quot;{{test}}&quot; data-fuck=&quot;fuck&quot; data-order=&quot;{{orders}}&quot; data-&gt;&lt;/order-by&gt; 中id是每个标签都具有的值，而以“data-”开头的数据都是这个页面中，暴露给触发事件的值，在事件处理函数中，可以通过如handOrderTap(e) { console.log(e) console.log(e.currentTarget.id) this.fuck = this.selectComponent(&quot;#fuck&quot;) console.log(this.fuck.data) console.log(this.fuck.dataset) } 获取到e（event）事件的具体信息，这里的handOrderTag只是自定义的函数，e.target和e.currentTarget分别代表不同的对象。 其中target是指事件的原触发对象，而currentTarget是指当前事件的触发对象，这是与事件的冒泡捕获机制相关的。 而不以“data-”开头，也不是如class、id、style等其他的属性如在上例中属性名为test的是页面传递给组件对象的信息，这里的test对应着组件对象之前设定的test属性，即在2中提到的暴露的属性名 而“=”号后面的“”和“”则均是属于当前页面的逻辑层Page对象内部的数据，即this.data.test和this.tata.orders（其中的this指代的是当前对象），也就是说，在与Component组件或页面Page对象对应的wxml中，其中的永远都是指的当前组件或页面对象，无法外指和内值，即在Component对应wxml中无法引用外部Page的对象（这个很合理，因为组件本来就是要被复用的，不应该出现还可以引用外部的数据的情况），Page对应的wxml中也无法引用内部Component对象的内部属性，而如果要使用内部的值，一种方法是内部定义触发的方法然后再使用如this.triggerEvent(‘change’, this)触发外部的change事件，这样组件外部就可以使用bindchange=”方法名”进行handle处理了。如下几个阶段： 1. 在Page的wxml中使用组件order-by,绑定了自定义事件MyEvent，这样在MyEvent事件被触发时，Page对象的handleMyEvent方法就会被执行。 2. handleMyEvent方法的内容如下： 3.Component的wxml中的text组件绑定tap事件到Component对象的myEvent方法 4.myEvent方法的内容如下： 因此整个的流程应当为：当我点击text文本的时候，会触发tap事件，这样它绑定的myEvent方法会被执行，然后方法内部又会主动引发MyEvent事件，这样在Page页面对其绑定的handleMyEvent方法会被执行，而该方法定义在Page对象内部。（注意不要搞混事件和方法，虽然我这里的名字比较混乱）控制台输出的结果为： 即先触发tap事件，再触发MyEvent自定义事件，下面我们来看一看内部传递的东西： 从中我们可以发现第一个事件e的currentTarget属性的dataset属性是一个空对象，对应着我们并没有在wxml的text组件内部填写“data-xx”属性，而第二个事件e的currentTarget属性的dataset属性是一个包含了fuck、order、tes三个属性的对象，尽管其中order和tes的内容为空（因为对应的数据在Page对象中没有，我错误的写成了Component对象内部的了，发现获取不到，这才有了这篇文章）。 因此一般情况下，我们可以通过这种事件的方式来实现数据的传递工作，并且 this.triggerEvent() 方法接收自定义事件名称外，还接收两个对象，eventDetail 和 eventOptions。这也就是说，我们完全可以不传递this，而传递任意自己定义的对象数据，比如在myEvent中我可以不传this，接着传e，我也可以定义只与业务相关的数据对象来处理，由于方法定义在页面或组件对象内部，可以访问内部数据，而通过事件传递后可以通过参数访问数据，以此就实现了组件向页面的数据传递工作。 当然，这样的一个特点是事件绑定是放在视图view层，而事件处理传递是放在逻辑js层，可能在做一些其他业务时还是需要相应的业务转化工作才可以，不够直接和方便，因为页面还是无法做到直接访问组件数据。 后来发现果然页面提供了这么一个方法：this.selectComponent(“#fuck”)可以在页面js中使用selectComponent选择某个component组件对象的实例，在此之上可以继续访问到它的data属性、dataset属性和properties属性，分别对应的是组件的properties属性、data属性和properties属性，如下图所示： 这里我们将组件的id设为fuck，handleOrderTap方法的内容如下： 打印的内容为： 我们可以发现它的id是自己定义的fuck,而is是项目的绝对路径，还有上面提到的data、properties、dataset属性（显而易见，properties和data属性指向同一个属性对象）（然而，经过测试发现虽然内容相同，不过并非指向同一个对象，如下图所示：真是奇了怪了。。。）。 如果打开proto属性，会发现更多的东西，比如说方法： 通过this.fuck.loghaha()即可完成对方法的调用，当然了，这里获取完全可以写成let fuck = this.selectComponent(“#fuck”)，然后通过fuck.loghaha()来调用，这里简单沿袭了网上搜的文章的实例。以上，也算自己学习的小经历总结吧。","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"微信小程序","slug":"微信小程序","permalink":"https://www.iamlightsmile.com/tags/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F/"}]},{"title":"常见10种自然语言处理技术（转载）","slug":"常见10种自然语言处理技术（转载）","date":"2018-03-05T07:28:41.000Z","updated":"2020-01-18T11:47:34.575Z","comments":true,"path":"articles/常见10种自然语言处理技术（转载）/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E5%B8%B8%E8%A7%8110%E7%A7%8D%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%EF%BC%88%E8%BD%AC%E8%BD%BD%EF%BC%89/","excerpt":"原文 该作者也是翻译的外文，英文原文链接 引言自然语言处理（NLP）是一种艺术与科学的结合，旨在从文本数据中提取信息。在它的帮助下，我们从文本中提炼出适用于计算机算法的信息。从自动翻译、文本分类到情绪分析，自然语言处理成为所有数据科学家的必备技能之一。 常见的10个NLP任务如下： 词干提取 词形还原 词向量化 词性标注 命名实体消岐 命名实体识别 情感分析 文本语义相似分析 语种辨识 文本总结","text":"原文 该作者也是翻译的外文，英文原文链接 引言自然语言处理（NLP）是一种艺术与科学的结合，旨在从文本数据中提取信息。在它的帮助下，我们从文本中提炼出适用于计算机算法的信息。从自动翻译、文本分类到情绪分析，自然语言处理成为所有数据科学家的必备技能之一。 常见的10个NLP任务如下： 词干提取 词形还原 词向量化 词性标注 命名实体消岐 命名实体识别 情感分析 文本语义相似分析 语种辨识 文本总结 以下将详细展开：1.词干提取什么是词干提取？词干提取是将词语去除变化或衍生形式，转换为词干或原型形式的过程。词干提取的目标是将相关词语还原为同样的词干，哪怕词干并非词典的词目。例如，英文中: beautiful和beautifully的词干同为beauti Good,better和best 的词干分别为good,better和best。 相关论文：Martin Porter的波特词干算法原文 相关算法：Porter2词干算法的Python实现 程序实现：Porter2算法做词干提取的代码： #!pip install stemming from stemming.porter2 import stem stem(&quot;casually&quot;) 2. 词形还原什么是词形还原？ 词形还原是将一组词语还原为词源或词典的词目形式的过程。还原过程考虑到了POS问题，即词语在句中的语义，词语对相邻语句的语义等。例如，英语中： beautiful和beautifully被分别还原为beautiful和beautifully。 good, better和best被分别还原为good, good和good 相关论文1: 这篇文章详细讨论了词形还原的不同方法。想要了解传统词形还原的工作原理必读。 相关论文2: 这篇论文非常出色，讨论了运用深度学习对变化丰富的语种做词形还原时会遇到的问题。 数据集: 这里是Treebank-3数据集的链接，你可以使用它创建一个自己的词形还原工具。 程序实现：下面给出了在spacy上的英语词形还原代码 #!pip install spacy #python -m spacy download en import spacy nlp=spacy.load(&quot;en&quot;) doc=&quot;good better best&quot; for token in nlp(doc): print(token,token.lemma_) 3. 词向量化什么是词向量化？词向量化是用一组实数构成的向量代表自然语言的叫法。这种技术非常实用，因为电脑无法处理自然语言。词向量化可以捕捉到自然语言和实数间的本质关系。通过词向量化，一个词语或者一段短语可以用一个定维的向量表示，例如向量的长度可以为100。 例如：Man这个词语可以用一个五维向量表示。 这里的每个数字代表了词语在某个特定方向上的量级。 相关博文：这篇文章详细解释了词向量化 相关论文：这篇论文解释了词向量化的细节。深入理解词向量化必读。 相关工具：这是个基于浏览器的词向量可视化工具。 预训练词向量：这里有一份facebook的预训练词向量列表，包含294种语言。 这里可以下载google news的预训练词向量。 #!pip install gensim from gensim.models.keyedvectors import KeyedVectors word_vectors=KeyedVectors.load_word2vec_format(&#39;GoogleNews-vectors-negative300.bin&#39;,binary=True) word_vectors[&#39;human&#39;] 程序实现：这段代码可以用gensim训练你自己的词向量 sentence=[[&#39;first&#39;,&#39;sentence&#39;],[&#39;second&#39;,&#39;sentence&#39;]] model = gensim.models.Word2Vec(sentence, min_count=1,size=300,workers=4) 4.词性标注什么事词性标注？简单来说，词性标注是对句子中的词语标注为名字、动词、形容词、副词等的过程。例如，对句子“Ashok killed the snake with a stick”，词性标注会识别： Ashok 代词 killed 动词 the 限定词 snake 名词 with 连词 a 限定词 stick 名词 . 标点 论文1：choi aptly的这篇《The Last Gist to theState-of-the-Art 》介绍了一种叫动态特征归纳的新方法。这是目前词性标注最先进的方法。 论文2：这篇文章介绍了通过隐马尔科夫模型做无监督词性标注学习的方法。 程序实现：这段代码可以在spacy上做词性标注 #!pip install spacy #!python -m spacy download en nlp=spacy.load(&#39;en&#39;) sentence=&quot;Ashok killed the snake with a stick&quot; for token in nlp(sentence): print(token,token.pos_) 5. 命名实体消歧什么是命名实体消岐？命名实体消岐是对句子中的提到的实体识别的过程。例如，对句子“Apple earned a revenue of 200 Billion USD in 2016”，命名实体消岐会推断出句子中的Apple是苹果公司而不是指一种水果。一般来说，命名实体要求有一个实体知识库，能够将句子中提到的实体和知识库联系起来。 论文1：Huang的这篇论文运用了基于深度神经网络和知识库的深层语义关联模型，在命名实体消岐上达到了领先水平。 论文2：Ganea and Hofmann的这篇文章运用了局部神经关注模型和词向量化，没有人为设置特征。 6. 命名实体识别体识别是识别一个句子中有特定意义的实体并将其区分为人名，机构名，日期，地名，时间等类别的任务。例如，一个NER会将一个这样的句子： “Ram of Apple Inc. travelled to Sydney on 5th October 2017” 返回如下的结果： RamofApple ORGInc. ORGtravelledtoSydney GPEon5th DATEOctober DATE2017 DATE 这里，ORG代表机构组织名，GPE代表地名。 然而，当NER被用在不同于该NER被训练的数据领域时，即使是最先进的NER也往往表现不佳。 论文：这篇优秀的论文使用双向LSTM（长短期记忆网络）神经网络结合监督学习和非监督学习方法，在4种语言领域实现了命名实体识别的最新成果。 程序实现：以下使用spacy执行命名实体识别。 import spacy nlp=spacy.load(&#39;en&#39;)sentence=&quot;Ram of Apple Inc. travelled to Sydney on 5th October 2017&quot; for token in nlp(sentence): print(token, token.ent_type_) 7. 情感分析什么是情感分析？情感分析是一种广泛的主观分析，它使用自然语言处理技术来识别客户评论的语义情感，语句表达的情绪正负面以及通过语音分析或书面文字判断其表达的情感等等。例如： “我不喜欢巧克力冰淇淋”—是对该冰淇淋的负面评价。 “我并不讨厌巧克力冰激凌”—可以被认为是一种中性的评价。 从使用LSTMs和Word嵌入来计算一个句子中的正负词数开始，有很多方法都可以用来进行情感分析。 博文1：本文重点对电影推文进行情感分析。 博文2：本文重点对印度金奈洪水期间的推文进行情感分析。 论文1：本文采用朴素贝叶斯的监督学习方法对IMDB评论进行分类。 论文2：本文利用LDA的无监督学习方法来识别用户生成评论的观点和情感。本文在解决注释评论短缺的问题上表现突出。 资料库：这是一个很好的包含相关研究论文和各种语言情感分析程序实现的资料库。 数据集1：多域情感数据集版本2.0 数据集2：Twitter情感分析数据集 竞赛：一个非常好的比赛，你可以检查你的模型在烂番茄电影评论的情感分析任务中的表现。 8. 语义文本相似度什么是语义文本相似度分析？语义文本相似度分析是对两段文本的意义和本质之间的相似度进行分析的过程。注意，相似性与相关性是不同的。 例如： 汽车和公共汽车是相似的，但是汽车和燃料是相关的。 论文1：本文详细介绍了文本相似度测量的不同方法。是一篇可以一站式了解目前所有方法的必读文章。 论文2：本文介绍了用CNN神经网络去比对两个短文本。 论文3：本文利用Tree-LSTMs方法得到了文本的语义相关和语义分类的最新成果。 9. 语言识别什么是语言识别？语言识别指的是将不同语言的文本区分出来。其利用语言的统计和语法属性来执行此任务。语言识别也可以被认为是文本分类的特殊情况。 博文：在这篇由fastText撰写的博文中介绍了一种新的工具，其可以在1MB的内存使用情况下识别170种语言。 论文1：本文讨论了285种语言的7种语言识别方法。 论文2：本文描述了如何使用深度神经网络来实现自动语言识别的最新成果。 10. 文本摘要什么是文本摘要？文本摘要是通过识别文本的重点并使用这些要点创建摘要来缩短文本的过程。文本摘要的目的是在不改变文本含义的前提下最大限度地缩短文本。 论文1：本文描述了基于神经注意模型的抽象语句梗概方法。 论文2：本文描述了使用序列到序列的RNN在文本摘要中达到的最新结果。 资料库：Google Brain团队的这个资料库拥有使用为文本摘要定制的序列到序列模型的代码。该模型在Gigaword数据集上进行训练。 应用程序：Reddit的autotldr机器人使用文本摘要来梗概从文章到帖子的各种评论。这个功能在Reddit用户中非常有名。 程序实现：以下是如何用gensim包快速实现文本摘要。 fromgensim.summarization import summarize sentence=&quot;Automatic summarization is the process of shortening a text document with software, in order to create a summary with the major points of the original document. Technologies that can make a coherent summary take into account variables such as length, writing style and syntax.Automatic data summarization is part of machine learning and data mining. The main idea of summarization is to find a subset of data which contains the information of the entire set. Such techniques are widely used in industry today. Search engines are an example; others include summarization of documents, image collections and videos. Document summarization tries to create a representative summary or abstract of the entire document, by finding the most informative sentences, while in image summarization the system finds the most representative and important (i.e. salient) images. For surveillance videos, one might want to extract the important events from the uneventful context.There are two general approaches to automatic summarization: extraction and abstraction. Extractive methods work by selecting a subset of existing words, phrases, or sentences in the original text to form the summary. In contrast, abstractive methods build an internal semantic representation and then use natural language generation techniques to create a summary that is closer to what a human might express. Such a summary might include verbal innovations. Research to date has focused primarily on extractive methods, which are appropriate for image collection summarization and video summarization.&quot; summarize(sentence) 结束语以上所有是最流行的NLP任务以及相关的博客、研究论文、资料库、应用等资源。 祝你学习愉快！","categories":[{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/tags/NLP/"}]},{"title":"朕的感情史-编程语言篇！","slug":"朕的感情史-编程语言篇！","date":"2018-03-05T01:16:32.000Z","updated":"2020-01-18T11:56:03.364Z","comments":true,"path":"articles/朕的感情史-编程语言篇！/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E6%9C%95%E7%9A%84%E6%84%9F%E6%83%85%E5%8F%B2-%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E7%AF%87%EF%BC%81/","excerpt":"对于每一个有理想有追求的程序猿而言，他们可以没有对象，但是不能没有自己的喜欢的语言。 古言道：兄弟诚可贵，老婆价更高。若为编程故（指死亡之die~），躲也躲不掉。 好吧，接下来我要正式介绍一下朕的后宫！","text":"对于每一个有理想有追求的程序猿而言，他们可以没有对象，但是不能没有自己的喜欢的语言。 古言道：兄弟诚可贵，老婆价更高。若为编程故（指死亡之die~），躲也躲不掉。 好吧，接下来我要正式介绍一下朕的后宫！ 第一任：C++ 大一学习编程语言最开始上手的就是C++，不过学了半天也没学出个所以然来，经常挣扎于混杂的概念之中，却又缺少电脑无法有效开展实战编程。后来随着考试结束，我和她的感情也就慢慢的越来越淡了。 好吧，不过呢，作为系统编程和游戏开发的无可替代的语言，她的高性能与开发效率综合而言目前怕是所有所有的都比不上。 大部分企业面试笔试好像都会问到C++，感觉不会点C++真的不配说自己是程序员，但是我觉得人生苦短，何必找死呢。感觉C++是我等屁民不可轻易染指的高冷女神。 第二任：C 为了更好的学习C++，曾经又跑去学了C，因为我觉得她是C++的姐姐吧。不过还是由于驱动力不足之类的原因吧，最终也没能学出个卵子，不过也在某种程度上理解了C++相对于C而言做的改进，例如多态、名称空间、类等对于结构化的编程还是挺有用的吧。 C语言也可以做的很吊，但是由于语言的设计里本身并没有许多高级概念，所以用起来不是很直接方便，搞系统编程或者其他对效率要求极高的才会用吧。看上去没有C++的高冷，但是也不好追，并且语言特性相对低级，自己本身不太喜欢。 第三任：Java Java这门语言其实真的是相当不错的。如所有的类都有一个共同的基类，只能继承自一个父类，其他的通过接口来实现，相对于C++的名称空间来说要好不少。 Java的语言世界里，程序总是在一个个实例化的类或类本身中的属性和方法中穿梭，某种程度上来说其实挺好的。相比C++而言，普通的人很容易上手并能培养起初步良好的编程习惯。 我在Java实验课程中手撸一个什么系统，在此过程中，初步培养起了软件编程的极初始的经验体会。后来学习Android过程中，由于也要用到Java，所以功底还算可以。 但是在定义和使用的过程中，还是会感觉到比较冗杂，当然规矩多了某种程度上也算好事。那些之后在JVM之上出现的其他语言，也是同样在JVM上运行程序，但是相对而言可能更简洁、更少束缚、更强表现力，如Scala、Kotlin等等。 曾经问我家邻居学软件怎么入手，他说你就学Java吧。Java语言在企业级应用系统开发中的主导地位怕是很难被动摇的。 无论什么时候，Java都是一个值得选择拥抱的小姐姐。 第四任：C# C#开发最初的目的可能是微软用于应对Java吧。 C#这门语言在面向对象的语言家族中还是很不错的，某些设计理念比Java还要先进。然而正如以前的VBScript等更多的是被捆绑在Windows操作系统中，不开源，在某种程度上也算束缚了它的发展进步。虽说现在开源了，但是由于Java已经占领了大部分市场，C#的份额还是挺小的了。 因课结缘，课完缘尽。定位和Java类似，但是对Java更有好感。 第五任：Lua 不得不说，Lua真的是个好语言，只是之前没怎么好好学，并且它上手极为简单容易。现在的话，很少接触，因为基本上用不到。对于它的C源码还是有必要看一下的。感觉很有好感的小妹妹。 第六任：Python Python的设计哲学现在看来真的是极好，这些年的发展壮大足以说明一切，在大部分编程应用领域里几乎都有了它的身影。极强的代码阅读性，上手很容易。于我而言，她现在是一个贤妻良母型的。 第七任：Ruby Python和Ruby各领风骚，许多爱好者各爱各的好。Ruby我以前也学过一下下，Ruby好像是基于对象的，里面啥都是对象。相对而言，用法超级灵活，而且比较简洁炫酷，但是可能因为用的少，我看着Ruby代码好像阅读起来不是很爽，比Python而言差远了。开发效率极高，Ruby on Rails嘛，但是好像项目做大之后就会受限于它的运行效率。现在也早就分了。感觉Ruby和我三观不符，私人感觉Ruby是一个比较追求时尚新颖的女生，比较开放外向。 第八任：Scala 我曾经学习过很短时间的Scala，网上的说法是学习起来很复杂，我当时感觉还不错，后来因为用不到也没在学了，可能还是不太感兴趣吧。也是一个不错的小姐姐，但是如果太专情于此，怕是不好吃饭。。。 第九任：aardio 最爱，没有之一。虽然它生于Windows，长于Windows，最终也将死于Windows，但是这还是无法阻挠我对它的喜爱，况且正是由于仅限于Windows平台，她的美才更加表现出来。她的不开源我也理解，是我我也不开源，正是一鹤校长非常爱她，才不允许其他误解开源精神的染指搞事情。 动态语言，快速开发，名称空间、类，句法灵活，调用简单，几行代码就可以实现复杂的功能，并且很方便的就可以开发出控制台、桌面、网络、后台程序，可以方便与其他语言实现互相调用。 自从无意间了解到这门语言之后，感觉一下子就被吸引到了，因为她当时完全符合我对编程语言的所有需求，他妈的当时把老纸激动坏了，差点一宿没睡着。当时学了编程两年多，都写不出个什么桌面程序来，用Java写的太丑，用C#开发的还得运行在.Net框架上。一点成就感都没有，我对可视化的界面还是很执着的。 后来花钱报了班，看视频学习，有时会在群里探讨问题，有时会直接向校长询问，感觉真的很值。后来我数据库实验、编译原理实验、操作系统实验等等全都是用的aardio语言，因为用起来实在是太爽了。 于我而言，aardio是我的初恋，是我第一门喜欢上的语言，虽然现在由于没有需求已经暂停和她失去了联系，但是我会永远喜欢她！ 第十任：Processing Processing这门语言用来做艺术设计以及自然模拟都是很不错的，并且跨平台，可以生成可执行程序，本身使用Java语言写的，同时也有JavaScript版和Python版，也是用不到所以没在用了。在我看来，像是一个很可爱的萝莉。 第十一任：JavaScript 个人感觉，JavaScript最屌了。它的语言哲学相对来说和我的三观最为符合，原型继承，闭包等等概念都很不错。随着es6的出现，它的语法规范感觉十分高级，个人十分喜欢，在某种程度上，部分设计已经超越了aardio（感觉aardio是集许多好的语言的特性于一身）。事件驱动、非阻塞I/O、回调的NodeJs感觉也很棒。是一个我非常想深入学习的语言，对我来说是一个极具诱惑力的女神。 第十二任：Racket Racket是Scheme的一种方言，而Scheme则是Lisp的一种方言，语言中处处都是函数式编程，感觉非常新颖且高大上，但是程序复杂起来了之后阅读体验极差，远远比不上Python。接下来打算有时间接触一下下，多吸取里面的先进思想。 第十三任：Julia 2018/3/5刚接触Julia语言，感觉真的挺厉害的，元编程，并行计算，超高性能，语法像Python、用法像Lisp、速度像C，渍渍，真是厉害了~ 第十四任：？ 第十五任：？ 第十六任：？ 第十七任：？ …… 接下来的语言还没出现或者还没接触到，可能今后才会冒出来，或者是我自己设计定义实现的吧……","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"编程语言","slug":"编程语言","permalink":"https://www.iamlightsmile.com/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}]},{"title":"Python学习笔记（1）骚操作之Unicode编码","slug":"Python学习笔记（1）骚操作之Unicode编码","date":"2018-03-04T11:53:42.000Z","updated":"2020-01-18T11:58:14.130Z","comments":true,"path":"articles/Python学习笔记（1）骚操作之Unicode编码/","link":"","permalink":"https://www.iamlightsmile.com/articles/Python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89%E9%AA%9A%E6%93%8D%E4%BD%9C%E4%B9%8BUnicode%E7%BC%96%E7%A0%81/","excerpt":"Python3内部使用的是Unicode编码，所以在变量定义的时候或许可以搞点事情。","text":"Python3内部使用的是Unicode编码，所以在变量定义的时候或许可以搞点事情。 例如创建一个文件,名为：人.py，里面的代码是： class 人(object): 性别 = &quot;男&quot; 然后同目录下创建一个test.py文件，里面内容为： from 人 import 人 李明 = 人() print(李明.性别) 结果输出：男，是不是有点骚~","categories":[{"name":"Python","slug":"Python","permalink":"https://www.iamlightsmile.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://www.iamlightsmile.com/tags/Python/"}]},{"title":"《和谐辩证法》笔记与心得（3）吾之平衡辩证法","slug":"《和谐辩证法》笔记与心得（3）吾之平衡辩证法","date":"2018-03-04T01:14:31.000Z","updated":"2020-01-18T11:50:01.038Z","comments":true,"path":"articles/《和谐辩证法》笔记与心得（3）吾之平衡辩证法/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E3%80%8A%E5%92%8C%E8%B0%90%E8%BE%A9%E8%AF%81%E6%B3%95%E3%80%8B%E7%AC%94%E8%AE%B0%E4%B8%8E%E5%BF%83%E5%BE%97%EF%BC%883%EF%BC%89%E5%90%BE%E4%B9%8B%E5%B9%B3%E8%A1%A1%E8%BE%A9%E8%AF%81%E6%B3%95/","excerpt":"吾之所见为，宇宙的发展其实就是能量间从不平衡状态到平衡状态的迁移罢了。 事物的稳定与不稳定两种状态可理解为运动之趋势变化抑或不变耳。 事物总是从不平衡的状态朝向平衡的状态运动和发展的，而之所以运动不止，发展不断，则是由于外界的作用又使得事物可能从平衡又趋于不平衡。","text":"吾之所见为，宇宙的发展其实就是能量间从不平衡状态到平衡状态的迁移罢了。 事物的稳定与不稳定两种状态可理解为运动之趋势变化抑或不变耳。 事物总是从不平衡的状态朝向平衡的状态运动和发展的，而之所以运动不止，发展不断，则是由于外界的作用又使得事物可能从平衡又趋于不平衡。 事物内部或事物之间的平衡或不平衡的状态实际上就是指在没有外物的作用下，事物之间或事物内部各要素之间能否保持稳定而不变化的状态，对应的是时刻，状态或趋势。而运动或静止对应的是时间，过程或阶段。平衡或不平衡是决定事物或事物之间运动以相互作用的决定因素，而运动与静止则是从不平衡态向平衡态迁移或平衡态迁移到不平衡态的实现过程。 然而吾仍不解的是宇宙之始态为何，宇宙之终态又为何，同时为什么能量非要从不平衡态迁移到平衡态。 举例如：生产关系之调整是生产关系与生产力从不平衡到平衡的过程；生产力之进步是生产力与人类生存发展不平衡到平衡的过程；人类之生存发展是理想与现实之不平衡到平衡的过程；但理想之追求非平衡，而是贪念和占有，故此之平衡终为不可持续之平衡，故马克思理想之共产主义社会终究不会实现与持久，缘何？人类与大自然和环境之极大不平衡也。当然，最好的结果自然是人类延续，欲望无休止，继续开采资源直至到其他星球为止。最坏的结果当为人类自掘坟墓、自取灭亡。","categories":[{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://www.iamlightsmile.com/tags/%E5%93%B2%E5%AD%A6/"}]},{"title":"《和谐辩证法》笔记与心得（2）能量供求之己见","slug":"《和谐辩证法》笔记与心得（2）能量供求之己见","date":"2018-03-04T01:08:20.000Z","updated":"2020-01-18T11:49:53.162Z","comments":true,"path":"articles/《和谐辩证法》笔记与心得（2）能量供求之己见/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E3%80%8A%E5%92%8C%E8%B0%90%E8%BE%A9%E8%AF%81%E6%B3%95%E3%80%8B%E7%AC%94%E8%AE%B0%E4%B8%8E%E5%BF%83%E5%BE%97%EF%BC%882%EF%BC%89%E8%83%BD%E9%87%8F%E4%BE%9B%E6%B1%82%E4%B9%8B%E5%B7%B1%E8%A7%81/","excerpt":"本书作者以为存在两种性质不同的能量作用方式，即：1.单向能量供求关系2.双向能量供求关系。同时存在三种不同的能量供求结果，即：1.能量相容2.能量冲突3.能量中立。 单向能量供求关系可形成能量链，链条上的每一节都存在能量的转换与运动形式的转换。 而双向能量供求关系则表现为单两者之间的相互吸引或者相互对抗、相互满足或者相互伤害。 然吾不以为然，因为事物之间的彼此联系实际上就是说存在着相互作用的关系，彼此可以影响对方的运动和发展。","text":"本书作者以为存在两种性质不同的能量作用方式，即：1.单向能量供求关系2.双向能量供求关系。同时存在三种不同的能量供求结果，即：1.能量相容2.能量冲突3.能量中立。 单向能量供求关系可形成能量链，链条上的每一节都存在能量的转换与运动形式的转换。 而双向能量供求关系则表现为单两者之间的相互吸引或者相互对抗、相互满足或者相互伤害。 然吾不以为然，因为事物之间的彼此联系实际上就是说存在着相互作用的关系，彼此可以影响对方的运动和发展。 所以可以说“凡事皆为众因之果，万物齐作众果之因”。 吾以为凡世间种种因缘之变化，皆能量相互作用之结果。能量自然成链，无限接力也。然天下间万事万物皆作能量之一小环，有供有求，无时无刻不相互作用耳。作者之见，实为取何其浩大之细微，沧海之一粟，往来之一瞬。然后取关联以相接，得知为链，然作者岂不明乎：双向能量供求关系岂非特殊两者之链而成环哉！ 如下图：,此即细微也。圆圈指能量体或物质外显或抽象之概念，而这指向圆环的箭头其实也是外界相加于圆圈之能量，而自圆环外指的箭头当为圆环向外界其他能量体施加之能量。 本书作者之单向能量链为：。 而双向能量供求关系为：。 岂不过度抽象与特殊化乎。所谓单向或双向在我看来无非作用程度不同罢了。 所谓“大道至简”，因而绝非有两种存在。 同时参考吾之运动与静止理解，可得，万事万物，都会直接或者间接地影响和改变某一事物内在的结构和内容或其作为要素与整体及整体的其他要素之关系，从而推动事物的运动和发展。 若拿函数方程来粗浅理解，如三个变量X，Y，Z，有函数方程组：。 三个方程三个未知量，若是再知道初态X0 、Y0、Z0，那么从逻辑上或许总是可以得到依次的相互对应的X，Y，Z的值的。 然而现实是现实中的未知量实在是太多了，同时函数关系式也太复杂了，所以理论来说实际上是不可能得到准确的解的。然而我们通过观察现实中某些量或许是线性的，也就是说两者之间是线性联系或者呈现出其他的联系函数，正是在这个基础上，我们的认识才更加深化和进步。 故而可理解为世间或宇宙或许为能量之一个奇大无比之网，而我们万物无非其中一个小小结罢了。 同时关于三种能量供求结果，我的想法是可以从物理学上机械能做功的角度。 （机械宏观运动中）物体运动有其方向，即速度是一个矢量，而外力平行于该方向上的分力，若方向一致则做正功，推动事物原有方向上的发展。若相反，则做负功。阻碍事物原有方向的发展，甚至使方向发生180度变化。而垂直于运动方向上的力不做功，但仍有改变方向之效用，因而能量相容即外界之能量作用于事物产生的运动状态与物质本身、当前运动状态相一致则为相容。相反则为冲突。垂直则为中立，并非无用，可起到改变方向之作用，但中立应该是特殊状态，且仅一瞬的状态，因为运动方向一旦改变而作用方向不变，即产生非中立关系，因而是不可持续的，若是站在物理力学之坐公交度，则不存在此状态。","categories":[{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://www.iamlightsmile.com/tags/%E5%93%B2%E5%AD%A6/"}]},{"title":"《和谐辩证法》笔记与心得（1）物质运动与静止之己见","slug":"《和谐辩证法》笔记与心得（1）物质运动与静止之己见","date":"2018-03-04T01:07:10.000Z","updated":"2020-01-18T11:49:43.322Z","comments":true,"path":"articles/《和谐辩证法》笔记与心得（1）物质运动与静止之己见/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E3%80%8A%E5%92%8C%E8%B0%90%E8%BE%A9%E8%AF%81%E6%B3%95%E3%80%8B%E7%AC%94%E8%AE%B0%E4%B8%8E%E5%BF%83%E5%BE%97%EF%BC%881%EF%BC%89%E7%89%A9%E8%B4%A8%E8%BF%90%E5%8A%A8%E4%B8%8E%E9%9D%99%E6%AD%A2%E4%B9%8B%E5%B7%B1%E8%A7%81/","excerpt":"对应p35吾以为马克思之运动与静止之观点与本书作者之运动与静止之观点均有偏颇之处，或者各有所见。然吾之角度或许不同于二者乎。 马克思云运动之绝对而静止之相对，而本书作者云运动与静止均绝对。恩格斯之运动绝对体现在：1.任何事物都是运动的2.任何事物在任何时候都是运动的。 而本书作者之运动与静止之界限取决于事物是否在特定能量下作为一个整体的运动变化，同时还伴随着其特定能量的释放。","text":"对应p35吾以为马克思之运动与静止之观点与本书作者之运动与静止之观点均有偏颇之处，或者各有所见。然吾之角度或许不同于二者乎。 马克思云运动之绝对而静止之相对，而本书作者云运动与静止均绝对。恩格斯之运动绝对体现在：1.任何事物都是运动的2.任何事物在任何时候都是运动的。 而本书作者之运动与静止之界限取决于事物是否在特定能量下作为一个整体的运动变化，同时还伴随着其特定能量的释放。 而吾之运动静止观在于两方面：1.事物内部各要素之间联系是否发生改变，事物的结构与内容是否发生变化2.事物作为一个整体的要素是否与其他要素之间的联系是否发生改变，以及因此导致的整体的结构及内容的变化。 然而事物作为一个整体而言，其要素的划分方式并非绝对的，而是相对的，同时该事物作为一个要素而言，可以和别的事物组成一整体，而这种组合也是多变的，多样的。具体含义为：一个事物根据不同的角度可以被划分为多种不同的要素的有机组合，如abcd可以分为a、b、c、d或者ab、cd或者abc、d等等，同时这一事物可以和其他事物组成不同的多样的整体，如a和b可以组合成ab而a和c可以组合成ac，此外同为ab与ba尽管内容相同，但内部要素之间结构不同，因而算是不同事物。 故吾看来，事物之运动或静止取决于以上两方面，同时他们的根本属性并非绝对性而在于其相对性，运动是相对的，静止也是相对的。这里的相对并非事物与事物之间的相对，而是事物与角度之间的相对。","categories":[{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://www.iamlightsmile.com/tags/%E5%93%B2%E5%AD%A6/"}]},{"title":"《智慧之根》笔记与心得（2）事物之结构浅解","slug":"《智慧之根》笔记与心得（2）事物之结构浅解","date":"2018-03-04T00:47:56.000Z","updated":"2020-01-18T11:50:22.946Z","comments":true,"path":"articles/《智慧之根》笔记与心得（2）事物之结构浅解/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E3%80%8A%E6%99%BA%E6%85%A7%E4%B9%8B%E6%A0%B9%E3%80%8B%E7%AC%94%E8%AE%B0%E4%B8%8E%E5%BF%83%E5%BE%97%EF%BC%882%EF%BC%89%E4%BA%8B%E7%89%A9%E4%B9%8B%E7%BB%93%E6%9E%84%E6%B5%85%E8%A7%A3/","excerpt":"&emsp;&emsp;吾以为，事物之结构该当如下：（注意：这里的事物应当是能量的物质外显，抑或人们的抽象之概念，然吾之推测当人们所不明之结构也当如此） &emsp;&emsp;联系需要联系者，因为联系是联系者之间的联系。联系者具体地说就是具体事物，抽象地说就是联系环节，因而联系环节就是指抽象的联系者。联系的基本环节包括：系统和要素、结构和功能、形势和内容、本质和现象、原因和结果、内因和外因、质与量、肯定与否定。","text":"&emsp;&emsp;吾以为，事物之结构该当如下：（注意：这里的事物应当是能量的物质外显，抑或人们的抽象之概念，然吾之推测当人们所不明之结构也当如此） &emsp;&emsp;联系需要联系者，因为联系是联系者之间的联系。联系者具体地说就是具体事物，抽象地说就是联系环节，因而联系环节就是指抽象的联系者。联系的基本环节包括：系统和要素、结构和功能、形势和内容、本质和现象、原因和结果、内因和外因、质与量、肯定与否定。 一 系统和要素 任何系统本身既是个系统，又处于更大的系统之中。系统是由要素构成的，因而相对于更大系统而言的某一具体事物又成为构成更大系统的要素。 系统是由一定数量相互联系的要素资格，有特定结构、性质和功能的有机整体。 如上图中，可将这个大的系统结构的某个要素视为四个该要素之要素组成之系统（整体）：，四个要素之要素可视为相对这个要素（系统）之要素（部分）：，应当注意系统与要素之间的相对性。无论系统还是要素都是相对的。 二 结构和功能 宇宙万物不仅作为系统由一定要素所构成，而且构成一事物的要素因其相互联系而构成特定的结构，从而具有特定的功能。 结构是事物内在要素的联结方式。结构不仅具有整体性，也具有相对稳定性（根据皮亚杰的观点，结构的各要素互相制约、互为条件且不受外界因素的影响），因而具有转换型（结构的各要素可按一定规则互相替换而不改变结构本身）。注：关于相对稳定性，吾不以为然，吾以为结构之间的要素的关联是要受到外界的干预影响的。 功能是事物由其结构而产生的对外部对象或环境的作用能力，或者说，是事物通过对外部对象或环境的作用而表现出来的性能。 结构与功能之区别：结构属于事物内部的内部联系，而功能则是一事物通过与另一事物发生外部联系而产生或体现出来。 如最上图，这个大的系统的最上面的那个要素的结构是蓝色部分，： ，而这个要素的功能是绿色部分： 。 三 形式与内容 结构作为事物内在要素的联结方式也就是事物的形式，要素就是事物的形式所依存的内容。 所谓内容就是构成事物的一切内在要素的总和。内容有两大类：一是实体方面的（部分、成分），一是属性方面的（内在矛盾、发展趋势）。 所谓形式就是把食物的内在要素组合起来的结构。 形式和内容是有区别的，内容是事物存在的基础，相对于形式来说，它是“实”，是形式这张网上的“结”；形式则是事物存在的结构，相对于内容来说，它是“虚”，是编织内容的“网”。因此，内容和形式的关系可以说是实（结）与虚（网）的关系。 如最上图，这个大的系统的最上面的那个要素的内容即粉红色部分：，而形式实则为对应功能之结构，只不过形式对应的是内容，其实（形式与结构）实质一样，但对应之物不同，故侧重角度略有不同：。 四 本质和现象 现象是事物显现于外的形象或面貌。它是事物本质的诸方面表现，其实质是外部联系，就是说，一事物如果不与一定量的其他事物发生联系或相互作用，就没有现象可言。 本质是事物深藏于内的根本性质，其实质是事物内在的根本要素之必然联系，它是由事物的根本矛盾或特殊矛盾决定的。3.就本质与性质的关系来说，本质通常是就个体事物之为其自身而言的，性质是就个体的类属而言的。虽然本质与性质都很抽象，但性质比本质更抽象。 就本质与结构（形式）的关系来说，结构（形式）相对于功能也相对于要素（内容）而言，但本质仅相对于现象而言。现象不等于功能和要素，所以本质也不同于结构（形式）。本质和结构都很抽象，但相比而言，本质比结构更抽象（结构较本质更具体）。 从根本上说，本质与结构（形式）是一致的。 本质与结构（形式）的一致，在于他们都不能脱离要素（内容）而独立存在。 就本质与规律、趋势（必然性）的关系来说：三者虽然都是抽象的，但本质是从相对静态的角度来深刻认识事物的，他所要揭示的是事物之为事物的当前规定性；而规律和趋势（必然性）则是从相对动态的角度来深刻把握事物的，他所要解释的是事物未来的进程和归宿。不过，本质与规律和趋势（必然性0也是一致的：本质决定规律和趋势（必然性），规律和趋势（必然性）反映本质。就是说，一个事物的本质是怎么样的，其发展的进程（规律）和结局（趋势或必然性）就是怎么样的。 如最上图，系统之现象当如： ，，吾以为现象当为系统呈现出的外部状态。 系统之本质当如： 。 如此，圆圈和线条就构成了事物结构之四个基本环节。即： 圆圈（外）与圆圈（内）构成系统与要素。 圆圈（外）与线条（内）构成现象与本质。 线条（内）与线条（外）构成结构与功能。 线条（内）与圆圈（内）构成形式与内容。 从以上可知，圆圈内与线条外不构成直接联系。 联系的基本形式 联系的环节是要解决联系的主题承担者问题。显然，没有联系的环节，联系是无法想象的，是不可能存在的。但现实事物中的联系，不仅需要作为联系者的联系环节，也需要联系的形式。联系的形式就是要解决事物时怎样联系的问题。 联系的具体形式无限多样，但其基本形式是有限的。联系的基本形式，依其复杂程度可分为两类：相对简单的联系形式和相对复杂的联系形式。 相对简单的联系形式——内部联系和外部联系、纵向联系和横向联系、直接联系和间接联系。 相对复杂的联系形式——必然联系和偶然联系、因果联系和非因果联系。 所谓必然联系，就是事物在发展过程中所表现出的确定不移的趋势，它是事物内在的直接的本质的稳定的联系。必然联系的首要特征是确定性或稳定性，因为必然联系或必然性根源于事物的根本矛盾。也正因为如此，必然联系在事物存在的全局或发展的全程中居于支配地位。 所谓偶然联系，就是事物在发展过程中所表现出的并非确定不移的趋势（可以出现，也可以不出现；可以早出现，也可以晚出现；可以这样出现，也可以那样出现），它是事物外在的非本质的不稳定的联系。偶然联系的首要特征是不确定性或不稳定性，因为偶然联系或偶然性根源于事物的非根本矛盾或外部矛盾。也正因为如此，偶然联系在事物存在的全局或发展的全程中居于被支配的地位。 偶然联系和必然联系不仅同时存在于一个事物的发展过程之中，而且二者都有其具体形式。偶然联系（偶然现象）的具体形式在事物发展过程的开始、中间和结果三个基本阶段中都可能出现或存在。必然联系的具体形式主要有：有先后的历时性必然联系（因果联系）与无先后的共时性必然联系（函数关系）。 要知道某一事物或现象是原因还是结果，必须把它放在特定关系中才行。 可以把原因定义为能引起（能生）一定事物的事物（实体、状态、性质、过程），而结果可以定义为被一定事物引起（所生）的事物（实体、状态、性质、过程）。 因果联系有两个基本特征：（1）先后性（2）必然性。 因果联系是有先后性的必然联系。 世界万物是处于普遍联系之中的，没有孤立存在的事物。但普遍联系的事物之联系的环节和形式是多样性的，联系的类型也是多样的。联系的基本类型主要有：局部联系与全局联系，暂时联系与长久联系，简单联系与复杂联系，紧密联系与松散联系，客观联系与主观联系，主要联系（本质的联系）与次要联系（非本质的联系），等等。","categories":[{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://www.iamlightsmile.com/tags/%E5%93%B2%E5%AD%A6/"}]},{"title":"事物变化之缘由之己见","slug":"《智慧之根》笔记与心得（1）事物变化之缘由之己见","date":"2018-03-03T05:20:02.000Z","updated":"2020-01-18T11:50:13.786Z","comments":true,"path":"articles/《智慧之根》笔记与心得（1）事物变化之缘由之己见/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E3%80%8A%E6%99%BA%E6%85%A7%E4%B9%8B%E6%A0%B9%E3%80%8B%E7%AC%94%E8%AE%B0%E4%B8%8E%E5%BF%83%E5%BE%97%EF%BC%881%EF%BC%89%E4%BA%8B%E7%89%A9%E5%8F%98%E5%8C%96%E4%B9%8B%E7%BC%98%E7%94%B1%E4%B9%8B%E5%B7%B1%E8%A7%81/","excerpt":"&emsp;&emsp;唯物辩证法之基础思想在于事物——世间的万事万物都是彼此联系和不断发展的。而矛盾是最深刻最本质的联系，同时矛盾是事物变化发展的根本动力。那么到底何为矛盾，又为何矛盾？矛盾矛盾，以子之矛攻子之盾，虽然唯物辩证法中的矛盾并非现实的实物的矛和盾，但其中精妙也在于此，否则为何意译为矛盾呢。 &emsp;&emsp;吾之前不能理解矛盾之到底为何物遂去图书馆查阅相关书籍，然余性驽智愚，未尝更愈明晓也。 &emsp;&emsp;观本书p115处似有朦胧浅薄之理解，矛盾是既对立又同一的双重关系或属性，换句话说应当是一个事物的两个相反相成的性质或属性吧。也可看作是两个事物彼此之间相反相成，但是当这两个事物作为要素构成一个整体时，或者同时作为属性构成于一个统一的事物时，即又可看做是一个事物的内部矛盾。","text":"&emsp;&emsp;唯物辩证法之基础思想在于事物——世间的万事万物都是彼此联系和不断发展的。而矛盾是最深刻最本质的联系，同时矛盾是事物变化发展的根本动力。那么到底何为矛盾，又为何矛盾？矛盾矛盾，以子之矛攻子之盾，虽然唯物辩证法中的矛盾并非现实的实物的矛和盾，但其中精妙也在于此，否则为何意译为矛盾呢。 &emsp;&emsp;吾之前不能理解矛盾之到底为何物遂去图书馆查阅相关书籍，然余性驽智愚，未尝更愈明晓也。 &emsp;&emsp;观本书p115处似有朦胧浅薄之理解，矛盾是既对立又同一的双重关系或属性，换句话说应当是一个事物的两个相反相成的性质或属性吧。也可看作是两个事物彼此之间相反相成，但是当这两个事物作为要素构成一个整体时，或者同时作为属性构成于一个统一的事物时，即又可看做是一个事物的内部矛盾。 &emsp;&emsp;书中云矛盾之基本属性关系有二：1.对立性和同一性2.普遍性和特殊性。 &emsp;&emsp;书中p117页所提矛盾之对立性是事物内部两个根本相反方面的对立性。以鄙之愚见当为若一事物有a属性同时又具有！（非）a属性，则这个a和！a当为一对矛盾。拿人类性别这一抽象事物举例吧，人类性别包含男，女，双性，非男非女四个类别。之前只知晓男和女两种类别，后面两种是近来才发现和命名的。So，男之所以为男，正是因为女的存在，女的照样也是如此。正如老子《道德经》所云：”世人皆知美之为美 斯恶已 皆知善之为善 斯不善已“。这里怎么理解呢？在我看来应该是无论男和女作为一种抽象的概念对具体事物的划分抑或美和丑作为抽象概念对认知感觉的划分，他们都是由人们的观念所决定的，换句话说意思就是在没有“男”和“女”这两个概念出来之前，世上自然就是不分男女的，当有了这样的变化或者说是人们的认知需要，才出现了男和女这两个对立而又同一的概念，它们两者自诞生以来便是同时的，无时无刻不相互对立而又同一，对立性体现在男的对立面即为女，女的对立面即为男，同一性体现在男和女所共同组成的整体正是全部人类，更确切的是其性别属性。当然以上概念可能有些不准确，我这里举着个例子并非含有任何性别歧视的含义。 &emsp;&emsp;从另一个角度来看，人的性别属性也是男性或女性，然而更确切的来看应该是既含男性又有女性，何也，万事无绝对也。只是男（女）性的男（女)性基因或男(女）性表现在其所处环境下得到了充分的表达而已。 &emsp;&emsp;从更抽象的角度来理解矛盾的关键抑或核心即4个字“一分为二”。 &emsp;&emsp;正如下图：一条线总能将这个圆分成两部分。然而这条线之划分并非绝对的，两边也是动态发展的，发展过程中，既可能你中有我我中有你，同时也会相互转化。最好的例证既是阴阳太极图： &emsp;&emsp;然而阴阳太极图以其对称形式体现且是静态图，所以要体现其动态变化性应该再加上五行和四象，五行相生相克，当为太极阴阳调和变化之道。 &emsp;&emsp;此即中西关于矛盾观念之相合且高度一致。 而在《和谐辩证法》中，事物之变化当取决于能量供求原理。物质之运动有六大逻辑要素，即物质、能量、数量、结构、程序、信息。而物质有三大显著特征：1.质量实体2.能量母体3.运动载体。而能量作用有三种不同形式：能量相容、能量冲突和能量中立。同时其供求两极正好对应太极阴阳之两化。同时其核心观点当为“能量推动物质运动、物质运动释放能量” 而在看了关于宇宙大爆炸理论、黑洞、奇点以及空心菜创作的《世界就是一个游戏》以及其在腾讯视频中《用道德经破解宇宙起源》的观点和理念让余产生了新的观点和看法。 吾之观念当为宇宙之中当为处处都有能量，而整个宇宙的发展过程，正是宇宙间各能量间从不平衡到平衡的发展过渡过程。而所谓的物质，则是人类可观察的能量的一种特殊形式，可称之为能量的物质外显，同时能量也可以不表现为物质的形式，如场以及我们尚不知晓的形式等等。 吾之理解中，宇宙之始吾不知，宇宙之末吾不晓。或如空心菜般更高层智慧所创造，或如进化论般偶然之所进化，或如为何能量之不平衡至平衡，吾尚不明也。 然吾等人类仅为银河系太阳系地球数百亿年历程之小小一瞬，当有自知之明，而非自傲视己为万物之灵长，敢于天地造化同在。 若宇宙如空心菜所言，自当为一游戏，此生当以修心为主。 若宇宙如大爆炸所云，则另有一可能如高层智慧之一团烟火，自燃时起，至黯时灭。思想观念来源于《黑衣人》 而吾之所见，当为无论物质之外显，抑或思维中抽象之概念，其发展阶段都为自不平衡至平衡发展的状态。而之所以运动不止，发展不断，则是由于外界的作用，使事物又趋于不平衡。","categories":[{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://www.iamlightsmile.com/tags/%E5%93%B2%E5%AD%A6/"}]},{"title":"算法学习笔记（2）数组","slug":"算法学习笔记（2）数组","date":"2018-03-02T09:15:47.000Z","updated":"2020-01-18T11:54:39.167Z","comments":true,"path":"articles/算法学习笔记（2）数组/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89%E6%95%B0%E7%BB%84/","excerpt":"学习自B站算法面试精讲 查找和排序 二分查找 元素交换 排序，中位数 归并 位运算 前缀和的应用 动态规划 排列组合","text":"学习自B站算法面试精讲 查找和排序 二分查找 元素交换 排序，中位数 归并 位运算 前缀和的应用 动态规划 排列组合","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://www.iamlightsmile.com/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"算法学习笔记（1）字符串","slug":"算法学习笔记（1）字符串","date":"2018-03-02T08:18:14.000Z","updated":"2020-01-18T11:54:14.998Z","comments":true,"path":"articles/算法学习笔记（1）字符串/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89%E5%AD%97%E7%AC%A6%E4%B8%B2/","excerpt":"学习自https://www.bilibili.com/video/av11739347/ 算法面试精讲 和数组相关，内容广泛 概念理解：字典序 简单操作：插入、删除字符，旋转 规则判断（罗马数字转换、是否是合法的整数、浮点数） 数字运算（大数加法、二进制加法） 排序、交换（partition过程） 字符计数（hash）：变位词 匹配（正则表达式、全串匹配、KMP、周期判断） 动态规划（LCS、编辑距离、最长回文子串） 搜索（单词变换、排列组合）","text":"学习自https://www.bilibili.com/video/av11739347/ 算法面试精讲 和数组相关，内容广泛 概念理解：字典序 简单操作：插入、删除字符，旋转 规则判断（罗马数字转换、是否是合法的整数、浮点数） 数字运算（大数加法、二进制加法） 排序、交换（partition过程） 字符计数（hash）：变位词 匹配（正则表达式、全串匹配、KMP、周期判断） 动态规划（LCS、编辑距离、最长回文子串） 搜索（单词变换、排列组合）","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://www.iamlightsmile.com/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"浏览器插件小试","slug":"浏览器插件小试","date":"2017-12-25T02:40:27.000Z","updated":"2020-01-18T11:52:57.637Z","comments":true,"path":"articles/浏览器插件小试/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E6%B5%8F%E8%A7%88%E5%99%A8%E6%8F%92%E4%BB%B6%E5%B0%8F%E8%AF%95/","excerpt":"由于时间比较久远，现在浏览器插件编写的工作都已经忘记了一大半，不过之前获取的只是图片的绝对地址，用起来还是不太方便，并且比如说插件的title、description、icon等都是原来的如testMenu等比较low的，于是后来又修改了一下，包括以上的项目属性，以及目前复制到剪贴板的直接是Markdown中的图片地址格式，如! [image_title] (image_absolute_path)的格式，并且已经把相关的源码上传到我的GitHub上面，链接地址为：https://github.com/smilelight/GithubImagePace 。","text":"由于时间比较久远，现在浏览器插件编写的工作都已经忘记了一大半，不过之前获取的只是图片的绝对地址，用起来还是不太方便，并且比如说插件的title、description、icon等都是原来的如testMenu等比较low的，于是后来又修改了一下，包括以上的项目属性，以及目前复制到剪贴板的直接是Markdown中的图片地址格式，如! [image_title] (image_absolute_path)的格式，并且已经把相关的源码上传到我的GitHub上面，链接地址为：https://github.com/smilelight/GithubImagePace 。 欢迎有需求的看客下载、使用、交流、分享等。","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"浏览器插件","slug":"浏览器插件","permalink":"https://www.iamlightsmile.com/tags/%E6%B5%8F%E8%A7%88%E5%99%A8%E6%8F%92%E4%BB%B6/"}]},{"title":"关于Markdown引用图片地址的尝试","slug":"关于Markdown引用图片地址的尝试","date":"2017-12-24T14:43:44.000Z","updated":"2020-01-18T11:52:02.503Z","comments":true,"path":"articles/关于Markdown引用图片地址的尝试/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E5%85%B3%E4%BA%8EMarkdown%E5%BC%95%E7%94%A8%E5%9B%BE%E7%89%87%E5%9C%B0%E5%9D%80%E7%9A%84%E5%B0%9D%E8%AF%95/","excerpt":"前两天某刻突然想到学习不能只有输入，更应该有输出，有时历程和心得更需要记录下来，于是就萌发起了写博客的念头，如今写博客的平台很多，比如博客园、CSDN、简书、新浪博客，甚至知乎等等，也可以通过GitHub pages来实现，甚至于购买云服务器搭建自己的博客网站。由于个人知识浅薄，并且想要拥有更高的自由度，以及一些其他因素限制，最终选择了通过GitHub pages+hexo来搭建自己的个人博客站点，借助于网上丰富详致的相关搭建博客教程终于把自己的小窝搭建起来了，吼吼！","text":"前两天某刻突然想到学习不能只有输入，更应该有输出，有时历程和心得更需要记录下来，于是就萌发起了写博客的念头，如今写博客的平台很多，比如博客园、CSDN、简书、新浪博客，甚至知乎等等，也可以通过GitHub pages来实现，甚至于购买云服务器搭建自己的博客网站。由于个人知识浅薄，并且想要拥有更高的自由度，以及一些其他因素限制，最终选择了通过GitHub pages+hexo来搭建自己的个人博客站点，借助于网上丰富详致的相关搭建博客教程终于把自己的小窝搭建起来了，吼吼！ 随后学习一些Markdown的语法发现这个图片的链接还真是一个问题，网上搜索的结果主要是通过七牛云啥的云图网站来实现的，然而一方面可能有数据量的限制，另外还要注册一些信息啥的，好屌麻烦，于是就想能不能直接通过GitHub仓库来实现呢？经过简单的分析之后，发现这个是可以实现的： 首先在GitHub上新建自己的图片仓库，以后的图片都可以放到这个里面。 随后可以把仓库克隆到本地计算机文件系统中，需要添加图片时，可以通过创建相关文件夹，然后在里面放入需要链接的图片。 通过Git命令实现仓库的提交。 git add . git commit -m &quot;change the images&quot; git push 通过对应GitHub上图片资源绝对地址的引用实现自己Markdown文章图片的引用工作。 在实际应用中，以上第1步只需要做一次，而每次需要在Markdown文章引用图片时，都需要做第4步，同时视是否需要引入新的图片可能也需要2、3步的工作。 在具体实现的过程中，发现第3步和第四步存在着一些问题和待优化之处。如第3步的提交过程中，可以通过浏览器的GitHub仓库页面实现添加，也可以通过本地的Git命令调用，本地的Git命令调用也可分为图形式的命令调用和shell下的命令句调用，以上无论哪种操作，都比较繁琐，这是绝对不行的。 由于通过Git命令的操作主要就是: git add . git commit -m &quot;change the images&quot; git push 这三步，所以很容易可以想到通过编写批处理文件来完成这样重复的工作。 所以我们可以创建一个名字为auto.bat的文件放到本地仓库的根目录下，里面的内容就是： git add . git commit -m &quot;change the images&quot; git push 经过测试发现，如果能把命令行的显示尽量隐藏掉就好了，于是可以在开头加上一个@echo off关闭命令的回显，然而毕竟Git提交是将本地数据提交到远端，需要有一个过程，同时也应该有一个结果提示，所以基本上不可避免的还是会弹出显示上传结果的shell界面，如： 然而，其工作一旦完成，便自动退出，也算可以接受的吧。 以后把要上传的图片放进该文件夹下，然后双击auto.bat文件就可以啦！ 而在第4步下，发现直接通过右键获取图片链接地址，得到的并不是图片的绝对链接地址，不是很准确，直接拿来引用的话不行，我们还需要对路径进行进一步的处理才可以。 如：这张图片，如果直接复制的话，我们将得到的路径为:https://github.com/smilelight/images/blob/master/lightsmile.png(通过右击链接)或者https://github.com/smilelight/images/blob/master/lightsmile.png?raw=true(通过右击图片)，而其实际路径可以为：https://github.com/smilelight/images/raw/master/lightsmile.png或者https://raw.githubusercontent.com/smilelight/images/master/lightsmile.png或者https://github.com/smilelight/images/blob/master/lightsmile.png?raw=true。因此我们具体要做的工作也很简单，就是原本得到的路径转化为有效的绝对路径，我这里采取的策略是将其转化为第一种有效路径，即如果路径带有?raw=true，我就把它去掉，然后通过字符串替换，将blob替换为raw。工作是知道怎么做，可是到底怎么具体实现呢？写一个桌面小程序？之前查看知乎上有人就自己写了插件，我想我也可以试一试啊！说做就做，于是就上网寻找关于编写chormium拓展插件的博客教程和视频资源，经过一系列的尝试和探索之后，终于完成了功能简洁、有时还会报错的小插件。。。 如图： 这是在测试右键菜单的小插件的基础上编写的，名字懒得改了，反正也是自己用着玩的。它的功能是在GitHub网站下右击链接或图片，可以复制该图片的有效地址到剪贴板中，同时在浏览器的右下角或者左下角弹出notification(通知)如下： 经过测试发现确实是可以工作的，并且在不是GitHub下的网站下，右键是不会弹出这个菜单项的。关于我的具体的插件编写工作请参考我的另外一篇博文。","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"https://www.iamlightsmile.com/tags/markdown/"},{"name":"浏览器插件","slug":"浏览器插件","permalink":"https://www.iamlightsmile.com/tags/%E6%B5%8F%E8%A7%88%E5%99%A8%E6%8F%92%E4%BB%B6/"},{"name":"github","slug":"github","permalink":"https://www.iamlightsmile.com/tags/github/"}]},{"title":"哲学小记","slug":"哲学小记","date":"2017-12-24T14:05:25.000Z","updated":"2020-01-31T13:58:11.703Z","comments":true,"path":"articles/哲学小记/","link":"","permalink":"https://www.iamlightsmile.com/articles/%E5%93%B2%E5%AD%A6%E5%B0%8F%E8%AE%B0/","excerpt":"&emsp;&emsp;人类社会永恒不变的主题便是生存与发展，如何能够更好的生存和发展，成为人类文明最强大、最根本的进步驱动力。 &emsp;&emsp;我们生活的世界是一个具体的现实的世界，它是非常复杂的，而人类智慧虽然发展迅速，但仍只能通过思维理解一些明显的客观规律，这里的理解也是相对于我们的思维逻辑而言的，世界的真正规律可能并不是这个样子，只是恰好被描述的比较准确罢了。 &emsp;&emsp;我们观察任何事物都是站在某个角度或某些角度上的，不能够全面透彻具体的了解某个事物，我们的逻辑便是不完全逻辑。而全面的又是困难的，有时也是没有必要的。","text":"&emsp;&emsp;人类社会永恒不变的主题便是生存与发展，如何能够更好的生存和发展，成为人类文明最强大、最根本的进步驱动力。 &emsp;&emsp;我们生活的世界是一个具体的现实的世界，它是非常复杂的，而人类智慧虽然发展迅速，但仍只能通过思维理解一些明显的客观规律，这里的理解也是相对于我们的思维逻辑而言的，世界的真正规律可能并不是这个样子，只是恰好被描述的比较准确罢了。 &emsp;&emsp;我们观察任何事物都是站在某个角度或某些角度上的，不能够全面透彻具体的了解某个事物，我们的逻辑便是不完全逻辑。而全面的又是困难的，有时也是没有必要的。 &emsp;&emsp;我们之所以会在某一认知系统中去定义一些事物，是因为它的属性不同于该认知系统中的其他事物，我们需要标记以加以区分，从此该标记就指代某个或一类事物，这种标记是人为规定的。 &emsp;&emsp;定义的标准和来源或来自于与系统中某些已定义事物的相同之处，抑或不同之处，符合某种映射规律，抑或简单的无逻辑映射。在复杂事物有机整体的定义上，也是自简单的无逻辑映射构建出复杂的有逻辑映射。有无逻辑是指事物之间是否存在某些定性的或者定量的关系，而这关系的确立也是建立在定义和观察之上的。 &emsp;&emsp;唯有建立在定义的基础上，方能进行逻辑活动，推演出某种事物内部或者事物与事物之间的某种定量的或者定性的属性或关系，即“规律”，也可以理解为具体的“道”，在此基础上，我们去适应和遵守甚至利用这种规律为我们所服务。 &emsp;&emsp;从某种程度上讲，我们认识任何事物的根本目的都是“为我所用”，为了解决某种问题，为了达到某种目的。 &emsp;&emsp;定义的基础和关键就在于抽象，抽象是目前为止我们人类认识世界的最强大的工具。 何为抽象？ 抽象，即特征提取并加以泛化的过程。 &emsp;&emsp;用自己的话说，就是我们在看待事物和考虑问题时，把重点只放在事物的相关属性上，而不去关注那些无关概念上，实现问题的由复杂到简单、由现象到本质的转化和事物的从特殊到一般的概念延伸和规律拓展，由此所得到的认识和规律适用于一系列的具有这样的本质的共性的事物，而不依赖于他们相互分别的非本质的个性。 &emsp;&emsp;抽象的意义在于它通过某些角度剥离出事物在某一问题或领域中的关键属性并屏蔽掉其他的不相关的或者相对不重要的属性，降低该事物在该问题域中的复杂程度，使得人们能够关注于事物的关键点从而实现问题聚焦的事物对象的简化工作，从而便于问题的解决。 &emsp;&emsp;许多事情能够抽象为数学问题，是因为存在某个具体的定义的量化标准，而那些过于复杂的，只能通过观察和试验来解决，只能做定性的抽象，抽象的具体了便是各具体科学，抽象的抽象了便是哲学。从这个角度而言，哲学可以描述数学，而数学无法描述哲学。 定义与抽象的关系 定性的抽象的尽头是哲学 定量的抽象的尽头是数学","categories":[{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://www.iamlightsmile.com/tags/%E5%93%B2%E5%AD%A6/"},{"name":"抽象","slug":"抽象","permalink":"https://www.iamlightsmile.com/tags/%E6%8A%BD%E8%B1%A1/"}]},{"title":"lua解析","slug":"lua解析","date":"2017-12-22T02:12:05.000Z","updated":"2020-01-18T11:56:52.713Z","comments":true,"path":"articles/lua解析/","link":"","permalink":"https://www.iamlightsmile.com/articles/lua%E8%A7%A3%E6%9E%90/","excerpt":"本lua版本为5.2.1 在lua的源码中，lua.c 实现了可执行的解释器，用于解释执行.out文件，luac.c 实现了字节码的编译器，用于将.lua文件编译为.out文件，即字节码文件。更加宏观的东西，则在打印的两份文档里，此处不详述，由于整个读入解析到解释执行的过程是先从读入.lua文件开始的，所以我这份lua源码解析大业便先从这luac.c文件的阅读学习开始了，以下是它的main程序源代码。","text":"本lua版本为5.2.1 在lua的源码中，lua.c 实现了可执行的解释器，用于解释执行.out文件，luac.c 实现了字节码的编译器，用于将.lua文件编译为.out文件，即字节码文件。更加宏观的东西，则在打印的两份文档里，此处不详述，由于整个读入解析到解释执行的过程是先从读入.lua文件开始的，所以我这份lua源码解析大业便先从这luac.c文件的阅读学习开始了，以下是它的main程序源代码。 int main(int argc, char* argv[]) { lua_State* L; int i=doargs(argc,argv); argc-=i; argv+=i; if (argc&lt;=0) usage(&quot;no input files given&quot;); L=luaL_newstate(); if (L==NULL) fatal(&quot;cannot create state: not enough memory&quot;); lua_pushcfunction(L,&amp;pmain); lua_pushinteger(L,argc); lua_pushlightuserdata(L,argv); if (lua_pcall(L,2,0,0)!=LUA_OK) fatal(lua_tostring(L,-1)); lua_close(L); return EXIT_SUCCESS; } tip1：在C语言中，函数内部的局部变量需要在开头定义首先先定义了一个代表lua虚拟机的数据结构lua_State，然后执行参数解析工作，即调用doargs函数，并将命令行参数传了进去以下是其源代码。 #define IS(s) (strcmp(argv[i],s)==0) static int doargs(int argc, char* argv[]) { int i; int version=0; if (argv[0]!=NULL &amp;&amp; *argv[0]!=0) progname=argv[0]; for (i=1; i&lt;argc; i++) { if (*argv[i]!=&#39;-&#39;) /* end of options; keep it */ break; else if (IS(&quot;--&quot;)) /* end of options; skip it */ { ++i; if (version) ++version; break; } else if (IS(&quot;-&quot;)) /* end of options; use stdin */ break; else if (IS(&quot;-l&quot;)) /* list */ ++listing; else if (IS(&quot;-o&quot;)) /* output file */ { output=argv[++i]; if (output==NULL || *output==0 || (*output==&#39;-&#39; &amp;&amp; output[1]!=0)) usage(&quot;&#39;-o&#39; needs argument&quot;); if (IS(&quot;-&quot;)) output=NULL; } else if (IS(&quot;-p&quot;)) /* parse only */ dumping=0; else if (IS(&quot;-s&quot;)) /* strip debug information */ stripping=1; else if (IS(&quot;-v&quot;)) /* show version */ ++version; else /* unknown option */ usage(argv[i]); } if (i==argc &amp;&amp; (listing || !dumping)) { dumping=0; argv[--i]=Output; } if (version) { printf(&quot;%s\\n&quot;,LUA_COPYRIGHT); if (version==argc-1) exit(EXIT_SUCCESS); } return i; } 在说明doargs函数之前，先列出在luac.c文件中前面的局部变量： #define PROGNAME &quot;luac&quot; /* default program name */ #define OUTPUT PROGNAME &quot;.out&quot; /* default output file */ static int listing=0; /* list bytecodes? */ static int dumping=1; /* dump bytecodes? */ static int stripping=0; /* strip debug information? */ static char Output[]={ OUTPUT }; /* default output file name */ static const char* output=Output; /* actual output file name */ static const char* progname=PROGNAME; /* actual program name */ 未完待续……","categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"lua","slug":"lua","permalink":"https://www.iamlightsmile.com/tags/lua/"}]}],"categories":[{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"},{"name":"知识图谱","slug":"知识图谱","permalink":"https://www.iamlightsmile.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"name":"Linux","slug":"Linux","permalink":"https://www.iamlightsmile.com/categories/Linux/"},{"name":"深度学习","slug":"深度学习","permalink":"https://www.iamlightsmile.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/categories/NLP/"},{"name":"其他","slug":"其他","permalink":"https://www.iamlightsmile.com/categories/%E5%85%B6%E4%BB%96/"},{"name":"随念","slug":"随念","permalink":"https://www.iamlightsmile.com/categories/%E9%9A%8F%E5%BF%B5/"},{"name":"Python","slug":"Python","permalink":"https://www.iamlightsmile.com/categories/Python/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://www.iamlightsmile.com/tags/docker/"},{"name":"知识库","slug":"知识库","permalink":"https://www.iamlightsmile.com/tags/%E7%9F%A5%E8%AF%86%E5%BA%93/"},{"name":"Neo4j","slug":"Neo4j","permalink":"https://www.iamlightsmile.com/tags/Neo4j/"},{"name":"Docker","slug":"Docker","permalink":"https://www.iamlightsmile.com/tags/Docker/"},{"name":"vscode","slug":"vscode","permalink":"https://www.iamlightsmile.com/tags/vscode/"},{"name":"centos","slug":"centos","permalink":"https://www.iamlightsmile.com/tags/centos/"},{"name":"Linux","slug":"Linux","permalink":"https://www.iamlightsmile.com/tags/Linux/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://www.iamlightsmile.com/tags/Elasticsearch/"},{"name":"深度学习","slug":"深度学习","permalink":"https://www.iamlightsmile.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"机器学习","slug":"机器学习","permalink":"https://www.iamlightsmile.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"mongodb","slug":"mongodb","permalink":"https://www.iamlightsmile.com/tags/mongodb/"},{"name":"ssh","slug":"ssh","permalink":"https://www.iamlightsmile.com/tags/ssh/"},{"name":"NLP","slug":"NLP","permalink":"https://www.iamlightsmile.com/tags/NLP/"},{"name":"damedane","slug":"damedane","permalink":"https://www.iamlightsmile.com/tags/damedane/"},{"name":"GNN","slug":"GNN","permalink":"https://www.iamlightsmile.com/tags/GNN/"},{"name":"杂谈","slug":"杂谈","permalink":"https://www.iamlightsmile.com/tags/%E6%9D%82%E8%B0%88/"},{"name":"nginx","slug":"nginx","permalink":"https://www.iamlightsmile.com/tags/nginx/"},{"name":"科学上网","slug":"科学上网","permalink":"https://www.iamlightsmile.com/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"},{"name":"VMware","slug":"VMware","permalink":"https://www.iamlightsmile.com/tags/VMware/"},{"name":"计算机","slug":"计算机","permalink":"https://www.iamlightsmile.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"},{"name":"frp","slug":"frp","permalink":"https://www.iamlightsmile.com/tags/frp/"},{"name":"内网穿透","slug":"内网穿透","permalink":"https://www.iamlightsmile.com/tags/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"},{"name":"SSL","slug":"SSL","permalink":"https://www.iamlightsmile.com/tags/SSL/"},{"name":"Python","slug":"Python","permalink":"https://www.iamlightsmile.com/tags/Python/"},{"name":"算法","slug":"算法","permalink":"https://www.iamlightsmile.com/tags/%E7%AE%97%E6%B3%95/"},{"name":"随念","slug":"随念","permalink":"https://www.iamlightsmile.com/tags/%E9%9A%8F%E5%BF%B5/"},{"name":"工程思想","slug":"工程思想","permalink":"https://www.iamlightsmile.com/tags/%E5%B7%A5%E7%A8%8B%E6%80%9D%E6%83%B3/"},{"name":"知识图谱","slug":"知识图谱","permalink":"https://www.iamlightsmile.com/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"name":"新词发现","slug":"新词发现","permalink":"https://www.iamlightsmile.com/tags/%E6%96%B0%E8%AF%8D%E5%8F%91%E7%8E%B0/"},{"name":"国士无双","slug":"国士无双","permalink":"https://www.iamlightsmile.com/tags/%E5%9B%BD%E5%A3%AB%E6%97%A0%E5%8F%8C/"},{"name":"blog","slug":"blog","permalink":"https://www.iamlightsmile.com/tags/blog/"},{"name":"light系列库","slug":"light系列库","permalink":"https://www.iamlightsmile.com/tags/light%E7%B3%BB%E5%88%97%E5%BA%93/"},{"name":"CentOS","slug":"CentOS","permalink":"https://www.iamlightsmile.com/tags/CentOS/"},{"name":"小窍门","slug":"小窍门","permalink":"https://www.iamlightsmile.com/tags/%E5%B0%8F%E7%AA%8D%E9%97%A8/"},{"name":"颈椎病","slug":"颈椎病","permalink":"https://www.iamlightsmile.com/tags/%E9%A2%88%E6%A4%8E%E7%97%85/"},{"name":"ReadtheDocs","slug":"ReadtheDocs","permalink":"https://www.iamlightsmile.com/tags/ReadtheDocs/"},{"name":"开发工具","slug":"开发工具","permalink":"https://www.iamlightsmile.com/tags/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"},{"name":"Windows","slug":"Windows","permalink":"https://www.iamlightsmile.com/tags/Windows/"},{"name":"Github","slug":"Github","permalink":"https://www.iamlightsmile.com/tags/Github/"},{"name":"个人","slug":"个人","permalink":"https://www.iamlightsmile.com/tags/%E4%B8%AA%E4%BA%BA/"},{"name":"数学","slug":"数学","permalink":"https://www.iamlightsmile.com/tags/%E6%95%B0%E5%AD%A6/"},{"name":"哲学","slug":"哲学","permalink":"https://www.iamlightsmile.com/tags/%E5%93%B2%E5%AD%A6/"},{"name":"抽象","slug":"抽象","permalink":"https://www.iamlightsmile.com/tags/%E6%8A%BD%E8%B1%A1/"},{"name":"Hexo","slug":"Hexo","permalink":"https://www.iamlightsmile.com/tags/Hexo/"},{"name":"Manjaro","slug":"Manjaro","permalink":"https://www.iamlightsmile.com/tags/Manjaro/"},{"name":"Pytorch","slug":"Pytorch","permalink":"https://www.iamlightsmile.com/tags/Pytorch/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"https://www.iamlightsmile.com/tags/Tensorflow/"},{"name":"hexo","slug":"hexo","permalink":"https://www.iamlightsmile.com/tags/hexo/"},{"name":"统计学","slug":"统计学","permalink":"https://www.iamlightsmile.com/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6/"},{"name":"ltp","slug":"ltp","permalink":"https://www.iamlightsmile.com/tags/ltp/"},{"name":"爬虫","slug":"爬虫","permalink":"https://www.iamlightsmile.com/tags/%E7%88%AC%E8%99%AB/"},{"name":"Scrapy","slug":"Scrapy","permalink":"https://www.iamlightsmile.com/tags/Scrapy/"},{"name":"微信小程序","slug":"微信小程序","permalink":"https://www.iamlightsmile.com/tags/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F/"},{"name":"编程语言","slug":"编程语言","permalink":"https://www.iamlightsmile.com/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"},{"name":"浏览器插件","slug":"浏览器插件","permalink":"https://www.iamlightsmile.com/tags/%E6%B5%8F%E8%A7%88%E5%99%A8%E6%8F%92%E4%BB%B6/"},{"name":"markdown","slug":"markdown","permalink":"https://www.iamlightsmile.com/tags/markdown/"},{"name":"github","slug":"github","permalink":"https://www.iamlightsmile.com/tags/github/"},{"name":"lua","slug":"lua","permalink":"https://www.iamlightsmile.com/tags/lua/"}]}